{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "94470f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… All imports loaded\n"
     ]
    }
   ],
   "source": [
    "# ====================\n",
    "# CELL 1: IMPORTS & SETUP\n",
    "# ====================\n",
    "\n",
    "# Standard library\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Optional, TypedDict, Any\n",
    "from datetime import datetime\n",
    "from enum import Enum\n",
    "import glob\n",
    "import sys\n",
    "import getpass\n",
    "import sqlite3\n",
    "\n",
    "# Third-party\n",
    "import assemblyai as aai\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# LangGraph\n",
    "from langgraph.graph import StateGraph\n",
    "\n",
    "# Anthropic\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "\n",
    "# Database\n",
    "from database.db_operations import db\n",
    "from database.models import (\n",
    "    Conversation, ConversationCreate\n",
    ")\n",
    "\n",
    "# Cell import in my code not in the anthropic console list\n",
    "\n",
    "print(\"âœ… All imports loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb001904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AssemblyAI API Key loaded: âœ…\n",
      "Key starts with: 972365f41d...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Add project root to Python path\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv(project_root / '.env')\n",
    "\n",
    "# Test API key\n",
    "assemblyai_key = os.getenv('ASSEMBLYAI_API_KEY')\n",
    "print(f\"AssemblyAI API Key loaded: {'âœ…' if assemblyai_key else 'âŒ'}\")\n",
    "print(f\"Key starts with: {assemblyai_key[:10] if assemblyai_key else 'None'}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42981215",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "_set_env(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "944e386b",
   "metadata": {},
   "outputs": [],
   "source": [
    "_set_env(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"ai_content_ops\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc1fee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Tables in app.db:\n",
      "\n",
      "ðŸ”§ conversations:\n",
      "   - id (INTEGER)\n",
      "   - title (TEXT)\n",
      "   - raw_text (TEXT)\n",
      "   - source (TEXT)\n",
      "   - word_count (INTEGER)\n",
      "   - created_at (DATETIME)\n",
      "   - status (TEXT)\n",
      "\n",
      "ðŸ”§ sqlite_sequence:\n",
      "   - name ()\n",
      "   - seq ()\n",
      "\n",
      "ðŸ”§ blog_post_ideas:\n",
      "   - id (INTEGER)\n",
      "   - conversation_id (INTEGER)\n",
      "   - title (TEXT)\n",
      "   - description (TEXT)\n",
      "   - usefulness_potential (INTEGER)\n",
      "   - fitwith_seo_strategy (INTEGER)\n",
      "   - fitwith_content_strategy (INTEGER)\n",
      "   - inspiration_potential (INTEGER)\n",
      "   - collaboration_potential (INTEGER)\n",
      "   - innovation (INTEGER)\n",
      "   - difficulty (INTEGER)\n",
      "   - total_score (INTEGER)\n",
      "   - sent_to_prod (BOOLEAN)\n",
      "   - raw_llm_response (TEXT)\n",
      "   - created_at (DATETIME)\n",
      "\n",
      "ðŸ”§ processing_status:\n",
      "   - id (INTEGER)\n",
      "   - conversation_id (INTEGER)\n",
      "   - stage (TEXT)\n",
      "   - status (TEXT)\n",
      "   - error_message (TEXT)\n",
      "   - started_at (DATETIME)\n",
      "   - completed_at (DATETIME)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "conn = sqlite3.connect(\"data/app.db\")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Get all table names\n",
    "cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "tables = cursor.fetchall()\n",
    "\n",
    "print(\"ðŸ“Š Tables in app.db:\")\n",
    "for table in tables:\n",
    "    table_name = table[0]\n",
    "    \n",
    "    # Get column info for each table\n",
    "    cursor.execute(f\"PRAGMA table_info({table_name})\")\n",
    "    columns = cursor.fetchall()\n",
    "    \n",
    "    print(f\"\\nðŸ”§ {table_name}:\")\n",
    "    for col in columns:\n",
    "        print(f\"   - {col[1]} ({col[2]})\")  # column_name (type)\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30147df",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. Pydantic Model for Structured Output\n",
    "\n",
    "\n",
    "\n",
    "class SpeakerRole(str, Enum):\n",
    "    \"\"\"Possible speaker roles in the conversation\"\"\"\n",
    "    CLIENT = \"client\"\n",
    "    INTERVIEWER = \"interviewer\"\n",
    "\n",
    "class Speaker(BaseModel):\n",
    "    \"\"\"Information about a person speaking in the conversation\"\"\"\n",
    "    name: Optional[str] = Field(default=None, description=\"Name of the speaker if mentioned\")\n",
    "    role: Optional[SpeakerRole] = Field(default=None, description=\"Role of the speaker in the conversation\")\n",
    "    company: Optional[str] = Field(default=None, description=\"Company they work for if mentioned\")\n",
    "\n",
    "class Challenge(BaseModel):\n",
    "    \"\"\"A challenge or problem mentioned in the conversation\"\"\"\n",
    "    description: Optional[str] = Field(default=None, description=\"Description of the challenge\")\n",
    "    impact: Optional[str] = Field(default=None, description=\"How this challenge affects them\")\n",
    "    urgency: Optional[str] = Field(default=None, description=\"Low, Medium, or High urgency\")\n",
    "\n",
    "class CurrentSolution(BaseModel):\n",
    "    \"\"\"How they currently solve their problems\"\"\"\n",
    "    solution: Optional[str] = Field(default=None, description=\"What they're currently doing\")\n",
    "    satisfaction_level: Optional[str] = Field(default=None, description=\"How satisfied they are: Very Satisfied, Satisfied, Neutral, Unsatisfied, Very Unsatisfied\")\n",
    "    limitations: Optional[List[str]] = Field(default=[], description=\"Limitations of current solution\")\n",
    "\n",
    "class Need(BaseModel):\n",
    "    \"\"\"A need identified using psychology frameworks like NVC\"\"\"\n",
    "    need_category: Optional[str] = Field(default=None, description=\"Category of need (e.g., autonomy, efficiency, security, connection)\")\n",
    "    description: Optional[str] = Field(default=None, description=\"Specific need description\")\n",
    "    intensity: Optional[str] = Field(default=None, description=\"Low, Medium, or High intensity\")\n",
    "\n",
    "class ExtractedInsights(BaseModel):\n",
    "    \"\"\"Complete structured output from conversation analysis\"\"\"\n",
    "    \n",
    "    # Speakers\n",
    "    speakers: Optional[List[Speaker]] = Field(default=[], description=\"People identified in the conversation\")\n",
    "    \n",
    "    # What they care about\n",
    "    core_values: Optional[List[str]] = Field(default=[], description=\"What this person/company cares about most\")\n",
    "    priorities: Optional[List[str]] = Field(default=[], description=\"Their current priorities and focus areas\")\n",
    "    \n",
    "    # Challenges\n",
    "    primary_challenges: Optional[List[Challenge]] = Field(default=[], description=\"Main problems they're facing\")\n",
    "    secondary_challenges: Optional[List[Challenge]] = Field(default=[], description=\"Secondary or related problems\")\n",
    "    \n",
    "    # Current solutions\n",
    "    current_solutions: Optional[List[CurrentSolution]] = Field(default=[], description=\"How they solve problems today\")\n",
    "    \n",
    "    # Needs analysis\n",
    "    psychological_needs: Optional[List[Need]] = Field(default=[], description=\"Underlying needs using NVC or similar frameworks\")\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89d86360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Simple RawBlogIdea model ready\n"
     ]
    }
   ],
   "source": [
    "# Cell 12: Raw Blog Idea Model (Simple)\n",
    "class RawBlogIdea(BaseModel):\n",
    "    \"\"\"Raw blog idea from creative agent\"\"\"\n",
    "    title: str\n",
    "    description: str\n",
    "    target_audience: str\n",
    "    content_angle: str\n",
    "    business_value: str\n",
    "\n",
    "print(\"âœ… Simple RawBlogIdea model ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77ecdfc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… RawBlogIdea model and validation ready\n"
     ]
    }
   ],
   "source": [
    "def validate_raw_blog_ideas(raw_ideas: List[Dict]) -> List[RawBlogIdea]:\n",
    "    \"\"\"Validate and convert raw JSON to Pydantic models\"\"\"\n",
    "    validated_ideas = []\n",
    "    \n",
    "    for idea in raw_ideas:\n",
    "        try:\n",
    "            validated_idea = RawBlogIdea(**idea)\n",
    "            validated_ideas.append(validated_idea)\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ Invalid blog idea skipped: {e}\")\n",
    "    \n",
    "    print(f\"âœ… Validated {len(validated_ideas)} out of {len(raw_ideas)} raw ideas\")\n",
    "    return validated_ideas\n",
    "\n",
    "print(\"âœ… RawBlogIdea model and validation ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19fad4ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Updated AudioPipelineState for 5-node pipeline\n"
     ]
    }
   ],
   "source": [
    "# Cell: Update AudioPipelineState for 5-Node Pipeline\n",
    "class AudioPipelineState(TypedDict):\n",
    "    # File info\n",
    "    file_path: str\n",
    "    filename: str\n",
    "    \n",
    "    # Processing results\n",
    "    transcript_text: Optional[str]\n",
    "    conversation_id: Optional[int]\n",
    "    extracted_insights: Optional[ExtractedInsights]\n",
    "    raw_blog_ideas: Optional[List[Dict]]        # From creative agent (Node 4)\n",
    "    scored_blog_ideas: Optional[List[Dict]]     # From analyst agent (Node 5) â† NEW\n",
    "    \n",
    "    \n",
    "    # Status & error handling\n",
    "    status: str\n",
    "    error: Optional[str]\n",
    "\n",
    "print(\"âœ… Updated AudioPipelineState for 5-node pipeline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bcb6358b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded company strategy (6555 chars)\n",
      "âœ… Loaded SEO strategy (1120 chars)\n",
      "âœ… Loaded content strategy (4469 chars)\n",
      "ðŸ“Š Strategy context keys: ['company_strategy', 'seo_strategy', 'content_strategy']\n",
      "ðŸ“Š Total context size: 12144 chars\n"
     ]
    }
   ],
   "source": [
    "# Cell: Updated Company Strategy Context Loader (3 Documents)\n",
    "def load_company_strategy_context():\n",
    "    \"\"\"Load company strategy, SEO strategy, and content strategy for context\"\"\"\n",
    "    \n",
    "    strategy_context = {}\n",
    "    \n",
    "    try:\n",
    "        # Load company strategy\n",
    "        company_strategy_path = \"../data/processed/company_strategy.mkd\"\n",
    "        if os.path.exists(company_strategy_path):\n",
    "            with open(company_strategy_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                strategy_context[\"company_strategy\"] = f.read()\n",
    "            print(f\"âœ… Loaded company strategy ({len(strategy_context['company_strategy'])} chars)\")\n",
    "        else:\n",
    "            strategy_context[\"company_strategy\"] = \"Company strategy document not available.\"\n",
    "            print(\"âš ï¸ Company strategy document not found\")\n",
    "        \n",
    "        # Load SEO strategy\n",
    "        seo_strategy_path = \"../data/processed/seo_strategy.mkd\"\n",
    "        if os.path.exists(seo_strategy_path):\n",
    "            with open(seo_strategy_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                strategy_context[\"seo_strategy\"] = f.read()\n",
    "            print(f\"âœ… Loaded SEO strategy ({len(strategy_context['seo_strategy'])} chars)\")\n",
    "        else:\n",
    "            strategy_context[\"seo_strategy\"] = \"SEO strategy document not available.\"\n",
    "            print(\"âš ï¸ SEO strategy document not found\")\n",
    "        \n",
    "        # Load content strategy (NEW)\n",
    "        content_strategy_path = \"../data/processed/content_strategy.mkd\"\n",
    "        if os.path.exists(content_strategy_path):\n",
    "            with open(content_strategy_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                strategy_context[\"content_strategy\"] = f.read()\n",
    "            print(f\"âœ… Loaded content strategy ({len(strategy_context['content_strategy'])} chars)\")\n",
    "        else:\n",
    "            strategy_context[\"content_strategy\"] = \"Content strategy document not available.\"\n",
    "            print(\"âš ï¸ Content strategy document not found\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error loading strategy documents: {e}\")\n",
    "        strategy_context = {\n",
    "            \"company_strategy\": \"Strategy document not available\",\n",
    "            \"seo_strategy\": \"SEO strategy document not available\", \n",
    "            \"content_strategy\": \"Content strategy document not available\"\n",
    "        }\n",
    "    \n",
    "    return strategy_context\n",
    "\n",
    "# Test loading all three documents\n",
    "strategy_context = load_company_strategy_context()\n",
    "print(f\"ðŸ“Š Strategy context keys: {list(strategy_context.keys())}\")\n",
    "print(f\"ðŸ“Š Total context size: {sum(len(v) for v in strategy_context.values() if isinstance(v, str))} chars\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1b52ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fixed creative agent function ready\n"
     ]
    }
   ],
   "source": [
    "# Cell: Fixed Creative Agent Function\n",
    "def generate_blog_ideas_from_insights(insights: ExtractedInsights, strategy_context: dict) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Fixed creative agent that handles Claude's markdown JSON response\n",
    "    \"\"\"\n",
    "    \n",
    "    creative_prompt = f\"\"\"\n",
    "    You are a creative content strategist for Big Kids Automation, a company that helps businesses implement AI and automation solutions.\n",
    "    \n",
    "    COMPANY CONTEXT:\n",
    "    {strategy_context.get('company_strategy', 'Strategy not available')[:1000]}...\n",
    "    \n",
    "    SEO STRATEGY:\n",
    "    {strategy_context.get('seo_strategy', 'SEO strategy not available')[:500]}...\n",
    "    \n",
    "    CONVERSATION INSIGHTS TO WORK FROM:\n",
    "    \n",
    "    Speakers: {[f\"{s.name} ({s.role}) from {s.company}\" for s in insights.speakers] if insights.speakers else \"Unknown speakers\"}\n",
    "    \n",
    "    Core Values: {\", \".join(insights.core_values) if insights.core_values else \"None identified\"}\n",
    "    \n",
    "    Priorities: {\", \".join(insights.priorities) if insights.priorities else \"None identified\"}\n",
    "    \n",
    "    Primary Challenges:\n",
    "    {chr(10).join([f\"- {c.description} (Impact: {c.impact}, Urgency: {c.urgency})\" for c in insights.primary_challenges]) if insights.primary_challenges else \"None identified\"}\n",
    "    \n",
    "    Current Solutions:\n",
    "    {chr(10).join([f\"- {s.solution} (Satisfaction: {s.satisfaction_level})\" for s in insights.current_solutions]) if insights.current_solutions else \"None identified\"}\n",
    "    \n",
    "    Psychological Needs:\n",
    "    {chr(10).join([f\"- {n.description} ({n.need_category}, {n.intensity} intensity)\" for n in insights.psychological_needs]) if insights.psychological_needs else \"None identified\"}\n",
    "    \n",
    "    TASK:\n",
    "    Generate 4-5 creative blog post ideas that:\n",
    "    1. Address the challenges and needs identified in this conversation\n",
    "    2. Align with Big Kids Automation's mission to help businesses with AI/automation\n",
    "    3. Provide value to potential clients facing similar challenges\n",
    "    4. Support our SEO and content marketing strategy\n",
    "    5. Are actionable and practical, not just theoretical\n",
    "    \n",
    "    For each blog post idea, provide:\n",
    "    - title: Clear, engaging title that includes relevant keywords\n",
    "    - description: 2-3 sentence description of what the post will cover\n",
    "    - target_audience: Who this post is primarily for\n",
    "    - content_angle: The unique angle or approach this post takes\n",
    "    - business_value: How this post helps our business goals\n",
    "    \n",
    "    IMPORTANT: Return ONLY the JSON array, no markdown formatting, no code blocks, no explanatory text.\n",
    "    \n",
    "    Format:\n",
    "    [\n",
    "        {{\n",
    "            \"title\": \"How AI Proposal Systems Balance Speed with Brand Differentiation\",\n",
    "            \"description\": \"A practical guide showing how modern AI-powered proposal systems solve the common problem of maintaining company uniqueness while leveraging automation. Includes real case studies and implementation steps.\",\n",
    "            \"target_audience\": \"Business development directors and proposal managers at consulting firms\",\n",
    "            \"content_angle\": \"Problem-solution with real case studies\",\n",
    "            \"business_value\": \"Attracts prospects struggling with proposal automation while maintaining differentiation\"\n",
    "        }}\n",
    "    ]\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Generate ideas using Claude\n",
    "        response = llm.invoke(creative_prompt)\n",
    "        raw_content = response.content.strip()\n",
    "        \n",
    "        print(f\"ðŸ“ Raw response length: {len(raw_content)} chars\")\n",
    "        print(f\"ðŸ“ Response starts with: {raw_content[:50]}...\")\n",
    "        \n",
    "        # Handle markdown code blocks\n",
    "        if raw_content.startswith('```'):\n",
    "            print(\"ðŸ”§ Removing markdown code blocks...\")\n",
    "            # Remove ```json and ``` wrappers\n",
    "            lines = raw_content.split('\\n')\n",
    "            # Remove first line if it's ```json or ```\n",
    "            if lines[0].startswith('```'):\n",
    "                lines = lines[1:]\n",
    "            # Remove last line if it's ```\n",
    "            if lines and lines[-1].strip() == '```':\n",
    "                lines = lines[:-1]\n",
    "            raw_content = '\\n'.join(lines).strip()\n",
    "            print(f\"ðŸ”§ Cleaned content starts with: {raw_content[:50]}...\")\n",
    "        \n",
    "        # Parse JSON response\n",
    "        blog_ideas = json.loads(raw_content)\n",
    "        \n",
    "        print(f\"âœ… Creative agent successfully parsed {len(blog_ideas)} blog ideas\")\n",
    "        return blog_ideas\n",
    "        \n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"âŒ JSON parsing error in creative agent: {e}\")\n",
    "        print(f\"ðŸ“ Cleaned content: {raw_content[:500]}...\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error in creative agent: {e}\")\n",
    "        return []\n",
    "\n",
    "print(\"âœ… Fixed creative agent function ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2a3c3251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Creative agent node (FIXED) ready\n"
     ]
    }
   ],
   "source": [
    "# Cell 13: Creative Agent Node - FIXED\n",
    "def creative_agent_node(state: AudioPipelineState) -> AudioPipelineState:\n",
    "    \"\"\"Creative agent that generates raw blog ideas as Pydantic objects\"\"\"\n",
    "    \n",
    "    try:\n",
    "        print(\"ðŸŽ¨ Starting creative blog idea generation...\")\n",
    "        \n",
    "        insights = state.get('extracted_insights')\n",
    "        if not insights:\n",
    "            return {**state, \"error\": \"No insights available\", \"status\": \"error\"}\n",
    "        \n",
    "        # Load strategy context\n",
    "        strategy_context = load_company_strategy_context()\n",
    "        \n",
    "        # Generate ideas (returns JSON)\n",
    "        raw_ideas_json = generate_blog_ideas_from_insights(insights, strategy_context)\n",
    "        \n",
    "        # Convert directly to Pydantic objects\n",
    "        raw_blog_ideas = []\n",
    "        for idea_json in raw_ideas_json:\n",
    "            try:\n",
    "                idea = RawBlogIdea(**idea_json)\n",
    "                raw_blog_ideas.append(idea)\n",
    "            except Exception as e:\n",
    "                print(f\"âš ï¸ Skipping invalid idea: {e}\")\n",
    "        \n",
    "        if raw_blog_ideas:\n",
    "            print(f\"ðŸŽ‰ Generated {len(raw_blog_ideas)} valid blog ideas\")\n",
    "            \n",
    "            # FIXED: Convert Pydantic objects back to dict for state storage\n",
    "            ideas_as_json = [idea.dict() for idea in raw_blog_ideas]\n",
    "            \n",
    "            return {\n",
    "                **state,\n",
    "                \"raw_blog_ideas\": ideas_as_json,  # Store as JSON/dict in state\n",
    "                \"status\": \"ideas_generated\"\n",
    "            }\n",
    "        else:\n",
    "            return {**state, \"error\": \"No valid ideas generated\", \"status\": \"error\"}\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Creative agent error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return {**state, \"error\": str(e), \"status\": \"error\"}\n",
    "\n",
    "print(\"âœ… Creative agent node (FIXED) ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5cabeaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… AssemblyAI connection successful\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 4: Test AssemblyAI Connection\n",
    "# Configure AssemblyAI\n",
    "aai.settings.api_key = os.getenv('ASSEMBLYAI_API_KEY')\n",
    "\n",
    "# Test with a simple transcription (we'll use a file from temp folder)\n",
    "def test_assemblyai_connection():\n",
    "    \"\"\"Test if AssemblyAI is working\"\"\"\n",
    "    try:\n",
    "        # Just test the API key is valid\n",
    "        transcriber = aai.Transcriber()\n",
    "        print(\"âœ… AssemblyAI connection successful\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ AssemblyAI connection failed: {e}\")\n",
    "        return False\n",
    "\n",
    "test_assemblyai_connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01335e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š BATCH PROCESSING INFO:\n",
      "   Files to process: 1\n",
      "   Total size: 24.4 MB\n",
      "\n",
      "ðŸ“ Files found:\n",
      "   1. blog_record_(purevitalize).wav (24.4 MB)\n",
      "\n",
      "ðŸš€ Ready to process 1 files!\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Batch File Discovery and Management\n",
    "def find_audio_files(temp_folder: Path) -> List[Path]:\n",
    "    \"\"\"Find all audio files in temp folder\"\"\"\n",
    "    audio_extensions = ['*.wav', '*.mp3', '*.m4a']\n",
    "    audio_files = []\n",
    "    \n",
    "    for ext in audio_extensions:\n",
    "        audio_files.extend(temp_folder.glob(ext))\n",
    "    \n",
    "    return sorted(audio_files)\n",
    "\n",
    "def display_batch_info(audio_files: List[Path]):\n",
    "    \"\"\"Display information about the batch of files\"\"\"\n",
    "    if not audio_files:\n",
    "        print(\"âŒ No audio files found in temp folder!\")\n",
    "        return False\n",
    "    \n",
    "    total_size_mb = sum(f.stat().st_size for f in audio_files) / (1024 * 1024)\n",
    "    \n",
    "    print(f\"ðŸ“Š BATCH PROCESSING INFO:\")\n",
    "    print(f\"   Files to process: {len(audio_files)}\")\n",
    "    print(f\"   Total size: {total_size_mb:.1f} MB\")\n",
    "    print(f\"\\nðŸ“ Files found:\")\n",
    "    \n",
    "    for i, file_path in enumerate(audio_files, 1):\n",
    "        size_mb = file_path.stat().st_size / (1024 * 1024)\n",
    "        print(f\"   {i}. {file_path.name} ({size_mb:.1f} MB)\")\n",
    "    \n",
    "    return True\n",
    "\n",
    "\n",
    "# Discover files in temp folder\n",
    "temp_folder = project_root / 'data' / 'temp'\n",
    "temp_folder.mkdir(parents=True, exist_ok=True)  # Ensure folder exists\n",
    "\n",
    "audio_files = find_audio_files(temp_folder)\n",
    "files_available = display_batch_info(audio_files)\n",
    "\n",
    "if files_available:\n",
    "    print(f\"\\nðŸš€ Ready to process {len(audio_files)} files!\")\n",
    "else:\n",
    "    print(\"\\nðŸ’¡ TIP: Add .wav files to data/temp/ folder for testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2c90af3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Batch processing function ready with full insights display\n"
     ]
    }
   ],
   "source": [
    "# Batch Processing Function (Updated with Full Insights Display)\n",
    "def process_audio_batch(audio_files: List[Path], pipeline) -> dict:\n",
    "    \"\"\"Process all audio files in batch with detailed insights display\"\"\"\n",
    "    \n",
    "    if not audio_files:\n",
    "        print(\"âŒ No files to process\")\n",
    "        return {\"processed\": [], \"failed\": [], \"total\": 0}\n",
    "    \n",
    "    print(f\"\\nðŸš€ STARTING BATCH PROCESSING - {len(audio_files)} files\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    processed_files = []\n",
    "    failed_files = []\n",
    "    results = []\n",
    "    \n",
    "    for i, file_path in enumerate(audio_files, 1):\n",
    "        print(f\"\\nðŸ“‚ Processing {i}/{len(audio_files)}: {file_path.name}\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        # Create initial state\n",
    "        initial_state = {\n",
    "            \"file_path\": str(file_path),\n",
    "            \"filename\": file_path.name,\n",
    "            \"transcript_text\": None,\n",
    "            \"conversation_id\": None,\n",
    "            \"extracted_insights\": None,  \n",
    "            \"error\": None,\n",
    "            \"status\": \"processing\"\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            # Run through pipeline\n",
    "            result = pipeline.invoke(initial_state)\n",
    "            \n",
    "            if result[\"status\"] in [\"completed\", \"insights_extracted\"]:\n",
    "                print(f\"âœ… SUCCESS: {file_path.name}\")\n",
    "                print(f\"   Conversation ID: {result['conversation_id']}\")\n",
    "                print(f\"   Transcript preview: {result['transcript_text'][:100]}...\")\n",
    "                \n",
    "                # FULL INSIGHTS DISPLAY\n",
    "                if result.get('extracted_insights'):\n",
    "                    insights = result['extracted_insights']\n",
    "                    print(f\"\\nðŸ§  === EXTRACTED INSIGHTS FOR: {file_path.name} ===\")\n",
    "                    print(\"=\" * 50)\n",
    "                    \n",
    "                    # Speakers\n",
    "                    if insights.speakers:\n",
    "                        print(\"ðŸ‘¥ SPEAKERS:\")\n",
    "                        for speaker in insights.speakers:\n",
    "                            print(f\"   â€¢ Name: {speaker.name or 'Unknown'}\")\n",
    "                            print(f\"     Role: {speaker.role or 'Unknown'}\")  \n",
    "                            print(f\"     Company: {speaker.company or 'Unknown'}\")\n",
    "                    \n",
    "                    # Core Values\n",
    "                    if insights.core_values:\n",
    "                        print(\"ðŸ’Ž CORE VALUES:\")\n",
    "                        for value in insights.core_values:\n",
    "                            print(f\"   â€¢ {value}\")\n",
    "                    \n",
    "                    # Priorities\n",
    "                    if insights.priorities:\n",
    "                        print(\"ðŸŽ¯ PRIORITIES:\")\n",
    "                        for priority in insights.priorities:\n",
    "                            print(f\"   â€¢ {priority}\")\n",
    "                    \n",
    "                    # Primary Challenges\n",
    "                    if insights.primary_challenges:\n",
    "                        print(\"ðŸ”¥ PRIMARY CHALLENGES:\")\n",
    "                        for challenge in insights.primary_challenges:\n",
    "                            print(f\"   â€¢ Challenge: {challenge.description}\")\n",
    "                            print(f\"     Impact: {challenge.impact}\")\n",
    "                            print(f\"     Urgency: {challenge.urgency}\")\n",
    "                    \n",
    "                    # Secondary Challenges\n",
    "                    if insights.secondary_challenges:\n",
    "                        print(\"âš ï¸  SECONDARY CHALLENGES:\")\n",
    "                        for challenge in insights.secondary_challenges:\n",
    "                            print(f\"   â€¢ Challenge: {challenge.description}\")\n",
    "                            print(f\"     Impact: {challenge.impact}\")\n",
    "                            print(f\"     Urgency: {challenge.urgency}\")\n",
    "                    \n",
    "                    # Current Solutions\n",
    "                    if insights.current_solutions:\n",
    "                        print(\"ðŸ”§ CURRENT SOLUTIONS:\")\n",
    "                        for solution in insights.current_solutions:\n",
    "                            print(f\"   â€¢ Solution: {solution.solution}\")\n",
    "                            print(f\"     Satisfaction: {solution.satisfaction_level}\")\n",
    "                            if solution.limitations:\n",
    "                                print(f\"     Limitations: {', '.join(solution.limitations)}\")\n",
    "                    \n",
    "                    # Psychological Needs\n",
    "                    if insights.psychological_needs:\n",
    "                        print(\"ðŸ§˜ PSYCHOLOGICAL NEEDS:\")\n",
    "                        for need in insights.psychological_needs:\n",
    "                            print(f\"   â€¢ {need.description}\")\n",
    "                            print(f\"     Category: {need.need_category}\")\n",
    "                            print(f\"     Intensity: {need.intensity}\")\n",
    "                    \n",
    "                    print(\"ðŸ§  === END INSIGHTS ===\")\n",
    "                    print(\"-\" * 50)\n",
    "                \n",
    "                processed_files.append(file_path)\n",
    "            else:\n",
    "                print(f\"âŒ FAILED: {file_path.name}\")\n",
    "                print(f\"   Status: {result.get('status', 'Unknown')}\")\n",
    "                print(f\"   Error: {result.get('error', 'Unknown error')}\")\n",
    "                failed_files.append(file_path)\n",
    "            \n",
    "            results.append(result)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ PIPELINE ERROR: {file_path.name}\")\n",
    "            print(f\"   Exception: {str(e)}\")\n",
    "            failed_files.append(file_path)\n",
    "            \n",
    "            results.append({\n",
    "                **initial_state,\n",
    "                \"error\": str(e),\n",
    "                \"status\": \"pipeline_error\"\n",
    "            })\n",
    "    \n",
    "    # Final Summary\n",
    "    print(f\"\\nðŸ“Š BATCH PROCESSING COMPLETE!\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"âœ… Successfully processed: {len(processed_files)}\")\n",
    "    print(f\"âŒ Failed: {len(failed_files)}\")\n",
    "    print(f\"ðŸ“ Total files: {len(audio_files)}\")\n",
    "    \n",
    "    if failed_files:\n",
    "        print(f\"\\nâŒ Failed files:\")\n",
    "        for failed_file in failed_files:\n",
    "            print(f\"   - {failed_file.name}\")\n",
    "    \n",
    "    return {\n",
    "        \"processed\": processed_files,\n",
    "        \"failed\": failed_files,\n",
    "        \"total\": len(audio_files),\n",
    "        \"results\": results\n",
    "    }\n",
    "\n",
    "print(\"âœ… Batch processing function ready with full insights display\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "419ae62d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… LangGraph nodes defined\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Define LangGraph Nodes\n",
    "def transcription_node(state: AudioPipelineState) -> AudioPipelineState:\n",
    "    \"\"\"Node 1: Transcribe audio file with AssemblyAI\"\"\"\n",
    "    try:\n",
    "        print(f\"ðŸŽ™ï¸ Transcribing: {state['filename']}\")\n",
    "        \n",
    "        # Configure transcriber\n",
    "        transcriber = aai.Transcriber()\n",
    "        \n",
    "        # Transcribe the file\n",
    "        transcript = transcriber.transcribe(state['file_path'])\n",
    "        \n",
    "        if transcript.status == aai.TranscriptStatus.error:\n",
    "            return {\n",
    "                **state,\n",
    "                \"error\": f\"AssemblyAI error: {transcript.error}\",\n",
    "                \"status\": \"transcription_failed\"\n",
    "            }\n",
    "        \n",
    "        return {\n",
    "            **state,\n",
    "            \"transcript_text\": transcript.text,\n",
    "            \"status\": \"transcribed\"\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            **state,\n",
    "            \"error\": f\"Transcription error: {str(e)}\",\n",
    "            \"status\": \"transcription_failed\"\n",
    "        }\n",
    "\n",
    "def database_saver_node(state: AudioPipelineState) -> AudioPipelineState:\n",
    "    \"\"\"Node 2: Save transcript to database\"\"\"\n",
    "    try:\n",
    "        print(f\"ðŸ’¾ Saving to database: {state['filename']}\")\n",
    "        \n",
    "        # Create conversation object\n",
    "        conversation = ConversationCreate(\n",
    "            title=f\"Audio: {state['filename']}\",\n",
    "            raw_text=state['transcript_text'],\n",
    "            source=\"transcribed\"\n",
    "        )\n",
    "        \n",
    "        # Save to database\n",
    "        conversation_id = db.create_conversation(conversation)\n",
    "        \n",
    "        return {\n",
    "            **state,\n",
    "            \"conversation_id\": conversation_id,\n",
    "            \"status\": \"completed\"\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            **state,\n",
    "            \"error\": f\"Database error: {str(e)}\",\n",
    "            \"status\": \"database_failed\"\n",
    "        }\n",
    "\n",
    "print(\"âœ… LangGraph nodes defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6a76e34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pain_extractor_node(state: AudioPipelineState) -> AudioPipelineState:\n",
    "    \"\"\"\n",
    "    LangGraph node: Extract structured insights from conversation transcript\n",
    "    \"\"\"\n",
    "    print(\"ðŸ§  Starting pain extraction...\")\n",
    "    \n",
    "    try:\n",
    "        # Extract insights using OpenAI structured output\n",
    "        insights = extract_insights_from_transcript(state['transcript_text'])\n",
    "        \n",
    "        if insights:\n",
    "            print(f\"âœ… Extracted insights: {len(insights.primary_challenges)} primary challenges, {len(insights.speakers)} speakers\")\n",
    "            \n",
    "            return {\n",
    "                **state,\n",
    "                \"extracted_insights\": insights,\n",
    "                \"status\": \"insights_extracted\"\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                **state,\n",
    "                \"error\": \"Failed to extract insights from transcript\",\n",
    "                \"status\": \"error\"\n",
    "            }\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Pain extraction failed: {e}\")\n",
    "        return {\n",
    "            **state,\n",
    "            \"error\": f\"Pain extraction error: {str(e)}\",\n",
    "            \"status\": \"error\"\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8c379c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… LangGraph pipeline compiled (5 nodes: transcribe â†’ save_to_db â†’ extract_insights â†’ creative_agent â†’ analyst_agent)\n"
     ]
    }
   ],
   "source": [
    "# Cell 21: Updated Pipeline Builder - Now with 5 Nodes\n",
    "def build_pipeline():\n",
    "    \"\"\"Build the complete LangGraph workflow: Audio â†’ Transcribe â†’ Save â†’ Insights â†’ Ideas â†’ Scoring\"\"\"\n",
    "    workflow = StateGraph(AudioPipelineState)\n",
    "    \n",
    "    # Add all 5 nodes\n",
    "    workflow.add_node(\"transcribe\", transcription_node)\n",
    "    workflow.add_node(\"save_to_db\", database_saver_node)  \n",
    "    workflow.add_node(\"extract_insights\", pain_extractor_node)\n",
    "    workflow.add_node(\"creative_agent\", creative_agent_node)\n",
    "    workflow.add_node(\"analyst_agent\", analyst_agent_node)  # NEW: Node 5\n",
    "    \n",
    "    # Chain them together\n",
    "    workflow.add_edge(\"transcribe\", \"save_to_db\")\n",
    "    workflow.add_edge(\"save_to_db\", \"extract_insights\")\n",
    "    workflow.add_edge(\"extract_insights\", \"creative_agent\")\n",
    "    workflow.add_edge(\"creative_agent\", \"analyst_agent\")     # NEW: Connect to analyst\n",
    "    \n",
    "    workflow.set_entry_point(\"transcribe\")\n",
    "    workflow.set_finish_point(\"analyst_agent\")              # NEW: End with analyst\n",
    "    \n",
    "    return workflow.compile()\n",
    "\n",
    "# Rebuild the pipeline with 5 nodes\n",
    "pipeline = build_pipeline()\n",
    "print(\"âœ… LangGraph pipeline compiled (5 nodes: transcribe â†’ save_to_db â†’ extract_insights â†’ creative_agent â†’ analyst_agent)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4cb00a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¯ Starting batch processing...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'pipeline' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mðŸŽ¯ Starting batch processing...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Process all files\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m batch_results = process_audio_batch(audio_files, \u001b[43mpipeline\u001b[49m)\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Display summary\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mðŸ“Š BATCH PROCESSING COMPLETE!\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'pipeline' is not defined"
     ]
    }
   ],
   "source": [
    "# Cell 9: Execute Batch Processing with Cleanup\n",
    "if files_available:\n",
    "    print(\"ðŸŽ¯ Starting batch processing...\")\n",
    "    \n",
    "    # Process all files\n",
    "    batch_results = process_audio_batch(audio_files, pipeline)\n",
    "    \n",
    "    # Display summary\n",
    "    print(f\"\\nðŸ“Š BATCH PROCESSING COMPLETE!\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"âœ… Successfully processed: {len(batch_results['processed'])}\")\n",
    "    print(f\"âŒ Failed: {len(batch_results['failed'])}\")\n",
    "    print(f\"ðŸ“ Total files: {batch_results['total']}\")\n",
    "    \n",
    "    # Show failed files\n",
    "    if batch_results['failed']:\n",
    "        print(f\"\\nâŒ Failed files:\")\n",
    "        for file_path in batch_results['failed']:\n",
    "            print(f\"   - {file_path.name}\")\n",
    "    \n",
    "    # Cleanup successfully processed files\n",
    "    if batch_results['processed']:\n",
    "        confirm = input(f\"\\nðŸ—‘ï¸ Delete {len(batch_results['processed'])} processed files? (y/N): \")\n",
    "        if confirm.lower() in ['y', 'yes']:\n",
    "            cleanup_processed_files(batch_results['processed'])\n",
    "        else:\n",
    "            print(\"ðŸ”§ Files kept in temp folder for inspection\")\n",
    "    \n",
    "    print(\"\\nðŸŽ‰ Batch processing complete!\")\n",
    "    \n",
    "else:\n",
    "    print(\"ðŸ’¡ Add audio files to data/temp/ folder and rerun this cell\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeaef0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Anthropic LLM initialized with Claude Haiku 4.5\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Setup Anthropic LLM for Insights Extraction (FIXED)\n",
    "\n",
    "\n",
    "# Initialize Anthropic with correct model name\n",
    "anthropic_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "if not anthropic_key:\n",
    "    print(\"âš ï¸  ANTHROPIC_API_KEY not found in .env file\")\n",
    "    print(\"Please add: ANTHROPIC_API_KEY=your_key_here\")\n",
    "else:\n",
    "    llm = ChatAnthropic(\n",
    "        model=\"claude-haiku-4-5\",  # â† Updated model name\n",
    "        api_key=anthropic_key,\n",
    "        temperature=0.1\n",
    "    )\n",
    "    print(\"âœ… Anthropic LLM initialized with Claude Haiku 4.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3cea20",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3. PainExtractor Node Implementation\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# System prompt\n",
    "PAIN_EXTRACTOR_SYSTEM_PROMPT = \"\"\"\n",
    "You are a UX researcher and business analyst for BigKids Automation. Your job is listening to transcripts from interviews with users and potential clients. \n",
    "\n",
    "You pay special attention to problems that users have regarding how their company is automating, using web apps and AI to save time and move towards a more ethical and sovereign tech infrastructure.\n",
    "\n",
    "You will be given the transcript of an interview with a user or potential client.\n",
    "\n",
    "Your task is to extract structured information about:\n",
    "- Who is speaking and their role\n",
    "- What this person cares about (values, priorities)\n",
    "- Their main primary and secondary challenges\n",
    "- How they are solving problems today\n",
    "- Are there AI agents that can assist them?\n",
    "- Their underlying psychological needs (using frameworks like NVC - Non-Violent Communication)\n",
    "\n",
    "Focus on automation, web apps, AI, time-saving, ethical tech, and sovereign infrastructure themes.\n",
    "\n",
    "Be thorough but concise. \n",
    "\n",
    "IMPORTANT: Only extract information that is explicitly mentioned in the transcript. \n",
    "If information is not clearly stated, leave the field empty/null rather than guessing or inferring.\n",
    "Do not hallucinate or make assumptions about missing information.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9e1c7b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Updated extract_insights_from_transcript with speaker role fix\n"
     ]
    }
   ],
   "source": [
    "# Cell: Extract Insights Function - ROLE FIXED VERSION\n",
    "def extract_insights_from_transcript(transcript: str) -> ExtractedInsights:\n",
    "    \"\"\"Extract structured insights using Anthropic Claude - ROLE FIXED VERSION\"\"\"\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    Analyze this conversation transcript and extract structured insights:\n",
    "    \n",
    "    Transcript: {transcript}\n",
    "    \n",
    "    IMPORTANT: For speaker roles, use ONLY these exact values:\n",
    "    - \"client\" for the person being interviewed/consulted (CTO, CEO, Manager, business owner, etc.)\n",
    "    - \"interviewer\" for the person asking questions or conducting the interview\n",
    "    \n",
    "    Extract the following information in JSON format:\n",
    "    - speakers: List of people mentioned with name, role (client/interviewer only), company\n",
    "    - core_values: What they care about most  \n",
    "    - priorities: Current focus areas\n",
    "    - primary_challenges: Main problems they face with description, impact, urgency\n",
    "    - secondary_challenges: Secondary problems\n",
    "    - current_solutions: How they solve problems now with satisfaction level\n",
    "    - psychological_needs: Underlying needs with category, description, intensity\n",
    "    \n",
    "    Return ONLY valid JSON in this exact structure - no markdown, no code blocks:\n",
    "    {{\n",
    "        \"speakers\": [\n",
    "            {{\"name\": \"Manuel\", \"role\": \"client\", \"company\": \"Drone flytech\"}}\n",
    "        ],\n",
    "        \"core_values\": [\"efficiency\", \"transparency\"],\n",
    "        \"priorities\": [\"improving processes\"],\n",
    "        \"primary_challenges\": [\n",
    "            {{\n",
    "                \"description\": \"Tracking payment issues\",\n",
    "                \"impact\": \"Creates confusion in processes\", \n",
    "                \"urgency\": \"High\"\n",
    "            }}\n",
    "        ],\n",
    "        \"secondary_challenges\": [\n",
    "            {{\n",
    "                \"description\": \"Secondary challenge\",\n",
    "                \"impact\": \"Secondary impact\",\n",
    "                \"urgency\": \"Medium\"\n",
    "            }}\n",
    "        ],\n",
    "        \"current_solutions\": [\n",
    "            {{\n",
    "                \"solution\": \"Current approach\",\n",
    "                \"satisfaction_level\": \"Neutral\",\n",
    "                \"limitations\": [\"limitation1\", \"limitation2\"]\n",
    "            }}\n",
    "        ],\n",
    "        \"psychological_needs\": [\n",
    "            {{\n",
    "                \"need_category\": \"security\",\n",
    "                \"description\": \"Need for confidence\",\n",
    "                \"intensity\": \"High\"\n",
    "            }}\n",
    "        ]\n",
    "    }}\n",
    "    \n",
    "    Remember: \n",
    "    - Use \"client\" for Manuel (even though he's CTO)\n",
    "    - Use \"interviewer\" for the person asking questions\n",
    "    - Use exact urgency values: \"Low\", \"Medium\", \"High\"\n",
    "    - Use exact satisfaction levels: \"Very Satisfied\", \"Satisfied\", \"Neutral\", \"Unsatisfied\", \"Very Unsatisfied\"\n",
    "    - Use exact intensity values: \"Low\", \"Medium\", \"High\"\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Use the Claude LLM you already set up\n",
    "        response = llm.invoke(prompt)\n",
    "        \n",
    "        print(f\"ðŸ“ Raw response length: {len(response.content)} chars\")\n",
    "        print(f\"ðŸ“ Response starts with: {response.content[:50]}...\")\n",
    "        \n",
    "        # Clean markdown code blocks\n",
    "        content = response.content.strip()\n",
    "        if content.startswith('```json'):\n",
    "            print(\"ðŸ”§ Removing JSON markdown blocks...\")\n",
    "            content = content.replace('```json', '').replace('```', '').strip()\n",
    "            print(f\"ðŸ”§ Cleaned content starts with: {content[:50]}...\")\n",
    "        \n",
    "        # Parse the cleaned JSON response\n",
    "        insights_data = json.loads(content)\n",
    "        \n",
    "        # Convert to Pydantic model\n",
    "        result = ExtractedInsights(**insights_data)\n",
    "        print(f\"âœ… Successfully extracted insights with correct speaker roles!\")\n",
    "        return result\n",
    "        \n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"âŒ JSON parsing error: {e}\")\n",
    "        print(f\"ðŸ“ Raw response: {response.content[:500]}...\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error in LLM call: {e}\")\n",
    "        raise\n",
    "\n",
    "print(\"âœ… Updated extract_insights_from_transcript with speaker role fix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c6a3dc7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âŒ No conversation found to test with\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell: Test Fixed Pain Extraction\n",
    "def test_pain_extraction_fix():\n",
    "    \"\"\"Test the fixed pain extraction with your transcript\"\"\"\n",
    "    \n",
    "    # Get the conversation that just failed\n",
    "    conversations = db.get_all_conversations()\n",
    "    latest_conversation = conversations[0] if conversations else None\n",
    "    \n",
    "    if latest_conversation and latest_conversation.raw_text:\n",
    "        print(\"ðŸ§ª Testing fixed pain extraction...\")\n",
    "        print(f\"ðŸ“ Using conversation: {latest_conversation.title}\")\n",
    "        \n",
    "        try:\n",
    "            # Test the fixed extraction\n",
    "            insights = extract_insights_from_transcript(latest_conversation.raw_text)\n",
    "            print(f\"âœ… Success! Extracted {len(insights.primary_challenges)} challenges\")\n",
    "            print(f\"ðŸ‘¥ Found {len(insights.speakers)} speakers\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Still failing: {e}\")\n",
    "            return False\n",
    "    else:\n",
    "        print(\"âŒ No conversation found to test with\")\n",
    "        return False\n",
    "\n",
    "# Test the fix\n",
    "test_pain_extraction_fix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3626c104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“ Found 1 audio files in temp:\n",
      "   blog_record_(purevitalize).wav (24.4 MB)\n"
     ]
    }
   ],
   "source": [
    "# Cell: Audio File Finder Function\n",
    "\n",
    "\n",
    "def find_audio_files_in_temp():\n",
    "    \"\"\"Find all audio files in temp folder\"\"\"\n",
    "    temp_folder = Path(\"../data/temp\")  # Adjust path based on notebook location\n",
    "    \n",
    "    if not temp_folder.exists():\n",
    "        print(f\"âŒ Temp folder not found: {temp_folder}\")\n",
    "        return []\n",
    "    \n",
    "    # Find audio files\n",
    "    audio_extensions = ['*.wav', '*.mp3', '*.m4a']\n",
    "    audio_files = []\n",
    "    \n",
    "    for ext in audio_extensions:\n",
    "        files = list(temp_folder.glob(ext))\n",
    "        audio_files.extend(files)\n",
    "    \n",
    "    return sorted(audio_files)\n",
    "\n",
    "# Test the function\n",
    "audio_files = find_audio_files_in_temp()\n",
    "print(f\"ðŸ“ Found {len(audio_files)} audio files in temp:\")\n",
    "for file in audio_files:\n",
    "    size_mb = file.stat().st_size / (1024 * 1024)\n",
    "    print(f\"   {file.name} ({size_mb:.1f} MB)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d3eb0478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§ª EXECUTING COMPLETE 4-NODE PIPELINE TEST...\n",
      "This will test: Audio â†’ Transcribe â†’ Save â†’ Insights â†’ Blog Ideas\n",
      "------------------------------------------------------------\n",
      "ðŸš€ TESTING COMPLETE 4-NODE PIPELINE\n",
      "============================================================\n",
      "Flow: Audio â†’ Transcribe â†’ Save to DB â†’ Extract Insights â†’ Generate Ideas\n",
      "============================================================\n",
      "ðŸ“ Found 1 audio files\n",
      "ðŸŽ¯ Testing with: blog_record_(manuelillo_cto).wav\n",
      "ðŸ“Š File size: 19758.0 KB\n",
      "\n",
      "ðŸŽ¬ STARTING COMPLETE PIPELINE EXECUTION...\n",
      "============================================================\n",
      "â³ Running pipeline.invoke()...\n",
      "ðŸŽ™ï¸ Transcribing: blog_record_(manuelillo_cto).wav\n",
      "ðŸ’¾ Saving to database: blog_record_(manuelillo_cto).wav\n",
      "ðŸ§  Starting pain extraction...\n",
      "ðŸ“ Raw response length: 2538 chars\n",
      "ðŸ“ Response starts with: ```json\n",
      "{\n",
      "    \"speakers\": [\n",
      "        {\"name\": \"Manu...\n",
      "ðŸ”§ Removing JSON markdown blocks...\n",
      "ðŸ”§ Cleaned content starts with: {\n",
      "    \"speakers\": [\n",
      "        {\"name\": \"Manuel\", \"ro...\n",
      "âœ… Successfully extracted insights with correct speaker roles!\n",
      "âœ… Extracted insights: 3 primary challenges, 1 speakers\n",
      "ðŸŽ¨ Starting creative blog idea generation...\n",
      "âœ… Loaded company strategy (6555 chars)\n",
      "âœ… Loaded SEO strategy (5566 chars)\n",
      "ðŸ“ Raw response length: 4060 chars\n",
      "ðŸ“ Response starts with: ```json\n",
      "[\n",
      "    {\n",
      "        \"title\": \"From Chaos to Cl...\n",
      "ðŸ”§ Removing markdown code blocks...\n",
      "ðŸ”§ Cleaned content starts with: [\n",
      "    {\n",
      "        \"title\": \"From Chaos to Clarity: H...\n",
      "âœ… Creative agent successfully parsed 5 blog ideas\n",
      "ðŸŽ‰ Generated 5 valid blog ideas\n",
      "\n",
      "ðŸ“Š COMPLETE PIPELINE RESULTS:\n",
      "============================================================\n",
      "ðŸŽ¯ Final Status: raw_ideas_generated\n",
      "\n",
      "ðŸ“‹ STAGE RESULTS:\n",
      "   ðŸŽ™ï¸  Transcription: âœ…\n",
      "   ðŸ’¾ Database Save: âœ…\n",
      "   ðŸ§  Insights Extraction: âœ…\n",
      "   ðŸŽ¨ Blog Ideas Generation: âœ…\n",
      "\n",
      "ðŸŽ‰ COMPLETE SUCCESS! End-to-end pipeline worked!\n",
      "======================================================================\n",
      "ðŸ“ Conversation ID: 14\n",
      "ðŸ“Š Transcript Length: 1688 characters\n",
      "ðŸ§  Extracted Insights:\n",
      "   ðŸ‘¥ Speakers: 1\n",
      "   ðŸ”¥ Primary Challenges: 3\n",
      "   ðŸ§˜ Psychological Needs: 4\n",
      "   ðŸ’Ž Core Values: 5\n",
      "\n",
      "ðŸŽ¨ Generated Blog Ideas (5):\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "ðŸ’¡ IDEA 1:\n",
      "   ðŸ“ Title: From Chaos to Clarity: How Automation Fixes Invoice Tracking Without Losing Control\n",
      "   ðŸ“„ Description: A practical guide exploring how SMEs can implement AI-powered invoice tracking systems that provide ...\n",
      "   ðŸŽ¯ Target Audience: Finance managers and business owners at SMEs struggling with manual invoice tracking and payment visibility\n",
      "   ðŸ“ˆ Business Value: Directly addresses high-urgency pain points (tracking, visibility, confidence) while positioning Big Kids as a trusted guide for financial automation\n",
      "\n",
      "ðŸ’¡ IDEA 2:\n",
      "   ðŸ“ Title: The Hidden Cost of 'Good Enough' Invoicing Software: When to Automate Instead of Tolerate\n",
      "   ðŸ“„ Description: An honest exploration of why off-the-shelf invoicing solutions often fail growing businesses, and ho...\n",
      "   ðŸŽ¯ Target Audience: Founders and finance leads at scaling SMEs currently dissatisfied with existing SaaS solutions\n",
      "   ðŸ“ˆ Business Value: Speaks directly to Manuel's MoneyOak dissatisfaction; positions custom automation as the intelligent alternative\n",
      "\n",
      "ðŸ’¡ IDEA 3:\n",
      "   ðŸ“ Title: Building Financial Transparency: How Automation Scales Your Invoicing Without Scaling Your Headaches\n",
      "   ðŸ“„ Description: A deep dive into how AI and automation handle the complexity of multi-client invoicing as businesses...\n",
      "   ðŸŽ¯ Target Audience: Operations managers and finance teams at rapidly growing service-based businesses\n",
      "   ðŸ“ˆ Business Value: Addresses urgency around managing complexity; attracts growth-stage companies before they become too large to help\n",
      "\n",
      "ðŸ’¡ IDEA 4:\n",
      "   ðŸ“ Title: Trust the System: How Transparent Automation Reduces Financial Anxiety in Growing Teams\n",
      "   ðŸ“„ Description: Explores the psychological and operational benefits of automating financial processesâ€”moving from an...\n",
      "   ðŸŽ¯ Target Audience: Business owners and finance leaders seeking to reduce operational stress and build team confidence\n",
      "   ðŸ“ˆ Business Value: Aligns with Big Kids' values (care, work smart not hard) while addressing Manuel's core psychological needs (confidence, peace of mind, trust)\n",
      "\n",
      "ðŸ’¡ IDEA 5:\n",
      "   ðŸ“ Title: Custom Invoice Automation for Service Businesses: When Off-the-Shelf Tools Aren't Enough\n",
      "   ðŸ“„ Description: A practical playbook for building custom invoicing solutions tailored to unique business models. Cov...\n",
      "   ðŸŽ¯ Target Audience: Service-based SME owners with complex or non-standard invoicing needs\n",
      "   ðŸ“ˆ Business Value: Directly supports SEO strategy around GenAI business value; generates qualified leads ready for custom automation conversations\n",
      "======================================================================\n",
      "ðŸŽ‰ COMPLETE 4-NODE PIPELINE: SUCCESS!\n",
      "âœ… System is working end-to-end!\n",
      "ðŸš€ Ready to build Node 5 (Analyst Agent)\n",
      "\n",
      "ðŸ“‹ FINAL TEST SUMMARY:\n",
      "   Test Status: SUCCESS\n",
      "   Pipeline Status: raw_ideas_generated\n",
      "   Blog Ideas Generated: 5\n"
     ]
    }
   ],
   "source": [
    "# Cell: Complete 4-Node Pipeline Test\n",
    "def test_complete_4_node_pipeline():\n",
    "    \"\"\"Test the complete pipeline: Audio â†’ Transcribe â†’ Save â†’ Insights â†’ Blog Ideas\"\"\"\n",
    "    \n",
    "    print(\"ðŸš€ TESTING COMPLETE 4-NODE PIPELINE\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Flow: Audio â†’ Transcribe â†’ Save to DB â†’ Extract Insights â†’ Generate Ideas\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Check if pipeline is built\n",
    "    if 'pipeline' not in globals():\n",
    "        print(\"âŒ Pipeline not found!\")\n",
    "        print(\"ðŸ’¡ Please run the build_pipeline() cell first\")\n",
    "        return None\n",
    "    \n",
    "    # Find audio files in temp\n",
    "    audio_files = find_audio_files_in_temp()\n",
    "    \n",
    "    if not audio_files:\n",
    "        print(\"âŒ No audio files found in data/temp/ folder\")\n",
    "        print(\"\\nðŸ’¡ SOLUTIONS:\")\n",
    "        print(\"   1. Add a .wav file manually to data/temp/\")\n",
    "        print(\"   2. Disable cleanup in file_monitor.py and upload new file\")\n",
    "        print(\"   3. Copy an existing audio file:\")\n",
    "        print(\"      cp /path/to/audio.wav data/temp/test_file.wav\")\n",
    "        return None\n",
    "    \n",
    "    # Use the first audio file\n",
    "    test_file = audio_files[0]\n",
    "    print(f\"ðŸ“ Found {len(audio_files)} audio files\")\n",
    "    print(f\"ðŸŽ¯ Testing with: {test_file.name}\")\n",
    "    print(f\"ðŸ“Š File size: {test_file.stat().st_size / 1024:.1f} KB\")\n",
    "    \n",
    "    # Create initial state for complete 4-node pipeline\n",
    "    initial_state = {\n",
    "        \"file_path\": str(test_file),\n",
    "        \"filename\": test_file.name,\n",
    "        \"transcript_text\": None,           # Will be filled by Node 1\n",
    "        \"conversation_id\": None,           # Will be filled by Node 2  \n",
    "        \"extracted_insights\": None,        # Will be filled by Node 3\n",
    "        \"raw_blog_ideas\": None,            # Will be filled by Node 4\n",
    "        \"scored_blog_ideas\": None,         # For future Node 5\n",
    "        \"saved_idea_ids\": None,            # For future Node 6\n",
    "        \"error\": None,\n",
    "        \"status\": \"processing\"\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nðŸŽ¬ STARTING COMPLETE PIPELINE EXECUTION...\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    try:\n",
    "        # Execute the complete 4-node pipeline\n",
    "        print(\"â³ Running pipeline.invoke()...\")\n",
    "        final_state = pipeline.invoke(initial_state)\n",
    "        \n",
    "        print(f\"\\nðŸ“Š COMPLETE PIPELINE RESULTS:\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # Check final status\n",
    "        final_status = final_state.get('status', 'unknown')\n",
    "        print(f\"ðŸŽ¯ Final Status: {final_status}\")\n",
    "        \n",
    "        # Check each stage\n",
    "        print(f\"\\nðŸ“‹ STAGE RESULTS:\")\n",
    "        print(f\"   ðŸŽ™ï¸  Transcription: {'âœ…' if final_state.get('transcript_text') else 'âŒ'}\")\n",
    "        print(f\"   ðŸ’¾ Database Save: {'âœ…' if final_state.get('conversation_id') else 'âŒ'}\")\n",
    "        print(f\"   ðŸ§  Insights Extraction: {'âœ…' if final_state.get('extracted_insights') else 'âŒ'}\")\n",
    "        print(f\"   ðŸŽ¨ Blog Ideas Generation: {'âœ…' if final_state.get('raw_blog_ideas') else 'âŒ'}\")\n",
    "        \n",
    "        # Show detailed results if successful\n",
    "        if final_state.get('raw_blog_ideas'):\n",
    "            ideas = final_state['raw_blog_ideas']\n",
    "            insights = final_state.get('extracted_insights')\n",
    "            \n",
    "            print(f\"\\nðŸŽ‰ COMPLETE SUCCESS! End-to-end pipeline worked!\")\n",
    "            print(\"=\" * 70)\n",
    "            print(f\"ðŸ“ Conversation ID: {final_state.get('conversation_id')}\")\n",
    "            print(f\"ðŸ“Š Transcript Length: {len(final_state.get('transcript_text', ''))} characters\")\n",
    "            \n",
    "            if insights:\n",
    "                print(f\"ðŸ§  Extracted Insights:\")\n",
    "                print(f\"   ðŸ‘¥ Speakers: {len(insights.speakers)}\")\n",
    "                print(f\"   ðŸ”¥ Primary Challenges: {len(insights.primary_challenges)}\")\n",
    "                print(f\"   ðŸ§˜ Psychological Needs: {len(insights.psychological_needs)}\")\n",
    "                print(f\"   ðŸ’Ž Core Values: {len(insights.core_values)}\")\n",
    "            \n",
    "            print(f\"\\nðŸŽ¨ Generated Blog Ideas ({len(ideas)}):\")\n",
    "            print(\"-\" * 70)\n",
    "            \n",
    "            for i, idea in enumerate(ideas, 1):\n",
    "                print(f\"\\nðŸ’¡ IDEA {i}:\")\n",
    "                # Handle both dict and Pydantic object formats\n",
    "                if hasattr(idea, 'title'):\n",
    "                    # Pydantic object\n",
    "                    print(f\"   ðŸ“ Title: {idea.title}\")\n",
    "                    print(f\"   ðŸ“„ Description: {idea.description[:100]}...\")\n",
    "                    print(f\"   ðŸŽ¯ Target Audience: {idea.target_audience}\")\n",
    "                    print(f\"   ðŸ“ˆ Business Value: {idea.business_value}\")\n",
    "                else:\n",
    "                    # Dictionary\n",
    "                    print(f\"   ðŸ“ Title: {idea.get('title', 'No title')}\")\n",
    "                    print(f\"   ðŸ“„ Description: {idea.get('description', 'No description')[:100]}...\")\n",
    "                    print(f\"   ðŸŽ¯ Target Audience: {idea.get('target_audience', 'Unknown')}\")\n",
    "                    print(f\"   ðŸ“ˆ Business Value: {idea.get('business_value', 'Unknown')}\")\n",
    "            \n",
    "            print(\"=\" * 70)\n",
    "            print(\"ðŸŽ‰ COMPLETE 4-NODE PIPELINE: SUCCESS!\")\n",
    "            print(\"âœ… System is working end-to-end!\")\n",
    "            print(\"ðŸš€ Ready to build Node 5 (Analyst Agent)\")\n",
    "            \n",
    "            return final_state\n",
    "            \n",
    "        else:\n",
    "            # Pipeline failed somewhere\n",
    "            print(f\"\\nâŒ PIPELINE INCOMPLETE\")\n",
    "            print(\"=\" * 50)\n",
    "            \n",
    "            error_msg = final_state.get('error', 'No specific error message')\n",
    "            print(f\"âŒ Error: {error_msg}\")\n",
    "            print(f\"ðŸ” Status: {final_status}\")\n",
    "            \n",
    "            # Debug info\n",
    "            print(f\"\\nðŸ” DEBUG INFO:\")\n",
    "            print(f\"   Transcript exists: {bool(final_state.get('transcript_text'))}\")\n",
    "            if final_state.get('transcript_text'):\n",
    "                print(f\"   Transcript preview: {final_state['transcript_text'][:100]}...\")\n",
    "            print(f\"   Insights exist: {bool(final_state.get('extracted_insights'))}\")\n",
    "            print(f\"   Ideas exist: {bool(final_state.get('raw_blog_ideas'))}\")\n",
    "            \n",
    "            return final_state\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nâŒ COMPLETE PIPELINE EXECUTION FAILED!\")\n",
    "        print(\"=\" * 60)\n",
    "        print(f\"ðŸ’¥ Exception: {str(e)}\")\n",
    "        \n",
    "        # Show full traceback for debugging\n",
    "        import traceback\n",
    "        print(f\"\\nðŸ” FULL ERROR TRACEBACK:\")\n",
    "        traceback.print_exc()\n",
    "        \n",
    "        print(f\"\\nðŸ’¡ DEBUGGING TIPS:\")\n",
    "        print(\"   1. Check if all 4 nodes are properly defined\")\n",
    "        print(\"   2. Verify AssemblyAI API key is working\")\n",
    "        print(\"   3. Check Anthropic API key is working\")\n",
    "        print(\"   4. Ensure audio file is not corrupted\")\n",
    "        \n",
    "        return None\n",
    "\n",
    "# Execute the complete pipeline test\n",
    "print(\"ðŸ§ª EXECUTING COMPLETE 4-NODE PIPELINE TEST...\")\n",
    "print(\"This will test: Audio â†’ Transcribe â†’ Save â†’ Insights â†’ Blog Ideas\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "complete_test_result = test_complete_4_node_pipeline()\n",
    "\n",
    "# Show final summary\n",
    "if complete_test_result:\n",
    "    print(f\"\\nðŸ“‹ FINAL TEST SUMMARY:\")\n",
    "    print(f\"   Test Status: {'SUCCESS' if complete_test_result.get('raw_blog_ideas') else 'PARTIAL/FAILED'}\")\n",
    "    print(f\"   Pipeline Status: {complete_test_result.get('status', 'unknown')}\")\n",
    "    print(f\"   Blog Ideas Generated: {len(complete_test_result.get('raw_blog_ideas', []))}\")\n",
    "else:\n",
    "    print(f\"\\nðŸ“‹ FINAL TEST SUMMARY:\")\n",
    "    print(f\"   Test Status: FAILED\")\n",
    "    print(f\"   Pipeline could not complete execution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4465cb3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded company strategy (6555 chars)\n",
      "âœ… Loaded SEO strategy (1120 chars)\n",
      "âœ… Loaded content strategy (4469 chars)\n",
      "âœ… Enhanced strategy context for scoring with 3 documents\n",
      "   Company strategy: 6555 chars\n",
      "   SEO strategy: 1120 chars\n",
      "   Content strategy: 4469 chars\n"
     ]
    }
   ],
   "source": [
    "# Cell 16: Enhanced Strategy Context for Scoring (Updated for 3 Documents)\n",
    "def prepare_strategy_context_for_scoring():\n",
    "    \"\"\"Prepare strategy context for scoring using all three strategy documents\"\"\"\n",
    "    \n",
    "    # Load all three strategy documents\n",
    "    strategy_context = load_company_strategy_context()\n",
    "    \n",
    "    # Add scoring guidelines\n",
    "    strategy_context[\"scoring_guidelines\"] = \"\"\"\n",
    "    SCORING CRITERIA (1-10 scale):\n",
    "    \n",
    "    1. usefulness_potential: How useful will this post be to readers with problems?\n",
    "    2. fitwith_seo_strategy: How well does this align with our SEO strategy and keywords?\n",
    "    3. fitwith_content_strategy: How well does this fit our content strategy and voice?\n",
    "    4. inspiration_potential: How likely is this to inspire readers to take action?\n",
    "    5. collaboration_potential: How likely is this to encourage prospects to contact us?\n",
    "    6. innovation: How unique/differentiated is this topic (10 = very unique)?\n",
    "    7. difficulty: How complex is this to write (1 = very complex, 10 = easy)?\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create summaries for LLM prompt efficiency (all three documents)\n",
    "    if strategy_context.get('company_strategy'):\n",
    "        strategy_context[\"company_strategy_summary\"] = strategy_context['company_strategy'][:800] + \"...\"\n",
    "    \n",
    "    if strategy_context.get('seo_strategy'):\n",
    "        strategy_context[\"seo_strategy_summary\"] = strategy_context['seo_strategy'][:600] + \"...\"\n",
    "    \n",
    "    if strategy_context.get('content_strategy'):  # NEW\n",
    "        strategy_context[\"content_strategy_summary\"] = strategy_context['content_strategy'][:600] + \"...\"\n",
    "    \n",
    "    print(f\"âœ… Enhanced strategy context for scoring with 3 documents\")\n",
    "    print(f\"   Company strategy: {len(strategy_context.get('company_strategy', ''))} chars\")\n",
    "    print(f\"   SEO strategy: {len(strategy_context.get('seo_strategy', ''))} chars\")\n",
    "    print(f\"   Content strategy: {len(strategy_context.get('content_strategy', ''))} chars\")\n",
    "    \n",
    "    return strategy_context\n",
    "\n",
    "# Test the enhanced context\n",
    "enhanced_context = prepare_strategy_context_for_scoring()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "32abca70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Updated LLM scoring engine with content strategy context\n"
     ]
    }
   ],
   "source": [
    "# Cell 17: Updated Scoring Engine with Content Strategy Context\n",
    "def score_blog_idea_with_llm(idea: dict, strategy_context: dict, conversation_context: str = \"\") -> dict:\n",
    "    \"\"\"Score a single blog idea using LLM with all three strategy contexts\"\"\"\n",
    "    \n",
    "    scoring_prompt = f\"\"\"\n",
    "    You are an expert content strategist for Big Kids Automation. Score this blog post idea on a 1-10 scale using our strategic context.\n",
    "    \n",
    "    COMPANY STRATEGY:\n",
    "    {strategy_context.get('company_strategy_summary', 'Not available')}\n",
    "    \n",
    "    SEO STRATEGY:\n",
    "    {strategy_context.get('seo_strategy_summary', 'Not available')}\n",
    "    \n",
    "    CONTENT STRATEGY:\n",
    "    {strategy_context.get('content_strategy_summary', 'Not available')}\n",
    "    \n",
    "    BLOG IDEA TO SCORE:\n",
    "    Title: {idea.get('title', 'No title')}\n",
    "    Description: {idea.get('description', 'No description')}\n",
    "    Target Audience: {idea.get('target_audience', 'Unknown')}\n",
    "    Business Value: {idea.get('business_value', 'Unknown')}\n",
    "    Content Angle: {idea.get('content_angle', 'Unknown')}\n",
    "    \n",
    "    CONVERSATION CONTEXT:\n",
    "    {conversation_context[:300] if conversation_context else 'No context available'}...\n",
    "    \n",
    "    SCORING INSTRUCTIONS:\n",
    "    Rate each criterion from 1-10 (10 = excellent, 1 = poor):\n",
    "    \n",
    "    1. usefulness_potential: How useful will this be to readers with real problems?\n",
    "    2. fitwith_seo_strategy: How well does this align with our SEO keywords and strategy?\n",
    "    3. fitwith_content_strategy: How well does this fit our content strategy, voice, and approach?\n",
    "    4. inspiration_potential: How likely to inspire readers to take meaningful action?\n",
    "    5. collaboration_potential: How likely to generate leads/prospects who contact us?\n",
    "    6. innovation: How unique is this topic compared to existing content?\n",
    "    7. difficulty: How complex/time-consuming will this be to write? (1=very hard, 10=easy)\n",
    "    \n",
    "    Return ONLY valid JSON with your scores and brief reasoning:\n",
    "    {{\n",
    "        \"usefulness_potential\": 8,\n",
    "        \"fitwith_seo_strategy\": 7,\n",
    "        \"fitwith_content_strategy\": 9,\n",
    "        \"inspiration_potential\": 6,\n",
    "        \"collaboration_potential\": 8,\n",
    "        \"innovation\": 7,\n",
    "        \"difficulty\": 4,\n",
    "        \"reasoning\": \"This idea scores well because it aligns with our content strategy focus on...\"\n",
    "    }}\n",
    "    \"\"\"\n",
    "    \n",
    "    # ... rest of the function stays the same\n",
    "    try:\n",
    "        response = llm.invoke(scoring_prompt)\n",
    "        \n",
    "        content = response.content.strip()\n",
    "        if content.startswith('```json'):\n",
    "            content = content.replace('```json', '').replace('```', '').strip()\n",
    "        \n",
    "        scores = json.loads(content)\n",
    "        \n",
    "        # Validate scores are in range\n",
    "        for criterion in ['usefulness_potential', 'fitwith_seo_strategy', 'fitwith_content_strategy', \n",
    "                         'inspiration_potential', 'collaboration_potential', 'innovation', 'difficulty']:\n",
    "            if criterion in scores:\n",
    "                scores[criterion] = max(1, min(10, scores[criterion]))\n",
    "        \n",
    "        # Calculate total score\n",
    "        total_score = sum([\n",
    "            scores.get('usefulness_potential', 5),\n",
    "            scores.get('fitwith_seo_strategy', 5),\n",
    "            scores.get('fitwith_content_strategy', 5),\n",
    "            scores.get('inspiration_potential', 5),\n",
    "            scores.get('collaboration_potential', 5),\n",
    "            scores.get('innovation', 5),\n",
    "            scores.get('difficulty', 5)\n",
    "        ])\n",
    "        \n",
    "        scores['total_score'] = total_score\n",
    "        return scores\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error scoring idea: {e}\")\n",
    "        return {\n",
    "            \"usefulness_potential\": 5, \"fitwith_seo_strategy\": 5, \"fitwith_content_strategy\": 5,\n",
    "            \"inspiration_potential\": 5, \"collaboration_potential\": 5, \"innovation\": 5,\n",
    "            \"difficulty\": 5, \"total_score\": 35, \"reasoning\": f\"Default scores due to error: {str(e)}\"\n",
    "        }\n",
    "\n",
    "print(\"âœ… Updated LLM scoring engine with content strategy context\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e7786fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§ª Testing three-document strategy loading...\n",
      "âœ… Loaded company strategy (6555 chars)\n",
      "âœ… Loaded SEO strategy (1120 chars)\n",
      "âœ… Loaded content strategy (4469 chars)\n",
      "âœ… Enhanced strategy context for scoring with 3 documents\n",
      "   Company strategy: 6555 chars\n",
      "   SEO strategy: 1120 chars\n",
      "   Content strategy: 4469 chars\n",
      "\n",
      "ðŸ“Š DOCUMENT SUMMARY:\n",
      "   company_strategy: âœ… Loaded (6555 chars)\n",
      "   seo_strategy: âœ… Loaded (1120 chars)\n",
      "   content_strategy: âœ… Loaded (4469 chars)\n"
     ]
    }
   ],
   "source": [
    "# Cell: Fixed Test Function (No Duplicate Loading)\n",
    "def test_three_document_loading():\n",
    "    \"\"\"Test loading all three strategy documents (optimized)\"\"\"\n",
    "    \n",
    "    print(\"ðŸ§ª Testing three-document strategy loading...\")\n",
    "    \n",
    "    # Load documents once and enhance\n",
    "    enhanced = prepare_strategy_context_for_scoring()  # This calls load_company_strategy_context() internally\n",
    "    \n",
    "    print(f\"\\nðŸ“Š DOCUMENT SUMMARY:\")\n",
    "    for doc_type in ['company_strategy', 'seo_strategy', 'content_strategy']:\n",
    "        if doc_type in enhanced:\n",
    "            length = len(enhanced[doc_type]) if enhanced[doc_type] else 0\n",
    "            status = \"âœ… Loaded\" if length > 100 else \"âš ï¸ Missing/Short\"\n",
    "            print(f\"   {doc_type}: {status} ({length} chars)\")\n",
    "    \n",
    "    return enhanced\n",
    "\n",
    "# Test with no duplicates\n",
    "test_context = test_three_document_loading()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f6b94c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Enhanced JSON cleaning for more robust scoring\n"
     ]
    }
   ],
   "source": [
    "# Cell: Enhanced JSON Cleaning for Analyst Agent\n",
    "def score_blog_idea_with_llm(idea: dict, strategy_context: dict, conversation_context: str = \"\") -> dict:\n",
    "    \"\"\"Score a single blog idea using LLM with enhanced JSON cleaning\"\"\"\n",
    "    \n",
    "    # ... existing prompt code stays the same ...\n",
    "    \n",
    "    try:\n",
    "        response = llm.invoke(scoring_prompt)\n",
    "        \n",
    "        # ENHANCED: More robust JSON cleaning\n",
    "        content = response.content.strip()\n",
    "        \n",
    "        # Remove markdown code blocks\n",
    "        if content.startswith('```json'):\n",
    "            content = content.replace('```json', '').replace('```', '').strip()\n",
    "        \n",
    "        # ENHANCED: Extract just the JSON part if there's extra content\n",
    "        try:\n",
    "            # Try to find JSON boundaries\n",
    "            json_start = content.find('{')\n",
    "            json_end = content.rfind('}') + 1\n",
    "            \n",
    "            if json_start != -1 and json_end > json_start:\n",
    "                json_content = content[json_start:json_end]\n",
    "                scores = json.loads(json_content)\n",
    "            else:\n",
    "                scores = json.loads(content)  # Fallback to original\n",
    "                \n",
    "        except json.JSONDecodeError:\n",
    "            # If still failing, try to extract just the first complete JSON object\n",
    "            import re\n",
    "            json_match = re.search(r'\\{.*?\\}', content, re.DOTALL)\n",
    "            if json_match:\n",
    "                scores = json.loads(json_match.group())\n",
    "            else:\n",
    "                raise  # Re-raise the original error\n",
    "        \n",
    "        # ... rest of validation code stays the same ...\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error scoring idea: {e}\")\n",
    "        return {\n",
    "            \"usefulness_potential\": 5, \"fitwith_seo_strategy\": 5, \"fitwith_content_strategy\": 5,\n",
    "            \"inspiration_potential\": 5, \"collaboration_potential\": 5, \"innovation\": 5,\n",
    "            \"difficulty\": 5, \"total_score\": 35, \"reasoning\": f\"Default scores due to error: {str(e)}\"\n",
    "        }\n",
    "\n",
    "print(\"âœ… Enhanced JSON cleaning for more robust scoring\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "79a1e537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Analyst agent node FIXED for Pydantic objects\n"
     ]
    }
   ],
   "source": [
    "# Cell 19: Analyst Agent Node - FIXED for Pydantic Objects\n",
    "def analyst_agent_node(state: AudioPipelineState) -> AudioPipelineState:\n",
    "    \"\"\"\n",
    "    LangGraph node that scores blog ideas using company strategy context\n",
    "    Input: state[\"raw_blog_ideas\"] \n",
    "    Output: state[\"scored_blog_ideas\"]\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        print(\"ðŸ” Starting analyst agent - scoring blog ideas...\")\n",
    "        \n",
    "        # Check current status\n",
    "        current_status = state.get('status', '')\n",
    "        print(f\"ðŸ“Š Input status: {current_status}\")\n",
    "        \n",
    "        # Check if we have raw blog ideas to score\n",
    "        raw_ideas = state.get('raw_blog_ideas')\n",
    "        if not raw_ideas:\n",
    "            return {\n",
    "                **state,\n",
    "                \"error\": \"No raw blog ideas available for scoring\",\n",
    "                \"status\": \"error\"\n",
    "            }\n",
    "        \n",
    "        print(f\"ðŸ“Š Found {len(raw_ideas)} blog ideas to score\")\n",
    "        \n",
    "        # Load strategy context for scoring\n",
    "        print(\"ðŸ“š Loading strategy context...\")\n",
    "        strategy_context = prepare_strategy_context_for_scoring()\n",
    "        \n",
    "        # Get conversation context for better scoring\n",
    "        conversation_context = state.get('transcript_text', '')\n",
    "        \n",
    "        # Score each blog idea\n",
    "        scored_ideas = []\n",
    "        for i, idea in enumerate(raw_ideas, 1):\n",
    "            # FIXED: Handle both Pydantic objects and dicts properly\n",
    "            if hasattr(idea, 'title'):\n",
    "                # It's a Pydantic object - convert to dict first\n",
    "                idea_dict = idea.dict() if hasattr(idea, 'dict') else idea.__dict__\n",
    "                title_preview = idea.title[:50]\n",
    "            else:\n",
    "                # It's already a dict\n",
    "                idea_dict = idea\n",
    "                title_preview = idea.get('title', 'No title')[:50]\n",
    "            \n",
    "            print(f\"ðŸ” Scoring idea {i}/{len(raw_ideas)}: {title_preview}...\")\n",
    "            \n",
    "            # Score the idea (now always working with dict)\n",
    "            scores = score_blog_idea_with_llm(idea_dict, strategy_context, conversation_context)\n",
    "            \n",
    "            # Combine original idea with scores\n",
    "            scored_idea = {\n",
    "                **idea_dict,  # Original idea data (now definitely a dict)\n",
    "                **scores      # Scoring data\n",
    "            }\n",
    "            \n",
    "            scored_ideas.append(scored_idea)\n",
    "            \n",
    "            print(f\"   âœ… Scored: {scores.get('total_score', 0)}/70 points\")\n",
    "        \n",
    "        # Sort by total score (highest first)\n",
    "        scored_ideas.sort(key=lambda x: x.get('total_score', 0), reverse=True)\n",
    "        \n",
    "        print(f\"\\nðŸŽ‰ Analyst agent completed scoring!\")\n",
    "        print(f\"ðŸ“Š Scored {len(scored_ideas)} ideas\")\n",
    "        \n",
    "        if scored_ideas:\n",
    "            print(f\"ðŸ† Top idea: '{scored_ideas[0].get('title', 'Unknown')[:50]}...' ({scored_ideas[0].get('total_score', 0)}/70)\")\n",
    "            print(f\"ðŸ“‰ Lowest idea: '{scored_ideas[-1].get('title', 'Unknown')[:50]}...' ({scored_ideas[-1].get('total_score', 0)}/70)\")\n",
    "        \n",
    "        return {\n",
    "            **state,\n",
    "            \"scored_blog_ideas\": scored_ideas,\n",
    "            \"status\": \"ideas_scored\"\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error in analyst agent node: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        \n",
    "        return {\n",
    "            **state,\n",
    "            \"error\": f\"Analyst agent error: {str(e)}\",\n",
    "            \"status\": \"error\"\n",
    "        }\n",
    "\n",
    "print(\"âœ… Analyst agent node FIXED for Pydantic objects\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c8dd7440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§ª EXECUTING COMPLETE 5-NODE PIPELINE TEST...\n",
      "Audio â†’ Transcribe â†’ Save â†’ Insights â†’ Ideas â†’ Scoring\n",
      "------------------------------------------------------------\n",
      "ðŸ“ Found 1 audio files\n",
      "ðŸŽ¯ Testing with: blog_record_(purevitalize).wav\n",
      "\n",
      "ðŸŽ¬ STARTING COMPLETE 5-NODE PIPELINE...\n",
      "============================================================\n",
      "ðŸŽ™ï¸ Transcribing: blog_record_(purevitalize).wav\n",
      "ðŸ’¾ Saving to database: blog_record_(purevitalize).wav\n",
      "ðŸ§  Starting pain extraction...\n",
      "ðŸ“ Raw response length: 3253 chars\n",
      "ðŸ“ Response starts with: ```json\n",
      "{\n",
      "    \"speakers\": [\n",
      "        {\n",
      "            ...\n",
      "ðŸ”§ Removing JSON markdown blocks...\n",
      "ðŸ”§ Cleaned content starts with: {\n",
      "    \"speakers\": [\n",
      "        {\n",
      "            \"name\": ...\n",
      "âœ… Successfully extracted insights with correct speaker roles!\n",
      "âœ… Extracted insights: 3 primary challenges, 1 speakers\n",
      "ðŸŽ¨ Starting creative blog idea generation...\n",
      "âœ… Loaded company strategy (6555 chars)\n",
      "âœ… Loaded SEO strategy (1120 chars)\n",
      "âœ… Loaded content strategy (4469 chars)\n",
      "ðŸ“ Raw response length: 4098 chars\n",
      "ðŸ“ Response starts with: ```json\n",
      "[\n",
      "    {\n",
      "        \"title\": \"Custom AI vs Saa...\n",
      "ðŸ”§ Removing markdown code blocks...\n",
      "ðŸ”§ Cleaned content starts with: [\n",
      "    {\n",
      "        \"title\": \"Custom AI vs SaaS for GD...\n",
      "âœ… Creative agent successfully parsed 5 blog ideas\n",
      "ðŸŽ‰ Generated 5 valid blog ideas\n",
      "âŒ Creative agent error: name 'ideas_as_json' is not defined\n",
      "ðŸ” Starting analyst agent - scoring blog ideas...\n",
      "ðŸ“Š Input status: error\n",
      "\n",
      "ðŸ“Š COMPLETE 5-NODE PIPELINE RESULTS:\n",
      "============================================================\n",
      "âœ… Final Status: error\n",
      "ðŸ“ Conversation ID: 19\n",
      "\n",
      "ðŸ“‹ STAGE RESULTS:\n",
      "   ðŸŽ™ï¸  Transcription: âœ…\n",
      "   ðŸ’¾ Database Save: âœ…\n",
      "   ðŸ§  Insights Extraction: âœ…\n",
      "   ðŸŽ¨ Blog Ideas Generation: âŒ\n",
      "   ðŸ” Blog Ideas Scoring: âŒ\n",
      "âŒ No scored blog ideas generated\n",
      "âŒ Error: No raw blog ideas available for scoring\n"
     ]
    }
   ],
   "source": [
    "# Cell 22: Test Complete 5-Node Pipeline\n",
    "def test_complete_5_node_pipeline():\n",
    "    \"\"\"Test the complete pipeline with analyst agent included\"\"\"\n",
    "    \n",
    "    print(\"ðŸ§ª EXECUTING COMPLETE 5-NODE PIPELINE TEST...\")\n",
    "    print(\"Audio â†’ Transcribe â†’ Save â†’ Insights â†’ Ideas â†’ Scoring\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    # Find audio files\n",
    "    audio_files = find_audio_files_in_temp()\n",
    "    \n",
    "    if not audio_files:\n",
    "        print(\"âŒ No audio files found in temp folder\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"ðŸ“ Found {len(audio_files)} audio files\")\n",
    "    print(f\"ðŸŽ¯ Testing with: {audio_files[0].name}\")\n",
    "    \n",
    "    # Create initial state for 5-node pipeline\n",
    "    initial_state = {\n",
    "        \"file_path\": str(audio_files[0]),\n",
    "        \"filename\": audio_files[0].name,\n",
    "        \"transcript_text\": None,\n",
    "        \"conversation_id\": None,\n",
    "        \"extracted_insights\": None,\n",
    "        \"raw_blog_ideas\": None,\n",
    "        \"scored_blog_ideas\": None,    # NEW: Will be filled by analyst\n",
    "        \"error\": None,\n",
    "        \"status\": \"processing\"\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        print(\"\\nðŸŽ¬ STARTING COMPLETE 5-NODE PIPELINE...\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # Run the complete pipeline\n",
    "        final_state = pipeline.invoke(initial_state)\n",
    "        \n",
    "        print(f\"\\nðŸ“Š COMPLETE 5-NODE PIPELINE RESULTS:\")\n",
    "        print(\"=\" * 60)\n",
    "        print(f\"âœ… Final Status: {final_state.get('status')}\")\n",
    "        print(f\"ðŸ“ Conversation ID: {final_state.get('conversation_id')}\")\n",
    "        \n",
    "        # Check all pipeline stages\n",
    "        print(f\"\\nðŸ“‹ STAGE RESULTS:\")\n",
    "        print(f\"   ðŸŽ™ï¸  Transcription: {'âœ…' if final_state.get('transcript_text') else 'âŒ'}\")\n",
    "        print(f\"   ðŸ’¾ Database Save: {'âœ…' if final_state.get('conversation_id') else 'âŒ'}\")\n",
    "        print(f\"   ðŸ§  Insights Extraction: {'âœ…' if final_state.get('extracted_insights') else 'âŒ'}\")\n",
    "        print(f\"   ðŸŽ¨ Blog Ideas Generation: {'âœ…' if final_state.get('raw_blog_ideas') else 'âŒ'}\")\n",
    "        print(f\"   ðŸ” Blog Ideas Scoring: {'âœ…' if final_state.get('scored_blog_ideas') else 'âŒ'}\")\n",
    "        \n",
    "        # Show scored results\n",
    "        if final_state.get('scored_blog_ideas'):\n",
    "            scored_ideas = final_state['scored_blog_ideas']\n",
    "            print(f\"\\nðŸŽ‰ COMPLETE SUCCESS! Generated and scored {len(scored_ideas)} blog ideas:\")\n",
    "            print(\"=\" * 80)\n",
    "            \n",
    "            for i, idea in enumerate(scored_ideas[:3], 1):  # Show top 3\n",
    "                print(f\"\\nðŸ† TOP IDEA #{i} (Score: {idea.get('total_score', 0)}/70):\")\n",
    "                print(f\"   ðŸ“ Title: {idea.get('title', 'No title')[:70]}...\")\n",
    "                print(f\"   ðŸ“Š Key Scores: Usefulness {idea.get('usefulness_potential', 0)}/10, \"\n",
    "                      f\"SEO {idea.get('fitwith_seo_strategy', 0)}/10, \"\n",
    "                      f\"Easy to Write {idea.get('difficulty', 0)}/10\")\n",
    "            \n",
    "            print(\"=\" * 80)\n",
    "            print(\"ðŸŽ‰ COMPLETE 5-NODE PIPELINE: SUCCESS!\")\n",
    "            print(\"âœ… System working end-to-end with scoring!\")\n",
    "            \n",
    "        else:\n",
    "            print(\"âŒ No scored blog ideas generated\")\n",
    "            print(f\"âŒ Error: {final_state.get('error', 'Unknown error')}\")\n",
    "        \n",
    "        return final_state\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ COMPLETE 5-NODE PIPELINE FAILED: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "# Run the complete 5-node test\n",
    "complete_5_node_result = test_complete_5_node_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b84e2942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Creative agent node RELOADED\n"
     ]
    }
   ],
   "source": [
    "# Cell: Creative Agent Node - FORCE RELOAD\n",
    "def creative_agent_node(state: AudioPipelineState) -> AudioPipelineState:\n",
    "    \"\"\"Creative agent that generates raw blog ideas\"\"\"\n",
    "    \n",
    "    try:\n",
    "        print(\"ðŸŽ¨ Starting creative blog idea generation...\")\n",
    "        \n",
    "        insights = state.get('extracted_insights')\n",
    "        if not insights:\n",
    "            return {**state, \"error\": \"No insights available\", \"status\": \"error\"}\n",
    "        \n",
    "        print(f\"ðŸ“Š Working with insights: {len(insights.primary_challenges)} challenges\")\n",
    "        \n",
    "        # Load strategy context\n",
    "        strategy_context = load_company_strategy_context()\n",
    "        \n",
    "        # Generate ideas (returns JSON list)\n",
    "        raw_ideas_json = generate_blog_ideas_from_insights(insights, strategy_context)\n",
    "        \n",
    "        if not raw_ideas_json:\n",
    "            return {**state, \"error\": \"No ideas generated\", \"status\": \"error\"}\n",
    "        \n",
    "        # Convert to Pydantic for validation\n",
    "        validated_ideas = []\n",
    "        for idea_json in raw_ideas_json:\n",
    "            try:\n",
    "                idea = RawBlogIdea(**idea_json)\n",
    "                validated_ideas.append(idea)\n",
    "            except Exception as e:\n",
    "                print(f\"âš ï¸ Skipping invalid idea: {e}\")\n",
    "        \n",
    "        if validated_ideas:\n",
    "            print(f\"ðŸŽ‰ Generated {len(validated_ideas)} valid blog ideas\")\n",
    "            \n",
    "            # Convert back to dict for state storage\n",
    "            ideas_as_dicts = [idea.dict() for idea in validated_ideas]\n",
    "            \n",
    "            return {\n",
    "                **state,\n",
    "                \"raw_blog_ideas\": ideas_as_dicts,\n",
    "                \"status\": \"ideas_generated\"\n",
    "            }\n",
    "        else:\n",
    "            return {**state, \"error\": \"No valid ideas after validation\", \"status\": \"error\"}\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Creative agent error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return {**state, \"error\": str(e), \"status\": \"error\"}\n",
    "\n",
    "print(\"âœ… Creative agent node RELOADED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "815ddcc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Pipeline rebuilt with updated creative agent\n"
     ]
    }
   ],
   "source": [
    "# Cell: Rebuild Pipeline with Updated Node\n",
    "pipeline = build_pipeline()\n",
    "print(\"âœ… Pipeline rebuilt with updated creative agent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cd735c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§ª EXECUTING COMPLETE 5-NODE PIPELINE TEST...\n",
      "Audio â†’ Transcribe â†’ Save â†’ Insights â†’ Ideas â†’ Scoring\n",
      "------------------------------------------------------------\n",
      "ðŸ“ Found 1 audio files\n",
      "ðŸŽ¯ Testing with: blog_record_(purevitalize).wav\n",
      "\n",
      "ðŸŽ¬ STARTING COMPLETE 5-NODE PIPELINE...\n",
      "============================================================\n",
      "ðŸŽ™ï¸ Transcribing: blog_record_(purevitalize).wav\n",
      "ðŸ’¾ Saving to database: blog_record_(purevitalize).wav\n",
      "ðŸ§  Starting pain extraction...\n",
      "ðŸ“ Raw response length: 3180 chars\n",
      "ðŸ“ Response starts with: ```json\n",
      "{\n",
      "    \"speakers\": [\n",
      "        {\n",
      "            ...\n",
      "ðŸ”§ Removing JSON markdown blocks...\n",
      "ðŸ”§ Cleaned content starts with: {\n",
      "    \"speakers\": [\n",
      "        {\n",
      "            \"name\": ...\n",
      "âœ… Successfully extracted insights with correct speaker roles!\n",
      "âœ… Extracted insights: 3 primary challenges, 1 speakers\n",
      "ðŸŽ¨ Starting creative blog idea generation...\n",
      "ðŸ“Š Working with insights: 3 challenges\n",
      "âœ… Loaded company strategy (6555 chars)\n",
      "âœ… Loaded SEO strategy (1120 chars)\n",
      "âœ… Loaded content strategy (4469 chars)\n",
      "ðŸ“ Raw response length: 4334 chars\n",
      "ðŸ“ Response starts with: ```json\n",
      "[\n",
      "    {\n",
      "        \"title\": \"Custom AI vs Saa...\n",
      "ðŸ”§ Removing markdown code blocks...\n",
      "ðŸ”§ Cleaned content starts with: [\n",
      "    {\n",
      "        \"title\": \"Custom AI vs SaaS for GD...\n",
      "âœ… Creative agent successfully parsed 5 blog ideas\n",
      "ðŸŽ‰ Generated 5 valid blog ideas\n",
      "ðŸ” Starting analyst agent - scoring blog ideas...\n",
      "ðŸ“Š Input status: ideas_generated\n",
      "ðŸ“Š Found 5 blog ideas to score\n",
      "ðŸ“š Loading strategy context...\n",
      "âœ… Loaded company strategy (6555 chars)\n",
      "âœ… Loaded SEO strategy (1120 chars)\n",
      "âœ… Loaded content strategy (4469 chars)\n",
      "âœ… Enhanced strategy context for scoring with 3 documents\n",
      "   Company strategy: 6555 chars\n",
      "   SEO strategy: 1120 chars\n",
      "   Content strategy: 4469 chars\n",
      "ðŸ” Scoring idea 1/5: Custom AI vs SaaS for GDPR Compliance: A European ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6204/4162762669.py:36: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  ideas_as_dicts = [idea.dict() for idea in validated_ideas]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   âœ… Scored: 45/70 points\n",
      "ðŸ” Scoring idea 2/5: The Privacy-First AI Implementation Playbook: Prot...\n",
      "   âœ… Scored: 50/70 points\n",
      "ðŸ” Scoring idea 3/5: From Email Chaos to Strategic Clarity: How to Eval...\n",
      "   âœ… Scored: 49/70 points\n",
      "ðŸ” Scoring idea 4/5: AI Implementation Risks for SMEs: A Realistic Asse...\n",
      "   âœ… Scored: 55/70 points\n",
      "ðŸ” Scoring idea 5/5: Competitive Advantage Through Smart Automation: Ho...\n",
      "   âœ… Scored: 48/70 points\n",
      "\n",
      "ðŸŽ‰ Analyst agent completed scoring!\n",
      "ðŸ“Š Scored 5 ideas\n",
      "ðŸ† Top idea: 'AI Implementation Risks for SMEs: A Realistic Asse...' (55/70)\n",
      "ðŸ“‰ Lowest idea: 'Custom AI vs SaaS for GDPR Compliance: A European ...' (45/70)\n",
      "\n",
      "ðŸ“Š COMPLETE 5-NODE PIPELINE RESULTS:\n",
      "============================================================\n",
      "âœ… Final Status: ideas_scored\n",
      "ðŸ“ Conversation ID: 20\n",
      "\n",
      "ðŸ“‹ STAGE RESULTS:\n",
      "   ðŸŽ™ï¸  Transcription: âœ…\n",
      "   ðŸ’¾ Database Save: âœ…\n",
      "   ðŸ§  Insights Extraction: âœ…\n",
      "   ðŸŽ¨ Blog Ideas Generation: âœ…\n",
      "   ðŸ” Blog Ideas Scoring: âœ…\n",
      "\n",
      "ðŸŽ‰ COMPLETE SUCCESS! Generated and scored 5 blog ideas:\n",
      "================================================================================\n",
      "\n",
      "ðŸ† TOP IDEA #1 (Score: 55/70):\n",
      "   ðŸ“ Title: AI Implementation Risks for SMEs: A Realistic Assessment (Not Hype) fo...\n",
      "   ðŸ“Š Key Scores: Usefulness 9/10, SEO 9/10, Easy to Write 5/10\n",
      "\n",
      "ðŸ† TOP IDEA #2 (Score: 50/70):\n",
      "   ðŸ“ Title: The Privacy-First AI Implementation Playbook: Protecting Data While Au...\n",
      "   ðŸ“Š Key Scores: Usefulness 8/10, SEO 8/10, Easy to Write 4/10\n",
      "\n",
      "ðŸ† TOP IDEA #3 (Score: 49/70):\n",
      "   ðŸ“ Title: From Email Chaos to Strategic Clarity: How to Evaluate AI Communicatio...\n",
      "   ðŸ“Š Key Scores: Usefulness 8/10, SEO 7/10, Easy to Write 5/10\n",
      "================================================================================\n",
      "ðŸŽ‰ COMPLETE 5-NODE PIPELINE: SUCCESS!\n",
      "âœ… System working end-to-end with scoring!\n"
     ]
    }
   ],
   "source": [
    "# Run the test again\n",
    "complete_5_node_result = test_complete_5_node_pipeline()S"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
