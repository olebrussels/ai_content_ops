{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb001904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AssemblyAI API Key loaded: ‚úÖ\n",
      "Key starts with: 972365f41d...\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Setup and Imports\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Add project root to Python path\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv(project_root / '.env')\n",
    "\n",
    "# Test API key\n",
    "assemblyai_key = os.getenv('ASSEMBLYAI_API_KEY')\n",
    "print(f\"AssemblyAI API Key loaded: {'‚úÖ' if assemblyai_key else '‚ùå'}\")\n",
    "print(f\"Key starts with: {assemblyai_key[:10] if assemblyai_key else 'None'}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cc1fee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Tables in app.db:\n",
      "\n",
      "üîß conversations:\n",
      "   - id (INTEGER)\n",
      "   - title (TEXT)\n",
      "   - raw_text (TEXT)\n",
      "   - source (TEXT)\n",
      "   - word_count (INTEGER)\n",
      "   - created_at (DATETIME)\n",
      "   - status (TEXT)\n",
      "\n",
      "üîß sqlite_sequence:\n",
      "   - name ()\n",
      "   - seq ()\n",
      "\n",
      "üîß blog_post_ideas:\n",
      "   - id (INTEGER)\n",
      "   - conversation_id (INTEGER)\n",
      "   - title (TEXT)\n",
      "   - description (TEXT)\n",
      "   - usefulness_potential (INTEGER)\n",
      "   - fitwith_seo_strategy (INTEGER)\n",
      "   - fitwith_content_strategy (INTEGER)\n",
      "   - inspiration_potential (INTEGER)\n",
      "   - collaboration_potential (INTEGER)\n",
      "   - innovation (INTEGER)\n",
      "   - difficulty (INTEGER)\n",
      "   - total_score (INTEGER)\n",
      "   - sent_to_prod (BOOLEAN)\n",
      "   - raw_llm_response (TEXT)\n",
      "   - created_at (DATETIME)\n",
      "\n",
      "üîß processing_status:\n",
      "   - id (INTEGER)\n",
      "   - conversation_id (INTEGER)\n",
      "   - stage (TEXT)\n",
      "   - status (TEXT)\n",
      "   - error_message (TEXT)\n",
      "   - started_at (DATETIME)\n",
      "   - completed_at (DATETIME)\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect(\"data/app.db\")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Get all table names\n",
    "cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "tables = cursor.fetchall()\n",
    "\n",
    "print(\"üìä Tables in app.db:\")\n",
    "for table in tables:\n",
    "    table_name = table[0]\n",
    "    \n",
    "    # Get column info for each table\n",
    "    cursor.execute(f\"PRAGMA table_info({table_name})\")\n",
    "    columns = cursor.fetchall()\n",
    "    \n",
    "    print(f\"\\nüîß {table_name}:\")\n",
    "    for col in columns:\n",
    "        print(f\"   - {col[1]} ({col[2]})\")  # column_name (type)\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30f9e880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All imports successful\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Import Dependencies\n",
    "import assemblyai as aai\n",
    "from langgraph.graph import StateGraph\n",
    "from typing import TypedDict, Optional, List  # ‚Üê Added List here\n",
    "import glob\n",
    "import time\n",
    "from pathlib import Path  # ‚Üê Also added Path here\n",
    "\n",
    "# Import our database\n",
    "from database.db_operations import db\n",
    "from database.models import ConversationCreate\n",
    "\n",
    "print(\"‚úÖ All imports successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e30147df",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. Pydantic Model for Structured Output\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Optional\n",
    "from enum import Enum\n",
    "\n",
    "class SpeakerRole(str, Enum):\n",
    "    \"\"\"Possible speaker roles in the conversation\"\"\"\n",
    "    CLIENT = \"client\"\n",
    "    INTERVIEWER = \"interviewer\"\n",
    "\n",
    "class Speaker(BaseModel):\n",
    "    \"\"\"Information about a person speaking in the conversation\"\"\"\n",
    "    name: Optional[str] = Field(default=None, description=\"Name of the speaker if mentioned\")\n",
    "    role: Optional[SpeakerRole] = Field(default=None, description=\"Role of the speaker in the conversation\")\n",
    "    company: Optional[str] = Field(default=None, description=\"Company they work for if mentioned\")\n",
    "\n",
    "class Challenge(BaseModel):\n",
    "    \"\"\"A challenge or problem mentioned in the conversation\"\"\"\n",
    "    description: Optional[str] = Field(default=None, description=\"Description of the challenge\")\n",
    "    impact: Optional[str] = Field(default=None, description=\"How this challenge affects them\")\n",
    "    urgency: Optional[str] = Field(default=None, description=\"Low, Medium, or High urgency\")\n",
    "\n",
    "class CurrentSolution(BaseModel):\n",
    "    \"\"\"How they currently solve their problems\"\"\"\n",
    "    solution: Optional[str] = Field(default=None, description=\"What they're currently doing\")\n",
    "    satisfaction_level: Optional[str] = Field(default=None, description=\"How satisfied they are: Very Satisfied, Satisfied, Neutral, Unsatisfied, Very Unsatisfied\")\n",
    "    limitations: Optional[List[str]] = Field(default=[], description=\"Limitations of current solution\")\n",
    "\n",
    "class Need(BaseModel):\n",
    "    \"\"\"A need identified using psychology frameworks like NVC\"\"\"\n",
    "    need_category: Optional[str] = Field(default=None, description=\"Category of need (e.g., autonomy, efficiency, security, connection)\")\n",
    "    description: Optional[str] = Field(default=None, description=\"Specific need description\")\n",
    "    intensity: Optional[str] = Field(default=None, description=\"Low, Medium, or High intensity\")\n",
    "\n",
    "class ExtractedInsights(BaseModel):\n",
    "    \"\"\"Complete structured output from conversation analysis\"\"\"\n",
    "    \n",
    "    # Speakers\n",
    "    speakers: Optional[List[Speaker]] = Field(default=[], description=\"People identified in the conversation\")\n",
    "    \n",
    "    # What they care about\n",
    "    core_values: Optional[List[str]] = Field(default=[], description=\"What this person/company cares about most\")\n",
    "    priorities: Optional[List[str]] = Field(default=[], description=\"Their current priorities and focus areas\")\n",
    "    \n",
    "    # Challenges\n",
    "    primary_challenges: Optional[List[Challenge]] = Field(default=[], description=\"Main problems they're facing\")\n",
    "    secondary_challenges: Optional[List[Challenge]] = Field(default=[], description=\"Secondary or related problems\")\n",
    "    \n",
    "    # Current solutions\n",
    "    current_solutions: Optional[List[CurrentSolution]] = Field(default=[], description=\"How they solve problems today\")\n",
    "    \n",
    "    # Needs analysis\n",
    "    psychological_needs: Optional[List[Need]] = Field(default=[], description=\"Underlying needs using NVC or similar frameworks\")\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19fad4ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ State defined\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Define LangGraph State\n",
    "class AudioPipelineState(TypedDict):\n",
    "    file_path: str\n",
    "    filename: str\n",
    "    transcript_text: Optional[str]\n",
    "    conversation_id: Optional[int]\n",
    "    extracted_insights: Optional[ExtractedInsights]  # ‚Üê NEW: Using our Pydantic model\n",
    "    error: Optional[str]\n",
    "    status: str\n",
    "\n",
    "print(\"‚úÖ State defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5cabeaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ AssemblyAI connection successful\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 4: Test AssemblyAI Connection\n",
    "# Configure AssemblyAI\n",
    "aai.settings.api_key = os.getenv('ASSEMBLYAI_API_KEY')\n",
    "\n",
    "# Test with a simple transcription (we'll use a file from temp folder)\n",
    "def test_assemblyai_connection():\n",
    "    \"\"\"Test if AssemblyAI is working\"\"\"\n",
    "    try:\n",
    "        # Just test the API key is valid\n",
    "        transcriber = aai.Transcriber()\n",
    "        print(\"‚úÖ AssemblyAI connection successful\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå AssemblyAI connection failed: {e}\")\n",
    "        return False\n",
    "\n",
    "test_assemblyai_connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "01335e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä BATCH PROCESSING INFO:\n",
      "   Files to process: 1\n",
      "   Total size: 24.2 MB\n",
      "\n",
      "üìÅ Files found:\n",
      "   1. blog_record (2025-10-26 11_58_14).wav (24.2 MB)\n",
      "\n",
      "üöÄ Ready to process 1 files!\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Batch File Discovery and Management\n",
    "def find_audio_files(temp_folder: Path) -> List[Path]:\n",
    "    \"\"\"Find all audio files in temp folder\"\"\"\n",
    "    audio_extensions = ['*.wav', '*.mp3', '*.m4a']\n",
    "    audio_files = []\n",
    "    \n",
    "    for ext in audio_extensions:\n",
    "        audio_files.extend(temp_folder.glob(ext))\n",
    "    \n",
    "    return sorted(audio_files)\n",
    "\n",
    "def display_batch_info(audio_files: List[Path]):\n",
    "    \"\"\"Display information about the batch of files\"\"\"\n",
    "    if not audio_files:\n",
    "        print(\"‚ùå No audio files found in temp folder!\")\n",
    "        return False\n",
    "    \n",
    "    total_size_mb = sum(f.stat().st_size for f in audio_files) / (1024 * 1024)\n",
    "    \n",
    "    print(f\"üìä BATCH PROCESSING INFO:\")\n",
    "    print(f\"   Files to process: {len(audio_files)}\")\n",
    "    print(f\"   Total size: {total_size_mb:.1f} MB\")\n",
    "    print(f\"\\nüìÅ Files found:\")\n",
    "    \n",
    "    for i, file_path in enumerate(audio_files, 1):\n",
    "        size_mb = file_path.stat().st_size / (1024 * 1024)\n",
    "        print(f\"   {i}. {file_path.name} ({size_mb:.1f} MB)\")\n",
    "    \n",
    "    return True\n",
    "\n",
    "def cleanup_processed_files(processed_files: List[Path]):\n",
    "    \"\"\"Delete all successfully processed files\"\"\"\n",
    "    print(f\"\\nüóëÔ∏è CLEANUP: Deleting {len(processed_files)} processed files...\")\n",
    "    deleted_count = 0\n",
    "    \n",
    "    for file_path in processed_files:\n",
    "        try:\n",
    "            file_path.unlink()  # Delete file\n",
    "            print(f\"   ‚úÖ Deleted: {file_path.name}\")\n",
    "            deleted_count += 1\n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå Failed to delete {file_path.name}: {e}\")\n",
    "    \n",
    "    print(f\"üóëÔ∏è Cleanup complete: {deleted_count}/{len(processed_files)} files deleted\")\n",
    "\n",
    "# Discover files in temp folder\n",
    "temp_folder = project_root / 'data' / 'temp'\n",
    "temp_folder.mkdir(parents=True, exist_ok=True)  # Ensure folder exists\n",
    "\n",
    "audio_files = find_audio_files(temp_folder)\n",
    "files_available = display_batch_info(audio_files)\n",
    "\n",
    "if files_available:\n",
    "    print(f\"\\nüöÄ Ready to process {len(audio_files)} files!\")\n",
    "else:\n",
    "    print(\"\\nüí° TIP: Add .wav files to data/temp/ folder for testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c90af3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Batch processing function ready\n"
     ]
    }
   ],
   "source": [
    "# Batch Processing Function (Updated with Full Insights Display)\n",
    "def process_audio_batch(audio_files: List[Path], pipeline) -> dict:\n",
    "    \"\"\"Process all audio files in batch with detailed insights display\"\"\"\n",
    "    \n",
    "    if not audio_files:\n",
    "        print(\"‚ùå No files to process\")\n",
    "        return {\"processed\": [], \"failed\": [], \"total\": 0}\n",
    "    \n",
    "    print(f\"\\nüöÄ STARTING BATCH PROCESSING - {len(audio_files)} files\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    processed_files = []\n",
    "    failed_files = []\n",
    "    results = []\n",
    "    \n",
    "    for i, file_path in enumerate(audio_files, 1):\n",
    "        print(f\"\\nüìÇ Processing {i}/{len(audio_files)}: {file_path.name}\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        # Create initial state\n",
    "        initial_state = {\n",
    "            \"file_path\": str(file_path),\n",
    "            \"filename\": file_path.name,\n",
    "            \"transcript_text\": None,\n",
    "            \"conversation_id\": None,\n",
    "            \"extracted_insights\": None,  \n",
    "            \"error\": None,\n",
    "            \"status\": \"processing\"\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            # Run through pipeline\n",
    "            result = pipeline.invoke(initial_state)\n",
    "            \n",
    "            if result[\"status\"] in [\"completed\", \"insights_extracted\"]:\n",
    "                print(f\"‚úÖ SUCCESS: {file_path.name}\")\n",
    "                print(f\"   Conversation ID: {result['conversation_id']}\")\n",
    "                print(f\"   Transcript preview: {result['transcript_text'][:100]}...\")\n",
    "                \n",
    "                # FULL INSIGHTS DISPLAY\n",
    "                if result.get('extracted_insights'):\n",
    "                    insights = result['extracted_insights']\n",
    "                    print(f\"\\nüß† === EXTRACTED INSIGHTS FOR: {file_path.name} ===\")\n",
    "                    print(\"=\" * 50)\n",
    "                    \n",
    "                    # Speakers\n",
    "                    if insights.speakers:\n",
    "                        print(\"üë• SPEAKERS:\")\n",
    "                        for speaker in insights.speakers:\n",
    "                            print(f\"   ‚Ä¢ Name: {speaker.name or 'Unknown'}\")\n",
    "                            print(f\"     Role: {speaker.role or 'Unknown'}\")  \n",
    "                            print(f\"     Company: {speaker.company or 'Unknown'}\")\n",
    "                    \n",
    "                    # Core Values\n",
    "                    if insights.core_values:\n",
    "                        print(\"üíé CORE VALUES:\")\n",
    "                        for value in insights.core_values:\n",
    "                            print(f\"   ‚Ä¢ {value}\")\n",
    "                    \n",
    "                    # Priorities\n",
    "                    if insights.priorities:\n",
    "                        print(\"üéØ PRIORITIES:\")\n",
    "                        for priority in insights.priorities:\n",
    "                            print(f\"   ‚Ä¢ {priority}\")\n",
    "                    \n",
    "                    # Primary Challenges\n",
    "                    if insights.primary_challenges:\n",
    "                        print(\"üî• PRIMARY CHALLENGES:\")\n",
    "                        for challenge in insights.primary_challenges:\n",
    "                            print(f\"   ‚Ä¢ Challenge: {challenge.description}\")\n",
    "                            print(f\"     Impact: {challenge.impact}\")\n",
    "                            print(f\"     Urgency: {challenge.urgency}\")\n",
    "                    \n",
    "                    # Secondary Challenges\n",
    "                    if insights.secondary_challenges:\n",
    "                        print(\"‚ö†Ô∏è  SECONDARY CHALLENGES:\")\n",
    "                        for challenge in insights.secondary_challenges:\n",
    "                            print(f\"   ‚Ä¢ Challenge: {challenge.description}\")\n",
    "                            print(f\"     Impact: {challenge.impact}\")\n",
    "                            print(f\"     Urgency: {challenge.urgency}\")\n",
    "                    \n",
    "                    # Current Solutions\n",
    "                    if insights.current_solutions:\n",
    "                        print(\"üîß CURRENT SOLUTIONS:\")\n",
    "                        for solution in insights.current_solutions:\n",
    "                            print(f\"   ‚Ä¢ Solution: {solution.solution}\")\n",
    "                            print(f\"     Satisfaction: {solution.satisfaction_level}\")\n",
    "                            if solution.limitations:\n",
    "                                print(f\"     Limitations: {', '.join(solution.limitations)}\")\n",
    "                    \n",
    "                    # Psychological Needs\n",
    "                    if insights.psychological_needs:\n",
    "                        print(\"üßò PSYCHOLOGICAL NEEDS:\")\n",
    "                        for need in insights.psychological_needs:\n",
    "                            print(f\"   ‚Ä¢ {need.description}\")\n",
    "                            print(f\"     Category: {need.need_category}\")\n",
    "                            print(f\"     Intensity: {need.intensity}\")\n",
    "                    \n",
    "                    print(\"üß† === END INSIGHTS ===\")\n",
    "                    print(\"-\" * 50)\n",
    "                \n",
    "                processed_files.append(file_path)\n",
    "            else:\n",
    "                print(f\"‚ùå FAILED: {file_path.name}\")\n",
    "                print(f\"   Status: {result.get('status', 'Unknown')}\")\n",
    "                print(f\"   Error: {result.get('error', 'Unknown error')}\")\n",
    "                failed_files.append(file_path)\n",
    "            \n",
    "            results.append(result)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå PIPELINE ERROR: {file_path.name}\")\n",
    "            print(f\"   Exception: {str(e)}\")\n",
    "            failed_files.append(file_path)\n",
    "            \n",
    "            results.append({\n",
    "                **initial_state,\n",
    "                \"error\": str(e),\n",
    "                \"status\": \"pipeline_error\"\n",
    "            })\n",
    "    \n",
    "    # Final Summary\n",
    "    print(f\"\\nüìä BATCH PROCESSING COMPLETE!\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"‚úÖ Successfully processed: {len(processed_files)}\")\n",
    "    print(f\"‚ùå Failed: {len(failed_files)}\")\n",
    "    print(f\"üìÅ Total files: {len(audio_files)}\")\n",
    "    \n",
    "    if failed_files:\n",
    "        print(f\"\\n‚ùå Failed files:\")\n",
    "        for failed_file in failed_files:\n",
    "            print(f\"   - {failed_file.name}\")\n",
    "    \n",
    "    return {\n",
    "        \"processed\": processed_files,\n",
    "        \"failed\": failed_files,\n",
    "        \"total\": len(audio_files),\n",
    "        \"results\": results\n",
    "    }\n",
    "\n",
    "print(\"‚úÖ Batch processing function ready with full insights display\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "419ae62d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ LangGraph nodes defined\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Define LangGraph Nodes\n",
    "def transcription_node(state: AudioPipelineState) -> AudioPipelineState:\n",
    "    \"\"\"Node 1: Transcribe audio file with AssemblyAI\"\"\"\n",
    "    try:\n",
    "        print(f\"üéôÔ∏è Transcribing: {state['filename']}\")\n",
    "        \n",
    "        # Configure transcriber\n",
    "        transcriber = aai.Transcriber()\n",
    "        \n",
    "        # Transcribe the file\n",
    "        transcript = transcriber.transcribe(state['file_path'])\n",
    "        \n",
    "        if transcript.status == aai.TranscriptStatus.error:\n",
    "            return {\n",
    "                **state,\n",
    "                \"error\": f\"AssemblyAI error: {transcript.error}\",\n",
    "                \"status\": \"transcription_failed\"\n",
    "            }\n",
    "        \n",
    "        return {\n",
    "            **state,\n",
    "            \"transcript_text\": transcript.text,\n",
    "            \"status\": \"transcribed\"\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            **state,\n",
    "            \"error\": f\"Transcription error: {str(e)}\",\n",
    "            \"status\": \"transcription_failed\"\n",
    "        }\n",
    "\n",
    "def database_saver_node(state: AudioPipelineState) -> AudioPipelineState:\n",
    "    \"\"\"Node 2: Save transcript to database\"\"\"\n",
    "    try:\n",
    "        print(f\"üíæ Saving to database: {state['filename']}\")\n",
    "        \n",
    "        # Create conversation object\n",
    "        conversation = ConversationCreate(\n",
    "            title=f\"Audio: {state['filename']}\",\n",
    "            raw_text=state['transcript_text'],\n",
    "            source=\"transcribed\"\n",
    "        )\n",
    "        \n",
    "        # Save to database\n",
    "        conversation_id = db.create_conversation(conversation)\n",
    "        \n",
    "        return {\n",
    "            **state,\n",
    "            \"conversation_id\": conversation_id,\n",
    "            \"status\": \"completed\"\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            **state,\n",
    "            \"error\": f\"Database error: {str(e)}\",\n",
    "            \"status\": \"database_failed\"\n",
    "        }\n",
    "\n",
    "print(\"‚úÖ LangGraph nodes defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c379c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ LangGraph pipeline compiled (3 nodes: transcribe ‚Üí save_to_db ‚Üí extract_insights)\n"
     ]
    }
   ],
   "source": [
    "# Cell: Build Current Pipeline (3 Nodes)\n",
    "def build_pipeline():\n",
    "    \"\"\"Build the current LangGraph workflow with transcription, save, and insights\"\"\"\n",
    "    workflow = StateGraph(AudioPipelineState)\n",
    "    \n",
    "    # Add current nodes\n",
    "    workflow.add_node(\"transcribe\", transcription_node)\n",
    "    workflow.add_node(\"save_to_db\", database_saver_node)  \n",
    "    workflow.add_node(\"extract_insights\", pain_extractor_node)\n",
    "    \n",
    "    # Chain them together\n",
    "    workflow.add_edge(\"transcribe\", \"save_to_db\")\n",
    "    workflow.add_edge(\"save_to_db\", \"extract_insights\")\n",
    "    \n",
    "    workflow.set_entry_point(\"transcribe\")\n",
    "    workflow.set_finish_point(\"extract_insights\")\n",
    "    \n",
    "    return workflow.compile()\n",
    "\n",
    "# Build the pipeline\n",
    "pipeline = build_pipeline()\n",
    "print(\"‚úÖ LangGraph pipeline compiled (3 nodes: transcribe ‚Üí save_to_db ‚Üí extract_insights)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "47a45a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Found 4 conversations to delete:\n",
      "  - ID 8: Audio: blog_record (2025-10-26 11_58_14).wav\n",
      "  - ID 7: Audio: blog_record (2025-10-26 11_58_14).wav\n",
      "  - ID 6: Audio: blog_record (2025-10-26 11_58_14).wav\n",
      "  - ID 5: Audio: blog_record (2025-10-26 11_58_14).wav\n",
      "‚úÖ All conversations deleted!\n",
      "‚úÖ Related blog ideas deleted!\n",
      "‚úÖ Processing status cleared!\n"
     ]
    }
   ],
   "source": [
    "# Cell: Clean Conversations Table\n",
    "def clean_conversations_table():\n",
    "    \"\"\"Delete all records from conversations table\"\"\"\n",
    "    \n",
    "    # First show what will be deleted\n",
    "    conversations = db.get_all_conversations()\n",
    "    print(f\"üìä Found {len(conversations)} conversations to delete:\")\n",
    "    for conv in conversations[:5]:  # Show first 5\n",
    "        print(f\"  - ID {conv.id}: {conv.title}\")\n",
    "    if len(conversations) > 5:\n",
    "        print(f\"  ... and {len(conversations) - 5} more\")\n",
    "    \n",
    "    # Ask for confirmation\n",
    "    response = input(f\"\\n‚ùì Delete all {len(conversations)} conversations? (y/N): \")\n",
    "    \n",
    "    if response.lower() in ['y', 'yes']:\n",
    "        conn = db.get_connection()\n",
    "        try:\n",
    "            cursor = conn.cursor()\n",
    "            \n",
    "            # Delete all conversations (this will also delete related blog_post_ideas due to foreign key)\n",
    "            cursor.execute(\"DELETE FROM blog_post_ideas\")\n",
    "            cursor.execute(\"DELETE FROM processing_status\") \n",
    "            cursor.execute(\"DELETE FROM conversations\")\n",
    "            conn.commit()\n",
    "            \n",
    "            print(\"‚úÖ All conversations deleted!\")\n",
    "            print(\"‚úÖ Related blog ideas deleted!\")\n",
    "            print(\"‚úÖ Processing status cleared!\")\n",
    "            \n",
    "        finally:\n",
    "            conn.close()\n",
    "    else:\n",
    "        print(\"‚ùå Deletion cancelled\")\n",
    "\n",
    "# Run the cleaner\n",
    "clean_conversations_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4cb00a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Starting batch processing...\n",
      "\n",
      "üöÄ STARTING BATCH PROCESSING - 1 files\n",
      "============================================================\n",
      "\n",
      "üìÇ Processing 1/1: blog_record (2025-10-26 11_58_14).wav\n",
      "----------------------------------------\n",
      "üéôÔ∏è Transcribing: blog_record (2025-10-26 11_58_14).wav\n",
      "üíæ Saving to database: blog_record (2025-10-26 11_58_14).wav\n",
      "üß† Starting pain extraction...\n",
      "‚úÖ Extracted insights: 1 primary challenges, 1 speakers\n",
      "‚úÖ SUCCESS: blog_record (2025-10-26 11_58_14).wav\n",
      "   Conversation ID: 8\n",
      "   Transcript preview: My name is Hugo and I am the CTO of Drone flytech. At Drone flightek, one of our primary challenges ...\n",
      "   üß† Insights extracted: 1 challenges found\n",
      "   üíé Core values: efficiency, transparency...\n",
      "\n",
      "üìä BATCH PROCESSING COMPLETE!\n",
      "============================================================\n",
      "‚úÖ Successfully processed: 1\n",
      "‚ùå Failed: 0\n",
      "üìÅ Total files: 1\n",
      "üîß Files kept in temp folder for inspection\n",
      "\n",
      "üéâ Batch processing complete!\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: Execute Batch Processing with Cleanup\n",
    "if files_available:\n",
    "    print(\"üéØ Starting batch processing...\")\n",
    "    \n",
    "    # Process all files\n",
    "    batch_results = process_audio_batch(audio_files, pipeline)\n",
    "    \n",
    "    # Display summary\n",
    "    print(f\"\\nüìä BATCH PROCESSING COMPLETE!\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"‚úÖ Successfully processed: {len(batch_results['processed'])}\")\n",
    "    print(f\"‚ùå Failed: {len(batch_results['failed'])}\")\n",
    "    print(f\"üìÅ Total files: {batch_results['total']}\")\n",
    "    \n",
    "    # Show failed files\n",
    "    if batch_results['failed']:\n",
    "        print(f\"\\n‚ùå Failed files:\")\n",
    "        for file_path in batch_results['failed']:\n",
    "            print(f\"   - {file_path.name}\")\n",
    "    \n",
    "    # Cleanup successfully processed files\n",
    "    if batch_results['processed']:\n",
    "        confirm = input(f\"\\nüóëÔ∏è Delete {len(batch_results['processed'])} processed files? (y/N): \")\n",
    "        if confirm.lower() in ['y', 'yes']:\n",
    "            cleanup_processed_files(batch_results['processed'])\n",
    "        else:\n",
    "            print(\"üîß Files kept in temp folder for inspection\")\n",
    "    \n",
    "    print(\"\\nüéâ Batch processing complete!\")\n",
    "    \n",
    "else:\n",
    "    print(\"üí° Add audio files to data/temp/ folder and rerun this cell\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eeaef0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Anthropic LLM initialized with Claude 3.5 Sonnet\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Setup Anthropic LLM for Insights Extraction (FIXED)\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "import json\n",
    "\n",
    "# Initialize Anthropic with correct model name\n",
    "anthropic_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "if not anthropic_key:\n",
    "    print(\"‚ö†Ô∏è  ANTHROPIC_API_KEY not found in .env file\")\n",
    "    print(\"Please add: ANTHROPIC_API_KEY=your_key_here\")\n",
    "else:\n",
    "    llm = ChatAnthropic(\n",
    "        model=\"claude-3-5-sonnet-20241022\",  # ‚Üê Updated model name\n",
    "        api_key=anthropic_key,\n",
    "        temperature=0.1\n",
    "    )\n",
    "    print(\"‚úÖ Anthropic LLM initialized with Claude 3.5 Sonnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b3cea20",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3. PainExtractor Node Implementation\n",
    "\n",
    "\n",
    "import openai\n",
    "import json\n",
    "from typing import Dict, Any\n",
    "\n",
    "# System prompt\n",
    "PAIN_EXTRACTOR_SYSTEM_PROMPT = \"\"\"\n",
    "You are a UX researcher and business analyst for BigKids Automation. Your job is listening to transcripts from interviews with users and potential clients. \n",
    "\n",
    "You pay special attention to problems that users have regarding how their company is automating, using web apps and AI to save time and move towards a more ethical and sovereign tech infrastructure.\n",
    "\n",
    "You will be given the transcript of an interview with a user or potential client.\n",
    "\n",
    "Your task is to extract structured information about:\n",
    "- Who is speaking and their role\n",
    "- What this person cares about (values, priorities)\n",
    "- Their main primary and secondary challenges\n",
    "- How they are solving problems today\n",
    "- Are there AI agents that can assist them?\n",
    "- Their underlying psychological needs (using frameworks like NVC - Non-Violent Communication)\n",
    "\n",
    "Focus on automation, web apps, AI, time-saving, ethical tech, and sovereign infrastructure themes.\n",
    "\n",
    "Be thorough but concise. \n",
    "\n",
    "IMPORTANT: Only extract information that is explicitly mentioned in the transcript. \n",
    "If information is not clearly stated, leave the field empty/null rather than guessing or inferring.\n",
    "Do not hallucinate or make assumptions about missing information.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "819a4829",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_insights_from_transcript(transcript: str) -> ExtractedInsights:\n",
    "    \"\"\"Extract structured insights using Anthropic Claude with proper JSON structure\"\"\"\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    Analyze this conversation transcript and extract structured insights in the exact JSON format below:\n",
    "\n",
    "    Transcript: {transcript}\n",
    "\n",
    "    Return ONLY valid JSON in this exact structure:\n",
    "    {{\n",
    "        \"speakers\": [\n",
    "            {{\n",
    "                \"name\": \"Hugo\",\n",
    "                \"role\": \"client\", \n",
    "                \"company\": \"Drone flytech\"\n",
    "            }}\n",
    "        ],\n",
    "        \"core_values\": [\"efficiency\", \"transparency\"],\n",
    "        \"priorities\": [\"improving financial processes\"],\n",
    "        \"primary_challenges\": [\n",
    "            {{\n",
    "                \"description\": \"Tracking who paid which invoice\",\n",
    "                \"impact\": \"Creates confusion in financial processes\",\n",
    "                \"urgency\": \"High\"\n",
    "            }}\n",
    "        ],\n",
    "        \"secondary_challenges\": [],\n",
    "        \"current_solutions\": [\n",
    "            {{\n",
    "                \"solution\": \"Using MoneyOak software\",\n",
    "                \"satisfaction_level\": \"Unsatisfied\", \n",
    "                \"limitations\": [\"inadequate functionality\", \"limited visibility\"]\n",
    "            }}\n",
    "        ],\n",
    "        \"psychological_needs\": [\n",
    "            {{\n",
    "                \"need_category\": \"security\",\n",
    "                \"description\": \"Confidence in financial operations\",\n",
    "                \"intensity\": \"High\"\n",
    "            }}\n",
    "        ]\n",
    "    }}\n",
    "\n",
    "    Important: \n",
    "    - Return ONLY the JSON, no other text\n",
    "    - Use exact field names as shown\n",
    "    - For urgency use: \"Low\", \"Medium\", or \"High\"\n",
    "    - For satisfaction_level use: \"Very Satisfied\", \"Satisfied\", \"Neutral\", \"Unsatisfied\", \"Very Unsatisfied\"\n",
    "    - For intensity use: \"Low\", \"Medium\", or \"High\"\n",
    "    - For speaker role use: \"client\" or \"interviewer\"\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Use the Claude LLM\n",
    "        response = llm.invoke(prompt)\n",
    "        \n",
    "        # Parse the JSON response\n",
    "        insights_data = json.loads(response.content)\n",
    "        \n",
    "        # Convert to Pydantic model\n",
    "        return ExtractedInsights(**insights_data)\n",
    "        \n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"‚ùå JSON parsing error: {e}\")\n",
    "        print(f\"üìù Raw response: {response.content[:500]}...\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error in LLM call: {e}\")\n",
    "        raise\n",
    "def pain_extractor_node(state: AudioPipelineState) -> AudioPipelineState:\n",
    "    \"\"\"\n",
    "    LangGraph node: Extract structured insights from conversation transcript\n",
    "    \"\"\"\n",
    "    print(\"üß† Starting pain extraction...\")\n",
    "    \n",
    "    try:\n",
    "        # Extract insights using OpenAI structured output\n",
    "        insights = extract_insights_from_transcript(state['transcript_text'])\n",
    "        \n",
    "        if insights:\n",
    "            print(f\"‚úÖ Extracted insights: {len(insights.primary_challenges)} primary challenges, {len(insights.speakers)} speakers\")\n",
    "            \n",
    "            return {\n",
    "                **state,\n",
    "                \"extracted_insights\": insights,\n",
    "                \"status\": \"insights_extracted\"\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                **state,\n",
    "                \"error\": \"Failed to extract insights from transcript\",\n",
    "                \"status\": \"error\"\n",
    "            }\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Pain extraction failed: {e}\")\n",
    "        return {\n",
    "            **state,\n",
    "            \"error\": f\"Pain extraction error: {str(e)}\",\n",
    "            \"status\": \"error\"\n",
    "        }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "205a8b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† Starting pain extraction...\n",
      "‚úÖ Extracted insights: 1 primary challenges, 1 speakers\n",
      "üéØ Extracted Insights:\n",
      "Speakers: ['John']\n",
      "Primary challenges: 1\n"
     ]
    }
   ],
   "source": [
    "## 4. Usage in Jupyter Notebook\n",
    "\n",
    "\n",
    "# Cell: Test Pain Extractor Node\n",
    "from openai import OpenAI\n",
    "\n",
    "# Initialize OpenAI client\n",
    "client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))\n",
    "\n",
    "# Test with sample transcript\n",
    "test_state = {\n",
    "    \"file_path\": \"data/temp/test.wav\",\n",
    "    \"filename\": \"test.wav\",\n",
    "    \"transcript_text\": \"Hi, I'm John from TechCorp. We're struggling with our manual processes. We spend hours every day on data entry and it's killing our productivity. We've tried some automation tools but they don't integrate well with our existing systems. What we really need is something that respects our data sovereignty and doesn't lock us into big tech platforms.\",\n",
    "    \"conversation_id\": 1,\n",
    "    \"extracted_insights\": None,\n",
    "    \"blog_ideas\": None,\n",
    "    \"error\": None,\n",
    "    \"status\": \"transcribed\"\n",
    "}\n",
    "\n",
    "# Run the pain extractor node\n",
    "result_state = pain_extractor_node(test_state)\n",
    "\n",
    "# Display results\n",
    "if result_state.get('extracted_insights'):\n",
    "    insights = result_state['extracted_insights']\n",
    "    print(\"üéØ Extracted Insights:\")\n",
    "    print(f\"Speakers: {[s.name for s in insights.speakers]}\")\n",
    "    print(f\"Primary challenges: {len(insights.primary_challenges)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d6e1ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Testing extract_insights_from_transcript...\n",
      "üìù Sample transcript: \n",
      "    my name is olivier masset from elia. \n",
      "\n",
      "my goal here in elia is to help my team to adopt a minds...\n",
      "‚úÖ Function executed successfully!\n",
      "\n",
      "üìä Extracted Insights:\n",
      "Speakers found: 1\n",
      "Primary challenges: 2\n",
      "Core values: ['continuous improvement', 'collaboration', 'innovation', 'well-being', 'human connection']\n",
      "\n",
      "üî• First challenge:\n",
      "   Description: Lack of top-down support and buy-in from management for continuous improvement initiatives.\n",
      "   Impact: Difficulty in achieving high scaling and full integration of continuous improvement practices.\n",
      "   Urgency: High\n"
     ]
    }
   ],
   "source": [
    "# Cell 8A: Test extract_insights_from_transcript function\n",
    "def test_extract_insights_standalone():\n",
    "    \"\"\"Test the insight extraction function with sample transcript\"\"\"\n",
    "    \n",
    "    # Sample transcript for testing\n",
    "    sample_transcript = \"\"\"\n",
    "    my name is olivier masset. i work at Lean and Agile Department from Elia (company). \n",
    "\n",
    "my goal here in elia is to help my team to adopt a mindset of continuous improvement. whatever the techniques. it does not matter if it's lean agile or something else they just come into the office and we have a chat about what they would like to improve. we analyse the \"as is\" situation why they would like to apply lean or agile techniques or whatever, what they want to do and we support them in the journey to get there. \n",
    "##do you work with teams? \n",
    "half of my job is IT teams, half is business teams. for the IT has been a top down approach. for the other is a success story approach. they can see that it works in other teams and they come to us to do ask to do the same. \n",
    "\n",
    "\n",
    "\n",
    "<img src=\"IMG_20190509_165555.jpg\" width=\"400\" height=\"400\" />\n",
    "__Lean and Agile office supports elia teams in their cultural change towards a continuous improvement mindset.__ Introducing, implementing, sustaining. \n",
    "a)awareness: communication, training and networking withing Eila\n",
    "b)new initiatives\n",
    "c)support: coaching & training , try to raise their maturity, regular follow up for example on the rituals, obeya room,logistic around that\n",
    "d)innovation new concepts, and techniques to try ex: if i read a new book (reinventing orgs) i try to implement it here. we try to be on top of the cultural change project. there is a program called \"make a difference\" we can have a sort of top down apporach. they have an impact in all the company. so is good we are together with them. when we create a workshop to provide feedback we support them with workshop design. if they like a technique they call us again for help on other meeting. \n",
    "f) networking outside elia\n",
    "-events training: journee agile. other companies. meetups \n",
    "-suppliers\n",
    "-companies\n",
    "\n",
    "that is how we are doing the transition here. little by little. step by step. based on word of mouth. t\n",
    "\n",
    "##team management\n",
    "my boss is sparring partner. we do try to brainstorm together.  i have my own coach. stephan levaque.he is coming here 1 o 2 times a month. help me with mentoring. help me unblock some issues. sometimes we cocreate workshops together.i have also 2 other coaches. one in schaarbeek to help the team there and another one 100 of the time but only since 1 month. we coach around 300 people. 150 in IT and about the same in the business. for us we need 1 coach for 30 people who start and 1 coach for \n",
    "100 people on sustain mode not a new initiative they have been doing this for a while and you help them to go further. i used to be a alone for 300 people. i started 3 years ago. i started in 2017 and the lean project started in 2016. they did the begining of the journey with 2 external coaches from cap gemini.i am employee of elia now. \n",
    "\n",
    "##main difficulties\n",
    "first one on top of everything, because we dont have a top down approach. you can have high scaling with the top down. some companies havea fulltop down approach. here is something you have to rise from th bottom. for me bottom up support is more important but you also need support from the top.   i miss somtimes some buy in from the management.the are convince is useful for the team but they say is for the team and not for us. you dont have \"the lead by example\" here. to help them to understand that this is very valuable for them this is my main challenge. help them to understand, if htey take the time to do it they will earn a lot behind, it will be worth it. this is a very big challenge. that is why I go to a lot of meetups where i can meet people like me. \n",
    "i feel alone. also pain. that is why i have an exernal coach. i want to discuss with someone. i need som eiother ideas that we hear on the books . release time for continuous improvement. to be a coach you need tthem to want to be coached. if you have as i to be. coach . help them to find the solution in  them. to do so you need them to come up i need to change something. get somt out of you confort zone. and thaat is difficult that they find this time. sometimes the come for the bad reason. they hear what others have done. we are not able to cut the work. the main issue is to release some real time to achieve their coaching objecitves. they are not able to manage the priorities. they don't allocate real time. they put it as something that their people need to do on top or their work. this creates risk of burnout. i think agile is good for that.\n",
    "version one report agile. what is the main value for you. as a result. the first one is always. a better ability to manage the priorities. do a choice between priorities. we are not always good at that. we want everyhing. they understood that and they started to release sometime.s this is problably the main difficulty i have. i prefer to have 3 people 100% agile or lean than 10 people 10%of their time.\n",
    "\n",
    "##final impact i want to have \n",
    "innovation mindset here at the end what i really try to do is to bring a bit of wellbeing for people. a bit better in their work everyday. ia m happy to be here. i am a bit better than yesterday. atmosphere of collab is improving. initiative spirit is here. you can do mistakes. you are not affraid to come to work. you like to come to work. that is why i want to work with the cultural change team as well. \n",
    "this diagram i like \n",
    "\n",
    "\n",
    "if you tell them you need to start to use a new tool, is feasible, they dont like it at the beginning but they have to . there is no choice. for example: use microsoft word.\n",
    "\n",
    "if you have in the agile manifesto people over tools and processes. mindset, is the less visible but the most powerful. when you hire someone, they focus on the hard skills. and not the soft skills. but the soft skills is one of the most important if you want to work in a team. as a painter you may do better work alone. here is about team . you need the righ tmindset. \n",
    "\n",
    "\n",
    "agile radar. how menaced do they feel. here they are quite confident: the company is going well. lots of companies started agile in a crisis. previsible vs exploratoire. innovation vs efficiency. better to be in an innovation mindset that to have always efficiency. \n",
    "\n",
    "it is a challenge becasue the context is not the best to to that. they don't want to go there. want to stay safe, we wont be predictble anymore. and this is a difficult. \n",
    "\n",
    "check and see how they are doing they are not so good at that.this is the reality here. \n",
    "\n",
    "lot of trouble with waiting time. lot of trouble with non utilized talent. using people to do thing they should not. \n",
    "\n",
    "##human aspect in the work environment\n",
    "the most important part . i am more interested by people than the content of their job. behaviour and mindset is my job. the good thing is they want to do it. they put it all over the walls. more collab. more feedback. one voice. they want to go there\n",
    "but most of the time in the wall is where you want to go but is what you don't have. some times this is what you see in the walls of the companies. this allow them to do it. some others feels dangerous and the prefer not to go there. you can do it if you want\n",
    "le croyance limitantes. there are a lot of those here. release them from their limitation of the mind. for me is amazing. sometimes i am doin ga very hard planning. at the end is one conversation at the coffee corner will have higher impact. we need time for that. we as coaches we need to live that style. take time and not always to focus on the operational goal. go to events. take time like talking to you. we need to keep that mind opening. all the success stories . in front of the stage. put it under the spot light. good behaviour. good team spirit. tell stories in our comm  tooo. i have a blog in the intranet. display screens. also simply i offer individual coaching. one on one. it has to come from them. +make a different project. for example one voice behaviour. fist feedbac. 2 one voice. you take decision as a team. once you tak decision you are all behind. team spirit approach. to do so we provide them some tools. check in check out. speech ball. everyone can share and is included in the conversation. ice breakers. getting to know eachother in the team. bring more humanity brings more empathy helping eachoter. i try to do a self assesment. ask them to evaluate themslelves in 100 questions. do you have time? is the cmm good? is electicity in the aair? gentle dissagreement. they have to take a decission as a team about that. if people \n",
    "have fun and others don't they ask during the self assessment workshope i invite them to express why in a group setting. and sometimes there are debates. and somethimes is the first time they share this info in a team. and this brings empathy collab. and at they end \n",
    "they wills start to have more fun. soft skills, start to help eachother and havea little more interest in the job of the other. values in common. i love one icebreaker who combine with energizer. the best thing that happen in their life in the last 5 days. with this one you can use it each week and repeat. at the end , with that ...last week i went with vacation with my kid. ah you have a kid. now environment. i am a fan of sunst dev. you are agile coach at the end with thos little exercises you have impact because they find things in common. this little things are sometimes more important than the big report.\n",
    "\n",
    "is more about connecting to the people. dont feel alone in the troubles. we can help eachother. the best meetups i go scrum clinic stuff. all the events in the network. \n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"üß™ Testing extract_insights_from_transcript...\")\n",
    "    print(f\"üìù Sample transcript: {sample_transcript[:100]}...\")\n",
    "    \n",
    "    try:\n",
    "        # Call your function\n",
    "        insights = extract_insights_from_transcript(sample_transcript)\n",
    "        \n",
    "        print(\"‚úÖ Function executed successfully!\")\n",
    "        print(\"\\nüìä Extracted Insights:\")\n",
    "        print(f\"Speakers found: {len(insights.speakers)}\")\n",
    "        print(f\"Primary challenges: {len(insights.primary_challenges)}\")\n",
    "        print(f\"Core values: {insights.core_values}\")\n",
    "        \n",
    "        # Print first challenge as example\n",
    "        if insights.primary_challenges:\n",
    "            challenge = insights.primary_challenges[0]\n",
    "            print(f\"\\nüî• First challenge:\")\n",
    "            print(f\"   Description: {challenge.description}\")\n",
    "            print(f\"   Impact: {challenge.impact}\")\n",
    "            print(f\"   Urgency: {challenge.urgency}\")\n",
    "            \n",
    "        return True, insights\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error in extract_insights_from_transcript: {e}\")\n",
    "        return False, None\n",
    "\n",
    "# Run the test\n",
    "success, test_insights = test_extract_insights_standalone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b8adac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Testing pain_extractor_node...\n",
      "üìù Mock state status: saved_to_db\n",
      "üß† Starting pain extraction...\n",
      "‚úÖ Extracted insights: 2 primary challenges, 1 speakers\n",
      "‚úÖ Node executed successfully!\n",
      "üìä Updated status: insights_extracted\n",
      "üîç Has insights: True\n",
      "\n",
      "üìã Insights Summary:\n",
      "   Speakers: 1\n",
      "   Primary challenges: 2\n",
      "   Current solutions: 3\n"
     ]
    }
   ],
   "source": [
    "# Cell 8B: Test pain_extractor_node with mock state\n",
    "def test_pain_extractor_node():\n",
    "    \"\"\"Test the LangGraph node with mock state\"\"\"\n",
    "    \n",
    "    # Create mock state (as if it came from previous nodes)\n",
    "    mock_state = {\n",
    "        \"file_path\": \"data/temp/test_file.wav\",\n",
    "        \"filename\": \"test_file.wav\", \n",
    "        \"transcript_text\": \"\"\"\n",
    "my name is olivier masset. i work at Lean and Agile Department from Elia (company). \n",
    "\n",
    "\n",
    "my goal here in elia is to help my team to adopt a mindset of continuous improvement. whatever the techniques. it does not matter if it's lean agile or something else they just come into the office and we have a chat about what they would like to improve. we analyse the \"as is\" situation why they would like to apply lean or agile techniques or whatever, what they want to do and we support them in the journey to get there. \n",
    "##do you work with teams? \n",
    "half of my job is IT teams, half is business teams. for the IT has been a top down approach. for the other is a success story approach. they can see that it works in other teams and they come to us to do ask to do the same. \n",
    "\n",
    "\n",
    "\n",
    "<img src=\"IMG_20190509_165555.jpg\" width=\"400\" height=\"400\" />\n",
    "__Lean and Agile office supports elia teams in their cultural change towards a continuous improvement mindset.__ Introducing, implementing, sustaining. \n",
    "a)awareness: communication, training and networking withing Eila\n",
    "b)new initiatives\n",
    "c)support: coaching & training , try to raise their maturity, regular follow up for example on the rituals, obeya room,logistic around that\n",
    "d)innovation new concepts, and techniques to try ex: if i read a new book (reinventing orgs) i try to implement it here. we try to be on top of the cultural change project. there is a program called \"make a difference\" we can have a sort of top down apporach. they have an impact in all the company. so is good we are together with them. when we create a workshop to provide feedback we support them with workshop design. if they like a technique they call us again for help on other meeting. \n",
    "f) networking outside elia\n",
    "-events training: journee agile. other companies. meetups \n",
    "-suppliers\n",
    "-companies\n",
    "\n",
    "that is how we are doing the transition here. little by little. step by step. based on word of mouth. t\n",
    "\n",
    "##team management\n",
    "my boss is sparring partner. we do try to brainstorm together.  i have my own coach. stephan levaque.he is coming here 1 o 2 times a month. help me with mentoring. help me unblock some issues. sometimes we cocreate workshops together.i have also 2 other coaches. one in schaarbeek to help the team there and another one 100 of the time but only since 1 month. we coach around 300 people. 150 in IT and about the same in the business. for us we need 1 coach for 30 people who start and 1 coach for \n",
    "100 people on sustain mode not a new initiative they have been doing this for a while and you help them to go further. i used to be a alone for 300 people. i started 3 years ago. i started in 2017 and the lean project started in 2016. they did the begining of the journey with 2 external coaches from cap gemini.i am employee of elia now. \n",
    "\n",
    "##main difficulties\n",
    "first one on top of everything, because we dont have a top down approach. you can have high scaling with the top down. some companies havea fulltop down approach. here is something you have to rise from th bottom. for me bottom up support is more important but you also need support from the top.   i miss somtimes some buy in from the management.the are convince is useful for the team but they say is for the team and not for us. you dont have \"the lead by example\" here. to help them to understand that this is very valuable for them this is my main challenge. help them to understand, if htey take the time to do it they will earn a lot behind, it will be worth it. this is a very big challenge. that is why I go to a lot of meetups where i can meet people like me. \n",
    "i feel alone. also pain. that is why i have an exernal coach. i want to discuss with someone. i need som eiother ideas that we hear on the books . release time for continuous improvement. to be a coach you need tthem to want to be coached. if you have as i to be. coach . help them to find the solution in  them. to do so you need them to come up i need to change something. get somt out of you confort zone. and thaat is difficult that they find this time. sometimes the come for the bad reason. they hear what others have done. we are not able to cut the work. the main issue is to release some real time to achieve their coaching objecitves. they are not able to manage the priorities. they don't allocate real time. they put it as something that their people need to do on top or their work. this creates risk of burnout. i think agile is good for that.\n",
    "version one report agile. what is the main value for you. as a result. the first one is always. a better ability to manage the priorities. do a choice between priorities. we are not always good at that. we want everyhing. they understood that and they started to release sometime.s this is problably the main difficulty i have. i prefer to have 3 people 100% agile or lean than 10 people 10%of their time.\n",
    "\n",
    "##final impact i want to have \n",
    "innovation mindset here at the end what i really try to do is to bring a bit of wellbeing for people. a bit better in their work everyday. ia m happy to be here. i am a bit better than yesterday. atmosphere of collab is improving. initiative spirit is here. you can do mistakes. you are not affraid to come to work. you like to come to work. that is why i want to work with the cultural change team as well. \n",
    "this diagram i like \n",
    "\n",
    "\n",
    "if you tell them you need to start to use a new tool, is feasible, they dont like it at the beginning but they have to . there is no choice. for example: use microsoft word.\n",
    "\n",
    "if you have in the agile manifesto people over tools and processes. mindset, is the less visible but the most powerful. when you hire someone, they focus on the hard skills. and not the soft skills. but the soft skills is one of the most important if you want to work in a team. as a painter you may do better work alone. here is about team . you need the righ tmindset. \n",
    "\n",
    "\n",
    "agile radar. how menaced do they feel. here they are quite confident: the company is going well. lots of companies started agile in a crisis. previsible vs exploratoire. innovation vs efficiency. better to be in an innovation mindset that to have always efficiency. \n",
    "\n",
    "it is a challenge becasue the context is not the best to to that. they don't want to go there. want to stay safe, we wont be predictble anymore. and this is a difficult. \n",
    "\n",
    "check and see how they are doing they are not so good at that.this is the reality here. \n",
    "\n",
    "lot of trouble with waiting time. lot of trouble with non utilized talent. using people to do thing they should not. \n",
    "\n",
    "##human aspect in the work environment\n",
    "the most important part . i am more interested by people than the content of their job. behaviour and mindset is my job. the good thing is they want to do it. they put it all over the walls. more collab. more feedback. one voice. they want to go there\n",
    "but most of the time in the wall is where you want to go but is what you don't have. some times this is what you see in the walls of the companies. this allow them to do it. some others feels dangerous and the prefer not to go there. you can do it if you want\n",
    "le croyance limitantes. there are a lot of those here. release them from their limitation of the mind. for me is amazing. sometimes i am doin ga very hard planning. at the end is one conversation at the coffee corner will have higher impact. we need time for that. we as coaches we need to live that style. take time and not always to focus on the operational goal. go to events. take time like talking to you. we need to keep that mind opening. all the success stories . in front of the stage. put it under the spot light. good behaviour. good team spirit. tell stories in our comm  tooo. i have a blog in the intranet. display screens. also simply i offer individual coaching. one on one. it has to come from them. +make a different project. for example one voice behaviour. fist feedbac. 2 one voice. you take decision as a team. once you tak decision you are all behind. team spirit approach. to do so we provide them some tools. check in check out. speech ball. everyone can share and is included in the conversation. ice breakers. getting to know eachother in the team. bring more humanity brings more empathy helping eachoter. i try to do a self assesment. ask them to evaluate themslelves in 100 questions. do you have time? is the cmm good? is electicity in the aair? gentle dissagreement. they have to take a decission as a team about that. if people \n",
    "have fun and others don't they ask during the self assessment workshope i invite them to express why in a group setting. and sometimes there are debates. and somethimes is the first time they share this info in a team. and this brings empathy collab. and at they end \n",
    "they wills start to have more fun. soft skills, start to help eachother and havea little more interest in the job of the other. values in common. i love one icebreaker who combine with energizer. the best thing that happen in their life in the last 5 days. with this one you can use it each week and repeat. at the end , with that ...last week i went with vacation with my kid. ah you have a kid. now environment. i am a fan of sunst dev. you are agile coach at the end with thos little exercises you have impact because they find things in common. this little things are sometimes more important than the big report.\n",
    "\n",
    "is more about connecting to the people. dont feel alone in the troubles. we can help eachother. the best meetups i go scrum clinic stuff. all the events in the network. \n",
    "\n",
    "        \"\"\",\n",
    "        \"conversation_id\": 100,  # Mock ID\n",
    "        \"extracted_insights\": None,\n",
    "        \"status\": \"saved_to_db\",\n",
    "        \"error\": None\n",
    "    }\n",
    "    \n",
    "    print(\"üß™ Testing pain_extractor_node...\")\n",
    "    print(f\"üìù Mock state status: {mock_state['status']}\")\n",
    "    \n",
    "    try:\n",
    "        # Call your node function\n",
    "        updated_state = pain_extractor_node(mock_state)\n",
    "        \n",
    "        print(\"‚úÖ Node executed successfully!\")\n",
    "        print(f\"üìä Updated status: {updated_state['status']}\")\n",
    "        print(f\"üîç Has insights: {'extracted_insights' in updated_state and updated_state['extracted_insights'] is not None}\")\n",
    "        \n",
    "        # Show extracted insights\n",
    "        if updated_state.get('extracted_insights'):\n",
    "            insights = updated_state['extracted_insights']\n",
    "            print(f\"\\nüìã Insights Summary:\")\n",
    "            print(f\"   Speakers: {len(insights.speakers) if insights.speakers else 0}\")\n",
    "            print(f\"   Primary challenges: {len(insights.primary_challenges) if insights.primary_challenges else 0}\")\n",
    "            print(f\"   Current solutions: {len(insights.current_solutions) if insights.current_solutions else 0}\")\n",
    "        \n",
    "        return True, updated_state\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error in pain_extractor_node: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return False, None\n",
    "\n",
    "# Run the test\n",
    "node_success, updated_state = test_pain_extractor_node()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cdfa5408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéâ Both functions work! Ready for integration.\n",
      "\n",
      "üîÑ Testing with real conversation: Audio: blog_batxhtwo.wav\n",
      "üß† Starting pain extraction...\n",
      "‚ùå Pain extraction failed: object of type 'NoneType' has no len()\n",
      "‚úÖ Real data test: error\n"
     ]
    }
   ],
   "source": [
    "# Cell 8C: Test integration (only run if previous tests pass)\n",
    "if success and node_success:\n",
    "    print(\"üéâ Both functions work! Ready for integration.\")\n",
    "    \n",
    "    # Test with real conversation from database\n",
    "    conversations = db.get_all_conversations()\n",
    "    if conversations:\n",
    "        real_conv = conversations[0]\n",
    "        print(f\"\\nüîÑ Testing with real conversation: {real_conv.title}\")\n",
    "        \n",
    "        real_state = {\n",
    "            \"conversation_id\": real_conv.id,\n",
    "            \"transcript_text\": real_conv.raw_text,\n",
    "            \"status\": \"saved_to_db\"\n",
    "        }\n",
    "        \n",
    "        final_result = pain_extractor_node(real_state)\n",
    "        print(f\"‚úÖ Real data test: {final_result['status']}\")\n",
    "    else:\n",
    "        print(\"‚ÑπÔ∏è No conversations in database for real data test\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Fix the failing tests before integration\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
