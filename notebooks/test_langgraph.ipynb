{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb001904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AssemblyAI API Key loaded: ‚úÖ\n",
      "Key starts with: 972365f41d...\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Setup and Imports\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Add project root to Python path\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv(project_root / '.env')\n",
    "\n",
    "# Test API key\n",
    "assemblyai_key = os.getenv('ASSEMBLYAI_API_KEY')\n",
    "print(f\"AssemblyAI API Key loaded: {'‚úÖ' if assemblyai_key else '‚ùå'}\")\n",
    "print(f\"Key starts with: {assemblyai_key[:10] if assemblyai_key else 'None'}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "30f9e880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All imports successful\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Import Dependencies\n",
    "import assemblyai as aai\n",
    "from langgraph.graph import StateGraph\n",
    "from typing import TypedDict, Optional, List  # ‚Üê Added List here\n",
    "import glob\n",
    "import time\n",
    "from pathlib import Path  # ‚Üê Also added Path here\n",
    "\n",
    "# Import our database\n",
    "from database.db_operations import db\n",
    "from database.models import ConversationCreate\n",
    "\n",
    "print(\"‚úÖ All imports successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fad4ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ State defined\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Define LangGraph State\n",
    "class AudioPipelineState(TypedDict):\n",
    "    file_path: str\n",
    "    filename: str\n",
    "    transcript_text: Optional[str]\n",
    "    conversation_id: Optional[int]\n",
    "    extracted_insights: Optional[ExtractedInsights]  # ‚Üê NEW: Using our Pydantic model\n",
    "    error: Optional[str]\n",
    "    status: str\n",
    "\n",
    "print(\"‚úÖ State defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f5cabeaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ AssemblyAI connection successful\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 4: Test AssemblyAI Connection\n",
    "# Configure AssemblyAI\n",
    "aai.settings.api_key = os.getenv('ASSEMBLYAI_API_KEY')\n",
    "\n",
    "# Test with a simple transcription (we'll use a file from temp folder)\n",
    "def test_assemblyai_connection():\n",
    "    \"\"\"Test if AssemblyAI is working\"\"\"\n",
    "    try:\n",
    "        # Just test the API key is valid\n",
    "        transcriber = aai.Transcriber()\n",
    "        print(\"‚úÖ AssemblyAI connection successful\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå AssemblyAI connection failed: {e}\")\n",
    "        return False\n",
    "\n",
    "test_assemblyai_connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "01335e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä BATCH PROCESSING INFO:\n",
      "   Files to process: 3\n",
      "   Total size: 2.1 MB\n",
      "\n",
      "üìÅ Files found:\n",
      "   1. blog_barchthreee.wav (0.7 MB)\n",
      "   2. blog_batchone.wav (0.9 MB)\n",
      "   3. blog_batxhtwo.wav (0.5 MB)\n",
      "\n",
      "üöÄ Ready to process 3 files!\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Batch File Discovery and Management\n",
    "def find_audio_files(temp_folder: Path) -> List[Path]:\n",
    "    \"\"\"Find all audio files in temp folder\"\"\"\n",
    "    audio_extensions = ['*.wav', '*.mp3', '*.m4a']\n",
    "    audio_files = []\n",
    "    \n",
    "    for ext in audio_extensions:\n",
    "        audio_files.extend(temp_folder.glob(ext))\n",
    "    \n",
    "    return sorted(audio_files)\n",
    "\n",
    "def display_batch_info(audio_files: List[Path]):\n",
    "    \"\"\"Display information about the batch of files\"\"\"\n",
    "    if not audio_files:\n",
    "        print(\"‚ùå No audio files found in temp folder!\")\n",
    "        return False\n",
    "    \n",
    "    total_size_mb = sum(f.stat().st_size for f in audio_files) / (1024 * 1024)\n",
    "    \n",
    "    print(f\"üìä BATCH PROCESSING INFO:\")\n",
    "    print(f\"   Files to process: {len(audio_files)}\")\n",
    "    print(f\"   Total size: {total_size_mb:.1f} MB\")\n",
    "    print(f\"\\nüìÅ Files found:\")\n",
    "    \n",
    "    for i, file_path in enumerate(audio_files, 1):\n",
    "        size_mb = file_path.stat().st_size / (1024 * 1024)\n",
    "        print(f\"   {i}. {file_path.name} ({size_mb:.1f} MB)\")\n",
    "    \n",
    "    return True\n",
    "\n",
    "def cleanup_processed_files(processed_files: List[Path]):\n",
    "    \"\"\"Delete all successfully processed files\"\"\"\n",
    "    print(f\"\\nüóëÔ∏è CLEANUP: Deleting {len(processed_files)} processed files...\")\n",
    "    deleted_count = 0\n",
    "    \n",
    "    for file_path in processed_files:\n",
    "        try:\n",
    "            file_path.unlink()  # Delete file\n",
    "            print(f\"   ‚úÖ Deleted: {file_path.name}\")\n",
    "            deleted_count += 1\n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå Failed to delete {file_path.name}: {e}\")\n",
    "    \n",
    "    print(f\"üóëÔ∏è Cleanup complete: {deleted_count}/{len(processed_files)} files deleted\")\n",
    "\n",
    "# Discover files in temp folder\n",
    "temp_folder = project_root / 'data' / 'temp'\n",
    "temp_folder.mkdir(parents=True, exist_ok=True)  # Ensure folder exists\n",
    "\n",
    "audio_files = find_audio_files(temp_folder)\n",
    "files_available = display_batch_info(audio_files)\n",
    "\n",
    "if files_available:\n",
    "    print(f\"\\nüöÄ Ready to process {len(audio_files)} files!\")\n",
    "else:\n",
    "    print(\"\\nüí° TIP: Add .wav files to data/temp/ folder for testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "419ae62d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ LangGraph nodes defined\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Define LangGraph Nodes\n",
    "def transcription_node(state: AudioPipelineState) -> AudioPipelineState:\n",
    "    \"\"\"Node 1: Transcribe audio file with AssemblyAI\"\"\"\n",
    "    try:\n",
    "        print(f\"üéôÔ∏è Transcribing: {state['filename']}\")\n",
    "        \n",
    "        # Configure transcriber\n",
    "        transcriber = aai.Transcriber()\n",
    "        \n",
    "        # Transcribe the file\n",
    "        transcript = transcriber.transcribe(state['file_path'])\n",
    "        \n",
    "        if transcript.status == aai.TranscriptStatus.error:\n",
    "            return {\n",
    "                **state,\n",
    "                \"error\": f\"AssemblyAI error: {transcript.error}\",\n",
    "                \"status\": \"transcription_failed\"\n",
    "            }\n",
    "        \n",
    "        return {\n",
    "            **state,\n",
    "            \"transcript_text\": transcript.text,\n",
    "            \"status\": \"transcribed\"\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            **state,\n",
    "            \"error\": f\"Transcription error: {str(e)}\",\n",
    "            \"status\": \"transcription_failed\"\n",
    "        }\n",
    "\n",
    "def database_saver_node(state: AudioPipelineState) -> AudioPipelineState:\n",
    "    \"\"\"Node 2: Save transcript to database\"\"\"\n",
    "    try:\n",
    "        print(f\"üíæ Saving to database: {state['filename']}\")\n",
    "        \n",
    "        # Create conversation object\n",
    "        conversation = ConversationCreate(\n",
    "            title=f\"Audio: {state['filename']}\",\n",
    "            raw_text=state['transcript_text'],\n",
    "            source=\"transcribed\"\n",
    "        )\n",
    "        \n",
    "        # Save to database\n",
    "        conversation_id = db.create_conversation(conversation)\n",
    "        \n",
    "        return {\n",
    "            **state,\n",
    "            \"conversation_id\": conversation_id,\n",
    "            \"status\": \"completed\"\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            **state,\n",
    "            \"error\": f\"Database error: {str(e)}\",\n",
    "            \"status\": \"database_failed\"\n",
    "        }\n",
    "\n",
    "print(\"‚úÖ LangGraph nodes defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0cd719a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Checking/creating database...\n",
      "Creating database at: data/app.db\n",
      "‚úÖ Database schema created successfully!\n",
      "‚úÖ Created tables: ['conversations', 'sqlite_sequence', 'blog_post_ideas', 'processing_status']\n",
      "‚úÖ Database ready!\n",
      "üìä Available tables: ['conversations', 'sqlite_sequence', 'blog_post_ideas', 'processing_status']\n"
     ]
    }
   ],
   "source": [
    "# Cell: Initialize Database\n",
    "from database.init_db import create_database\n",
    "\n",
    "print(\"üîß Checking/creating database...\")\n",
    "try:\n",
    "    create_database()\n",
    "    print(\"‚úÖ Database ready!\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Database error: {e}\")\n",
    "\n",
    "# Verify tables exist\n",
    "import sqlite3\n",
    "conn = sqlite3.connect('data/app.db')\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "tables = cursor.fetchall()\n",
    "print(f\"üìä Available tables: {[table[0] for table in tables]}\")\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8c379c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ LangGraph pipeline compiled and ready\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Build LangGraph Workflow\n",
    "def build_pipeline():\n",
    "    \"\"\"Build the LangGraph workflow\"\"\"\n",
    "    workflow = StateGraph(AudioPipelineState)\n",
    "    \n",
    "    # Add nodes\n",
    "    workflow.add_node(\"transcribe\", transcription_node)\n",
    "    workflow.add_node(\"save_to_db\", database_saver_node)\n",
    "    \n",
    "    # Add edges\n",
    "    workflow.add_edge(\"transcribe\", \"save_to_db\")\n",
    "    workflow.set_entry_point(\"transcribe\")\n",
    "    workflow.set_finish_point(\"save_to_db\")\n",
    "    \n",
    "    return workflow.compile()\n",
    "\n",
    "# Build the pipeline\n",
    "pipeline = build_pipeline()\n",
    "print(\"‚úÖ LangGraph pipeline compiled and ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "078aae2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Batch processing function ready\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Batch Processing Function\n",
    "def process_audio_batch(audio_files: List[Path], pipeline) -> dict:\n",
    "    \"\"\"Process all audio files in batch\"\"\"\n",
    "    \n",
    "    if not audio_files:\n",
    "        print(\"‚ùå No files to process\")\n",
    "        return {\"processed\": [], \"failed\": [], \"total\": 0}\n",
    "    \n",
    "    print(f\"\\nüöÄ STARTING BATCH PROCESSING - {len(audio_files)} files\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    processed_files = []\n",
    "    failed_files = []\n",
    "    results = []\n",
    "    \n",
    "    for i, file_path in enumerate(audio_files, 1):\n",
    "        print(f\"\\nüìÇ Processing {i}/{len(audio_files)}: {file_path.name}\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        # Create initial state\n",
    "        initial_state = {\n",
    "            \"file_path\": str(file_path),\n",
    "            \"filename\": file_path.name,\n",
    "            \"transcript_text\": None,\n",
    "            \"conversation_id\": None,\n",
    "            \"error\": None,\n",
    "            \"status\": \"processing\"\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            # Run through pipeline\n",
    "            result = pipeline.invoke(initial_state)\n",
    "            \n",
    "            if result[\"status\"] == \"completed\":\n",
    "                print(f\"‚úÖ SUCCESS: {file_path.name}\")\n",
    "                print(f\"   Conversation ID: {result['conversation_id']}\")\n",
    "                print(f\"   Transcript preview: {result['transcript_text'][:100]}...\")\n",
    "                processed_files.append(file_path)\n",
    "            else:\n",
    "                print(f\"‚ùå FAILED: {file_path.name}\")\n",
    "                print(f\"   Error: {result.get('error', 'Unknown error')}\")\n",
    "                failed_files.append(file_path)\n",
    "            \n",
    "            results.append(result)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå PIPELINE ERROR: {file_path.name}\")\n",
    "            print(f\"   Exception: {str(e)}\")\n",
    "            failed_files.append(file_path)\n",
    "            \n",
    "            results.append({\n",
    "                **initial_state,\n",
    "                \"error\": str(e),\n",
    "                \"status\": \"pipeline_error\"\n",
    "            })\n",
    "    \n",
    "    return {\n",
    "        \"processed\": processed_files,\n",
    "        \"failed\": failed_files,\n",
    "        \"total\": len(audio_files),\n",
    "        \"results\": results\n",
    "    }\n",
    "\n",
    "print(\"‚úÖ Batch processing function ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4cb00a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Starting batch processing...\n",
      "\n",
      "üöÄ STARTING BATCH PROCESSING - 3 files\n",
      "============================================================\n",
      "\n",
      "üìÇ Processing 1/3: blog_barchthreee.wav\n",
      "----------------------------------------\n",
      "üéôÔ∏è Transcribing: blog_barchthreee.wav\n",
      "üíæ Saving to database: blog_barchthreee.wav\n",
      "‚úÖ SUCCESS: blog_barchthreee.wav\n",
      "   Conversation ID: 2\n",
      "   Transcript preview: Testing batch processing number three....\n",
      "\n",
      "üìÇ Processing 2/3: blog_batchone.wav\n",
      "----------------------------------------\n",
      "üéôÔ∏è Transcribing: blog_batchone.wav\n",
      "üíæ Saving to database: blog_batchone.wav\n",
      "‚úÖ SUCCESS: blog_batchone.wav\n",
      "   Conversation ID: 3\n",
      "   Transcript preview: Testing batch processing one....\n",
      "\n",
      "üìÇ Processing 3/3: blog_batxhtwo.wav\n",
      "----------------------------------------\n",
      "üéôÔ∏è Transcribing: blog_batxhtwo.wav\n",
      "üíæ Saving to database: blog_batxhtwo.wav\n",
      "‚úÖ SUCCESS: blog_batxhtwo.wav\n",
      "   Conversation ID: 4\n",
      "   Transcript preview: Testing batch process into....\n",
      "\n",
      "üìä BATCH PROCESSING COMPLETE!\n",
      "============================================================\n",
      "‚úÖ Successfully processed: 3\n",
      "‚ùå Failed: 0\n",
      "üìÅ Total files: 3\n",
      "\n",
      "üóëÔ∏è CLEANUP: Deleting 3 processed files...\n",
      "   ‚úÖ Deleted: blog_barchthreee.wav\n",
      "   ‚úÖ Deleted: blog_batchone.wav\n",
      "   ‚úÖ Deleted: blog_batxhtwo.wav\n",
      "üóëÔ∏è Cleanup complete: 3/3 files deleted\n",
      "\n",
      "üéâ Batch processing complete!\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: Execute Batch Processing with Cleanup\n",
    "if files_available:\n",
    "    print(\"üéØ Starting batch processing...\")\n",
    "    \n",
    "    # Process all files\n",
    "    batch_results = process_audio_batch(audio_files, pipeline)\n",
    "    \n",
    "    # Display summary\n",
    "    print(f\"\\nüìä BATCH PROCESSING COMPLETE!\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"‚úÖ Successfully processed: {len(batch_results['processed'])}\")\n",
    "    print(f\"‚ùå Failed: {len(batch_results['failed'])}\")\n",
    "    print(f\"üìÅ Total files: {batch_results['total']}\")\n",
    "    \n",
    "    # Show failed files\n",
    "    if batch_results['failed']:\n",
    "        print(f\"\\n‚ùå Failed files:\")\n",
    "        for file_path in batch_results['failed']:\n",
    "            print(f\"   - {file_path.name}\")\n",
    "    \n",
    "    # Cleanup successfully processed files\n",
    "    if batch_results['processed']:\n",
    "        confirm = input(f\"\\nüóëÔ∏è Delete {len(batch_results['processed'])} processed files? (y/N): \")\n",
    "        if confirm.lower() in ['y', 'yes']:\n",
    "            cleanup_processed_files(batch_results['processed'])\n",
    "        else:\n",
    "            print(\"üîß Files kept in temp folder for inspection\")\n",
    "    \n",
    "    print(\"\\nüéâ Batch processing complete!\")\n",
    "    \n",
    "else:\n",
    "    print(\"üí° Add audio files to data/temp/ folder and rerun this cell\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d95b79d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Recent Conversations (showing 4):\n",
      "------------------------------------------------------------\n",
      "ID: 4 | Title: Audio: blog_batxhtwo.wav\n",
      "Source: transcribed | Words: 4 | Status: pending\n",
      "Created: 2025-09-24 08:20:07\n",
      "Preview: Testing batch process into....\n",
      "------------------------------------------------------------\n",
      "ID: 3 | Title: Audio: blog_batchone.wav\n",
      "Source: transcribed | Words: 4 | Status: pending\n",
      "Created: 2025-09-24 08:20:02\n",
      "Preview: Testing batch processing one....\n",
      "------------------------------------------------------------\n",
      "ID: 2 | Title: Audio: blog_barchthreee.wav\n",
      "Source: transcribed | Words: 5 | Status: pending\n",
      "Created: 2025-09-24 08:19:57\n",
      "Preview: Testing batch processing number three....\n",
      "------------------------------------------------------------\n",
      "ID: 1 | Title: Audio: blog_recordcomtines.wav\n",
      "Source: transcribed | Words: 30 | Status: pending\n",
      "Created: 2025-09-24 07:48:54\n",
      "Preview: I'm uploading a file from my telephone, and the idea is that this file is going to be monitored and moved to the temporary file in the AI ContentOps f...\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Cell 10: View Results in Database\n",
    "def show_recent_conversations(limit=10):\n",
    "    \"\"\"Display recent conversations from database\"\"\"\n",
    "    conversations = db.get_all_conversations()\n",
    "    \n",
    "    if not conversations:\n",
    "        print(\"üìù No conversations found in database\")\n",
    "        return\n",
    "    \n",
    "    print(f\"üìù Recent Conversations (showing {min(limit, len(conversations))}):\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    for conv in conversations[:limit]:\n",
    "        print(f\"ID: {conv.id} | Title: {conv.title}\")\n",
    "        print(f\"Source: {conv.source} | Words: {conv.word_count} | Status: {conv.status}\")\n",
    "        print(f\"Created: {conv.created_at}\")\n",
    "        print(f\"Preview: {conv.raw_text[:150]}...\")\n",
    "        print(\"-\" * 60)\n",
    "\n",
    "# Show results\n",
    "show_recent_conversations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e771cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## 1. Pydantic Model for Structured Output\n",
    "\n",
    "```python\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Optional\n",
    "from enum import Enum\n",
    "\n",
    "class SpeakerRole(str, Enum):\n",
    "    \"\"\"Possible speaker roles in the conversation\"\"\"\n",
    "    USER = \"user\"\n",
    "    CLIENT = \"client\"\n",
    "    POTENTIAL_CLIENT = \"potential_client\"\n",
    "    INTERVIEWER = \"interviewer\"\n",
    "    TEAM_MEMBER = \"team_member\"\n",
    "    OTHER = \"other\"\n",
    "\n",
    "class Speaker(BaseModel):\n",
    "    \"\"\"Information about a person speaking in the conversation\"\"\"\n",
    "    name: Optional[str] = Field(description=\"Name of the speaker if mentioned\")\n",
    "    role: SpeakerRole = Field(description=\"Role of the speaker in the conversation\")\n",
    "    company: Optional[str] = Field(description=\"Company they work for if mentioned\")\n",
    "\n",
    "class Challenge(BaseModel):\n",
    "    \"\"\"A challenge or problem mentioned in the conversation\"\"\"\n",
    "    description: str = Field(description=\"Description of the challenge\")\n",
    "    impact: str = Field(description=\"How this challenge affects them\")\n",
    "    urgency: str = Field(description=\"Low, Medium, or High urgency\")\n",
    "\n",
    "class CurrentSolution(BaseModel):\n",
    "    \"\"\"How they currently solve their problems\"\"\"\n",
    "    solution: str = Field(description=\"What they're currently doing\")\n",
    "    satisfaction_level: str = Field(description=\"How satisfied they are: Very Satisfied, Satisfied, Neutral, Unsatisfied, Very Unsatisfied\")\n",
    "    limitations: List[str] = Field(description=\"Limitations of current solution\")\n",
    "\n",
    "class Need(BaseModel):\n",
    "    \"\"\"A need identified using psychology frameworks like NVC\"\"\"\n",
    "    need_category: str = Field(description=\"Category of need (e.g., autonomy, efficiency, security, connection)\")\n",
    "    description: str = Field(description=\"Specific need description\")\n",
    "    intensity: str = Field(description=\"Low, Medium, or High intensity\")\n",
    "\n",
    "class ExtractedInsights(BaseModel):\n",
    "    \"\"\"Complete structured output from conversation analysis\"\"\"\n",
    "    \n",
    "    # Speakers\n",
    "    speakers: List[Speaker] = Field(description=\"People identified in the conversation\")\n",
    "    \n",
    "    # What they care about\n",
    "    core_values: List[str] = Field(description=\"What this person/company cares about most\")\n",
    "    priorities: List[str] = Field(description=\"Their current priorities and focus areas\")\n",
    "    \n",
    "    # Challenges\n",
    "    primary_challenges: List[Challenge] = Field(description=\"Main problems they're facing\")\n",
    "    secondary_challenges: List[Challenge] = Field(description=\"Secondary or related problems\")\n",
    "    \n",
    "    # Current solutions\n",
    "    current_solutions: List[CurrentSolution] = Field(description=\"How they solve problems today\")\n",
    "    \n",
    "    # Needs analysis\n",
    "    psychological_needs: List[Need] = Field(description=\"Underlying needs using NVC or similar frameworks\")\n",
    "    \n",
    "    # Keywords and themes\n",
    "    problem_keywords: List[str] = Field(description=\"Key words/phrases they use to describe problems\")\n",
    "    main_themes: List[str] = Field(description=\"Overarching themes in the conversation\")\n",
    "    \n",
    "    # Context\n",
    "    conversation_summary: str = Field(description=\"Brief summary of the conversation\")\n",
    "    automation_context: str = Field(description=\"Specific context about their automation/tech challenges\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3cea20",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3. PainExtractor Node Implementation\n",
    "\n",
    "```python\n",
    "import openai\n",
    "import json\n",
    "from typing import Dict, Any\n",
    "\n",
    "# System prompt\n",
    "PAIN_EXTRACTOR_SYSTEM_PROMPT = \"\"\"\n",
    "You are a UX researcher and business analyst for BigKids Automation. Your job is listening to transcripts from interviews with users and potential clients. \n",
    "\n",
    "You pay special attention to problems that users have regarding how their company is automating, using web apps and AI to save time and move towards a more ethical and sovereign tech infrastructure.\n",
    "\n",
    "You will be given the transcript of an interview with a user or potential client.\n",
    "\n",
    "Your task is to extract structured information about:\n",
    "- Who is speaking and their role\n",
    "- What this person cares about (values, priorities)\n",
    "- Their main primary and secondary challenges\n",
    "- How they are solving problems today\n",
    "- Their underlying psychological needs (using frameworks like NVC - Non-Violent Communication)\n",
    "- Keywords they use to describe their main problems\n",
    "\n",
    "Focus on automation, web apps, AI, time-saving, ethical tech, and sovereign infrastructure themes.\n",
    "\n",
    "Be thorough but concise. If information is not clearly stated, mark as null/empty rather than guessing.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819a4829",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_insights_from_transcript(transcript_text: str, model=\"gpt-4o-2024-08-06\", temperature=0) -> ExtractedInsights:\n",
    "    \"\"\"\n",
    "    Extract structured insights from conversation transcript using OpenAI structured output\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = client.beta.chat.completions.parse(\n",
    "            model=model,\n",
    "            temperature=temperature,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": PAIN_EXTRACTOR_SYSTEM_PROMPT},\n",
    "                {\"role\": \"user\", \"content\": transcript_text},\n",
    "            ],\n",
    "            response_format=ExtractedInsights\n",
    "        )\n",
    "        \n",
    "        return response.choices[0].message.parsed\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error extracting insights: {e}\")\n",
    "        return None\n",
    "\n",
    "def pain_extractor_node(state: AudioPipelineState) -> AudioPipelineState:\n",
    "    \"\"\"\n",
    "    LangGraph node: Extract structured insights from conversation transcript\n",
    "    \"\"\"\n",
    "    print(\"üß† Starting pain extraction...\")\n",
    "    \n",
    "    try:\n",
    "        # Extract insights using OpenAI structured output\n",
    "        insights = extract_insights_from_transcript(state['transcript_text'])\n",
    "        \n",
    "        if insights:\n",
    "            print(f\"‚úÖ Extracted insights: {len(insights.primary_challenges)} primary challenges, {len(insights.speakers)} speakers\")\n",
    "            \n",
    "            return {\n",
    "                **state,\n",
    "                \"extracted_insights\": insights,\n",
    "                \"status\": \"insights_extracted\"\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                **state,\n",
    "                \"error\": \"Failed to extract insights from transcript\",\n",
    "                \"status\": \"error\"\n",
    "            }\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Pain extraction failed: {e}\")\n",
    "        return {\n",
    "            **state,\n",
    "            \"error\": f\"Pain extraction error: {str(e)}\",\n",
    "            \"status\": \"error\"\n",
    "        }\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205a8b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 4. Usage in Jupyter Notebook\n",
    "\n",
    "```python\n",
    "# Cell: Test Pain Extractor Node\n",
    "from openai import OpenAI\n",
    "\n",
    "# Initialize OpenAI client\n",
    "client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))\n",
    "\n",
    "# Test with sample transcript\n",
    "test_state = {\n",
    "    \"file_path\": \"data/temp/test.wav\",\n",
    "    \"filename\": \"test.wav\",\n",
    "    \"transcript_text\": \"Hi, I'm John from TechCorp. We're struggling with our manual processes. We spend hours every day on data entry and it's killing our productivity. We've tried some automation tools but they don't integrate well with our existing systems. What we really need is something that respects our data sovereignty and doesn't lock us into big tech platforms.\",\n",
    "    \"conversation_id\": 1,\n",
    "    \"extracted_insights\": None,\n",
    "    \"blog_ideas\": None,\n",
    "    \"error\": None,\n",
    "    \"status\": \"transcribed\"\n",
    "}\n",
    "\n",
    "# Run the pain extractor node\n",
    "result_state = pain_extractor_node(test_state)\n",
    "\n",
    "# Display results\n",
    "if result_state.get('extracted_insights'):\n",
    "    insights = result_state['extracted_insights']\n",
    "    print(\"üéØ Extracted Insights:\")\n",
    "    print(f\"Speakers: {[s.name for s in insights.speakers]}\")\n",
    "    print(f\"Primary challenges: {len(insights.primary_challenges)}\")\n",
    "    print(f\"Keywords: {insights.problem_keywords}\")\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
