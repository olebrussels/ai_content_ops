{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb001904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AssemblyAI API Key loaded: âœ…\n",
      "Key starts with: 972365f41d...\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Setup and Imports\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Add project root to Python path\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv(project_root / '.env')\n",
    "\n",
    "# Test API key\n",
    "assemblyai_key = os.getenv('ASSEMBLYAI_API_KEY')\n",
    "print(f\"AssemblyAI API Key loaded: {'âœ…' if assemblyai_key else 'âŒ'}\")\n",
    "print(f\"Key starts with: {assemblyai_key[:10] if assemblyai_key else 'None'}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "42981215",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, getpass\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "_set_env(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "944e386b",
   "metadata": {},
   "outputs": [],
   "source": [
    "_set_env(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"ai_content_ops\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7cc1fee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Tables in app.db:\n",
      "\n",
      "ðŸ”§ conversations:\n",
      "   - id (INTEGER)\n",
      "   - title (TEXT)\n",
      "   - raw_text (TEXT)\n",
      "   - source (TEXT)\n",
      "   - word_count (INTEGER)\n",
      "   - created_at (DATETIME)\n",
      "   - status (TEXT)\n",
      "\n",
      "ðŸ”§ sqlite_sequence:\n",
      "   - name ()\n",
      "   - seq ()\n",
      "\n",
      "ðŸ”§ blog_post_ideas:\n",
      "   - id (INTEGER)\n",
      "   - conversation_id (INTEGER)\n",
      "   - title (TEXT)\n",
      "   - description (TEXT)\n",
      "   - usefulness_potential (INTEGER)\n",
      "   - fitwith_seo_strategy (INTEGER)\n",
      "   - fitwith_content_strategy (INTEGER)\n",
      "   - inspiration_potential (INTEGER)\n",
      "   - collaboration_potential (INTEGER)\n",
      "   - innovation (INTEGER)\n",
      "   - difficulty (INTEGER)\n",
      "   - total_score (INTEGER)\n",
      "   - sent_to_prod (BOOLEAN)\n",
      "   - raw_llm_response (TEXT)\n",
      "   - created_at (DATETIME)\n",
      "\n",
      "ðŸ”§ processing_status:\n",
      "   - id (INTEGER)\n",
      "   - conversation_id (INTEGER)\n",
      "   - stage (TEXT)\n",
      "   - status (TEXT)\n",
      "   - error_message (TEXT)\n",
      "   - started_at (DATETIME)\n",
      "   - completed_at (DATETIME)\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect(\"data/app.db\")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Get all table names\n",
    "cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "tables = cursor.fetchall()\n",
    "\n",
    "print(\"ðŸ“Š Tables in app.db:\")\n",
    "for table in tables:\n",
    "    table_name = table[0]\n",
    "    \n",
    "    # Get column info for each table\n",
    "    cursor.execute(f\"PRAGMA table_info({table_name})\")\n",
    "    columns = cursor.fetchall()\n",
    "    \n",
    "    print(f\"\\nðŸ”§ {table_name}:\")\n",
    "    for col in columns:\n",
    "        print(f\"   - {col[1]} ({col[2]})\")  # column_name (type)\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30f9e880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… All imports successful\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Import Dependencies\n",
    "import assemblyai as aai\n",
    "from langgraph.graph import StateGraph\n",
    "from typing import TypedDict, Optional, List, Dict  # â† Added List here\n",
    "import glob\n",
    "import time\n",
    "from pathlib import Path  # â† Also added Path here\n",
    "\n",
    "# Import our database\n",
    "from database.db_operations import db\n",
    "from database.models import ConversationCreate\n",
    "\n",
    "print(\"âœ… All imports successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e30147df",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. Pydantic Model for Structured Output\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Optional\n",
    "from enum import Enum\n",
    "\n",
    "class SpeakerRole(str, Enum):\n",
    "    \"\"\"Possible speaker roles in the conversation\"\"\"\n",
    "    CLIENT = \"client\"\n",
    "    INTERVIEWER = \"interviewer\"\n",
    "\n",
    "class Speaker(BaseModel):\n",
    "    \"\"\"Information about a person speaking in the conversation\"\"\"\n",
    "    name: Optional[str] = Field(default=None, description=\"Name of the speaker if mentioned\")\n",
    "    role: Optional[SpeakerRole] = Field(default=None, description=\"Role of the speaker in the conversation\")\n",
    "    company: Optional[str] = Field(default=None, description=\"Company they work for if mentioned\")\n",
    "\n",
    "class Challenge(BaseModel):\n",
    "    \"\"\"A challenge or problem mentioned in the conversation\"\"\"\n",
    "    description: Optional[str] = Field(default=None, description=\"Description of the challenge\")\n",
    "    impact: Optional[str] = Field(default=None, description=\"How this challenge affects them\")\n",
    "    urgency: Optional[str] = Field(default=None, description=\"Low, Medium, or High urgency\")\n",
    "\n",
    "class CurrentSolution(BaseModel):\n",
    "    \"\"\"How they currently solve their problems\"\"\"\n",
    "    solution: Optional[str] = Field(default=None, description=\"What they're currently doing\")\n",
    "    satisfaction_level: Optional[str] = Field(default=None, description=\"How satisfied they are: Very Satisfied, Satisfied, Neutral, Unsatisfied, Very Unsatisfied\")\n",
    "    limitations: Optional[List[str]] = Field(default=[], description=\"Limitations of current solution\")\n",
    "\n",
    "class Need(BaseModel):\n",
    "    \"\"\"A need identified using psychology frameworks like NVC\"\"\"\n",
    "    need_category: Optional[str] = Field(default=None, description=\"Category of need (e.g., autonomy, efficiency, security, connection)\")\n",
    "    description: Optional[str] = Field(default=None, description=\"Specific need description\")\n",
    "    intensity: Optional[str] = Field(default=None, description=\"Low, Medium, or High intensity\")\n",
    "\n",
    "class ExtractedInsights(BaseModel):\n",
    "    \"\"\"Complete structured output from conversation analysis\"\"\"\n",
    "    \n",
    "    # Speakers\n",
    "    speakers: Optional[List[Speaker]] = Field(default=[], description=\"People identified in the conversation\")\n",
    "    \n",
    "    # What they care about\n",
    "    core_values: Optional[List[str]] = Field(default=[], description=\"What this person/company cares about most\")\n",
    "    priorities: Optional[List[str]] = Field(default=[], description=\"Their current priorities and focus areas\")\n",
    "    \n",
    "    # Challenges\n",
    "    primary_challenges: Optional[List[Challenge]] = Field(default=[], description=\"Main problems they're facing\")\n",
    "    secondary_challenges: Optional[List[Challenge]] = Field(default=[], description=\"Secondary or related problems\")\n",
    "    \n",
    "    # Current solutions\n",
    "    current_solutions: Optional[List[CurrentSolution]] = Field(default=[], description=\"How they solve problems today\")\n",
    "    \n",
    "    # Needs analysis\n",
    "    psychological_needs: Optional[List[Need]] = Field(default=[], description=\"Underlying needs using NVC or similar frameworks\")\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89d86360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Simple RawBlogIdea model ready\n"
     ]
    }
   ],
   "source": [
    "# Cell 12: Raw Blog Idea Model (Simple)\n",
    "class RawBlogIdea(BaseModel):\n",
    "    \"\"\"Raw blog idea from creative agent\"\"\"\n",
    "    title: str\n",
    "    description: str\n",
    "    target_audience: str\n",
    "    content_angle: str\n",
    "    business_value: str\n",
    "\n",
    "print(\"âœ… Simple RawBlogIdea model ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77ecdfc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… RawBlogIdea model and validation ready\n"
     ]
    }
   ],
   "source": [
    "def validate_raw_blog_ideas(raw_ideas: List[Dict]) -> List[RawBlogIdea]:\n",
    "    \"\"\"Validate and convert raw JSON to Pydantic models\"\"\"\n",
    "    validated_ideas = []\n",
    "    \n",
    "    for idea in raw_ideas:\n",
    "        try:\n",
    "            validated_idea = RawBlogIdea(**idea)\n",
    "            validated_ideas.append(validated_idea)\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ Invalid blog idea skipped: {e}\")\n",
    "    \n",
    "    print(f\"âœ… Validated {len(validated_ideas)} out of {len(raw_ideas)} raw ideas\")\n",
    "    return validated_ideas\n",
    "\n",
    "print(\"âœ… RawBlogIdea model and validation ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19fad4ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… State defined\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Define LangGraph State\n",
    "class AudioPipelineState(TypedDict):\n",
    "    file_path: str\n",
    "    filename: str\n",
    "    transcript_text: Optional[str]\n",
    "    conversation_id: Optional[int]\n",
    "    extracted_insights: Optional[ExtractedInsights]  \n",
    "    raw_blog_ideas: Optional[List[Dict]]           # Pydantic objects from creative agent\n",
    "\n",
    "    \n",
    "    # Status & error handling\n",
    "    status: str\n",
    "    error: Optional[str]\n",
    "\n",
    "\n",
    "print(\"âœ… State defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bcb6358b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded company strategy (6555 chars)\n",
      "âœ… Loaded SEO strategy (1120 chars)\n",
      "âœ… Loaded content strategy (4469 chars)\n",
      "ðŸ“Š Strategy context keys: ['company_strategy', 'seo_strategy', 'content_strategy']\n",
      "ðŸ“Š Total context size: 12144 chars\n"
     ]
    }
   ],
   "source": [
    "# Cell: Updated Company Strategy Context Loader (3 Documents)\n",
    "def load_company_strategy_context():\n",
    "    \"\"\"Load company strategy, SEO strategy, and content strategy for context\"\"\"\n",
    "    \n",
    "    strategy_context = {}\n",
    "    \n",
    "    try:\n",
    "        # Load company strategy\n",
    "        company_strategy_path = \"../data/processed/company_strategy.mkd\"\n",
    "        if os.path.exists(company_strategy_path):\n",
    "            with open(company_strategy_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                strategy_context[\"company_strategy\"] = f.read()\n",
    "            print(f\"âœ… Loaded company strategy ({len(strategy_context['company_strategy'])} chars)\")\n",
    "        else:\n",
    "            strategy_context[\"company_strategy\"] = \"Company strategy document not available.\"\n",
    "            print(\"âš ï¸ Company strategy document not found\")\n",
    "        \n",
    "        # Load SEO strategy\n",
    "        seo_strategy_path = \"../data/processed/seo_strategy.mkd\"\n",
    "        if os.path.exists(seo_strategy_path):\n",
    "            with open(seo_strategy_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                strategy_context[\"seo_strategy\"] = f.read()\n",
    "            print(f\"âœ… Loaded SEO strategy ({len(strategy_context['seo_strategy'])} chars)\")\n",
    "        else:\n",
    "            strategy_context[\"seo_strategy\"] = \"SEO strategy document not available.\"\n",
    "            print(\"âš ï¸ SEO strategy document not found\")\n",
    "        \n",
    "        # Load content strategy (NEW)\n",
    "        content_strategy_path = \"../data/processed/content_strategy.mkd\"\n",
    "        if os.path.exists(content_strategy_path):\n",
    "            with open(content_strategy_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                strategy_context[\"content_strategy\"] = f.read()\n",
    "            print(f\"âœ… Loaded content strategy ({len(strategy_context['content_strategy'])} chars)\")\n",
    "        else:\n",
    "            strategy_context[\"content_strategy\"] = \"Content strategy document not available.\"\n",
    "            print(\"âš ï¸ Content strategy document not found\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error loading strategy documents: {e}\")\n",
    "        strategy_context = {\n",
    "            \"company_strategy\": \"Strategy document not available\",\n",
    "            \"seo_strategy\": \"SEO strategy document not available\", \n",
    "            \"content_strategy\": \"Content strategy document not available\"\n",
    "        }\n",
    "    \n",
    "    return strategy_context\n",
    "\n",
    "# Test loading all three documents\n",
    "strategy_context = load_company_strategy_context()\n",
    "print(f\"ðŸ“Š Strategy context keys: {list(strategy_context.keys())}\")\n",
    "print(f\"ðŸ“Š Total context size: {sum(len(v) for v in strategy_context.values() if isinstance(v, str))} chars\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1b52ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fixed creative agent function ready\n"
     ]
    }
   ],
   "source": [
    "# Cell: Fixed Creative Agent Function\n",
    "def generate_blog_ideas_from_insights(insights: ExtractedInsights, strategy_context: dict) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Fixed creative agent that handles Claude's markdown JSON response\n",
    "    \"\"\"\n",
    "    \n",
    "    creative_prompt = f\"\"\"\n",
    "    You are a creative content strategist for Big Kids Automation, a company that helps businesses implement AI and automation solutions.\n",
    "    \n",
    "    COMPANY CONTEXT:\n",
    "    {strategy_context.get('company_strategy', 'Strategy not available')[:1000]}...\n",
    "    \n",
    "    SEO STRATEGY:\n",
    "    {strategy_context.get('seo_strategy', 'SEO strategy not available')[:500]}...\n",
    "    \n",
    "    CONVERSATION INSIGHTS TO WORK FROM:\n",
    "    \n",
    "    Speakers: {[f\"{s.name} ({s.role}) from {s.company}\" for s in insights.speakers] if insights.speakers else \"Unknown speakers\"}\n",
    "    \n",
    "    Core Values: {\", \".join(insights.core_values) if insights.core_values else \"None identified\"}\n",
    "    \n",
    "    Priorities: {\", \".join(insights.priorities) if insights.priorities else \"None identified\"}\n",
    "    \n",
    "    Primary Challenges:\n",
    "    {chr(10).join([f\"- {c.description} (Impact: {c.impact}, Urgency: {c.urgency})\" for c in insights.primary_challenges]) if insights.primary_challenges else \"None identified\"}\n",
    "    \n",
    "    Current Solutions:\n",
    "    {chr(10).join([f\"- {s.solution} (Satisfaction: {s.satisfaction_level})\" for s in insights.current_solutions]) if insights.current_solutions else \"None identified\"}\n",
    "    \n",
    "    Psychological Needs:\n",
    "    {chr(10).join([f\"- {n.description} ({n.need_category}, {n.intensity} intensity)\" for n in insights.psychological_needs]) if insights.psychological_needs else \"None identified\"}\n",
    "    \n",
    "    TASK:\n",
    "    Generate 4-5 creative blog post ideas that:\n",
    "    1. Address the challenges and needs identified in this conversation\n",
    "    2. Align with Big Kids Automation's mission to help businesses with AI/automation\n",
    "    3. Provide value to potential clients facing similar challenges\n",
    "    4. Support our SEO and content marketing strategy\n",
    "    5. Are actionable and practical, not just theoretical\n",
    "    \n",
    "    For each blog post idea, provide:\n",
    "    - title: Clear, engaging title that includes relevant keywords\n",
    "    - description: 2-3 sentence description of what the post will cover\n",
    "    - target_audience: Who this post is primarily for\n",
    "    - content_angle: The unique angle or approach this post takes\n",
    "    - business_value: How this post helps our business goals\n",
    "    \n",
    "    IMPORTANT: Return ONLY the JSON array, no markdown formatting, no code blocks, no explanatory text.\n",
    "    \n",
    "    Format:\n",
    "    [\n",
    "        {{\n",
    "            \"title\": \"How AI Proposal Systems Balance Speed with Brand Differentiation\",\n",
    "            \"description\": \"A practical guide showing how modern AI-powered proposal systems solve the common problem of maintaining company uniqueness while leveraging automation. Includes real case studies and implementation steps.\",\n",
    "            \"target_audience\": \"Business development directors and proposal managers at consulting firms\",\n",
    "            \"content_angle\": \"Problem-solution with real case studies\",\n",
    "            \"business_value\": \"Attracts prospects struggling with proposal automation while maintaining differentiation\"\n",
    "        }}\n",
    "    ]\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Generate ideas using Claude\n",
    "        response = llm.invoke(creative_prompt)\n",
    "        raw_content = response.content.strip()\n",
    "        \n",
    "        print(f\"ðŸ“ Raw response length: {len(raw_content)} chars\")\n",
    "        print(f\"ðŸ“ Response starts with: {raw_content[:50]}...\")\n",
    "        \n",
    "        # Handle markdown code blocks\n",
    "        if raw_content.startswith('```'):\n",
    "            print(\"ðŸ”§ Removing markdown code blocks...\")\n",
    "            # Remove ```json and ``` wrappers\n",
    "            lines = raw_content.split('\\n')\n",
    "            # Remove first line if it's ```json or ```\n",
    "            if lines[0].startswith('```'):\n",
    "                lines = lines[1:]\n",
    "            # Remove last line if it's ```\n",
    "            if lines and lines[-1].strip() == '```':\n",
    "                lines = lines[:-1]\n",
    "            raw_content = '\\n'.join(lines).strip()\n",
    "            print(f\"ðŸ”§ Cleaned content starts with: {raw_content[:50]}...\")\n",
    "        \n",
    "        # Parse JSON response\n",
    "        blog_ideas = json.loads(raw_content)\n",
    "        \n",
    "        print(f\"âœ… Creative agent successfully parsed {len(blog_ideas)} blog ideas\")\n",
    "        return blog_ideas\n",
    "        \n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"âŒ JSON parsing error in creative agent: {e}\")\n",
    "        print(f\"ðŸ“ Cleaned content: {raw_content[:500]}...\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error in creative agent: {e}\")\n",
    "        return []\n",
    "\n",
    "print(\"âœ… Fixed creative agent function ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a3c3251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Creative agent node (direct Pydantic) ready\n"
     ]
    }
   ],
   "source": [
    "# Cell 13: Creative Agent Node (Direct Pydantic)\n",
    "def creative_agent_node(state: AudioPipelineState) -> AudioPipelineState:\n",
    "    \"\"\"Creative agent that generates raw blog ideas as Pydantic objects\"\"\"\n",
    "    \n",
    "    try:\n",
    "        print(\"ðŸŽ¨ Starting creative blog idea generation...\")\n",
    "        \n",
    "        insights = state.get('extracted_insights')\n",
    "        if not insights:\n",
    "            return {**state, \"error\": \"No insights available\", \"status\": \"error\"}\n",
    "        \n",
    "        # Load strategy context\n",
    "        strategy_context = load_company_strategy_context()\n",
    "        \n",
    "        # Generate ideas (returns JSON)\n",
    "        raw_ideas_json = generate_blog_ideas_from_insights(insights, strategy_context)\n",
    "        \n",
    "        # Convert directly to Pydantic objects\n",
    "        raw_blog_ideas = []\n",
    "        for idea_json in raw_ideas_json:\n",
    "            try:\n",
    "                idea = RawBlogIdea(**idea_json)\n",
    "                raw_blog_ideas.append(idea)\n",
    "            except Exception as e:\n",
    "                print(f\"âš ï¸ Skipping invalid idea: {e}\")\n",
    "        \n",
    "        if raw_blog_ideas:\n",
    "            print(f\"ðŸŽ‰ Generated {len(raw_blog_ideas)} valid blog ideas\")\n",
    "            return {\n",
    "                **state,\n",
    "                \"raw_blog_ideas\": raw_blog_ideas,  # Direct Pydantic objects\n",
    "                \"status\": \"raw_ideas_generated\"\n",
    "            }\n",
    "        else:\n",
    "            return {**state, \"error\": \"No valid ideas generated\", \"status\": \"error\"}\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Creative agent error: {e}\")\n",
    "        return {**state, \"error\": str(e), \"status\": \"error\"}\n",
    "\n",
    "print(\"âœ… Creative agent node (direct Pydantic) ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5cabeaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… AssemblyAI connection successful\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 4: Test AssemblyAI Connection\n",
    "# Configure AssemblyAI\n",
    "aai.settings.api_key = os.getenv('ASSEMBLYAI_API_KEY')\n",
    "\n",
    "# Test with a simple transcription (we'll use a file from temp folder)\n",
    "def test_assemblyai_connection():\n",
    "    \"\"\"Test if AssemblyAI is working\"\"\"\n",
    "    try:\n",
    "        # Just test the API key is valid\n",
    "        transcriber = aai.Transcriber()\n",
    "        print(\"âœ… AssemblyAI connection successful\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ AssemblyAI connection failed: {e}\")\n",
    "        return False\n",
    "\n",
    "test_assemblyai_connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01335e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š BATCH PROCESSING INFO:\n",
      "   Files to process: 1\n",
      "   Total size: 19.3 MB\n",
      "\n",
      "ðŸ“ Files found:\n",
      "   1. blog_record_(manuelillo_cto).wav (19.3 MB)\n",
      "\n",
      "ðŸš€ Ready to process 1 files!\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Batch File Discovery and Management\n",
    "def find_audio_files(temp_folder: Path) -> List[Path]:\n",
    "    \"\"\"Find all audio files in temp folder\"\"\"\n",
    "    audio_extensions = ['*.wav', '*.mp3', '*.m4a']\n",
    "    audio_files = []\n",
    "    \n",
    "    for ext in audio_extensions:\n",
    "        audio_files.extend(temp_folder.glob(ext))\n",
    "    \n",
    "    return sorted(audio_files)\n",
    "\n",
    "def display_batch_info(audio_files: List[Path]):\n",
    "    \"\"\"Display information about the batch of files\"\"\"\n",
    "    if not audio_files:\n",
    "        print(\"âŒ No audio files found in temp folder!\")\n",
    "        return False\n",
    "    \n",
    "    total_size_mb = sum(f.stat().st_size for f in audio_files) / (1024 * 1024)\n",
    "    \n",
    "    print(f\"ðŸ“Š BATCH PROCESSING INFO:\")\n",
    "    print(f\"   Files to process: {len(audio_files)}\")\n",
    "    print(f\"   Total size: {total_size_mb:.1f} MB\")\n",
    "    print(f\"\\nðŸ“ Files found:\")\n",
    "    \n",
    "    for i, file_path in enumerate(audio_files, 1):\n",
    "        size_mb = file_path.stat().st_size / (1024 * 1024)\n",
    "        print(f\"   {i}. {file_path.name} ({size_mb:.1f} MB)\")\n",
    "    \n",
    "    return True\n",
    "\n",
    "def cleanup_processed_files(processed_files: List[Path]):\n",
    "    \"\"\"Delete all successfully processed files\"\"\"\n",
    "    print(f\"\\nðŸ—‘ï¸ CLEANUP: Deleting {len(processed_files)} processed files...\")\n",
    "    deleted_count = 0\n",
    "    \n",
    "    for file_path in processed_files:\n",
    "        try:\n",
    "            file_path.unlink()  # Delete file\n",
    "            print(f\"   âœ… Deleted: {file_path.name}\")\n",
    "            deleted_count += 1\n",
    "        except Exception as e:\n",
    "            print(f\"   âŒ Failed to delete {file_path.name}: {e}\")\n",
    "    \n",
    "    print(f\"ðŸ—‘ï¸ Cleanup complete: {deleted_count}/{len(processed_files)} files deleted\")\n",
    "\n",
    "# Discover files in temp folder\n",
    "temp_folder = project_root / 'data' / 'temp'\n",
    "temp_folder.mkdir(parents=True, exist_ok=True)  # Ensure folder exists\n",
    "\n",
    "audio_files = find_audio_files(temp_folder)\n",
    "files_available = display_batch_info(audio_files)\n",
    "\n",
    "if files_available:\n",
    "    print(f\"\\nðŸš€ Ready to process {len(audio_files)} files!\")\n",
    "else:\n",
    "    print(\"\\nðŸ’¡ TIP: Add .wav files to data/temp/ folder for testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c90af3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Batch processing function ready with full insights display\n"
     ]
    }
   ],
   "source": [
    "# Batch Processing Function (Updated with Full Insights Display)\n",
    "def process_audio_batch(audio_files: List[Path], pipeline) -> dict:\n",
    "    \"\"\"Process all audio files in batch with detailed insights display\"\"\"\n",
    "    \n",
    "    if not audio_files:\n",
    "        print(\"âŒ No files to process\")\n",
    "        return {\"processed\": [], \"failed\": [], \"total\": 0}\n",
    "    \n",
    "    print(f\"\\nðŸš€ STARTING BATCH PROCESSING - {len(audio_files)} files\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    processed_files = []\n",
    "    failed_files = []\n",
    "    results = []\n",
    "    \n",
    "    for i, file_path in enumerate(audio_files, 1):\n",
    "        print(f\"\\nðŸ“‚ Processing {i}/{len(audio_files)}: {file_path.name}\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        # Create initial state\n",
    "        initial_state = {\n",
    "            \"file_path\": str(file_path),\n",
    "            \"filename\": file_path.name,\n",
    "            \"transcript_text\": None,\n",
    "            \"conversation_id\": None,\n",
    "            \"extracted_insights\": None,  \n",
    "            \"error\": None,\n",
    "            \"status\": \"processing\"\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            # Run through pipeline\n",
    "            result = pipeline.invoke(initial_state)\n",
    "            \n",
    "            if result[\"status\"] in [\"completed\", \"insights_extracted\"]:\n",
    "                print(f\"âœ… SUCCESS: {file_path.name}\")\n",
    "                print(f\"   Conversation ID: {result['conversation_id']}\")\n",
    "                print(f\"   Transcript preview: {result['transcript_text'][:100]}...\")\n",
    "                \n",
    "                # FULL INSIGHTS DISPLAY\n",
    "                if result.get('extracted_insights'):\n",
    "                    insights = result['extracted_insights']\n",
    "                    print(f\"\\nðŸ§  === EXTRACTED INSIGHTS FOR: {file_path.name} ===\")\n",
    "                    print(\"=\" * 50)\n",
    "                    \n",
    "                    # Speakers\n",
    "                    if insights.speakers:\n",
    "                        print(\"ðŸ‘¥ SPEAKERS:\")\n",
    "                        for speaker in insights.speakers:\n",
    "                            print(f\"   â€¢ Name: {speaker.name or 'Unknown'}\")\n",
    "                            print(f\"     Role: {speaker.role or 'Unknown'}\")  \n",
    "                            print(f\"     Company: {speaker.company or 'Unknown'}\")\n",
    "                    \n",
    "                    # Core Values\n",
    "                    if insights.core_values:\n",
    "                        print(\"ðŸ’Ž CORE VALUES:\")\n",
    "                        for value in insights.core_values:\n",
    "                            print(f\"   â€¢ {value}\")\n",
    "                    \n",
    "                    # Priorities\n",
    "                    if insights.priorities:\n",
    "                        print(\"ðŸŽ¯ PRIORITIES:\")\n",
    "                        for priority in insights.priorities:\n",
    "                            print(f\"   â€¢ {priority}\")\n",
    "                    \n",
    "                    # Primary Challenges\n",
    "                    if insights.primary_challenges:\n",
    "                        print(\"ðŸ”¥ PRIMARY CHALLENGES:\")\n",
    "                        for challenge in insights.primary_challenges:\n",
    "                            print(f\"   â€¢ Challenge: {challenge.description}\")\n",
    "                            print(f\"     Impact: {challenge.impact}\")\n",
    "                            print(f\"     Urgency: {challenge.urgency}\")\n",
    "                    \n",
    "                    # Secondary Challenges\n",
    "                    if insights.secondary_challenges:\n",
    "                        print(\"âš ï¸  SECONDARY CHALLENGES:\")\n",
    "                        for challenge in insights.secondary_challenges:\n",
    "                            print(f\"   â€¢ Challenge: {challenge.description}\")\n",
    "                            print(f\"     Impact: {challenge.impact}\")\n",
    "                            print(f\"     Urgency: {challenge.urgency}\")\n",
    "                    \n",
    "                    # Current Solutions\n",
    "                    if insights.current_solutions:\n",
    "                        print(\"ðŸ”§ CURRENT SOLUTIONS:\")\n",
    "                        for solution in insights.current_solutions:\n",
    "                            print(f\"   â€¢ Solution: {solution.solution}\")\n",
    "                            print(f\"     Satisfaction: {solution.satisfaction_level}\")\n",
    "                            if solution.limitations:\n",
    "                                print(f\"     Limitations: {', '.join(solution.limitations)}\")\n",
    "                    \n",
    "                    # Psychological Needs\n",
    "                    if insights.psychological_needs:\n",
    "                        print(\"ðŸ§˜ PSYCHOLOGICAL NEEDS:\")\n",
    "                        for need in insights.psychological_needs:\n",
    "                            print(f\"   â€¢ {need.description}\")\n",
    "                            print(f\"     Category: {need.need_category}\")\n",
    "                            print(f\"     Intensity: {need.intensity}\")\n",
    "                    \n",
    "                    print(\"ðŸ§  === END INSIGHTS ===\")\n",
    "                    print(\"-\" * 50)\n",
    "                \n",
    "                processed_files.append(file_path)\n",
    "            else:\n",
    "                print(f\"âŒ FAILED: {file_path.name}\")\n",
    "                print(f\"   Status: {result.get('status', 'Unknown')}\")\n",
    "                print(f\"   Error: {result.get('error', 'Unknown error')}\")\n",
    "                failed_files.append(file_path)\n",
    "            \n",
    "            results.append(result)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ PIPELINE ERROR: {file_path.name}\")\n",
    "            print(f\"   Exception: {str(e)}\")\n",
    "            failed_files.append(file_path)\n",
    "            \n",
    "            results.append({\n",
    "                **initial_state,\n",
    "                \"error\": str(e),\n",
    "                \"status\": \"pipeline_error\"\n",
    "            })\n",
    "    \n",
    "    # Final Summary\n",
    "    print(f\"\\nðŸ“Š BATCH PROCESSING COMPLETE!\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"âœ… Successfully processed: {len(processed_files)}\")\n",
    "    print(f\"âŒ Failed: {len(failed_files)}\")\n",
    "    print(f\"ðŸ“ Total files: {len(audio_files)}\")\n",
    "    \n",
    "    if failed_files:\n",
    "        print(f\"\\nâŒ Failed files:\")\n",
    "        for failed_file in failed_files:\n",
    "            print(f\"   - {failed_file.name}\")\n",
    "    \n",
    "    return {\n",
    "        \"processed\": processed_files,\n",
    "        \"failed\": failed_files,\n",
    "        \"total\": len(audio_files),\n",
    "        \"results\": results\n",
    "    }\n",
    "\n",
    "print(\"âœ… Batch processing function ready with full insights display\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "419ae62d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… LangGraph nodes defined\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Define LangGraph Nodes\n",
    "def transcription_node(state: AudioPipelineState) -> AudioPipelineState:\n",
    "    \"\"\"Node 1: Transcribe audio file with AssemblyAI\"\"\"\n",
    "    try:\n",
    "        print(f\"ðŸŽ™ï¸ Transcribing: {state['filename']}\")\n",
    "        \n",
    "        # Configure transcriber\n",
    "        transcriber = aai.Transcriber()\n",
    "        \n",
    "        # Transcribe the file\n",
    "        transcript = transcriber.transcribe(state['file_path'])\n",
    "        \n",
    "        if transcript.status == aai.TranscriptStatus.error:\n",
    "            return {\n",
    "                **state,\n",
    "                \"error\": f\"AssemblyAI error: {transcript.error}\",\n",
    "                \"status\": \"transcription_failed\"\n",
    "            }\n",
    "        \n",
    "        return {\n",
    "            **state,\n",
    "            \"transcript_text\": transcript.text,\n",
    "            \"status\": \"transcribed\"\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            **state,\n",
    "            \"error\": f\"Transcription error: {str(e)}\",\n",
    "            \"status\": \"transcription_failed\"\n",
    "        }\n",
    "\n",
    "def database_saver_node(state: AudioPipelineState) -> AudioPipelineState:\n",
    "    \"\"\"Node 2: Save transcript to database\"\"\"\n",
    "    try:\n",
    "        print(f\"ðŸ’¾ Saving to database: {state['filename']}\")\n",
    "        \n",
    "        # Create conversation object\n",
    "        conversation = ConversationCreate(\n",
    "            title=f\"Audio: {state['filename']}\",\n",
    "            raw_text=state['transcript_text'],\n",
    "            source=\"transcribed\"\n",
    "        )\n",
    "        \n",
    "        # Save to database\n",
    "        conversation_id = db.create_conversation(conversation)\n",
    "        \n",
    "        return {\n",
    "            **state,\n",
    "            \"conversation_id\": conversation_id,\n",
    "            \"status\": \"completed\"\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            **state,\n",
    "            \"error\": f\"Database error: {str(e)}\",\n",
    "            \"status\": \"database_failed\"\n",
    "        }\n",
    "\n",
    "print(\"âœ… LangGraph nodes defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a76e34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pain_extractor_node(state: AudioPipelineState) -> AudioPipelineState:\n",
    "    \"\"\"\n",
    "    LangGraph node: Extract structured insights from conversation transcript\n",
    "    \"\"\"\n",
    "    print(\"ðŸ§  Starting pain extraction...\")\n",
    "    \n",
    "    try:\n",
    "        # Extract insights using OpenAI structured output\n",
    "        insights = extract_insights_from_transcript(state['transcript_text'])\n",
    "        \n",
    "        if insights:\n",
    "            print(f\"âœ… Extracted insights: {len(insights.primary_challenges)} primary challenges, {len(insights.speakers)} speakers\")\n",
    "            \n",
    "            return {\n",
    "                **state,\n",
    "                \"extracted_insights\": insights,\n",
    "                \"status\": \"insights_extracted\"\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                **state,\n",
    "                \"error\": \"Failed to extract insights from transcript\",\n",
    "                \"status\": \"error\"\n",
    "            }\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Pain extraction failed: {e}\")\n",
    "        return {\n",
    "            **state,\n",
    "            \"error\": f\"Pain extraction error: {str(e)}\",\n",
    "            \"status\": \"error\"\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8c379c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… LangGraph pipeline compiled (4 nodes: transcribe â†’ save_to_db â†’ extract_insights â†’ creative_agent)\n"
     ]
    }
   ],
   "source": [
    "# Cell: Build Current Pipeline (4 Nodes) - FIXED\n",
    "def build_pipeline():\n",
    "    \"\"\"Build the current LangGraph workflow with transcription, save, insights, and creative agent\"\"\"\n",
    "    workflow = StateGraph(AudioPipelineState)\n",
    "    \n",
    "    # Add current nodes (use consistent naming - no spaces)\n",
    "    workflow.add_node(\"transcribe\", transcription_node)\n",
    "    workflow.add_node(\"save_to_db\", database_saver_node)  \n",
    "    workflow.add_node(\"extract_insights\", pain_extractor_node)\n",
    "    workflow.add_node(\"creative_agent\", creative_agent_node)  # â† Fixed: no space\n",
    "    \n",
    "    # Chain them together (use exact node names)\n",
    "    workflow.add_edge(\"transcribe\", \"save_to_db\")\n",
    "    workflow.add_edge(\"save_to_db\", \"extract_insights\")\n",
    "    workflow.add_edge(\"extract_insights\", \"creative_agent\")  # â† Fixed: consistent names\n",
    "    \n",
    "    workflow.set_entry_point(\"transcribe\")\n",
    "    workflow.set_finish_point(\"creative_agent\")  # â† Fixed: no space\n",
    "    \n",
    "    return workflow.compile()\n",
    "\n",
    "# Build the pipeline\n",
    "pipeline = build_pipeline()\n",
    "print(\"âœ… LangGraph pipeline compiled (4 nodes: transcribe â†’ save_to_db â†’ extract_insights â†’ creative_agent)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "47a45a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Found 2 conversations to delete:\n",
      "  - ID 14: Audio: blog_record_(manuelillo_cto).wav\n",
      "  - ID 13: Audio: blog_record_(manuel_cto).wav\n",
      "âœ… All conversations deleted!\n",
      "âœ… Related blog ideas deleted!\n",
      "âœ… Processing status cleared!\n"
     ]
    }
   ],
   "source": [
    "# Cell: Clean Conversations Table\n",
    "def clean_conversations_table():\n",
    "    \"\"\"Delete all records from conversations table\"\"\"\n",
    "    \n",
    "    # First show what will be deleted\n",
    "    conversations = db.get_all_conversations()\n",
    "    print(f\"ðŸ“Š Found {len(conversations)} conversations to delete:\")\n",
    "    for conv in conversations[:5]:  # Show first 5\n",
    "        print(f\"  - ID {conv.id}: {conv.title}\")\n",
    "    if len(conversations) > 5:\n",
    "        print(f\"  ... and {len(conversations) - 5} more\")\n",
    "    \n",
    "    # Ask for confirmation\n",
    "    response = input(f\"\\nâ“ Delete all {len(conversations)} conversations? (y/N): \")\n",
    "    \n",
    "    if response.lower() in ['y', 'yes']:\n",
    "        conn = db.get_connection()\n",
    "        try:\n",
    "            cursor = conn.cursor()\n",
    "            \n",
    "            # Delete all conversations (this will also delete related blog_post_ideas due to foreign key)\n",
    "            cursor.execute(\"DELETE FROM blog_post_ideas\")\n",
    "            cursor.execute(\"DELETE FROM processing_status\") \n",
    "            cursor.execute(\"DELETE FROM conversations\")\n",
    "            conn.commit()\n",
    "            \n",
    "            print(\"âœ… All conversations deleted!\")\n",
    "            print(\"âœ… Related blog ideas deleted!\")\n",
    "            print(\"âœ… Processing status cleared!\")\n",
    "            \n",
    "        finally:\n",
    "            conn.close()\n",
    "    else:\n",
    "        print(\"âŒ Deletion cancelled\")\n",
    "\n",
    "# Run the cleaner\n",
    "clean_conversations_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4cb00a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ’¡ Add audio files to data/temp/ folder and rerun this cell\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: Execute Batch Processing with Cleanup\n",
    "if files_available:\n",
    "    print(\"ðŸŽ¯ Starting batch processing...\")\n",
    "    \n",
    "    # Process all files\n",
    "    batch_results = process_audio_batch(audio_files, pipeline)\n",
    "    \n",
    "    # Display summary\n",
    "    print(f\"\\nðŸ“Š BATCH PROCESSING COMPLETE!\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"âœ… Successfully processed: {len(batch_results['processed'])}\")\n",
    "    print(f\"âŒ Failed: {len(batch_results['failed'])}\")\n",
    "    print(f\"ðŸ“ Total files: {batch_results['total']}\")\n",
    "    \n",
    "    # Show failed files\n",
    "    if batch_results['failed']:\n",
    "        print(f\"\\nâŒ Failed files:\")\n",
    "        for file_path in batch_results['failed']:\n",
    "            print(f\"   - {file_path.name}\")\n",
    "    \n",
    "    # Cleanup successfully processed files\n",
    "    if batch_results['processed']:\n",
    "        confirm = input(f\"\\nðŸ—‘ï¸ Delete {len(batch_results['processed'])} processed files? (y/N): \")\n",
    "        if confirm.lower() in ['y', 'yes']:\n",
    "            cleanup_processed_files(batch_results['processed'])\n",
    "        else:\n",
    "            print(\"ðŸ”§ Files kept in temp folder for inspection\")\n",
    "    \n",
    "    print(\"\\nðŸŽ‰ Batch processing complete!\")\n",
    "    \n",
    "else:\n",
    "    print(\"ðŸ’¡ Add audio files to data/temp/ folder and rerun this cell\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eeaef0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Anthropic LLM initialized with Claude Haiku 4.5\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Setup Anthropic LLM for Insights Extraction (FIXED)\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "import json\n",
    "\n",
    "# Initialize Anthropic with correct model name\n",
    "anthropic_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "if not anthropic_key:\n",
    "    print(\"âš ï¸  ANTHROPIC_API_KEY not found in .env file\")\n",
    "    print(\"Please add: ANTHROPIC_API_KEY=your_key_here\")\n",
    "else:\n",
    "    llm = ChatAnthropic(\n",
    "        model=\"claude-haiku-4-5\",  # â† Updated model name\n",
    "        api_key=anthropic_key,\n",
    "        temperature=0.1\n",
    "    )\n",
    "    print(\"âœ… Anthropic LLM initialized with Claude Haiku 4.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6b3cea20",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3. PainExtractor Node Implementation\n",
    "\n",
    "\n",
    "import openai\n",
    "import json\n",
    "from typing import Dict, Any\n",
    "\n",
    "# System prompt\n",
    "PAIN_EXTRACTOR_SYSTEM_PROMPT = \"\"\"\n",
    "You are a UX researcher and business analyst for BigKids Automation. Your job is listening to transcripts from interviews with users and potential clients. \n",
    "\n",
    "You pay special attention to problems that users have regarding how their company is automating, using web apps and AI to save time and move towards a more ethical and sovereign tech infrastructure.\n",
    "\n",
    "You will be given the transcript of an interview with a user or potential client.\n",
    "\n",
    "Your task is to extract structured information about:\n",
    "- Who is speaking and their role\n",
    "- What this person cares about (values, priorities)\n",
    "- Their main primary and secondary challenges\n",
    "- How they are solving problems today\n",
    "- Are there AI agents that can assist them?\n",
    "- Their underlying psychological needs (using frameworks like NVC - Non-Violent Communication)\n",
    "\n",
    "Focus on automation, web apps, AI, time-saving, ethical tech, and sovereign infrastructure themes.\n",
    "\n",
    "Be thorough but concise. \n",
    "\n",
    "IMPORTANT: Only extract information that is explicitly mentioned in the transcript. \n",
    "If information is not clearly stated, leave the field empty/null rather than guessing or inferring.\n",
    "Do not hallucinate or make assumptions about missing information.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9e1c7b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Updated extract_insights_from_transcript with speaker role fix\n"
     ]
    }
   ],
   "source": [
    "# Cell: Extract Insights Function - ROLE FIXED VERSION\n",
    "def extract_insights_from_transcript(transcript: str) -> ExtractedInsights:\n",
    "    \"\"\"Extract structured insights using Anthropic Claude - ROLE FIXED VERSION\"\"\"\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    Analyze this conversation transcript and extract structured insights:\n",
    "    \n",
    "    Transcript: {transcript}\n",
    "    \n",
    "    IMPORTANT: For speaker roles, use ONLY these exact values:\n",
    "    - \"client\" for the person being interviewed/consulted (CTO, CEO, Manager, business owner, etc.)\n",
    "    - \"interviewer\" for the person asking questions or conducting the interview\n",
    "    \n",
    "    Extract the following information in JSON format:\n",
    "    - speakers: List of people mentioned with name, role (client/interviewer only), company\n",
    "    - core_values: What they care about most  \n",
    "    - priorities: Current focus areas\n",
    "    - primary_challenges: Main problems they face with description, impact, urgency\n",
    "    - secondary_challenges: Secondary problems\n",
    "    - current_solutions: How they solve problems now with satisfaction level\n",
    "    - psychological_needs: Underlying needs with category, description, intensity\n",
    "    \n",
    "    Return ONLY valid JSON in this exact structure - no markdown, no code blocks:\n",
    "    {{\n",
    "        \"speakers\": [\n",
    "            {{\"name\": \"Manuel\", \"role\": \"client\", \"company\": \"Drone flytech\"}}\n",
    "        ],\n",
    "        \"core_values\": [\"efficiency\", \"transparency\"],\n",
    "        \"priorities\": [\"improving processes\"],\n",
    "        \"primary_challenges\": [\n",
    "            {{\n",
    "                \"description\": \"Tracking payment issues\",\n",
    "                \"impact\": \"Creates confusion in processes\", \n",
    "                \"urgency\": \"High\"\n",
    "            }}\n",
    "        ],\n",
    "        \"secondary_challenges\": [\n",
    "            {{\n",
    "                \"description\": \"Secondary challenge\",\n",
    "                \"impact\": \"Secondary impact\",\n",
    "                \"urgency\": \"Medium\"\n",
    "            }}\n",
    "        ],\n",
    "        \"current_solutions\": [\n",
    "            {{\n",
    "                \"solution\": \"Current approach\",\n",
    "                \"satisfaction_level\": \"Neutral\",\n",
    "                \"limitations\": [\"limitation1\", \"limitation2\"]\n",
    "            }}\n",
    "        ],\n",
    "        \"psychological_needs\": [\n",
    "            {{\n",
    "                \"need_category\": \"security\",\n",
    "                \"description\": \"Need for confidence\",\n",
    "                \"intensity\": \"High\"\n",
    "            }}\n",
    "        ]\n",
    "    }}\n",
    "    \n",
    "    Remember: \n",
    "    - Use \"client\" for Manuel (even though he's CTO)\n",
    "    - Use \"interviewer\" for the person asking questions\n",
    "    - Use exact urgency values: \"Low\", \"Medium\", \"High\"\n",
    "    - Use exact satisfaction levels: \"Very Satisfied\", \"Satisfied\", \"Neutral\", \"Unsatisfied\", \"Very Unsatisfied\"\n",
    "    - Use exact intensity values: \"Low\", \"Medium\", \"High\"\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Use the Claude LLM you already set up\n",
    "        response = llm.invoke(prompt)\n",
    "        \n",
    "        print(f\"ðŸ“ Raw response length: {len(response.content)} chars\")\n",
    "        print(f\"ðŸ“ Response starts with: {response.content[:50]}...\")\n",
    "        \n",
    "        # Clean markdown code blocks\n",
    "        content = response.content.strip()\n",
    "        if content.startswith('```json'):\n",
    "            print(\"ðŸ”§ Removing JSON markdown blocks...\")\n",
    "            content = content.replace('```json', '').replace('```', '').strip()\n",
    "            print(f\"ðŸ”§ Cleaned content starts with: {content[:50]}...\")\n",
    "        \n",
    "        # Parse the cleaned JSON response\n",
    "        insights_data = json.loads(content)\n",
    "        \n",
    "        # Convert to Pydantic model\n",
    "        result = ExtractedInsights(**insights_data)\n",
    "        print(f\"âœ… Successfully extracted insights with correct speaker roles!\")\n",
    "        return result\n",
    "        \n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"âŒ JSON parsing error: {e}\")\n",
    "        print(f\"ðŸ“ Raw response: {response.content[:500]}...\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error in LLM call: {e}\")\n",
    "        raise\n",
    "\n",
    "print(\"âœ… Updated extract_insights_from_transcript with speaker role fix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c6a3dc7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âŒ No conversation found to test with\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell: Test Fixed Pain Extraction\n",
    "def test_pain_extraction_fix():\n",
    "    \"\"\"Test the fixed pain extraction with your transcript\"\"\"\n",
    "    \n",
    "    # Get the conversation that just failed\n",
    "    conversations = db.get_all_conversations()\n",
    "    latest_conversation = conversations[0] if conversations else None\n",
    "    \n",
    "    if latest_conversation and latest_conversation.raw_text:\n",
    "        print(\"ðŸ§ª Testing fixed pain extraction...\")\n",
    "        print(f\"ðŸ“ Using conversation: {latest_conversation.title}\")\n",
    "        \n",
    "        try:\n",
    "            # Test the fixed extraction\n",
    "            insights = extract_insights_from_transcript(latest_conversation.raw_text)\n",
    "            print(f\"âœ… Success! Extracted {len(insights.primary_challenges)} challenges\")\n",
    "            print(f\"ðŸ‘¥ Found {len(insights.speakers)} speakers\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Still failing: {e}\")\n",
    "            return False\n",
    "    else:\n",
    "        print(\"âŒ No conversation found to test with\")\n",
    "        return False\n",
    "\n",
    "# Test the fix\n",
    "test_pain_extraction_fix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3626c104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“ Found 1 audio files in temp:\n",
      "   blog_record_(manuelillo_cto).wav (19.3 MB)\n"
     ]
    }
   ],
   "source": [
    "# Cell: Audio File Finder Function\n",
    "from pathlib import Path\n",
    "import glob\n",
    "\n",
    "def find_audio_files_in_temp():\n",
    "    \"\"\"Find all audio files in temp folder\"\"\"\n",
    "    temp_folder = Path(\"../data/temp\")  # Adjust path based on notebook location\n",
    "    \n",
    "    if not temp_folder.exists():\n",
    "        print(f\"âŒ Temp folder not found: {temp_folder}\")\n",
    "        return []\n",
    "    \n",
    "    # Find audio files\n",
    "    audio_extensions = ['*.wav', '*.mp3', '*.m4a']\n",
    "    audio_files = []\n",
    "    \n",
    "    for ext in audio_extensions:\n",
    "        files = list(temp_folder.glob(ext))\n",
    "        audio_files.extend(files)\n",
    "    \n",
    "    return sorted(audio_files)\n",
    "\n",
    "# Test the function\n",
    "audio_files = find_audio_files_in_temp()\n",
    "print(f\"ðŸ“ Found {len(audio_files)} audio files in temp:\")\n",
    "for file in audio_files:\n",
    "    size_mb = file.stat().st_size / (1024 * 1024)\n",
    "    print(f\"   {file.name} ({size_mb:.1f} MB)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d3eb0478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§ª EXECUTING COMPLETE 4-NODE PIPELINE TEST...\n",
      "This will test: Audio â†’ Transcribe â†’ Save â†’ Insights â†’ Blog Ideas\n",
      "------------------------------------------------------------\n",
      "ðŸš€ TESTING COMPLETE 4-NODE PIPELINE\n",
      "============================================================\n",
      "Flow: Audio â†’ Transcribe â†’ Save to DB â†’ Extract Insights â†’ Generate Ideas\n",
      "============================================================\n",
      "ðŸ“ Found 1 audio files\n",
      "ðŸŽ¯ Testing with: blog_record_(manuelillo_cto).wav\n",
      "ðŸ“Š File size: 19758.0 KB\n",
      "\n",
      "ðŸŽ¬ STARTING COMPLETE PIPELINE EXECUTION...\n",
      "============================================================\n",
      "â³ Running pipeline.invoke()...\n",
      "ðŸŽ™ï¸ Transcribing: blog_record_(manuelillo_cto).wav\n",
      "ðŸ’¾ Saving to database: blog_record_(manuelillo_cto).wav\n",
      "ðŸ§  Starting pain extraction...\n",
      "ðŸ“ Raw response length: 2538 chars\n",
      "ðŸ“ Response starts with: ```json\n",
      "{\n",
      "    \"speakers\": [\n",
      "        {\"name\": \"Manu...\n",
      "ðŸ”§ Removing JSON markdown blocks...\n",
      "ðŸ”§ Cleaned content starts with: {\n",
      "    \"speakers\": [\n",
      "        {\"name\": \"Manuel\", \"ro...\n",
      "âœ… Successfully extracted insights with correct speaker roles!\n",
      "âœ… Extracted insights: 3 primary challenges, 1 speakers\n",
      "ðŸŽ¨ Starting creative blog idea generation...\n",
      "âœ… Loaded company strategy (6555 chars)\n",
      "âœ… Loaded SEO strategy (5566 chars)\n",
      "ðŸ“ Raw response length: 4060 chars\n",
      "ðŸ“ Response starts with: ```json\n",
      "[\n",
      "    {\n",
      "        \"title\": \"From Chaos to Cl...\n",
      "ðŸ”§ Removing markdown code blocks...\n",
      "ðŸ”§ Cleaned content starts with: [\n",
      "    {\n",
      "        \"title\": \"From Chaos to Clarity: H...\n",
      "âœ… Creative agent successfully parsed 5 blog ideas\n",
      "ðŸŽ‰ Generated 5 valid blog ideas\n",
      "\n",
      "ðŸ“Š COMPLETE PIPELINE RESULTS:\n",
      "============================================================\n",
      "ðŸŽ¯ Final Status: raw_ideas_generated\n",
      "\n",
      "ðŸ“‹ STAGE RESULTS:\n",
      "   ðŸŽ™ï¸  Transcription: âœ…\n",
      "   ðŸ’¾ Database Save: âœ…\n",
      "   ðŸ§  Insights Extraction: âœ…\n",
      "   ðŸŽ¨ Blog Ideas Generation: âœ…\n",
      "\n",
      "ðŸŽ‰ COMPLETE SUCCESS! End-to-end pipeline worked!\n",
      "======================================================================\n",
      "ðŸ“ Conversation ID: 14\n",
      "ðŸ“Š Transcript Length: 1688 characters\n",
      "ðŸ§  Extracted Insights:\n",
      "   ðŸ‘¥ Speakers: 1\n",
      "   ðŸ”¥ Primary Challenges: 3\n",
      "   ðŸ§˜ Psychological Needs: 4\n",
      "   ðŸ’Ž Core Values: 5\n",
      "\n",
      "ðŸŽ¨ Generated Blog Ideas (5):\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "ðŸ’¡ IDEA 1:\n",
      "   ðŸ“ Title: From Chaos to Clarity: How Automation Fixes Invoice Tracking Without Losing Control\n",
      "   ðŸ“„ Description: A practical guide exploring how SMEs can implement AI-powered invoice tracking systems that provide ...\n",
      "   ðŸŽ¯ Target Audience: Finance managers and business owners at SMEs struggling with manual invoice tracking and payment visibility\n",
      "   ðŸ“ˆ Business Value: Directly addresses high-urgency pain points (tracking, visibility, confidence) while positioning Big Kids as a trusted guide for financial automation\n",
      "\n",
      "ðŸ’¡ IDEA 2:\n",
      "   ðŸ“ Title: The Hidden Cost of 'Good Enough' Invoicing Software: When to Automate Instead of Tolerate\n",
      "   ðŸ“„ Description: An honest exploration of why off-the-shelf invoicing solutions often fail growing businesses, and ho...\n",
      "   ðŸŽ¯ Target Audience: Founders and finance leads at scaling SMEs currently dissatisfied with existing SaaS solutions\n",
      "   ðŸ“ˆ Business Value: Speaks directly to Manuel's MoneyOak dissatisfaction; positions custom automation as the intelligent alternative\n",
      "\n",
      "ðŸ’¡ IDEA 3:\n",
      "   ðŸ“ Title: Building Financial Transparency: How Automation Scales Your Invoicing Without Scaling Your Headaches\n",
      "   ðŸ“„ Description: A deep dive into how AI and automation handle the complexity of multi-client invoicing as businesses...\n",
      "   ðŸŽ¯ Target Audience: Operations managers and finance teams at rapidly growing service-based businesses\n",
      "   ðŸ“ˆ Business Value: Addresses urgency around managing complexity; attracts growth-stage companies before they become too large to help\n",
      "\n",
      "ðŸ’¡ IDEA 4:\n",
      "   ðŸ“ Title: Trust the System: How Transparent Automation Reduces Financial Anxiety in Growing Teams\n",
      "   ðŸ“„ Description: Explores the psychological and operational benefits of automating financial processesâ€”moving from an...\n",
      "   ðŸŽ¯ Target Audience: Business owners and finance leaders seeking to reduce operational stress and build team confidence\n",
      "   ðŸ“ˆ Business Value: Aligns with Big Kids' values (care, work smart not hard) while addressing Manuel's core psychological needs (confidence, peace of mind, trust)\n",
      "\n",
      "ðŸ’¡ IDEA 5:\n",
      "   ðŸ“ Title: Custom Invoice Automation for Service Businesses: When Off-the-Shelf Tools Aren't Enough\n",
      "   ðŸ“„ Description: A practical playbook for building custom invoicing solutions tailored to unique business models. Cov...\n",
      "   ðŸŽ¯ Target Audience: Service-based SME owners with complex or non-standard invoicing needs\n",
      "   ðŸ“ˆ Business Value: Directly supports SEO strategy around GenAI business value; generates qualified leads ready for custom automation conversations\n",
      "======================================================================\n",
      "ðŸŽ‰ COMPLETE 4-NODE PIPELINE: SUCCESS!\n",
      "âœ… System is working end-to-end!\n",
      "ðŸš€ Ready to build Node 5 (Analyst Agent)\n",
      "\n",
      "ðŸ“‹ FINAL TEST SUMMARY:\n",
      "   Test Status: SUCCESS\n",
      "   Pipeline Status: raw_ideas_generated\n",
      "   Blog Ideas Generated: 5\n"
     ]
    }
   ],
   "source": [
    "# Cell: Complete 4-Node Pipeline Test\n",
    "def test_complete_4_node_pipeline():\n",
    "    \"\"\"Test the complete pipeline: Audio â†’ Transcribe â†’ Save â†’ Insights â†’ Blog Ideas\"\"\"\n",
    "    \n",
    "    print(\"ðŸš€ TESTING COMPLETE 4-NODE PIPELINE\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Flow: Audio â†’ Transcribe â†’ Save to DB â†’ Extract Insights â†’ Generate Ideas\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Check if pipeline is built\n",
    "    if 'pipeline' not in globals():\n",
    "        print(\"âŒ Pipeline not found!\")\n",
    "        print(\"ðŸ’¡ Please run the build_pipeline() cell first\")\n",
    "        return None\n",
    "    \n",
    "    # Find audio files in temp\n",
    "    audio_files = find_audio_files_in_temp()\n",
    "    \n",
    "    if not audio_files:\n",
    "        print(\"âŒ No audio files found in data/temp/ folder\")\n",
    "        print(\"\\nðŸ’¡ SOLUTIONS:\")\n",
    "        print(\"   1. Add a .wav file manually to data/temp/\")\n",
    "        print(\"   2. Disable cleanup in file_monitor.py and upload new file\")\n",
    "        print(\"   3. Copy an existing audio file:\")\n",
    "        print(\"      cp /path/to/audio.wav data/temp/test_file.wav\")\n",
    "        return None\n",
    "    \n",
    "    # Use the first audio file\n",
    "    test_file = audio_files[0]\n",
    "    print(f\"ðŸ“ Found {len(audio_files)} audio files\")\n",
    "    print(f\"ðŸŽ¯ Testing with: {test_file.name}\")\n",
    "    print(f\"ðŸ“Š File size: {test_file.stat().st_size / 1024:.1f} KB\")\n",
    "    \n",
    "    # Create initial state for complete 4-node pipeline\n",
    "    initial_state = {\n",
    "        \"file_path\": str(test_file),\n",
    "        \"filename\": test_file.name,\n",
    "        \"transcript_text\": None,           # Will be filled by Node 1\n",
    "        \"conversation_id\": None,           # Will be filled by Node 2  \n",
    "        \"extracted_insights\": None,        # Will be filled by Node 3\n",
    "        \"raw_blog_ideas\": None,            # Will be filled by Node 4\n",
    "        \"scored_blog_ideas\": None,         # For future Node 5\n",
    "        \"saved_idea_ids\": None,            # For future Node 6\n",
    "        \"error\": None,\n",
    "        \"status\": \"processing\"\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nðŸŽ¬ STARTING COMPLETE PIPELINE EXECUTION...\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    try:\n",
    "        # Execute the complete 4-node pipeline\n",
    "        print(\"â³ Running pipeline.invoke()...\")\n",
    "        final_state = pipeline.invoke(initial_state)\n",
    "        \n",
    "        print(f\"\\nðŸ“Š COMPLETE PIPELINE RESULTS:\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # Check final status\n",
    "        final_status = final_state.get('status', 'unknown')\n",
    "        print(f\"ðŸŽ¯ Final Status: {final_status}\")\n",
    "        \n",
    "        # Check each stage\n",
    "        print(f\"\\nðŸ“‹ STAGE RESULTS:\")\n",
    "        print(f\"   ðŸŽ™ï¸  Transcription: {'âœ…' if final_state.get('transcript_text') else 'âŒ'}\")\n",
    "        print(f\"   ðŸ’¾ Database Save: {'âœ…' if final_state.get('conversation_id') else 'âŒ'}\")\n",
    "        print(f\"   ðŸ§  Insights Extraction: {'âœ…' if final_state.get('extracted_insights') else 'âŒ'}\")\n",
    "        print(f\"   ðŸŽ¨ Blog Ideas Generation: {'âœ…' if final_state.get('raw_blog_ideas') else 'âŒ'}\")\n",
    "        \n",
    "        # Show detailed results if successful\n",
    "        if final_state.get('raw_blog_ideas'):\n",
    "            ideas = final_state['raw_blog_ideas']\n",
    "            insights = final_state.get('extracted_insights')\n",
    "            \n",
    "            print(f\"\\nðŸŽ‰ COMPLETE SUCCESS! End-to-end pipeline worked!\")\n",
    "            print(\"=\" * 70)\n",
    "            print(f\"ðŸ“ Conversation ID: {final_state.get('conversation_id')}\")\n",
    "            print(f\"ðŸ“Š Transcript Length: {len(final_state.get('transcript_text', ''))} characters\")\n",
    "            \n",
    "            if insights:\n",
    "                print(f\"ðŸ§  Extracted Insights:\")\n",
    "                print(f\"   ðŸ‘¥ Speakers: {len(insights.speakers)}\")\n",
    "                print(f\"   ðŸ”¥ Primary Challenges: {len(insights.primary_challenges)}\")\n",
    "                print(f\"   ðŸ§˜ Psychological Needs: {len(insights.psychological_needs)}\")\n",
    "                print(f\"   ðŸ’Ž Core Values: {len(insights.core_values)}\")\n",
    "            \n",
    "            print(f\"\\nðŸŽ¨ Generated Blog Ideas ({len(ideas)}):\")\n",
    "            print(\"-\" * 70)\n",
    "            \n",
    "            for i, idea in enumerate(ideas, 1):\n",
    "                print(f\"\\nðŸ’¡ IDEA {i}:\")\n",
    "                # Handle both dict and Pydantic object formats\n",
    "                if hasattr(idea, 'title'):\n",
    "                    # Pydantic object\n",
    "                    print(f\"   ðŸ“ Title: {idea.title}\")\n",
    "                    print(f\"   ðŸ“„ Description: {idea.description[:100]}...\")\n",
    "                    print(f\"   ðŸŽ¯ Target Audience: {idea.target_audience}\")\n",
    "                    print(f\"   ðŸ“ˆ Business Value: {idea.business_value}\")\n",
    "                else:\n",
    "                    # Dictionary\n",
    "                    print(f\"   ðŸ“ Title: {idea.get('title', 'No title')}\")\n",
    "                    print(f\"   ðŸ“„ Description: {idea.get('description', 'No description')[:100]}...\")\n",
    "                    print(f\"   ðŸŽ¯ Target Audience: {idea.get('target_audience', 'Unknown')}\")\n",
    "                    print(f\"   ðŸ“ˆ Business Value: {idea.get('business_value', 'Unknown')}\")\n",
    "            \n",
    "            print(\"=\" * 70)\n",
    "            print(\"ðŸŽ‰ COMPLETE 4-NODE PIPELINE: SUCCESS!\")\n",
    "            print(\"âœ… System is working end-to-end!\")\n",
    "            print(\"ðŸš€ Ready to build Node 5 (Analyst Agent)\")\n",
    "            \n",
    "            return final_state\n",
    "            \n",
    "        else:\n",
    "            # Pipeline failed somewhere\n",
    "            print(f\"\\nâŒ PIPELINE INCOMPLETE\")\n",
    "            print(\"=\" * 50)\n",
    "            \n",
    "            error_msg = final_state.get('error', 'No specific error message')\n",
    "            print(f\"âŒ Error: {error_msg}\")\n",
    "            print(f\"ðŸ” Status: {final_status}\")\n",
    "            \n",
    "            # Debug info\n",
    "            print(f\"\\nðŸ” DEBUG INFO:\")\n",
    "            print(f\"   Transcript exists: {bool(final_state.get('transcript_text'))}\")\n",
    "            if final_state.get('transcript_text'):\n",
    "                print(f\"   Transcript preview: {final_state['transcript_text'][:100]}...\")\n",
    "            print(f\"   Insights exist: {bool(final_state.get('extracted_insights'))}\")\n",
    "            print(f\"   Ideas exist: {bool(final_state.get('raw_blog_ideas'))}\")\n",
    "            \n",
    "            return final_state\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nâŒ COMPLETE PIPELINE EXECUTION FAILED!\")\n",
    "        print(\"=\" * 60)\n",
    "        print(f\"ðŸ’¥ Exception: {str(e)}\")\n",
    "        \n",
    "        # Show full traceback for debugging\n",
    "        import traceback\n",
    "        print(f\"\\nðŸ” FULL ERROR TRACEBACK:\")\n",
    "        traceback.print_exc()\n",
    "        \n",
    "        print(f\"\\nðŸ’¡ DEBUGGING TIPS:\")\n",
    "        print(\"   1. Check if all 4 nodes are properly defined\")\n",
    "        print(\"   2. Verify AssemblyAI API key is working\")\n",
    "        print(\"   3. Check Anthropic API key is working\")\n",
    "        print(\"   4. Ensure audio file is not corrupted\")\n",
    "        \n",
    "        return None\n",
    "\n",
    "# Execute the complete pipeline test\n",
    "print(\"ðŸ§ª EXECUTING COMPLETE 4-NODE PIPELINE TEST...\")\n",
    "print(\"This will test: Audio â†’ Transcribe â†’ Save â†’ Insights â†’ Blog Ideas\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "complete_test_result = test_complete_4_node_pipeline()\n",
    "\n",
    "# Show final summary\n",
    "if complete_test_result:\n",
    "    print(f\"\\nðŸ“‹ FINAL TEST SUMMARY:\")\n",
    "    print(f\"   Test Status: {'SUCCESS' if complete_test_result.get('raw_blog_ideas') else 'PARTIAL/FAILED'}\")\n",
    "    print(f\"   Pipeline Status: {complete_test_result.get('status', 'unknown')}\")\n",
    "    print(f\"   Blog Ideas Generated: {len(complete_test_result.get('raw_blog_ideas', []))}\")\n",
    "else:\n",
    "    print(f\"\\nðŸ“‹ FINAL TEST SUMMARY:\")\n",
    "    print(f\"   Test Status: FAILED\")\n",
    "    print(f\"   Pipeline could not complete execution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4465cb3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded company strategy (6555 chars)\n",
      "âœ… Loaded SEO strategy (1120 chars)\n",
      "âœ… Loaded content strategy (4469 chars)\n",
      "âœ… Enhanced strategy context for scoring with 3 documents\n",
      "   Company strategy: 6555 chars\n",
      "   SEO strategy: 1120 chars\n",
      "   Content strategy: 4469 chars\n"
     ]
    }
   ],
   "source": [
    "# Cell 16: Enhanced Strategy Context for Scoring (Updated for 3 Documents)\n",
    "def prepare_strategy_context_for_scoring():\n",
    "    \"\"\"Prepare strategy context for scoring using all three strategy documents\"\"\"\n",
    "    \n",
    "    # Load all three strategy documents\n",
    "    strategy_context = load_company_strategy_context()\n",
    "    \n",
    "    # Add scoring guidelines\n",
    "    strategy_context[\"scoring_guidelines\"] = \"\"\"\n",
    "    SCORING CRITERIA (1-10 scale):\n",
    "    \n",
    "    1. usefulness_potential: How useful will this post be to readers with problems?\n",
    "    2. fitwith_seo_strategy: How well does this align with our SEO strategy and keywords?\n",
    "    3. fitwith_content_strategy: How well does this fit our content strategy and voice?\n",
    "    4. inspiration_potential: How likely is this to inspire readers to take action?\n",
    "    5. collaboration_potential: How likely is this to encourage prospects to contact us?\n",
    "    6. innovation: How unique/differentiated is this topic (10 = very unique)?\n",
    "    7. difficulty: How complex is this to write (1 = easy, 10 = very complex)?\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create summaries for LLM prompt efficiency (all three documents)\n",
    "    if strategy_context.get('company_strategy'):\n",
    "        strategy_context[\"company_strategy_summary\"] = strategy_context['company_strategy'][:800] + \"...\"\n",
    "    \n",
    "    if strategy_context.get('seo_strategy'):\n",
    "        strategy_context[\"seo_strategy_summary\"] = strategy_context['seo_strategy'][:600] + \"...\"\n",
    "    \n",
    "    if strategy_context.get('content_strategy'):  # NEW\n",
    "        strategy_context[\"content_strategy_summary\"] = strategy_context['content_strategy'][:600] + \"...\"\n",
    "    \n",
    "    print(f\"âœ… Enhanced strategy context for scoring with 3 documents\")\n",
    "    print(f\"   Company strategy: {len(strategy_context.get('company_strategy', ''))} chars\")\n",
    "    print(f\"   SEO strategy: {len(strategy_context.get('seo_strategy', ''))} chars\")\n",
    "    print(f\"   Content strategy: {len(strategy_context.get('content_strategy', ''))} chars\")\n",
    "    \n",
    "    return strategy_context\n",
    "\n",
    "# Test the enhanced context\n",
    "enhanced_context = prepare_strategy_context_for_scoring()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "32abca70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Updated LLM scoring engine with content strategy context\n"
     ]
    }
   ],
   "source": [
    "# Cell 17: Updated Scoring Engine with Content Strategy Context\n",
    "def score_blog_idea_with_llm(idea: dict, strategy_context: dict, conversation_context: str = \"\") -> dict:\n",
    "    \"\"\"Score a single blog idea using LLM with all three strategy contexts\"\"\"\n",
    "    \n",
    "    scoring_prompt = f\"\"\"\n",
    "    You are an expert content strategist for Big Kids Automation. Score this blog post idea on a 1-10 scale using our strategic context.\n",
    "    \n",
    "    COMPANY STRATEGY:\n",
    "    {strategy_context.get('company_strategy_summary', 'Not available')}\n",
    "    \n",
    "    SEO STRATEGY:\n",
    "    {strategy_context.get('seo_strategy_summary', 'Not available')}\n",
    "    \n",
    "    CONTENT STRATEGY:\n",
    "    {strategy_context.get('content_strategy_summary', 'Not available')}\n",
    "    \n",
    "    BLOG IDEA TO SCORE:\n",
    "    Title: {idea.get('title', 'No title')}\n",
    "    Description: {idea.get('description', 'No description')}\n",
    "    Target Audience: {idea.get('target_audience', 'Unknown')}\n",
    "    Business Value: {idea.get('business_value', 'Unknown')}\n",
    "    Content Angle: {idea.get('content_angle', 'Unknown')}\n",
    "    \n",
    "    CONVERSATION CONTEXT:\n",
    "    {conversation_context[:300] if conversation_context else 'No context available'}...\n",
    "    \n",
    "    SCORING INSTRUCTIONS:\n",
    "    Rate each criterion from 1-10 (10 = excellent, 1 = poor):\n",
    "    \n",
    "    1. usefulness_potential: How useful will this be to readers with real problems?\n",
    "    2. fitwith_seo_strategy: How well does this align with our SEO keywords and strategy?\n",
    "    3. fitwith_content_strategy: How well does this fit our content strategy, voice, and approach?\n",
    "    4. inspiration_potential: How likely to inspire readers to take meaningful action?\n",
    "    5. collaboration_potential: How likely to generate leads/prospects who contact us?\n",
    "    6. innovation: How unique is this topic compared to existing content?\n",
    "    7. difficulty: How complex/time-consuming will this be to write? (1=easy, 10=very hard)\n",
    "    \n",
    "    Return ONLY valid JSON with your scores and brief reasoning:\n",
    "    {{\n",
    "        \"usefulness_potential\": 8,\n",
    "        \"fitwith_seo_strategy\": 7,\n",
    "        \"fitwith_content_strategy\": 9,\n",
    "        \"inspiration_potential\": 6,\n",
    "        \"collaboration_potential\": 8,\n",
    "        \"innovation\": 7,\n",
    "        \"difficulty\": 4,\n",
    "        \"reasoning\": \"This idea scores well because it aligns with our content strategy focus on...\"\n",
    "    }}\n",
    "    \"\"\"\n",
    "    \n",
    "    # ... rest of the function stays the same\n",
    "    try:\n",
    "        response = llm.invoke(scoring_prompt)\n",
    "        \n",
    "        content = response.content.strip()\n",
    "        if content.startswith('```json'):\n",
    "            content = content.replace('```json', '').replace('```', '').strip()\n",
    "        \n",
    "        scores = json.loads(content)\n",
    "        \n",
    "        # Validate scores are in range\n",
    "        for criterion in ['usefulness_potential', 'fitwith_seo_strategy', 'fitwith_content_strategy', \n",
    "                         'inspiration_potential', 'collaboration_potential', 'innovation', 'difficulty']:\n",
    "            if criterion in scores:\n",
    "                scores[criterion] = max(1, min(10, scores[criterion]))\n",
    "        \n",
    "        # Calculate total score\n",
    "        total_score = sum([\n",
    "            scores.get('usefulness_potential', 5),\n",
    "            scores.get('fitwith_seo_strategy', 5),\n",
    "            scores.get('fitwith_content_strategy', 5),\n",
    "            scores.get('inspiration_potential', 5),\n",
    "            scores.get('collaboration_potential', 5),\n",
    "            scores.get('innovation', 5),\n",
    "            scores.get('difficulty', 5)\n",
    "        ])\n",
    "        \n",
    "        scores['total_score'] = total_score\n",
    "        return scores\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error scoring idea: {e}\")\n",
    "        return {\n",
    "            \"usefulness_potential\": 5, \"fitwith_seo_strategy\": 5, \"fitwith_content_strategy\": 5,\n",
    "            \"inspiration_potential\": 5, \"collaboration_potential\": 5, \"innovation\": 5,\n",
    "            \"difficulty\": 5, \"total_score\": 35, \"reasoning\": f\"Default scores due to error: {str(e)}\"\n",
    "        }\n",
    "\n",
    "print(\"âœ… Updated LLM scoring engine with content strategy context\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e7786fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§ª Testing three-document strategy loading...\n",
      "âœ… Loaded company strategy (6555 chars)\n",
      "âœ… Loaded SEO strategy (1120 chars)\n",
      "âœ… Loaded content strategy (4469 chars)\n",
      "âœ… Loaded company strategy (6555 chars)\n",
      "âœ… Loaded SEO strategy (1120 chars)\n",
      "âœ… Loaded content strategy (4469 chars)\n",
      "âœ… Enhanced strategy context for scoring with 3 documents\n",
      "   Company strategy: 6555 chars\n",
      "   SEO strategy: 1120 chars\n",
      "   Content strategy: 4469 chars\n",
      "\n",
      "ðŸ“Š DOCUMENT SUMMARY:\n",
      "   company_strategy: âœ… Loaded (6555 chars)\n",
      "   seo_strategy: âœ… Loaded (1120 chars)\n",
      "   content_strategy: âœ… Loaded (4469 chars)\n"
     ]
    }
   ],
   "source": [
    "# Cell: Test Three-Document Strategy Loading\n",
    "def test_three_document_loading():\n",
    "    \"\"\"Test loading all three strategy documents\"\"\"\n",
    "    \n",
    "    print(\"ðŸ§ª Testing three-document strategy loading...\")\n",
    "    \n",
    "    # Test basic loading\n",
    "    context = load_company_strategy_context()\n",
    "    \n",
    "    # Test enhanced loading for scoring\n",
    "    enhanced = prepare_strategy_context_for_scoring()\n",
    "    \n",
    "    print(f\"\\nðŸ“Š DOCUMENT SUMMARY:\")\n",
    "    for doc_type in ['company_strategy', 'seo_strategy', 'content_strategy']:\n",
    "        if doc_type in context:\n",
    "            length = len(context[doc_type]) if context[doc_type] else 0\n",
    "            status = \"âœ… Loaded\" if length > 100 else \"âš ï¸ Missing/Short\"\n",
    "            print(f\"   {doc_type}: {status} ({length} chars)\")\n",
    "    \n",
    "    return context\n",
    "\n",
    "# Run the test\n",
    "test_context = test_three_document_loading()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dd27f3e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§ª Testing Analyst Agent Components...\n",
      "ðŸ“ Sample idea: From Chaos to Clarity: How Automation Fixes Invoic...\n",
      "âœ… Loaded company strategy (6555 chars)\n",
      "âœ… Loaded SEO strategy (1120 chars)\n",
      "âœ… Loaded content strategy (4469 chars)\n",
      "âœ… Enhanced strategy context for scoring with 3 documents\n",
      "   Company strategy: 6555 chars\n",
      "   SEO strategy: 1120 chars\n",
      "   Content strategy: 4469 chars\n",
      "\n",
      "ðŸ“Š SCORING RESULTS:\n",
      "   Usefulness: 8/10\n",
      "   SEO Fit: 8/10\n",
      "   Content Fit: 7/10\n",
      "   Inspiration: 6/10\n",
      "   Collaboration: 8/10\n",
      "   Innovation: 0/10\n",
      "   Difficulty: 4/10\n",
      "   TOTAL SCORE: 46/70\n",
      "\n",
      "ðŸ’­ Reasoning: Strong alignment with SME pain points and long-tail keywords ('business process automation for small companies', 'how to implement AI in small business workflows'). Directly addresses high-urgency finance problems. However, the content angle is undefined and the title leans toward operational efficiency rather than the deeper philosophical relationship with tech that defines Big Kids' mission. The 'Without Losing Control' framing hints at trust/transparency but needs stronger connection to curiosity, comprehension, and the human-tech alliance. The piece risks becoming a standard automation how-to rather than exploring *why* SMEs should rethink their relationship with these tools. Recommend clarifying the angle to emphasize understanding and intentionality over just solving the problemâ€”this would elevate fit with content strategy and inspiration potential.\n"
     ]
    }
   ],
   "source": [
    "def test_analyst_components():\n",
    "    \"\"\"Test the analyst agent components using existing functions\"\"\"\n",
    "    \n",
    "    # Sample idea from your recent pipeline success\n",
    "    sample_idea = {\n",
    "        \"title\": \"From Chaos to Clarity: How Automation Fixes Invoice Tracking Without Losing Control\",\n",
    "        \"description\": \"A practical guide exploring how SMEs can implement AI-powered invoice tracking systems...\",\n",
    "        \"target_audience\": \"Finance managers and business owners at SMEs struggling with manual invoice tracking\",\n",
    "        \"business_value\": \"Directly addresses high-urgency pain points while positioning Big Kids as trusted guide\"\n",
    "    }\n",
    "    \n",
    "    print(\"ðŸ§ª Testing Analyst Agent Components...\")\n",
    "    print(f\"ðŸ“ Sample idea: {sample_idea['title'][:50]}...\")\n",
    "    \n",
    "    # Use the enhanced existing function\n",
    "    context = prepare_strategy_context_for_scoring()\n",
    "    \n",
    "    # Score the idea\n",
    "    scores = score_blog_idea_with_llm(sample_idea, context)\n",
    "    \n",
    "    print(f\"\\nðŸ“Š SCORING RESULTS:\")\n",
    "    print(f\"   Usefulness: {scores.get('usefulness_potential', 0)}/10\")\n",
    "    print(f\"   SEO Fit: {scores.get('fitwith_seo_strategy', 0)}/10\") \n",
    "    print(f\"   Content Fit: {scores.get('fitwith_content_strategy', 0)}/10\")\n",
    "    print(f\"   Inspiration: {scores.get('inspiration_potential', 0)}/10\")\n",
    "    print(f\"   Collaboration: {scores.get('collaboration_potential', 0)}/10\")\n",
    "    print(f\"   Innovation: {scores.get('innovation', 0)}/10\")\n",
    "    print(f\"   Difficulty: {scores.get('difficulty', 0)}/10\")\n",
    "    print(f\"   TOTAL SCORE: {scores.get('total_score', 0)}/70\")\n",
    "    \n",
    "    if scores.get('reasoning'):\n",
    "        print(f\"\\nðŸ’­ Reasoning: {scores['reasoning']}\")\n",
    "    \n",
    "    return scores\n",
    "\n",
    "# Run the test with existing functions\n",
    "test_scores = test_analyst_components()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
