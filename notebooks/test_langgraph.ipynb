{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94470f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“ Current directory: /home/manuel/Documents/tech/ai_content_ops/notebooks\n",
      "ðŸ“ Current directory name: notebooks\n",
      "ðŸ“ Project root: /home/manuel/Documents/tech/ai_content_ops\n",
      "ðŸ“ Database path: /home/manuel/Documents/tech/ai_content_ops/database\n",
      "âœ… Database folder exists: True\n",
      "âœ… Added to Python path: /home/manuel/Documents/tech/ai_content_ops\n",
      "\n",
      "ðŸ“‹ Python path (first 3):\n",
      "   1. /home/manuel/Documents/tech/ai_content_ops\n",
      "   2. /usr/lib/python313.zip\n",
      "   3. /usr/lib/python3.13\n",
      "âœ… Standard library imports loaded\n",
      "âœ… Loaded .env from: /home/manuel/Documents/tech/ai_content_ops/.env\n",
      "âœ… Third-party imports loaded\n",
      "âœ… Database imports loaded\n",
      "\n",
      "ðŸŽ‰ All imports loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CELL 1: IMPORTS & SETUP\n",
    "# ============================================================\n",
    "\n",
    "# --- PATH SETUP (MUST BE FIRST) ---\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Get current directory (should be notebooks/)\n",
    "current_dir = Path.cwd()\n",
    "print(f\"ðŸ“ Current directory: {current_dir}\")\n",
    "print(f\"ðŸ“ Current directory name: {current_dir.name}\")\n",
    "\n",
    "# Go up one level to project root\n",
    "project_root = current_dir.parent\n",
    "print(f\"ðŸ“ Project root: {project_root}\")\n",
    "\n",
    "# Verify database folder exists\n",
    "database_path = project_root / 'database'\n",
    "print(f\"ðŸ“ Database path: {database_path}\")\n",
    "print(f\"âœ… Database folder exists: {database_path.exists()}\")\n",
    "\n",
    "# Add project root to Python path\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "    print(f\"âœ… Added to Python path: {project_root}\")\n",
    "else:\n",
    "    print(f\"âœ… Already in Python path\")\n",
    "\n",
    "print(f\"\\nðŸ“‹ Python path (first 3):\")\n",
    "for i, p in enumerate(sys.path[:3], 1):\n",
    "    print(f\"   {i}. {p}\")\n",
    "\n",
    "\n",
    "# --- STANDARD LIBRARY IMPORTS ---\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import sqlite3\n",
    "import glob\n",
    "from typing import TypedDict, Optional, List, Dict, Any\n",
    "from datetime import datetime\n",
    "from enum import Enum\n",
    "\n",
    "print(\"âœ… Standard library imports loaded\")\n",
    "\n",
    "\n",
    "# --- ENVIRONMENT & CONFIGURATION ---\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from project root\n",
    "env_path = project_root / '.env'\n",
    "if env_path.exists():\n",
    "    load_dotenv(env_path)\n",
    "    print(f\"âœ… Loaded .env from: {env_path}\")\n",
    "else:\n",
    "    print(f\"âš ï¸  .env not found at: {env_path}\")\n",
    "\n",
    "\n",
    "# --- THIRD-PARTY ML/AI ---\n",
    "import assemblyai as aai\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langgraph.graph import StateGraph\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "print(\"âœ… Third-party imports loaded\")\n",
    "\n",
    "\n",
    "# --- DATABASE IMPORTS ---\n",
    "from database.db_operations import db\n",
    "from database.models import Conversation, ConversationCreate\n",
    "\n",
    "print(\"âœ… Database imports loaded\")\n",
    "print(\"\\nðŸŽ‰ All imports loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb001904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AssemblyAI API Key loaded: âœ…\n",
      "Key starts with: 972365f41d...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Cell 2 \n",
    "\n",
    "# Test API key\n",
    "assemblyai_key = os.getenv('ASSEMBLYAI_API_KEY')\n",
    "print(f\"AssemblyAI API Key loaded: {'âœ…' if assemblyai_key else 'âŒ'}\")\n",
    "print(f\"Key starts with: {assemblyai_key[:10] if assemblyai_key else 'None'}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08a6571a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… LangSmith tracing enabled\n",
      "   Project: ai_content_ops\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CELL 3: LANGSMITH TRACING SETUP (OPTIONAL)\n",
    "# ============================================================\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables if not already loaded\n",
    "load_dotenv()\n",
    "\n",
    "# Get LangSmith API key from environment\n",
    "langsmith_api_key = os.getenv(\"LANGSMITH_API_KEY\")\n",
    "\n",
    "if langsmith_api_key:\n",
    "    # Enable LangSmith tracing\n",
    "    os.environ[\"LANGSMITH_API_KEY\"] = langsmith_api_key\n",
    "    os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "    os.environ[\"LANGCHAIN_PROJECT\"] = \"ai_content_ops\"\n",
    "    print(\"âœ… LangSmith tracing enabled\")\n",
    "    print(f\"   Project: ai_content_ops\")\n",
    "else:\n",
    "    print(\"âš ï¸  LANGSMITH_API_KEY not found in .env\")\n",
    "    print(\"   LangSmith tracing disabled\")\n",
    "    print(\"   ðŸ’¡ Add LANGSMITH_API_KEY to your .env file to enable tracing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cc1fee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Tables in app.db:\n",
      "\n",
      "ðŸ”§ conversations:\n",
      "   - id (INTEGER)\n",
      "   - title (TEXT)\n",
      "   - raw_text (TEXT)\n",
      "   - source (TEXT)\n",
      "   - word_count (INTEGER)\n",
      "   - created_at (DATETIME)\n",
      "   - status (TEXT)\n",
      "\n",
      "ðŸ”§ sqlite_sequence:\n",
      "   - name ()\n",
      "   - seq ()\n",
      "\n",
      "ðŸ”§ blog_post_ideas:\n",
      "   - id (INTEGER)\n",
      "   - conversation_id (INTEGER)\n",
      "   - title (TEXT)\n",
      "   - description (TEXT)\n",
      "   - usefulness_potential (INTEGER)\n",
      "   - fitwith_seo_strategy (INTEGER)\n",
      "   - fitwith_content_strategy (INTEGER)\n",
      "   - inspiration_potential (INTEGER)\n",
      "   - collaboration_potential (INTEGER)\n",
      "   - innovation (INTEGER)\n",
      "   - difficulty (INTEGER)\n",
      "   - total_score (INTEGER)\n",
      "   - sent_to_prod (BOOLEAN)\n",
      "   - raw_llm_response (TEXT)\n",
      "   - created_at (DATETIME)\n",
      "\n",
      "ðŸ”§ processing_status:\n",
      "   - id (INTEGER)\n",
      "   - conversation_id (INTEGER)\n",
      "   - stage (TEXT)\n",
      "   - status (TEXT)\n",
      "   - error_message (TEXT)\n",
      "   - started_at (DATETIME)\n",
      "   - completed_at (DATETIME)\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Database Connection Test\n",
    "\n",
    "conn = sqlite3.connect(\"data/app.db\")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Get all table names\n",
    "cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "tables = cursor.fetchall()\n",
    "\n",
    "print(\"ðŸ“Š Tables in app.db:\")\n",
    "for table in tables:\n",
    "    table_name = table[0]\n",
    "    \n",
    "    # Get column info for each table\n",
    "    cursor.execute(f\"PRAGMA table_info({table_name})\")\n",
    "    columns = cursor.fetchall()\n",
    "    \n",
    "    print(f\"\\nðŸ”§ {table_name}:\")\n",
    "    for col in columns:\n",
    "        print(f\"   - {col[1]} ({col[2]})\")  # column_name (type)\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e30147df",
   "metadata": {},
   "outputs": [],
   "source": [
    "## cell 4. Pydantic Model for Structured Output\n",
    "\n",
    "\n",
    "\n",
    "class SpeakerRole(str, Enum):\n",
    "    \"\"\"Possible speaker roles in the conversation\"\"\"\n",
    "    CLIENT = \"client\"\n",
    "    INTERVIEWER = \"interviewer\"\n",
    "\n",
    "class Speaker(BaseModel):\n",
    "    \"\"\"Information about a person speaking in the conversation\"\"\"\n",
    "    name: Optional[str] = Field(default=None, description=\"Name of the speaker if mentioned\")\n",
    "    role: Optional[SpeakerRole] = Field(default=None, description=\"Role of the speaker in the conversation\")\n",
    "    company: Optional[str] = Field(default=None, description=\"Company they work for if mentioned\")\n",
    "\n",
    "class Challenge(BaseModel):\n",
    "    \"\"\"A challenge or problem mentioned in the conversation\"\"\"\n",
    "    description: Optional[str] = Field(default=None, description=\"Description of the challenge\")\n",
    "    impact: Optional[str] = Field(default=None, description=\"How this challenge affects them\")\n",
    "    urgency: Optional[str] = Field(default=None, description=\"Low, Medium, or High urgency\")\n",
    "\n",
    "class CurrentSolution(BaseModel):\n",
    "    \"\"\"How they currently solve their problems\"\"\"\n",
    "    solution: Optional[str] = Field(default=None, description=\"What they're currently doing\")\n",
    "    satisfaction_level: Optional[str] = Field(default=None, description=\"How satisfied they are: Very Satisfied, Satisfied, Neutral, Unsatisfied, Very Unsatisfied\")\n",
    "    limitations: Optional[List[str]] = Field(default=[], description=\"Limitations of current solution\")\n",
    "\n",
    "class Need(BaseModel):\n",
    "    \"\"\"A need identified using psychology frameworks like NVC\"\"\"\n",
    "    need_category: Optional[str] = Field(default=None, description=\"Category of need (e.g., autonomy, efficiency, security, connection)\")\n",
    "    description: Optional[str] = Field(default=None, description=\"Specific need description\")\n",
    "    intensity: Optional[str] = Field(default=None, description=\"Low, Medium, or High intensity\")\n",
    "\n",
    "class ExtractedInsights(BaseModel):\n",
    "    \"\"\"Complete structured output from conversation analysis\"\"\"\n",
    "    \n",
    "    # Speakers\n",
    "    speakers: Optional[List[Speaker]] = Field(default=[], description=\"People identified in the conversation\")\n",
    "    \n",
    "    # What they care about\n",
    "    core_values: Optional[List[str]] = Field(default=[], description=\"What this person/company cares about most\")\n",
    "    priorities: Optional[List[str]] = Field(default=[], description=\"Their current priorities and focus areas\")\n",
    "    \n",
    "    # Challenges\n",
    "    primary_challenges: Optional[List[Challenge]] = Field(default=[], description=\"Main problems they're facing\")\n",
    "    secondary_challenges: Optional[List[Challenge]] = Field(default=[], description=\"Secondary or related problems\")\n",
    "    \n",
    "    # Current solutions\n",
    "    current_solutions: Optional[List[CurrentSolution]] = Field(default=[], description=\"How they solve problems today\")\n",
    "    \n",
    "    # Needs analysis\n",
    "    psychological_needs: Optional[List[Need]] = Field(default=[], description=\"Underlying needs using NVC or similar frameworks\")\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89d86360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Simple RawBlogIdea model ready\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Raw Blog Idea Model (Simple)\n",
    "class RawBlogIdea(BaseModel):\n",
    "    \"\"\"Raw blog idea from creative agent\"\"\"\n",
    "    title: str\n",
    "    description: str\n",
    "    target_audience: str\n",
    "    content_angle: str\n",
    "    business_value: str\n",
    "\n",
    "print(\"âœ… Simple RawBlogIdea model ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77ecdfc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… RawBlogIdea model and validation ready\n"
     ]
    }
   ],
   "source": [
    "def validate_raw_blog_ideas(raw_ideas: List[Dict]) -> List[RawBlogIdea]:\n",
    "    \"\"\"Validate and convert raw JSON to Pydantic models\"\"\"\n",
    "    validated_ideas = []\n",
    "    \n",
    "    for idea in raw_ideas:\n",
    "        try:\n",
    "            validated_idea = RawBlogIdea(**idea)\n",
    "            validated_ideas.append(validated_idea)\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ Invalid blog idea skipped: {e}\")\n",
    "    \n",
    "    print(f\"âœ… Validated {len(validated_ideas)} out of {len(raw_ideas)} raw ideas\")\n",
    "    return validated_ideas\n",
    "\n",
    "print(\"âœ… RawBlogIdea model and validation ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19fad4ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Updated AudioPipelineState for 6-node pipeline\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Update AudioPipelineState for 5-Node Pipeline\n",
    "class AudioPipelineState(TypedDict):\n",
    "    # File info\n",
    "    file_path: str\n",
    "    filename: str\n",
    "    \n",
    "    # Processing results\n",
    "    transcript_text: Optional[str]\n",
    "    conversation_id: Optional[int]\n",
    "    extracted_insights: Optional[ExtractedInsights]\n",
    "    raw_blog_ideas: Optional[List[Dict]]        # From creative agent (Node 4)\n",
    "    scored_blog_ideas: Optional[List[Dict]]     # From analyst agent (Node 5) \n",
    "    saved_idea_ids: Optional[List[int]]         # From database saver (Node 6) \n",
    "    \n",
    "    \n",
    "    # Status & error handling\n",
    "    status: str\n",
    "    error: Optional[str]\n",
    "\n",
    "print(\"âœ… Updated AudioPipelineState for 6-node pipeline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46143d78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Individual strategy loader functions ready\n",
      "âœ… prepare_strategy_context_for_scoring() ready\n"
     ]
    }
   ],
   "source": [
    "# Cell: Individual Strategy Loader Function\n",
    "\n",
    "def load_company_strategy():\n",
    "    \"\"\"Load company strategy document\"\"\"\n",
    "    try:\n",
    "        company_strategy_path = \"../data/processed/company_strategy.mkd\"\n",
    "        if os.path.exists(company_strategy_path):\n",
    "            with open(company_strategy_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                content = f.read()\n",
    "            print(f\"âœ… Loaded company strategy ({len(content)} chars)\")\n",
    "            return content\n",
    "        else:\n",
    "            print(\"âš ï¸ Company strategy document not found\")\n",
    "            return \"Company strategy document not available.\"\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error loading company strategy: {e}\")\n",
    "        return \"Company strategy document not available.\"\n",
    "\n",
    "def load_seo_strategy():\n",
    "    \"\"\"Load SEO strategy document\"\"\"\n",
    "    try:\n",
    "        seo_strategy_path = \"../data/processed/seo_strategy.mkd\"\n",
    "        if os.path.exists(seo_strategy_path):\n",
    "            with open(seo_strategy_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                content = f.read()\n",
    "            print(f\"âœ… Loaded SEO strategy ({len(content)} chars)\")\n",
    "            return content\n",
    "        else:\n",
    "            print(\"âš ï¸ SEO strategy document not found\")\n",
    "            return \"SEO strategy document not available.\"\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error loading SEO strategy: {e}\")\n",
    "        return \"SEO strategy document not available.\"\n",
    "\n",
    "def load_content_strategy():\n",
    "    \"\"\"Load content strategy document\"\"\"\n",
    "    try:\n",
    "        content_strategy_path = \"../data/processed/content_strategy.mkd\"\n",
    "        if os.path.exists(content_strategy_path):\n",
    "            with open(content_strategy_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                content = f.read()\n",
    "            print(f\"âœ… Loaded content strategy ({len(content)} chars)\")\n",
    "            return content\n",
    "        else:\n",
    "            print(\"âš ï¸ Content strategy document not found\")\n",
    "            return \"Content strategy document not available.\"\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error loading content strategy: {e}\")\n",
    "        return \"Content strategy document not available.\"\n",
    "\n",
    "def prepare_strategy_context_for_scoring():\n",
    "    \"\"\"Prepare full strategy context for scoring (used by analyst agent)\"\"\"\n",
    "    return {\n",
    "        'company_strategy_summary': load_company_strategy(),\n",
    "        'seo_strategy_summary': load_seo_strategy(),\n",
    "        'content_strategy_summary': load_content_strategy()\n",
    "    }\n",
    "\n",
    "print(\"âœ… Individual strategy loader functions ready\")\n",
    "print(\"âœ… prepare_strategy_context_for_scoring() ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bcb6358b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded company strategy (6555 chars)\n",
      "âœ… Loaded SEO strategy (1120 chars)\n",
      "âœ… Loaded content strategy (4469 chars)\n",
      "ðŸ“Š Strategy context keys: ['company_strategy', 'seo_strategy', 'content_strategy']\n",
      "ðŸ“Š Total context size: 12144 chars\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Updated Company Strategy Context Loader (3 Documents)\n",
    "def load_company_strategy_context():\n",
    "    \"\"\"Load company strategy, SEO strategy, and content strategy for context\"\"\"\n",
    "    \n",
    "    strategy_context = {}\n",
    "    \n",
    "    try:\n",
    "        # Load company strategy\n",
    "        company_strategy_path = \"../data/processed/company_strategy.mkd\"\n",
    "        if os.path.exists(company_strategy_path):\n",
    "            with open(company_strategy_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                strategy_context[\"company_strategy\"] = f.read()\n",
    "            print(f\"âœ… Loaded company strategy ({len(strategy_context['company_strategy'])} chars)\")\n",
    "        else:\n",
    "            strategy_context[\"company_strategy\"] = \"Company strategy document not available.\"\n",
    "            print(\"âš ï¸ Company strategy document not found\")\n",
    "        \n",
    "        # Load SEO strategy\n",
    "        seo_strategy_path = \"../data/processed/seo_strategy.mkd\"\n",
    "        if os.path.exists(seo_strategy_path):\n",
    "            with open(seo_strategy_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                strategy_context[\"seo_strategy\"] = f.read()\n",
    "            print(f\"âœ… Loaded SEO strategy ({len(strategy_context['seo_strategy'])} chars)\")\n",
    "        else:\n",
    "            strategy_context[\"seo_strategy\"] = \"SEO strategy document not available.\"\n",
    "            print(\"âš ï¸ SEO strategy document not found\")\n",
    "        \n",
    "        # Load content strategy (NEW)\n",
    "        content_strategy_path = \"../data/processed/content_strategy.mkd\"\n",
    "        if os.path.exists(content_strategy_path):\n",
    "            with open(content_strategy_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                strategy_context[\"content_strategy\"] = f.read()\n",
    "            print(f\"âœ… Loaded content strategy ({len(strategy_context['content_strategy'])} chars)\")\n",
    "        else:\n",
    "            strategy_context[\"content_strategy\"] = \"Content strategy document not available.\"\n",
    "            print(\"âš ï¸ Content strategy document not found\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error loading strategy documents: {e}\")\n",
    "        strategy_context = {\n",
    "            \"company_strategy\": \"Strategy document not available\",\n",
    "            \"seo_strategy\": \"SEO strategy document not available\", \n",
    "            \"content_strategy\": \"Content strategy document not available\"\n",
    "        }\n",
    "    \n",
    "    return strategy_context\n",
    "\n",
    "# Test loading all three documents\n",
    "strategy_context = load_company_strategy_context()\n",
    "print(f\"ðŸ“Š Strategy context keys: {list(strategy_context.keys())}\")\n",
    "print(f\"ðŸ“Š Total context size: {sum(len(v) for v in strategy_context.values() if isinstance(v, str))} chars\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dcad1d83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Batch processing function ready with full insights display\n"
     ]
    }
   ],
   "source": [
    "# Batch Processing Function (Updated with Full Insights Display)\n",
    "def process_audio_batch(audio_files: List[Path], pipeline) -> dict:\n",
    "    \"\"\"Process all audio files in batch with detailed insights display\"\"\"\n",
    "    \n",
    "    if not audio_files:\n",
    "        print(\"âŒ No files to process\")\n",
    "        return {\"processed\": [], \"failed\": [], \"total\": 0}\n",
    "    \n",
    "    print(f\"\\nðŸš€ STARTING BATCH PROCESSING - {len(audio_files)} files\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    processed_files = []\n",
    "    failed_files = []\n",
    "    results = []\n",
    "    \n",
    "    for i, file_path in enumerate(audio_files, 1):\n",
    "        print(f\"\\nðŸ“‚ Processing {i}/{len(audio_files)}: {file_path.name}\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        # Create initial state\n",
    "        initial_state = {\n",
    "            \"file_path\": str(file_path),\n",
    "            \"filename\": file_path.name,\n",
    "            \"transcript_text\": None,\n",
    "            \"conversation_id\": None,\n",
    "            \"extracted_insights\": None,  \n",
    "            \"error\": None,\n",
    "            \"status\": \"processing\"\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            # Run through pipeline\n",
    "            result = pipeline.invoke(initial_state)\n",
    "            \n",
    "            if result[\"status\"] in [\"completed\", \"insights_extracted\"]:\n",
    "                print(f\"âœ… SUCCESS: {file_path.name}\")\n",
    "                print(f\"   Conversation ID: {result['conversation_id']}\")\n",
    "                print(f\"   Transcript preview: {result['transcript_text'][:100]}...\")\n",
    "                \n",
    "                # FULL INSIGHTS DISPLAY\n",
    "                if result.get('extracted_insights'):\n",
    "                    insights = result['extracted_insights']\n",
    "                    print(f\"\\nðŸ§  === EXTRACTED INSIGHTS FOR: {file_path.name} ===\")\n",
    "                    print(\"=\" * 50)\n",
    "                    \n",
    "                    # Speakers\n",
    "                    if insights.speakers:\n",
    "                        print(\"ðŸ‘¥ SPEAKERS:\")\n",
    "                        for speaker in insights.speakers:\n",
    "                            print(f\"   â€¢ Name: {speaker.name or 'Unknown'}\")\n",
    "                            print(f\"     Role: {speaker.role or 'Unknown'}\")  \n",
    "                            print(f\"     Company: {speaker.company or 'Unknown'}\")\n",
    "                    \n",
    "                    # Core Values\n",
    "                    if insights.core_values:\n",
    "                        print(\"ðŸ’Ž CORE VALUES:\")\n",
    "                        for value in insights.core_values:\n",
    "                            print(f\"   â€¢ {value}\")\n",
    "                    \n",
    "                    # Priorities\n",
    "                    if insights.priorities:\n",
    "                        print(\"ðŸŽ¯ PRIORITIES:\")\n",
    "                        for priority in insights.priorities:\n",
    "                            print(f\"   â€¢ {priority}\")\n",
    "                    \n",
    "                    # Primary Challenges\n",
    "                    if insights.primary_challenges:\n",
    "                        print(\"ðŸ”¥ PRIMARY CHALLENGES:\")\n",
    "                        for challenge in insights.primary_challenges:\n",
    "                            print(f\"   â€¢ Challenge: {challenge.description}\")\n",
    "                            print(f\"     Impact: {challenge.impact}\")\n",
    "                            print(f\"     Urgency: {challenge.urgency}\")\n",
    "                    \n",
    "                    # Secondary Challenges\n",
    "                    if insights.secondary_challenges:\n",
    "                        print(\"âš ï¸  SECONDARY CHALLENGES:\")\n",
    "                        for challenge in insights.secondary_challenges:\n",
    "                            print(f\"   â€¢ Challenge: {challenge.description}\")\n",
    "                            print(f\"     Impact: {challenge.impact}\")\n",
    "                            print(f\"     Urgency: {challenge.urgency}\")\n",
    "                    \n",
    "                    # Current Solutions\n",
    "                    if insights.current_solutions:\n",
    "                        print(\"ðŸ”§ CURRENT SOLUTIONS:\")\n",
    "                        for solution in insights.current_solutions:\n",
    "                            print(f\"   â€¢ Solution: {solution.solution}\")\n",
    "                            print(f\"     Satisfaction: {solution.satisfaction_level}\")\n",
    "                            if solution.limitations:\n",
    "                                print(f\"     Limitations: {', '.join(solution.limitations)}\")\n",
    "                    \n",
    "                    # Psychological Needs\n",
    "                    if insights.psychological_needs:\n",
    "                        print(\"ðŸ§˜ PSYCHOLOGICAL NEEDS:\")\n",
    "                        for need in insights.psychological_needs:\n",
    "                            print(f\"   â€¢ {need.description}\")\n",
    "                            print(f\"     Category: {need.need_category}\")\n",
    "                            print(f\"     Intensity: {need.intensity}\")\n",
    "                    \n",
    "                    print(\"ðŸ§  === END INSIGHTS ===\")\n",
    "                    print(\"-\" * 50)\n",
    "                \n",
    "                processed_files.append(file_path)\n",
    "            else:\n",
    "                print(f\"âŒ FAILED: {file_path.name}\")\n",
    "                print(f\"   Status: {result.get('status', 'Unknown')}\")\n",
    "                print(f\"   Error: {result.get('error', 'Unknown error')}\")\n",
    "                failed_files.append(file_path)\n",
    "            \n",
    "            results.append(result)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ PIPELINE ERROR: {file_path.name}\")\n",
    "            print(f\"   Exception: {str(e)}\")\n",
    "            failed_files.append(file_path)\n",
    "            \n",
    "            results.append({\n",
    "                **initial_state,\n",
    "                \"error\": str(e),\n",
    "                \"status\": \"pipeline_error\"\n",
    "            })\n",
    "    \n",
    "    # Final Summary\n",
    "    print(f\"\\nðŸ“Š BATCH PROCESSING COMPLETE!\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"âœ… Successfully processed: {len(processed_files)}\")\n",
    "    print(f\"âŒ Failed: {len(failed_files)}\")\n",
    "    print(f\"ðŸ“ Total files: {len(audio_files)}\")\n",
    "    \n",
    "    if failed_files:\n",
    "        print(f\"\\nâŒ Failed files:\")\n",
    "        for failed_file in failed_files:\n",
    "            print(f\"   - {failed_file.name}\")\n",
    "    \n",
    "    return {\n",
    "        \"processed\": processed_files,\n",
    "        \"failed\": failed_files,\n",
    "        \"total\": len(audio_files),\n",
    "        \"results\": results\n",
    "    }\n",
    "\n",
    "print(\"âœ… Batch processing function ready with full insights display\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b06e004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… File management functions defined\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Batch File Discovery and Management\n",
    "\n",
    "\n",
    "def find_audio_files_in_temp(temp_folder: Path = None) -> List[Path]:\n",
    "    \"\"\"Find all audio files in temp folder\"\"\"\n",
    "    \n",
    "    # Use default temp folder if not specified\n",
    "    if temp_folder is None:\n",
    "        temp_folder = project_root / 'data' / 'temp'\n",
    "    \n",
    "    # Ensure folder exists\n",
    "    temp_folder.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Check if folder exists\n",
    "    if not temp_folder.exists():\n",
    "        print(f\"âŒ Temp folder not found: {temp_folder}\")\n",
    "        return []\n",
    "    \n",
    "    # Find audio files\n",
    "    audio_extensions = ['*.wav', '*.mp3', '*.m4a']\n",
    "    audio_files = []\n",
    "    \n",
    "    for ext in audio_extensions:\n",
    "        files = list(temp_folder.glob(ext))\n",
    "        audio_files.extend(files)\n",
    "    \n",
    "    return sorted(audio_files)\n",
    "\n",
    "\n",
    "def display_batch_info(audio_files: List[Path]) -> bool:\n",
    "    \"\"\"Display information about the batch of files\"\"\"\n",
    "    \n",
    "    if not audio_files:\n",
    "        print(\"âŒ No audio files found in temp folder!\")\n",
    "        print(\"ðŸ’¡ TIP: Add .wav files to data/temp/ folder\")\n",
    "        return False\n",
    "    \n",
    "    total_size_mb = sum(f.stat().st_size for f in audio_files) / (1024 * 1024)\n",
    "    \n",
    "    print(f\"ðŸ“Š BATCH INFO:\")\n",
    "    print(f\"   Files to process: {len(audio_files)}\")\n",
    "    print(f\"   Total size: {total_size_mb:.1f} MB\")\n",
    "    print(f\"\\nðŸ“ Files found:\")\n",
    "    \n",
    "    for i, file_path in enumerate(audio_files, 1):\n",
    "        size_mb = file_path.stat().st_size / (1024 * 1024)\n",
    "        print(f\"   {i}. {file_path.name} ({size_mb:.1f} MB)\")\n",
    "    \n",
    "    return True\n",
    "\n",
    "\n",
    "print(\"âœ… File management functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c79e939f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Updated extract_insights_from_transcript with speaker role fix\n"
     ]
    }
   ],
   "source": [
    "# Cell: Extract Insights Function - ROLE FIXED VERSION\n",
    "def extract_insights_from_transcript(transcript: str) -> ExtractedInsights:\n",
    "    \"\"\"Extract structured insights using Anthropic Claude - ROLE FIXED VERSION\"\"\"\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    Analyze this conversation transcript and extract structured insights:\n",
    "    \n",
    "    Transcript: {transcript}\n",
    "    \n",
    "    IMPORTANT: For speaker roles, use ONLY these exact values:\n",
    "    - \"client\" for the person being interviewed/consulted (CTO, CEO, Manager, business owner, etc.)\n",
    "    - \"interviewer\" for the person asking questions or conducting the interview\n",
    "    \n",
    "    Extract the following information in JSON format:\n",
    "    - speakers: List of people mentioned with name, role (client/interviewer only), company\n",
    "    - core_values: What they care about most  \n",
    "    - priorities: Current focus areas\n",
    "    - primary_challenges: Main problems they face with description, impact, urgency\n",
    "    - secondary_challenges: Secondary problems\n",
    "    - current_solutions: How they solve problems now with satisfaction level\n",
    "    - psychological_needs: Underlying needs with category, description, intensity\n",
    "    \n",
    "    Return ONLY valid JSON in this exact structure - no markdown, no code blocks:\n",
    "    {{\n",
    "        \"speakers\": [\n",
    "            {{\"name\": \"Manuel\", \"role\": \"client\", \"company\": \"Drone flytech\"}}\n",
    "        ],\n",
    "        \"core_values\": [\"efficiency\", \"transparency\"],\n",
    "        \"priorities\": [\"improving processes\"],\n",
    "        \"primary_challenges\": [\n",
    "            {{\n",
    "                \"description\": \"Tracking payment issues\",\n",
    "                \"impact\": \"Creates confusion in processes\", \n",
    "                \"urgency\": \"High\"\n",
    "            }}\n",
    "        ],\n",
    "        \"secondary_challenges\": [\n",
    "            {{\n",
    "                \"description\": \"Secondary challenge\",\n",
    "                \"impact\": \"Secondary impact\",\n",
    "                \"urgency\": \"Medium\"\n",
    "            }}\n",
    "        ],\n",
    "        \"current_solutions\": [\n",
    "            {{\n",
    "                \"solution\": \"Current approach\",\n",
    "                \"satisfaction_level\": \"Neutral\",\n",
    "                \"limitations\": [\"limitation1\", \"limitation2\"]\n",
    "            }}\n",
    "        ],\n",
    "        \"psychological_needs\": [\n",
    "            {{\n",
    "                \"need_category\": \"security\",\n",
    "                \"description\": \"Need for confidence\",\n",
    "                \"intensity\": \"High\"\n",
    "            }}\n",
    "        ]\n",
    "    }}\n",
    "    \n",
    "    Remember: \n",
    "    - Use \"client\" for Manuel (even though he's CTO)\n",
    "    - Use \"interviewer\" for the person asking questions\n",
    "    - Use exact urgency values: \"Low\", \"Medium\", \"High\"\n",
    "    - Use exact satisfaction levels: \"Very Satisfied\", \"Satisfied\", \"Neutral\", \"Unsatisfied\", \"Very Unsatisfied\"\n",
    "    - Use exact intensity values: \"Low\", \"Medium\", \"High\"\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Use the Claude LLM you already set up\n",
    "        response = llm.invoke(prompt)\n",
    "        \n",
    "        print(f\"ðŸ“ Raw response length: {len(response.content)} chars\")\n",
    "        print(f\"ðŸ“ Response starts with: {response.content[:50]}...\")\n",
    "        \n",
    "        # Clean markdown code blocks\n",
    "        content = response.content.strip()\n",
    "        if content.startswith('```json'):\n",
    "            print(\"ðŸ”§ Removing JSON markdown blocks...\")\n",
    "            content = content.replace('```json', '').replace('```', '').strip()\n",
    "            print(f\"ðŸ”§ Cleaned content starts with: {content[:50]}...\")\n",
    "        \n",
    "        # Parse the cleaned JSON response\n",
    "        insights_data = json.loads(content)\n",
    "        \n",
    "        # Convert to Pydantic model\n",
    "        result = ExtractedInsights(**insights_data)\n",
    "        print(f\"âœ… Successfully extracted insights with correct speaker roles!\")\n",
    "        return result\n",
    "        \n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"âŒ JSON parsing error: {e}\")\n",
    "        print(f\"ðŸ“ Raw response: {response.content[:500]}...\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error in LLM call: {e}\")\n",
    "        raise\n",
    "\n",
    "print(\"âœ… Updated extract_insights_from_transcript with speaker role fix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1b52ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fixed creative agent function ready\n"
     ]
    }
   ],
   "source": [
    "# Cell: Fixed Creative Agent Function\n",
    "def generate_blog_ideas_from_insights(insights: ExtractedInsights, strategy_context: dict) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Fixed creative agent that handles Claude's markdown JSON response\n",
    "    \"\"\"\n",
    "    \n",
    "    creative_prompt = f\"\"\"\n",
    "    You are a creative content strategist for Big Kids Automation, a company that helps businesses implement AI and automation solutions.\n",
    "    \n",
    "    COMPANY CONTEXT:\n",
    "    {strategy_context.get('company_strategy', 'Strategy not available')[:1000]}...\n",
    "    \n",
    "    SEO STRATEGY:\n",
    "    {strategy_context.get('seo_strategy', 'SEO strategy not available')[:500]}...\n",
    "    \n",
    "    CONVERSATION INSIGHTS TO WORK FROM:\n",
    "    \n",
    "    Speakers: {[f\"{s.name} ({s.role}) from {s.company}\" for s in insights.speakers] if insights.speakers else \"Unknown speakers\"}\n",
    "    \n",
    "    Core Values: {\", \".join(insights.core_values) if insights.core_values else \"None identified\"}\n",
    "    \n",
    "    Priorities: {\", \".join(insights.priorities) if insights.priorities else \"None identified\"}\n",
    "    \n",
    "    Primary Challenges:\n",
    "    {chr(10).join([f\"- {c.description} (Impact: {c.impact}, Urgency: {c.urgency})\" for c in insights.primary_challenges]) if insights.primary_challenges else \"None identified\"}\n",
    "    \n",
    "    Current Solutions:\n",
    "    {chr(10).join([f\"- {s.solution} (Satisfaction: {s.satisfaction_level})\" for s in insights.current_solutions]) if insights.current_solutions else \"None identified\"}\n",
    "    \n",
    "    Psychological Needs:\n",
    "    {chr(10).join([f\"- {n.description} ({n.need_category}, {n.intensity} intensity)\" for n in insights.psychological_needs]) if insights.psychological_needs else \"None identified\"}\n",
    "    \n",
    "    TASK:\n",
    "    Generate 4-5 creative blog post ideas that:\n",
    "    1. Address the challenges and needs identified in this conversation\n",
    "    2. Align with Big Kids Automation's mission to help businesses with AI/automation\n",
    "    3. Provide value to potential clients facing similar challenges\n",
    "    4. Support our SEO and content marketing strategy\n",
    "    5. Are actionable and practical, not just theoretical\n",
    "    \n",
    "    For each blog post idea, provide:\n",
    "    - title: Clear, engaging title that includes relevant keywords\n",
    "    - description: 2-3 sentence description of what the post will cover\n",
    "    - target_audience: Who this post is primarily for\n",
    "    - content_angle: The unique angle or approach this post takes\n",
    "    - business_value: How this post helps our business goals\n",
    "    \n",
    "    IMPORTANT: Return ONLY the JSON array, no markdown formatting, no code blocks, no explanatory text.\n",
    "    \n",
    "    Format:\n",
    "    [\n",
    "        {{\n",
    "            \"title\": \"How AI Proposal Systems Balance Speed with Brand Differentiation\",\n",
    "            \"description\": \"A practical guide showing how modern AI-powered proposal systems solve the common problem of maintaining company uniqueness while leveraging automation. Includes real case studies and implementation steps.\",\n",
    "            \"target_audience\": \"Business development directors and proposal managers at consulting firms\",\n",
    "            \"content_angle\": \"Problem-solution with real case studies\",\n",
    "            \"business_value\": \"Attracts prospects struggling with proposal automation while maintaining differentiation\"\n",
    "        }}\n",
    "    ]\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Generate ideas using Claude\n",
    "        response = llm.invoke(creative_prompt)\n",
    "        raw_content = response.content.strip()\n",
    "        \n",
    "        print(f\"ðŸ“ Raw response length: {len(raw_content)} chars\")\n",
    "        print(f\"ðŸ“ Response starts with: {raw_content[:50]}...\")\n",
    "        \n",
    "        # Handle markdown code blocks\n",
    "        if raw_content.startswith('```'):\n",
    "            print(\"ðŸ”§ Removing markdown code blocks...\")\n",
    "            # Remove ```json and ``` wrappers\n",
    "            lines = raw_content.split('\\n')\n",
    "            # Remove first line if it's ```json or ```\n",
    "            if lines[0].startswith('```'):\n",
    "                lines = lines[1:]\n",
    "            # Remove last line if it's ```\n",
    "            if lines and lines[-1].strip() == '```':\n",
    "                lines = lines[:-1]\n",
    "            raw_content = '\\n'.join(lines).strip()\n",
    "            print(f\"ðŸ”§ Cleaned content starts with: {raw_content[:50]}...\")\n",
    "        \n",
    "        # Parse JSON response\n",
    "        blog_ideas = json.loads(raw_content)\n",
    "        \n",
    "        print(f\"âœ… Creative agent successfully parsed {len(blog_ideas)} blog ideas\")\n",
    "        return blog_ideas\n",
    "        \n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"âŒ JSON parsing error in creative agent: {e}\")\n",
    "        print(f\"ðŸ“ Cleaned content: {raw_content[:500]}...\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error in creative agent: {e}\")\n",
    "        return []\n",
    "\n",
    "print(\"âœ… Fixed creative agent function ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b0e67228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Updated LLM scoring engine with content strategy context\n"
     ]
    }
   ],
   "source": [
    "# Cell 17: Updated Scoring Engine with Content Strategy Context\n",
    "def score_blog_idea_with_llm(idea: dict, strategy_context: dict, conversation_context: str = \"\") -> dict:\n",
    "    \"\"\"Score a single blog idea using LLM with all three strategy contexts\"\"\"\n",
    "    \n",
    "    scoring_prompt = f\"\"\"\n",
    "    You are an expert content strategist for Big Kids Automation. Score this blog post idea on a 1-10 scale using our strategic context.\n",
    "    \n",
    "    COMPANY STRATEGY:\n",
    "    {strategy_context.get('company_strategy_summary', 'Not available')}\n",
    "    \n",
    "    SEO STRATEGY:\n",
    "    {strategy_context.get('seo_strategy_summary', 'Not available')}\n",
    "    \n",
    "    CONTENT STRATEGY:\n",
    "    {strategy_context.get('content_strategy_summary', 'Not available')}\n",
    "    \n",
    "    BLOG IDEA TO SCORE:\n",
    "    Title: {idea.get('title', 'No title')}\n",
    "    Description: {idea.get('description', 'No description')}\n",
    "    Target Audience: {idea.get('target_audience', 'Unknown')}\n",
    "    Business Value: {idea.get('business_value', 'Unknown')}\n",
    "    Content Angle: {idea.get('content_angle', 'Unknown')}\n",
    "    \n",
    "    CONVERSATION CONTEXT:\n",
    "    {conversation_context[:300] if conversation_context else 'No context available'}...\n",
    "    \n",
    "    SCORING INSTRUCTIONS:\n",
    "    Rate each criterion from 1-10 (10 = excellent, 1 = poor):\n",
    "    \n",
    "    1. usefulness_potential: How useful will this be to readers with real problems?\n",
    "    2. fitwith_seo_strategy: How well does this align with our SEO keywords and strategy?\n",
    "    3. fitwith_content_strategy: How well does this fit our content strategy, voice, and approach?\n",
    "    4. inspiration_potential: How likely to inspire readers to take meaningful action?\n",
    "    5. collaboration_potential: How likely to generate leads/prospects who contact us?\n",
    "    6. innovation: How unique is this topic compared to existing content?\n",
    "    7. difficulty: How complex/time-consuming will this be to write? (1=very hard, 10=easy)\n",
    "    \n",
    "    Return ONLY valid JSON with your scores and brief reasoning:\n",
    "    {{\n",
    "        \"usefulness_potential\": 8,\n",
    "        \"fitwith_seo_strategy\": 7,\n",
    "        \"fitwith_content_strategy\": 9,\n",
    "        \"inspiration_potential\": 6,\n",
    "        \"collaboration_potential\": 8,\n",
    "        \"innovation\": 7,\n",
    "        \"difficulty\": 4,\n",
    "        \"reasoning\": \"This idea scores well because it aligns with our content strategy focus on...\"\n",
    "    }}\n",
    "    \"\"\"\n",
    "    \n",
    "    # ... rest of the function stays the same\n",
    "    try:\n",
    "        response = llm.invoke(scoring_prompt)\n",
    "        \n",
    "        content = response.content.strip()\n",
    "        if content.startswith('```json'):\n",
    "            content = content.replace('```json', '').replace('```', '').strip()\n",
    "        \n",
    "        scores = json.loads(content)\n",
    "        \n",
    "        # Validate scores are in range\n",
    "        for criterion in ['usefulness_potential', 'fitwith_seo_strategy', 'fitwith_content_strategy', \n",
    "                         'inspiration_potential', 'collaboration_potential', 'innovation', 'difficulty']:\n",
    "            if criterion in scores:\n",
    "                scores[criterion] = max(1, min(10, scores[criterion]))\n",
    "        \n",
    "        # Calculate total score\n",
    "        total_score = sum([\n",
    "            scores.get('usefulness_potential', 5),\n",
    "            scores.get('fitwith_seo_strategy', 5),\n",
    "            scores.get('fitwith_content_strategy', 5),\n",
    "            scores.get('inspiration_potential', 5),\n",
    "            scores.get('collaboration_potential', 5),\n",
    "            scores.get('innovation', 5),\n",
    "            scores.get('difficulty', 5)\n",
    "        ])\n",
    "        \n",
    "        scores['total_score'] = total_score\n",
    "        return scores\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error scoring idea: {e}\")\n",
    "        return {\n",
    "            \"usefulness_potential\": 5, \"fitwith_seo_strategy\": 5, \"fitwith_content_strategy\": 5,\n",
    "            \"inspiration_potential\": 5, \"collaboration_potential\": 5, \"innovation\": 5,\n",
    "            \"difficulty\": 5, \"total_score\": 35, \"reasoning\": f\"Default scores due to error: {str(e)}\"\n",
    "        }\n",
    "\n",
    "print(\"âœ… Updated LLM scoring engine with content strategy context\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3972ba82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… LangGraph nodes defined\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Define LangGraph Nodes\n",
    "def transcription_node(state: AudioPipelineState) -> AudioPipelineState:\n",
    "    \"\"\"Node 1: Transcribe audio file with AssemblyAI\"\"\"\n",
    "    try:\n",
    "        print(f\"ðŸŽ™ï¸ Transcribing: {state['filename']}\")\n",
    "        \n",
    "        # Configure transcriber\n",
    "        transcriber = aai.Transcriber()\n",
    "        \n",
    "        # Transcribe the file\n",
    "        transcript = transcriber.transcribe(state['file_path'])\n",
    "        \n",
    "        if transcript.status == aai.TranscriptStatus.error:\n",
    "            return {\n",
    "                **state,\n",
    "                \"error\": f\"AssemblyAI error: {transcript.error}\",\n",
    "                \"status\": \"transcription_failed\"\n",
    "            }\n",
    "        \n",
    "        return {\n",
    "            **state,\n",
    "            \"transcript_text\": transcript.text,\n",
    "            \"status\": \"transcribed\"\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            **state,\n",
    "            \"error\": f\"Transcription error: {str(e)}\",\n",
    "            \"status\": \"transcription_failed\"\n",
    "        }\n",
    "\n",
    "def database_saver_node_conversations(state: AudioPipelineState) -> AudioPipelineState:\n",
    "    \"\"\"Node 2: Save transcript to database\"\"\"\n",
    "    try:\n",
    "        print(f\"ðŸ’¾ Saving to database: {state['filename']}\")\n",
    "        \n",
    "        # Create conversation object\n",
    "        conversation = ConversationCreate(\n",
    "            title=f\"Audio: {state['filename']}\",\n",
    "            raw_text=state['transcript_text'],\n",
    "            source=\"transcribed\"\n",
    "        )\n",
    "        \n",
    "        # Save to database\n",
    "        conversation_id = db.create_conversation(conversation)\n",
    "        \n",
    "        return {\n",
    "            **state,\n",
    "            \"conversation_id\": conversation_id,\n",
    "            \"status\": \"completed\"\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            **state,\n",
    "            \"error\": f\"Database error: {str(e)}\",\n",
    "            \"status\": \"database_failed\"\n",
    "        }\n",
    "\n",
    "print(\"âœ… LangGraph nodes defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d0edabd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pain_extractor_node(state: AudioPipelineState) -> AudioPipelineState:\n",
    "    \"\"\"\n",
    "    LangGraph node: Extract structured insights from conversation transcript\n",
    "    \"\"\"\n",
    "    print(\"ðŸ§  Starting pain extraction...\")\n",
    "    \n",
    "    try:\n",
    "        # Extract insights using OpenAI structured output\n",
    "        insights = extract_insights_from_transcript(state['transcript_text'])\n",
    "        \n",
    "        if insights:\n",
    "            print(f\"âœ… Extracted insights: {len(insights.primary_challenges)} primary challenges, {len(insights.speakers)} speakers\")\n",
    "            \n",
    "            return {\n",
    "                **state,\n",
    "                \"extracted_insights\": insights,\n",
    "                \"status\": \"insights_extracted\"\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                **state,\n",
    "                \"error\": \"Failed to extract insights from transcript\",\n",
    "                \"status\": \"error\"\n",
    "            }\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Pain extraction failed: {e}\")\n",
    "        return {\n",
    "            **state,\n",
    "            \"error\": f\"Pain extraction error: {str(e)}\",\n",
    "            \"status\": \"error\"\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a0137a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Creative agent node RELOADED\n"
     ]
    }
   ],
   "source": [
    "# Cell: Creative Agent Node - FORCE RELOAD\n",
    "def creative_agent_node(state: AudioPipelineState) -> AudioPipelineState:\n",
    "    \"\"\"Creative agent that generates raw blog ideas\"\"\"\n",
    "    \n",
    "    try:\n",
    "        print(\"ðŸŽ¨ Starting creative blog idea generation...\")\n",
    "        \n",
    "        insights = state.get('extracted_insights')\n",
    "        if not insights:\n",
    "            return {**state, \"error\": \"No insights available\", \"status\": \"error\"}\n",
    "        \n",
    "        print(f\"ðŸ“Š Working with insights: {len(insights.primary_challenges)} challenges\")\n",
    "        \n",
    "        # Load strategy context\n",
    "        strategy_context = load_company_strategy_context()\n",
    "        \n",
    "        # Generate ideas (returns JSON list)\n",
    "        raw_ideas_json = generate_blog_ideas_from_insights(insights, strategy_context)\n",
    "        \n",
    "        if not raw_ideas_json:\n",
    "            return {**state, \"error\": \"No ideas generated\", \"status\": \"error\"}\n",
    "        \n",
    "        # Convert to Pydantic for validation\n",
    "        validated_ideas = []\n",
    "        for idea_json in raw_ideas_json:\n",
    "            try:\n",
    "                idea = RawBlogIdea(**idea_json)\n",
    "                validated_ideas.append(idea)\n",
    "            except Exception as e:\n",
    "                print(f\"âš ï¸ Skipping invalid idea: {e}\")\n",
    "        \n",
    "        if validated_ideas:\n",
    "            print(f\"ðŸŽ‰ Generated {len(validated_ideas)} valid blog ideas\")\n",
    "            \n",
    "            # Convert back to dict for state storage\n",
    "            ideas_as_dicts = [idea.model_dump() for idea in validated_ideas]\n",
    "            \n",
    "            return {\n",
    "                **state,\n",
    "                \"raw_blog_ideas\": ideas_as_dicts,\n",
    "                \"status\": \"ideas_generated\"\n",
    "            }\n",
    "        else:\n",
    "            return {**state, \"error\": \"No valid ideas after validation\", \"status\": \"error\"}\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Creative agent error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return {**state, \"error\": str(e), \"status\": \"error\"}\n",
    "\n",
    "print(\"âœ… Creative agent node RELOADED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dbc0740a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Analyst agent node FIXED for Pydantic objects\n"
     ]
    }
   ],
   "source": [
    "# Cell 19: Analyst Agent Node - FIXED for Pydantic Objects\n",
    "def analyst_agent_node(state: AudioPipelineState) -> AudioPipelineState:\n",
    "    \"\"\"\n",
    "    LangGraph node that scores blog ideas using company strategy context\n",
    "    Input: state[\"raw_blog_ideas\"] \n",
    "    Output: state[\"scored_blog_ideas\"]\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        print(\"ðŸ” Starting analyst agent - scoring blog ideas...\")\n",
    "        \n",
    "        # Check current status\n",
    "        current_status = state.get('status', '')\n",
    "        print(f\"ðŸ“Š Input status: {current_status}\")\n",
    "        \n",
    "        # Check if we have raw blog ideas to score\n",
    "        raw_ideas = state.get('raw_blog_ideas')\n",
    "        if not raw_ideas:\n",
    "            return {\n",
    "                **state,\n",
    "                \"error\": \"No raw blog ideas available for scoring\",\n",
    "                \"status\": \"error\"\n",
    "            }\n",
    "        \n",
    "        print(f\"ðŸ“Š Found {len(raw_ideas)} blog ideas to score\")\n",
    "        \n",
    "        # Load strategy context for scoring\n",
    "        print(\"ðŸ“š Loading strategy context...\")\n",
    "        strategy_context = prepare_strategy_context_for_scoring()\n",
    "        \n",
    "        # Get conversation context for better scoring\n",
    "        conversation_context = state.get('transcript_text', '')\n",
    "        \n",
    "        # Score each blog idea\n",
    "        scored_ideas = []\n",
    "        for i, idea in enumerate(raw_ideas, 1):\n",
    "            # FIXED: Handle both Pydantic objects and dicts properly\n",
    "            if hasattr(idea, 'title'):\n",
    "                # It's a Pydantic object - convert to dict first\n",
    "                idea_dict = idea.model_dump() if hasattr(idea, 'model_dump') else idea.__dict__\n",
    "                title_preview = idea.title[:50]\n",
    "            else:\n",
    "                # It's already a dict\n",
    "                idea_dict = idea\n",
    "                title_preview = idea.get('title', 'No title')[:50]\n",
    "            \n",
    "            print(f\"ðŸ” Scoring idea {i}/{len(raw_ideas)}: {title_preview}...\")\n",
    "            \n",
    "            # Score the idea (now always working with dict)\n",
    "            scores = score_blog_idea_with_llm(idea_dict, strategy_context, conversation_context)\n",
    "            \n",
    "            # Combine original idea with scores\n",
    "            scored_idea = {\n",
    "                **idea_dict,  # Original idea data (now definitely a dict)\n",
    "                **scores      # Scoring data\n",
    "            }\n",
    "            \n",
    "            scored_ideas.append(scored_idea)\n",
    "            \n",
    "            print(f\"   âœ… Scored: {scores.get('total_score', 0)}/70 points\")\n",
    "        \n",
    "        # Sort by total score (highest first)\n",
    "        scored_ideas.sort(key=lambda x: x.get('total_score', 0), reverse=True)\n",
    "        \n",
    "        print(f\"\\nðŸŽ‰ Analyst agent completed scoring!\")\n",
    "        print(f\"ðŸ“Š Scored {len(scored_ideas)} ideas\")\n",
    "        \n",
    "        if scored_ideas:\n",
    "            print(f\"ðŸ† Top idea: '{scored_ideas[0].get('title', 'Unknown')[:50]}...' ({scored_ideas[0].get('total_score', 0)}/70)\")\n",
    "            print(f\"ðŸ“‰ Lowest idea: '{scored_ideas[-1].get('title', 'Unknown')[:50]}...' ({scored_ideas[-1].get('total_score', 0)}/70)\")\n",
    "        \n",
    "        return {\n",
    "            **state,\n",
    "            \"scored_blog_ideas\": scored_ideas,\n",
    "            \"status\": \"ideas_scored\"\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error in analyst agent node: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        \n",
    "        return {\n",
    "            **state,\n",
    "            \"error\": f\"Analyst agent error: {str(e)}\",\n",
    "            \"status\": \"error\"\n",
    "        }\n",
    "\n",
    "print(\"âœ… Analyst agent node FIXED for Pydantic objects\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f5cabeaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… AssemblyAI connection successful\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 4: Test AssemblyAI Connection\n",
    "# Configure AssemblyAI\n",
    "aai.settings.api_key = os.getenv('ASSEMBLYAI_API_KEY')\n",
    "\n",
    "# Test with a simple transcription (we'll use a file from temp folder)\n",
    "def test_assemblyai_connection():\n",
    "    \"\"\"Test if AssemblyAI is working\"\"\"\n",
    "    try:\n",
    "        # Just test the API key is valid\n",
    "        transcriber = aai.Transcriber()\n",
    "        print(\"âœ… AssemblyAI connection successful\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ AssemblyAI connection failed: {e}\")\n",
    "        return False\n",
    "\n",
    "test_assemblyai_connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8762d70d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Database saver node (blog ideas) ready - FIXED RETURN\n"
     ]
    }
   ],
   "source": [
    "# Cell: Database Saver Node for BLOG IDEAS (Node 6) - FIXED RETURN\n",
    "from database.models import BlogPostIdeaCreate\n",
    "\n",
    "def database_saver_node(state: AudioPipelineState) -> AudioPipelineState:\n",
    "    \"\"\"\n",
    "    LangGraph node that saves scored blog ideas to database\n",
    "    Input: state[\"scored_blog_ideas\"]\n",
    "    Output: state[\"saved_idea_ids\"]\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        print(\"ðŸ’¾ Starting database saver - saving scored blog ideas...\")\n",
    "        \n",
    "        scored_ideas = state.get('scored_blog_ideas')\n",
    "        conversation_id = state.get('conversation_id')\n",
    "        \n",
    "        if not scored_ideas:\n",
    "            print(\"âŒ No scored blog ideas available to save\")\n",
    "            return {\n",
    "                **state,\n",
    "                \"error\": \"No scored blog ideas available to save\",\n",
    "                \"status\": \"error\"\n",
    "            }\n",
    "        \n",
    "        if not conversation_id:\n",
    "            print(\"âŒ No conversation_id available for linking ideas\")\n",
    "            return {\n",
    "                **state,\n",
    "                \"error\": \"No conversation_id available for linking ideas\",\n",
    "                \"status\": \"error\"\n",
    "            }\n",
    "        \n",
    "        print(f\"ðŸ“Š Found {len(scored_ideas)} scored ideas to save\")\n",
    "        print(f\"ðŸ”— Linking ideas to conversation_id: {conversation_id}\")\n",
    "        \n",
    "        saved_idea_ids = []\n",
    "        failed_count = 0\n",
    "        \n",
    "        for i, scored_idea in enumerate(scored_ideas, 1):\n",
    "            try:\n",
    "                # Calculate total_score if not present\n",
    "                if 'total_score' not in scored_idea:\n",
    "                    scored_idea['total_score'] = sum([\n",
    "                        scored_idea.get('usefulness_potential', 0),\n",
    "                        scored_idea.get('fitwith_seo_strategy', 0),\n",
    "                        scored_idea.get('fitwith_content_strategy', 0),\n",
    "                        scored_idea.get('inspiration_potential', 0),\n",
    "                        scored_idea.get('collaboration_potential', 0),\n",
    "                        scored_idea.get('innovation', 0),\n",
    "                        scored_idea.get('difficulty', 0)\n",
    "                    ])\n",
    "                \n",
    "                blog_idea = BlogPostIdeaCreate(\n",
    "                    conversation_id=conversation_id,\n",
    "                    title=scored_idea.get('title', 'Untitled'),\n",
    "                    description=scored_idea.get('description', ''),\n",
    "                    usefulness_potential=scored_idea.get('usefulness_potential', 5),\n",
    "                    fitwith_seo_strategy=scored_idea.get('fitwith_seo_strategy', 5),\n",
    "                    fitwith_content_strategy=scored_idea.get('fitwith_content_strategy', 5),\n",
    "                    inspiration_potential=scored_idea.get('inspiration_potential', 5),\n",
    "                    collaboration_potential=scored_idea.get('collaboration_potential', 5),\n",
    "                    innovation=scored_idea.get('innovation', 5),\n",
    "                    difficulty=scored_idea.get('difficulty', 5),\n",
    "                    sent_to_prod=False,\n",
    "                    raw_llm_response=scored_idea.get('reasoning', None)\n",
    "                )\n",
    "                \n",
    "                idea_id = db.create_blog_post_idea(blog_idea)\n",
    "                saved_idea_ids.append(idea_id)\n",
    "                \n",
    "                print(f\"   âœ… Saved idea {i}: '{scored_idea.get('title', 'Unknown')[:50]}...' (ID: {idea_id})\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"   âŒ Failed to save idea {i}: {e}\")\n",
    "                failed_count += 1\n",
    "        \n",
    "        if saved_idea_ids:\n",
    "            print(f\"\\nðŸŽ‰ Database saver completed!\")\n",
    "            print(f\"âœ… Successfully saved: {len(saved_idea_ids)} ideas\")\n",
    "            if failed_count > 0:\n",
    "                print(f\"âš ï¸  Failed to save: {failed_count} ideas\")\n",
    "            \n",
    "            # FIXED: Explicitly return saved_idea_ids in the state\n",
    "            return {\n",
    "                **state,\n",
    "                \"saved_idea_ids\": saved_idea_ids,  # â† This is the critical line\n",
    "                \"status\": \"ideas_saved_to_db\"\n",
    "            }\n",
    "        else:\n",
    "            print(\"âŒ Failed to save any ideas to database\")\n",
    "            return {\n",
    "                **state,\n",
    "                \"saved_idea_ids\": [],  # Return empty list instead of None\n",
    "                \"error\": \"Failed to save any ideas to database\",\n",
    "                \"status\": \"error\"\n",
    "            }\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error in database saver node: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        \n",
    "        return {\n",
    "            **state,\n",
    "            \"saved_idea_ids\": [],  # Return empty list on error\n",
    "            \"error\": f\"Database saver error: {str(e)}\",\n",
    "            \"status\": \"error\"\n",
    "        }\n",
    "\n",
    "print(\"âœ… Database saver node (blog ideas) ready - FIXED RETURN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8c379c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… LangGraph pipeline compiled (6 nodes: transcribe â†’ save_to_db â†’ extract_insights â†’ creative_agent â†’ analyst_agent - save scored ideas to db)\n"
     ]
    }
   ],
   "source": [
    "# Cell 21: Updated Pipeline Builder - Now with 5 Nodes\n",
    "def build_pipeline():\n",
    "    \"\"\"Build the complete LangGraph workflow: Audio â†’ Transcribe â†’ Save â†’ Insights â†’ Ideas â†’ Scoring\"\"\"\n",
    "    workflow = StateGraph(AudioPipelineState)\n",
    "    \n",
    "    # Add all 5 nodes\n",
    "    workflow.add_node(\"transcribe\", transcription_node)\n",
    "    workflow.add_node(\"save_to_db\", database_saver_node_conversations)  \n",
    "    workflow.add_node(\"extract_insights\", pain_extractor_node)\n",
    "    workflow.add_node(\"creative_agent\", creative_agent_node)\n",
    "    workflow.add_node(\"analyst_agent\", analyst_agent_node)\n",
    "    workflow.add_node(\"save_ideas\", database_saver_node)  # NEW: Node 6\n",
    "    \n",
    "    # Chain them together\n",
    "    workflow.add_edge(\"transcribe\", \"save_to_db\")\n",
    "    workflow.add_edge(\"save_to_db\", \"extract_insights\")\n",
    "    workflow.add_edge(\"extract_insights\", \"creative_agent\")\n",
    "    workflow.add_edge(\"creative_agent\", \"analyst_agent\")    \n",
    "    workflow.add_edge(\"analyst_agent\", \"save_ideas\") \n",
    "    \n",
    "    workflow.set_entry_point(\"transcribe\")\n",
    "    workflow.set_finish_point(\"analyst_agent\")              # NEW: End with analyst\n",
    "    \n",
    "    return workflow.compile()\n",
    "\n",
    "# Rebuild the pipeline with 5 nodes\n",
    "pipeline = build_pipeline()\n",
    "print(\"âœ… LangGraph pipeline compiled (6 nodes: transcribe â†’ save_to_db â†’ extract_insights â†’ creative_agent â†’ analyst_agent - save scored ideas to db)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2e18e44f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Anthropic LLM initialized with Claude Haiku 4.5\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Setup Anthropic LLM for Insights Extraction (FIXED)\n",
    "\n",
    "\n",
    "# Initialize Anthropic with correct model name\n",
    "anthropic_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "if not anthropic_key:\n",
    "    print(\"âš ï¸  ANTHROPIC_API_KEY not found in .env file\")\n",
    "    print(\"Please add: ANTHROPIC_API_KEY=your_key_here\")\n",
    "else:\n",
    "    llm = ChatAnthropic(\n",
    "        model=\"claude-haiku-4-5\",  # â† Updated model name\n",
    "        api_key=anthropic_key,\n",
    "        temperature=0.1\n",
    "    )\n",
    "    print(\"âœ… Anthropic LLM initialized with Claude Haiku 4.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6b3cea20",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3. PainExtractor Node Implementation\n",
    "\n",
    "# System prompt\n",
    "PAIN_EXTRACTOR_SYSTEM_PROMPT = \"\"\"\n",
    "You are a UX researcher and business analyst for BigKids Automation. Your job is listening to transcripts from interviews with users and potential clients. \n",
    "\n",
    "You pay special attention to problems that users have regarding how their company is automating, using web apps and AI to save time and move towards a more ethical and sovereign tech infrastructure.\n",
    "\n",
    "You will be given the transcript of an interview with a user or potential client.\n",
    "\n",
    "Your task is to extract structured information about:\n",
    "- Who is speaking and their role\n",
    "- What this person cares about (values, priorities)\n",
    "- Their main primary and secondary challenges\n",
    "- How they are solving problems today\n",
    "- Are there AI agents that can assist them?\n",
    "- Their underlying psychological needs (using frameworks like NVC - Non-Violent Communication)\n",
    "\n",
    "Focus on automation, web apps, AI, time-saving, ethical tech, and sovereign infrastructure themes.\n",
    "\n",
    "Be thorough but concise. \n",
    "\n",
    "IMPORTANT: Only extract information that is explicitly mentioned in the transcript. \n",
    "If information is not clearly stated, leave the field empty/null rather than guessing or inferring.\n",
    "Do not hallucinate or make assumptions about missing information.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4465cb3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded company strategy (6555 chars)\n",
      "âœ… Loaded SEO strategy (1120 chars)\n",
      "âœ… Loaded content strategy (4469 chars)\n",
      "âœ… Enhanced strategy context for scoring with 3 documents\n",
      "   Company strategy: 6555 chars\n",
      "   SEO strategy: 1120 chars\n",
      "   Content strategy: 4469 chars\n"
     ]
    }
   ],
   "source": [
    "# Cell 16: Enhanced Strategy Context for Scoring (Updated for 3 Documents)\n",
    "def prepare_strategy_context_for_scoring():\n",
    "    \"\"\"Prepare strategy context for scoring using all three strategy documents\"\"\"\n",
    "    \n",
    "    # Load all three strategy documents\n",
    "    strategy_context = load_company_strategy_context()\n",
    "    \n",
    "    # Add scoring guidelines\n",
    "    strategy_context[\"scoring_guidelines\"] = \"\"\"\n",
    "    SCORING CRITERIA (1-10 scale):\n",
    "    \n",
    "    1. usefulness_potential: How useful will this post be to readers with problems?\n",
    "    2. fitwith_seo_strategy: How well does this align with our SEO strategy and keywords?\n",
    "    3. fitwith_content_strategy: How well does this fit our content strategy and voice?\n",
    "    4. inspiration_potential: How likely is this to inspire readers to take action?\n",
    "    5. collaboration_potential: How likely is this to encourage prospects to contact us?\n",
    "    6. innovation: How unique/differentiated is this topic (10 = very unique)?\n",
    "    7. difficulty: How complex is this to write (1 = very complex, 10 = easy)?\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create summaries for LLM prompt efficiency (all three documents)\n",
    "    if strategy_context.get('company_strategy'):\n",
    "        strategy_context[\"company_strategy_summary\"] = strategy_context['company_strategy'][:800] + \"...\"\n",
    "    \n",
    "    if strategy_context.get('seo_strategy'):\n",
    "        strategy_context[\"seo_strategy_summary\"] = strategy_context['seo_strategy'][:600] + \"...\"\n",
    "    \n",
    "    if strategy_context.get('content_strategy'):  # NEW\n",
    "        strategy_context[\"content_strategy_summary\"] = strategy_context['content_strategy'][:600] + \"...\"\n",
    "    \n",
    "    print(f\"âœ… Enhanced strategy context for scoring with 3 documents\")\n",
    "    print(f\"   Company strategy: {len(strategy_context.get('company_strategy', ''))} chars\")\n",
    "    print(f\"   SEO strategy: {len(strategy_context.get('seo_strategy', ''))} chars\")\n",
    "    print(f\"   Content strategy: {len(strategy_context.get('content_strategy', ''))} chars\")\n",
    "    \n",
    "    return strategy_context\n",
    "\n",
    "# Test the enhanced context\n",
    "enhanced_context = prepare_strategy_context_for_scoring()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e7786fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§ª Testing three-document strategy loading...\n",
      "âœ… Loaded company strategy (6555 chars)\n",
      "âœ… Loaded SEO strategy (1120 chars)\n",
      "âœ… Loaded content strategy (4469 chars)\n",
      "âœ… Enhanced strategy context for scoring with 3 documents\n",
      "   Company strategy: 6555 chars\n",
      "   SEO strategy: 1120 chars\n",
      "   Content strategy: 4469 chars\n",
      "\n",
      "ðŸ“Š DOCUMENT SUMMARY:\n",
      "   company_strategy: âœ… Loaded (6555 chars)\n",
      "   seo_strategy: âœ… Loaded (1120 chars)\n",
      "   content_strategy: âœ… Loaded (4469 chars)\n"
     ]
    }
   ],
   "source": [
    "# Cell: Fixed Test Function (No Duplicate Loading)\n",
    "def test_three_document_loading():\n",
    "    \"\"\"Test loading all three strategy documents (optimized)\"\"\"\n",
    "    \n",
    "    print(\"ðŸ§ª Testing three-document strategy loading...\")\n",
    "    \n",
    "    # Load documents once and enhance\n",
    "    enhanced = prepare_strategy_context_for_scoring()  # This calls load_company_strategy_context() internally\n",
    "    \n",
    "    print(f\"\\nðŸ“Š DOCUMENT SUMMARY:\")\n",
    "    for doc_type in ['company_strategy', 'seo_strategy', 'content_strategy']:\n",
    "        if doc_type in enhanced:\n",
    "            length = len(enhanced[doc_type]) if enhanced[doc_type] else 0\n",
    "            status = \"âœ… Loaded\" if length > 100 else \"âš ï¸ Missing/Short\"\n",
    "            print(f\"   {doc_type}: {status} ({length} chars)\")\n",
    "    \n",
    "    return enhanced\n",
    "\n",
    "# Test with no duplicates\n",
    "test_context = test_three_document_loading()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c8dd7440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Ready to test complete 6-node pipeline\n",
      "ðŸ’¡ Run the cell below to execute the test\n",
      "\n",
      "ðŸ§ª EXECUTING COMPLETE 6-NODE PIPELINE TEST...\n",
      "Audio â†’ Transcribe â†’ Save â†’ Insights â†’ Ideas â†’ Scoring â†’ Save Ideas\n",
      "------------------------------------------------------------\n",
      "ðŸ“ Found 1 audio file(s)\n",
      "ðŸŽ¯ Testing with: blog_record_(purevitalize).wav\n",
      "ðŸ“Š File size: 25016.7 KB\n",
      "\n",
      "ðŸŽ¬ STARTING COMPLETE PIPELINE EXECUTION...\n",
      "============================================================\n",
      "ðŸŽ™ï¸ Transcribing: blog_record_(purevitalize).wav\n",
      "ðŸ’¾ Saving to database: blog_record_(purevitalize).wav\n",
      "ðŸ§  Starting pain extraction...\n",
      "ðŸ“ Raw response length: 3201 chars\n",
      "ðŸ“ Response starts with: ```json\n",
      "{\n",
      "    \"speakers\": [\n",
      "        {\n",
      "            ...\n",
      "ðŸ”§ Removing JSON markdown blocks...\n",
      "ðŸ”§ Cleaned content starts with: {\n",
      "    \"speakers\": [\n",
      "        {\n",
      "            \"name\": ...\n",
      "âœ… Successfully extracted insights with correct speaker roles!\n",
      "âœ… Extracted insights: 3 primary challenges, 1 speakers\n",
      "ðŸŽ¨ Starting creative blog idea generation...\n",
      "ðŸ“Š Working with insights: 3 challenges\n",
      "âœ… Loaded company strategy (6555 chars)\n",
      "âœ… Loaded SEO strategy (1120 chars)\n",
      "âœ… Loaded content strategy (4469 chars)\n",
      "ðŸ“ Raw response length: 4412 chars\n",
      "ðŸ“ Response starts with: ```json\n",
      "[\n",
      "    {\n",
      "        \"title\": \"Custom AI vs Saa...\n",
      "ðŸ”§ Removing markdown code blocks...\n",
      "ðŸ”§ Cleaned content starts with: [\n",
      "    {\n",
      "        \"title\": \"Custom AI vs SaaS for GD...\n",
      "âœ… Creative agent successfully parsed 5 blog ideas\n",
      "ðŸŽ‰ Generated 5 valid blog ideas\n",
      "ðŸ” Starting analyst agent - scoring blog ideas...\n",
      "ðŸ“Š Input status: ideas_generated\n",
      "ðŸ“Š Found 5 blog ideas to score\n",
      "ðŸ“š Loading strategy context...\n",
      "âœ… Loaded company strategy (6555 chars)\n",
      "âœ… Loaded SEO strategy (1120 chars)\n",
      "âœ… Loaded content strategy (4469 chars)\n",
      "ðŸ” Scoring idea 1/5: Custom AI vs SaaS for GDPR Compliance: A Decision ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6381/4162762669.py:36: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  ideas_as_dicts = [idea.dict() for idea in validated_ideas]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   âœ… Scored: 47/70 points\n",
      "ðŸ” Scoring idea 2/5: The Security Audit Checklist: What to Ask Before I...\n",
      "   âœ… Scored: 43/70 points\n",
      "ðŸ” Scoring idea 3/5: Email Automation Without the Risk: How to Implemen...\n",
      "   âœ… Scored: 43/70 points\n",
      "ðŸ” Scoring idea 4/5: From Uncertainty to Strategy: How to Build Your AI...\n",
      "   âœ… Scored: 43/70 points\n",
      "ðŸ” Scoring idea 5/5: The Interdependence Model: How to Choose AI Soluti...\n",
      "   âœ… Scored: 56/70 points\n",
      "\n",
      "ðŸŽ‰ Analyst agent completed scoring!\n",
      "ðŸ“Š Scored 5 ideas\n",
      "ðŸ† Top idea: 'The Interdependence Model: How to Choose AI Soluti...' (56/70)\n",
      "ðŸ“‰ Lowest idea: 'From Uncertainty to Strategy: How to Build Your AI...' (43/70)\n",
      "ðŸ’¾ Starting database saver - saving scored blog ideas...\n",
      "ðŸ“Š Found 5 scored ideas to save\n",
      "ðŸ”— Linking ideas to conversation_id: 28\n",
      "   âœ… Saved idea 1: 'The Interdependence Model: How to Choose AI Soluti...' (ID: 13)\n",
      "   âœ… Saved idea 2: 'Custom AI vs SaaS for GDPR Compliance: A Decision ...' (ID: 14)\n",
      "   âœ… Saved idea 3: 'The Security Audit Checklist: What to Ask Before I...' (ID: 15)\n",
      "   âœ… Saved idea 4: 'Email Automation Without the Risk: How to Implemen...' (ID: 16)\n",
      "   âœ… Saved idea 5: 'From Uncertainty to Strategy: How to Build Your AI...' (ID: 17)\n",
      "\n",
      "ðŸŽ‰ Database saver completed!\n",
      "âœ… Successfully saved: 5 ideas\n",
      "\n",
      "ðŸ“Š COMPLETE PIPELINE RESULTS:\n",
      "============================================================\n",
      "ðŸŽ¯ Final Status: ideas_saved_to_db\n",
      "ðŸ“ Conversation ID: 28\n",
      "ðŸ’¾ Saved Blog Idea IDs: [13, 14, 15, 16, 17]\n",
      "\n",
      "ðŸ“‹ STAGE RESULTS:\n",
      "   ðŸŽ™ï¸  Transcription: âœ…\n",
      "   ðŸ’¾ Database Save (Conversation): âœ…\n",
      "   ðŸ§  Insights Extraction: âœ…\n",
      "   ðŸŽ¨ Blog Ideas Generation: âœ…\n",
      "   ðŸ” Blog Ideas Scoring: âœ…\n",
      "   ðŸ’¾ Database Save (Ideas): âœ…\n",
      "\n",
      "ðŸŽ‰ COMPLETE SUCCESS! Pipeline generated, scored, and saved 5 blog ideas\n",
      "================================================================================\n",
      "\n",
      "ðŸ“ Conversation Details:\n",
      "   ID: 28\n",
      "   Transcript Length: 1790 characters\n",
      "\n",
      "ðŸ§  Extracted Insights:\n",
      "   ðŸ‘¥ Speakers: 1\n",
      "   ðŸ”¥ Primary Challenges: 3\n",
      "   ðŸ§˜ Psychological Needs: 5\n",
      "   ðŸ’Ž Core Values: 6\n",
      "\n",
      "ðŸ’¾ Database Save Summary:\n",
      "   Total Ideas Generated: 5\n",
      "   Ideas Successfully Saved: 5\n",
      "   Save Success Rate: 100.0%\n",
      "   Saved Idea IDs: [13, 14, 15, 16, 17]\n",
      "\n",
      "ðŸŽ¨ Top Scored Blog Ideas (Now in Database!):\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "ðŸ† RANKED IDEA #1 (Total Score: 56/70):\n",
      "   ðŸ†” Database ID: 13\n",
      "   ðŸ“ Title: The Interdependence Model: How to Choose AI Solutions That Align With Your ...\n",
      "   ðŸ“– Description: A values-driven framework for evaluating AI and automation tools that honors both human and technolo...\n",
      "   ðŸ“Š Breakdown:\n",
      "      â€¢ Usefulness: 9/10\n",
      "      â€¢ SEO Fit: 7/10\n",
      "      â€¢ Content Fit: 10/10\n",
      "      â€¢ Inspiration: 8/10\n",
      "      â€¢ Collaboration: 9/10\n",
      "      â€¢ Innovation: 8/10\n",
      "      â€¢ Easy to Write: 5/10\n",
      "\n",
      "ðŸ† RANKED IDEA #2 (Total Score: 47/70):\n",
      "   ðŸ†” Database ID: 14\n",
      "   ðŸ“ Title: Custom AI vs SaaS for GDPR Compliance: A Decision Framework for European SM...\n",
      "   ðŸ“– Description: A practical comparison guide that helps European businesses evaluate custom AI solutions against Saa...\n",
      "   ðŸ“Š Breakdown:\n",
      "      â€¢ Usefulness: 8/10\n",
      "      â€¢ SEO Fit: 9/10\n",
      "      â€¢ Content Fit: 7/10\n",
      "      â€¢ Inspiration: 5/10\n",
      "      â€¢ Collaboration: 9/10\n",
      "      â€¢ Innovation: 6/10\n",
      "      â€¢ Easy to Write: 3/10\n",
      "\n",
      "ðŸ† RANKED IDEA #3 (Total Score: 43/70):\n",
      "   ðŸ†” Database ID: 15\n",
      "   ðŸ“ Title: The Security Audit Checklist: What to Ask Before Implementing Any AI Automa...\n",
      "   ðŸ“– Description: An actionable security framework that helps business leaders evaluate data protection capabilities o...\n",
      "   ðŸ“Š Breakdown:\n",
      "      â€¢ Usefulness: 7/10\n",
      "      â€¢ SEO Fit: 8/10\n",
      "      â€¢ Content Fit: 6/10\n",
      "      â€¢ Inspiration: 5/10\n",
      "      â€¢ Collaboration: 7/10\n",
      "      â€¢ Innovation: 6/10\n",
      "      â€¢ Easy to Write: 4/10\n",
      "================================================================================\n",
      "ðŸŽ‰ COMPLETE 6-NODE PIPELINE: SUCCESS!\n",
      "âœ… All stages completed successfully\n",
      "ðŸ’¾ Conversation saved (ID: 28)\n",
      "ðŸ’¾ 5 blog ideas saved to database\n",
      "ðŸ”— Ideas linked to conversation for traceability\n",
      "\n",
      "ðŸ’¡ NEXT STEPS:\n",
      "   â€¢ Query saved ideas: db.get_blog_post_ideas_by_conversation(28)\n",
      "   â€¢ View conversation: db.get_conversation(28)\n",
      "   â€¢ Access specific idea: db.get_blog_post_idea(13)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CELL 22: EXECUTE COMPLETE 6-NODE PIPELINE TEST (FIXED)\n",
    "# ============================================================\n",
    "\n",
    "def test_complete_6_node_pipeline():\n",
    "    \"\"\"Test the complete 6-node pipeline: Audio â†’ Transcribe â†’ Save â†’ Insights â†’ Ideas â†’ Scoring â†’ Save Ideas\"\"\"\n",
    "    \n",
    "    print(\"ðŸ§ª EXECUTING COMPLETE 6-NODE PIPELINE TEST...\")\n",
    "    print(\"Audio â†’ Transcribe â†’ Save â†’ Insights â†’ Ideas â†’ Scoring â†’ Save Ideas\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    # Find audio files\n",
    "    audio_files = find_audio_files_in_temp()\n",
    "    \n",
    "    if not audio_files:\n",
    "        print(\"âŒ No audio files found in data/temp/\")\n",
    "        print(\"ðŸ’¡ Add .wav files to data/temp/ and run this cell again\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"ðŸ“ Found {len(audio_files)} audio file(s)\")\n",
    "    print(f\"ðŸŽ¯ Testing with: {audio_files[0].name}\")\n",
    "    print(f\"ðŸ“Š File size: {audio_files[0].stat().st_size / 1024:.1f} KB\")\n",
    "    \n",
    "    # Create initial state for 6-node pipeline\n",
    "    initial_state = {\n",
    "        \"file_path\": str(audio_files[0]),\n",
    "        \"filename\": audio_files[0].name,\n",
    "        \"transcript_text\": None,\n",
    "        \"conversation_id\": None,\n",
    "        \"extracted_insights\": None,\n",
    "        \"raw_blog_ideas\": None,\n",
    "        \"scored_blog_ideas\": None,\n",
    "        \"saved_idea_ids\": None,  # NEW: For Node 6\n",
    "        \"error\": None,\n",
    "        \"status\": \"processing\"\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        print(\"\\nðŸŽ¬ STARTING COMPLETE PIPELINE EXECUTION...\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # Run the complete 6-node pipeline\n",
    "        final_state = pipeline.invoke(initial_state)\n",
    "        \n",
    "        print(f\"\\nðŸ“Š COMPLETE PIPELINE RESULTS:\")\n",
    "        print(\"=\" * 60)\n",
    "        print(f\"ðŸŽ¯ Final Status: {final_state.get('status')}\")\n",
    "        print(f\"ðŸ“ Conversation ID: {final_state.get('conversation_id')}\")\n",
    "        print(f\"ðŸ’¾ Saved Blog Idea IDs: {final_state.get('saved_idea_ids')}\")\n",
    "        \n",
    "        # Check all pipeline stages\n",
    "        print(f\"\\nðŸ“‹ STAGE RESULTS:\")\n",
    "        stages = [\n",
    "            (\"ðŸŽ™ï¸  Transcription\", final_state.get('transcript_text')),\n",
    "            (\"ðŸ’¾ Database Save (Conversation)\", final_state.get('conversation_id')),\n",
    "            (\"ðŸ§  Insights Extraction\", final_state.get('extracted_insights')),\n",
    "            (\"ðŸŽ¨ Blog Ideas Generation\", final_state.get('raw_blog_ideas')),\n",
    "            (\"ðŸ” Blog Ideas Scoring\", final_state.get('scored_blog_ideas')),\n",
    "            (\"ðŸ’¾ Database Save (Ideas)\", final_state.get('saved_idea_ids'))  # NEW: Node 6\n",
    "        ]\n",
    "        \n",
    "        all_passed = True\n",
    "        for stage_name, stage_data in stages:\n",
    "            status = \"âœ…\" if stage_data else \"âŒ\"\n",
    "            print(f\"   {stage_name}: {status}\")\n",
    "            if not stage_data:\n",
    "                all_passed = False\n",
    "        \n",
    "        # Show detailed results if all stages passed\n",
    "        if all_passed and final_state.get('scored_blog_ideas') and final_state.get('saved_idea_ids'):\n",
    "            scored_ideas = final_state['scored_blog_ideas']\n",
    "            saved_ids = final_state['saved_idea_ids']\n",
    "            \n",
    "            print(f\"\\nðŸŽ‰ COMPLETE SUCCESS! Pipeline generated, scored, and saved {len(saved_ids)} blog ideas\")\n",
    "            print(\"=\" * 80)\n",
    "            \n",
    "            # Show conversation info\n",
    "            print(f\"\\nðŸ“ Conversation Details:\")\n",
    "            print(f\"   ID: {final_state.get('conversation_id')}\")\n",
    "            print(f\"   Transcript Length: {len(final_state.get('transcript_text', ''))} characters\")\n",
    "            \n",
    "            # Show insights summary\n",
    "            if final_state.get('extracted_insights'):\n",
    "                insights = final_state['extracted_insights']\n",
    "                print(f\"\\nðŸ§  Extracted Insights:\")\n",
    "                print(f\"   ðŸ‘¥ Speakers: {len(insights.speakers) if hasattr(insights, 'speakers') else 'N/A'}\")\n",
    "                print(f\"   ðŸ”¥ Primary Challenges: {len(insights.primary_challenges) if hasattr(insights, 'primary_challenges') else 'N/A'}\")\n",
    "                print(f\"   ðŸ§˜ Psychological Needs: {len(insights.psychological_needs) if hasattr(insights, 'psychological_needs') else 'N/A'}\")\n",
    "                print(f\"   ðŸ’Ž Core Values: {len(insights.core_values) if hasattr(insights, 'core_values') else 'N/A'}\")\n",
    "            \n",
    "            # Show database save results\n",
    "            print(f\"\\nðŸ’¾ Database Save Summary:\")\n",
    "            print(f\"   Total Ideas Generated: {len(scored_ideas)}\")\n",
    "            print(f\"   Ideas Successfully Saved: {len(saved_ids)}\")\n",
    "            print(f\"   Save Success Rate: {len(saved_ids)/len(scored_ideas)*100:.1f}%\")\n",
    "            print(f\"   Saved Idea IDs: {saved_ids}\")\n",
    "            \n",
    "            # Show top scored ideas with their database IDs\n",
    "            print(f\"\\nðŸŽ¨ Top Scored Blog Ideas (Now in Database!):\")\n",
    "            print(\"-\" * 80)\n",
    "            \n",
    "            # FIXED: Proper zip syntax\n",
    "            top_count = min(3, len(scored_ideas), len(saved_ids))  # Get minimum to avoid index errors\n",
    "            for i in range(top_count):\n",
    "                idea = scored_ideas[i]\n",
    "                db_id = saved_ids[i]\n",
    "                \n",
    "                print(f\"\\nðŸ† RANKED IDEA #{i+1} (Total Score: {idea.get('total_score', 0)}/70):\")\n",
    "                print(f\"   ðŸ†” Database ID: {db_id}\")\n",
    "                print(f\"   ðŸ“ Title: {idea.get('title', 'No title')[:75]}...\")\n",
    "                print(f\"   ðŸ“– Description: {idea.get('description', 'No description')[:100]}...\")\n",
    "                print(f\"   ðŸ“Š Breakdown:\")\n",
    "                print(f\"      â€¢ Usefulness: {idea.get('usefulness_potential', 0)}/10\")\n",
    "                print(f\"      â€¢ SEO Fit: {idea.get('fitwith_seo_strategy', 0)}/10\")\n",
    "                print(f\"      â€¢ Content Fit: {idea.get('fitwith_content_strategy', 0)}/10\")\n",
    "                print(f\"      â€¢ Inspiration: {idea.get('inspiration_potential', 0)}/10\")\n",
    "                print(f\"      â€¢ Collaboration: {idea.get('collaboration_potential', 0)}/10\")\n",
    "                print(f\"      â€¢ Innovation: {idea.get('innovation', 0)}/10\")\n",
    "                print(f\"      â€¢ Easy to Write: {idea.get('difficulty', 0)}/10\")\n",
    "            \n",
    "            print(\"=\" * 80)\n",
    "            print(\"ðŸŽ‰ COMPLETE 6-NODE PIPELINE: SUCCESS!\")\n",
    "            print(\"âœ… All stages completed successfully\")\n",
    "            print(f\"ðŸ’¾ Conversation saved (ID: {final_state.get('conversation_id')})\")\n",
    "            print(f\"ðŸ’¾ {len(saved_ids)} blog ideas saved to database\")\n",
    "            print(f\"ðŸ”— Ideas linked to conversation for traceability\")\n",
    "            \n",
    "            # Show how to retrieve the saved data\n",
    "            print(f\"\\nðŸ’¡ NEXT STEPS:\")\n",
    "            print(f\"   â€¢ Query saved ideas: db.get_blog_post_ideas_by_conversation({final_state.get('conversation_id')})\")\n",
    "            print(f\"   â€¢ View conversation: db.get_conversation({final_state.get('conversation_id')})\")\n",
    "            print(f\"   â€¢ Access specific idea: db.get_blog_post_idea({saved_ids[0]})\")\n",
    "            \n",
    "        else:\n",
    "            # Something failed\n",
    "            print(\"\\nâŒ PIPELINE INCOMPLETE\")\n",
    "            print(\"=\" * 50)\n",
    "            if final_state.get('error'):\n",
    "                print(f\"âŒ Error: {final_state.get('error')}\")\n",
    "            else:\n",
    "                print(\"âŒ Pipeline stopped but no error message provided\")\n",
    "            \n",
    "            # Show what we did get\n",
    "            print(f\"\\nðŸ” DEBUG INFO:\")\n",
    "            print(f\"   Transcript exists: {bool(final_state.get('transcript_text'))}\")\n",
    "            if final_state.get('transcript_text'):\n",
    "                print(f\"   Transcript preview: {final_state.get('transcript_text')[:100]}...\")\n",
    "            print(f\"   Conversation ID: {final_state.get('conversation_id')}\")\n",
    "            print(f\"   Insights exist: {bool(final_state.get('extracted_insights'))}\")\n",
    "            print(f\"   Raw ideas exist: {bool(final_state.get('raw_blog_ideas'))}\")\n",
    "            if final_state.get('raw_blog_ideas'):\n",
    "                print(f\"   Raw ideas count: {len(final_state.get('raw_blog_ideas'))}\")\n",
    "            print(f\"   Scored ideas exist: {bool(final_state.get('scored_blog_ideas'))}\")\n",
    "            if final_state.get('scored_blog_ideas'):\n",
    "                print(f\"   Scored ideas count: {len(final_state.get('scored_blog_ideas'))}\")\n",
    "            print(f\"   Saved idea IDs exist: {bool(final_state.get('saved_idea_ids'))}\")\n",
    "            if final_state.get('saved_idea_ids'):\n",
    "                print(f\"   Saved ideas count: {len(final_state.get('saved_idea_ids'))}\")\n",
    "        \n",
    "        return final_state\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nâŒ COMPLETE PIPELINE FAILED WITH EXCEPTION:\")\n",
    "        print(f\"   {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "# ============================================================\n",
    "# RUN THE TEST\n",
    "# ============================================================\n",
    "\n",
    "print(\"ðŸš€ Ready to test complete 6-node pipeline\")\n",
    "print(\"ðŸ’¡ Run the cell below to execute the test\\n\")\n",
    "\n",
    "# Uncomment the line below to run automatically, or run it manually\n",
    "test_result = test_complete_6_node_pipeline()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "815ddcc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Pipeline rebuilt with updated creative agent\n"
     ]
    }
   ],
   "source": [
    "# Cell: Rebuild Pipeline with Updated Node\n",
    "pipeline = build_pipeline()\n",
    "print(\"âœ… Pipeline rebuilt with updated creative agent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "603ff83b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Terminal dashboard ready (using db.get_all_ideas and db.get_ideas_by_conversation)\n"
     ]
    }
   ],
   "source": [
    "# Cell: Terminal Dashboard - Using Existing DB Methods\n",
    "def show_ideas_dashboard(conversation_id=None, top_n=10):\n",
    "    \"\"\"\n",
    "    Beautiful terminal dashboard showing scored blog ideas\n",
    "    Uses existing db.get_all_ideas() or db.get_ideas_by_conversation()\n",
    "    \n",
    "    Args:\n",
    "        conversation_id: Show ideas for specific conversation (None = all ideas)\n",
    "        top_n: Number of top ideas to show\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 100)\n",
    "    print(\"ðŸ“Š BLOG IDEAS DASHBOARD\")\n",
    "    print(\"=\" * 100)\n",
    "    \n",
    "    # Get ideas using existing methods\n",
    "    if conversation_id:\n",
    "        ideas = db.get_ideas_by_conversation(conversation_id)\n",
    "        print(f\"ðŸ“ Showing ideas from Conversation ID: {conversation_id}\")\n",
    "    else:\n",
    "        ideas = db.get_all_ideas()\n",
    "        print(f\"ðŸ“ Showing ALL ideas from database\")\n",
    "    \n",
    "    if not ideas:\n",
    "        print(\"âš ï¸  No ideas found in database\")\n",
    "        return\n",
    "    \n",
    "    # Calculate scores and sort\n",
    "    scored_ideas = []\n",
    "    for idea in ideas:\n",
    "        # Handle both dict and object formats\n",
    "        if isinstance(idea, dict):\n",
    "            total = sum([\n",
    "                idea.get('usefulness_potential', 0),\n",
    "                idea.get('fitwith_seo_strategy', 0),\n",
    "                idea.get('fitwith_content_strategy', 0),\n",
    "                idea.get('inspiration_potential', 0),\n",
    "                idea.get('collaboration_potential', 0),\n",
    "                idea.get('innovation', 0),\n",
    "                idea.get('difficulty', 0)\n",
    "            ])\n",
    "        else:\n",
    "            total = sum([\n",
    "                idea.usefulness_potential,\n",
    "                idea.fitwith_seo_strategy,\n",
    "                idea.fitwith_content_strategy,\n",
    "                idea.inspiration_potential,\n",
    "                idea.collaboration_potential,\n",
    "                idea.innovation,\n",
    "                idea.difficulty\n",
    "            ])\n",
    "        scored_ideas.append((idea, total))\n",
    "    \n",
    "    # Sort by total score (highest first)\n",
    "    scored_ideas.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Show summary stats\n",
    "    all_scores = [s[1] for s in scored_ideas]\n",
    "    avg_score = sum(all_scores) / len(all_scores)\n",
    "    \n",
    "    print(f\"\\nðŸ“ˆ SUMMARY STATISTICS\")\n",
    "    print(f\"   Total Ideas: {len(scored_ideas)}\")\n",
    "    print(f\"   Average Score: {avg_score:.1f}/70 ({avg_score/70*100:.1f}%)\")\n",
    "    print(f\"   Highest Score: {scored_ideas[0][1]}/70 ({scored_ideas[0][1]/70*100:.1f}%)\")\n",
    "    print(f\"   Lowest Score: {scored_ideas[-1][1]}/70 ({scored_ideas[-1][1]/70*100:.1f}%)\")\n",
    "    \n",
    "    # Show score distribution\n",
    "    high_scores = sum(1 for s in all_scores if s >= 60)\n",
    "    medium_scores = sum(1 for s in all_scores if 50 <= s < 60)\n",
    "    low_scores = sum(1 for s in all_scores if s < 50)\n",
    "    \n",
    "    print(f\"\\nðŸ“Š SCORE DISTRIBUTION\")\n",
    "    print(f\"   ðŸŸ¢ High (60-70):  {high_scores} ideas ({high_scores/len(all_scores)*100:.1f}%)\")\n",
    "    print(f\"   ðŸŸ¡ Medium (50-59): {medium_scores} ideas ({medium_scores/len(all_scores)*100:.1f}%)\")\n",
    "    print(f\"   ðŸ”´ Low (<50):     {low_scores} ideas ({low_scores/len(all_scores)*100:.1f}%)\")\n",
    "    \n",
    "    # Show top ideas\n",
    "    display_count = min(top_n, len(scored_ideas))\n",
    "    print(f\"\\nðŸ† TOP {display_count} IDEAS\")\n",
    "    print(\"-\" * 100)\n",
    "    \n",
    "    for rank, (idea, total_score) in enumerate(scored_ideas[:top_n], 1):\n",
    "        # Handle both dict and object formats\n",
    "        if isinstance(idea, dict):\n",
    "            idea_id = idea.get('id')\n",
    "            title = idea.get('title', 'Untitled')\n",
    "            usefulness = idea.get('usefulness_potential', 0)\n",
    "            seo = idea.get('fitwith_seo_strategy', 0)\n",
    "            content = idea.get('fitwith_content_strategy', 0)\n",
    "            inspiration = idea.get('inspiration_potential', 0)\n",
    "            collaboration = idea.get('collaboration_potential', 0)\n",
    "            innovation = idea.get('innovation', 0)\n",
    "            difficulty = idea.get('difficulty', 0)\n",
    "            created_at = idea.get('created_at', 'Unknown')\n",
    "            conv_id = idea.get('conversation_id', 'N/A')\n",
    "            sent_to_prod = idea.get('sent_to_prod', False)\n",
    "        else:\n",
    "            idea_id = idea.id\n",
    "            title = idea.title\n",
    "            usefulness = idea.usefulness_potential\n",
    "            seo = idea.fitwith_seo_strategy\n",
    "            content = idea.fitwith_content_strategy\n",
    "            inspiration = idea.inspiration_potential\n",
    "            collaboration = idea.collaboration_potential\n",
    "            innovation = idea.innovation\n",
    "            difficulty = idea.difficulty\n",
    "            created_at = idea.created_at\n",
    "            conv_id = idea.conversation_id\n",
    "            sent_to_prod = idea.sent_to_prod\n",
    "        \n",
    "        # Create score bar\n",
    "        bar_length = 35\n",
    "        percentage = total_score / 70\n",
    "        filled = int(percentage * bar_length)\n",
    "        bar = \"â–ˆ\" * filled + \"â–‘\" * (bar_length - filled)\n",
    "        \n",
    "        # Medal emoji for top 3\n",
    "        medal = {1: \"ðŸ¥‡\", 2: \"ðŸ¥ˆ\", 3: \"ðŸ¥‰\"}.get(rank, f\"{rank:2d}.\")\n",
    "        \n",
    "        # Color indicator based on score\n",
    "        if total_score >= 60:\n",
    "            indicator = \"ðŸŸ¢\"  # High score\n",
    "        elif total_score >= 50:\n",
    "            indicator = \"ðŸŸ¡\"  # Medium score\n",
    "        else:\n",
    "            indicator = \"ðŸ”´\"  # Low score\n",
    "        \n",
    "        print(f\"\\n{medal} {indicator} ID: {idea_id} | Score: {total_score}/70 ({percentage*100:.1f}%)\")\n",
    "        print(f\"   ðŸ“ {title}\")\n",
    "        print(f\"   ðŸ“Š [{bar}] {total_score}/70\")\n",
    "        print(f\"   ðŸ’¡ Breakdown:\")\n",
    "        print(f\"      â€¢ Usefulness: {usefulness}/10 | SEO Fit: {seo}/10 | Content Fit: {content}/10\")\n",
    "        print(f\"      â€¢ Inspiration: {inspiration}/10 | Collaboration: {collaboration}/10\")\n",
    "        print(f\"      â€¢ Innovation: {innovation}/10 | Difficulty (ease): {difficulty}/10\")\n",
    "        print(f\"   ðŸ“… Created: {created_at}\")\n",
    "        print(f\"   ðŸ”— Conversation: {conv_id}\")\n",
    "        \n",
    "        if sent_to_prod:\n",
    "            print(f\"   âœ… STATUS: SENT TO PRODUCTION\")\n",
    "        else:\n",
    "            print(f\"   ðŸ“ STATUS: Draft\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 100)\n",
    "    print(\"ðŸ’¡ USAGE TIPS:\")\n",
    "    print(\"   show_ideas_dashboard()              # Show all ideas\")\n",
    "    print(\"   show_ideas_dashboard(28)            # Show ideas from conversation 28\")\n",
    "    print(\"   show_ideas_dashboard(28, top_n=3)   # Show top 3 ideas only\")\n",
    "    print(\"=\" * 100 + \"\\n\")\n",
    "\n",
    "print(\"âœ… Terminal dashboard ready (using db.get_all_ideas and db.get_ideas_by_conversation)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e004553b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Quick view function ready\n"
     ]
    }
   ],
   "source": [
    "# Cell: Quick View - Compact Dashboard\n",
    "def quick_view(conversation_id=None):\n",
    "    \"\"\"Quick compact view of scored ideas\"\"\"\n",
    "    \n",
    "    ideas = db.get_ideas_by_conversation(conversation_id) if conversation_id else db.get_all_ideas()\n",
    "    \n",
    "    if not ideas:\n",
    "        print(\"âš ï¸  No ideas found\")\n",
    "        return\n",
    "    \n",
    "    # Score and sort\n",
    "    scored = []\n",
    "    for idea in ideas:\n",
    "        if isinstance(idea, dict):\n",
    "            total = sum([idea.get('usefulness_potential', 0), idea.get('fitwith_seo_strategy', 0),\n",
    "                        idea.get('fitwith_content_strategy', 0), idea.get('inspiration_potential', 0),\n",
    "                        idea.get('collaboration_potential', 0), idea.get('innovation', 0), idea.get('difficulty', 0)])\n",
    "            scored.append((idea, total))\n",
    "        else:\n",
    "            total = sum([idea.usefulness_potential, idea.fitwith_seo_strategy, idea.fitwith_content_strategy,\n",
    "                        idea.inspiration_potential, idea.collaboration_potential, idea.innovation, idea.difficulty])\n",
    "            scored.append((idea, total))\n",
    "    \n",
    "    scored.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    print(f\"\\n{'='*100}\")\n",
    "    print(f\"ðŸ“Š {'CONVERSATION ' + str(conversation_id) if conversation_id else 'ALL IDEAS'} | Total: {len(scored)} ideas | Avg: {sum(s[1] for s in scored)/len(scored):.1f}/70\")\n",
    "    print(f\"{'='*100}\\n\")\n",
    "    \n",
    "    for rank, (idea, score) in enumerate(scored, 1):\n",
    "        if isinstance(idea, dict):\n",
    "            idea_id, title = idea.get('id'), idea.get('title', 'Untitled')\n",
    "        else:\n",
    "            idea_id, title = idea.id, idea.title\n",
    "        \n",
    "        medal = {1: \"ðŸ¥‡\", 2: \"ðŸ¥ˆ\", 3: \"ðŸ¥‰\"}.get(rank, f\"{rank:2d}.\")\n",
    "        indicator = \"ðŸŸ¢\" if score >= 60 else \"ðŸŸ¡\" if score >= 50 else \"ðŸ”´\"\n",
    "        \n",
    "        print(f\"{medal} {indicator} [{idea_id:3d}] {score:2d}/70 | {title[:75]}\")\n",
    "    \n",
    "    print(f\"\\n{'='*100}\\n\")\n",
    "\n",
    "print(\"âœ… Quick view function ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e508f9ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§ª Test 1: Full dashboard for conversation 28\n",
      "\n",
      "====================================================================================================\n",
      "ðŸ“Š BLOG IDEAS DASHBOARD\n",
      "====================================================================================================\n",
      "ðŸ“ Showing ideas from Conversation ID: 28\n",
      "\n",
      "ðŸ“ˆ SUMMARY STATISTICS\n",
      "   Total Ideas: 5\n",
      "   Average Score: 46.4/70 (66.3%)\n",
      "   Highest Score: 56/70 (80.0%)\n",
      "   Lowest Score: 43/70 (61.4%)\n",
      "\n",
      "ðŸ“Š SCORE DISTRIBUTION\n",
      "   ðŸŸ¢ High (60-70):  0 ideas (0.0%)\n",
      "   ðŸŸ¡ Medium (50-59): 1 ideas (20.0%)\n",
      "   ðŸ”´ Low (<50):     4 ideas (80.0%)\n",
      "\n",
      "ðŸ† TOP 5 IDEAS\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "ðŸ¥‡ ðŸŸ¡ ID: 13 | Score: 56/70 (80.0%)\n",
      "   ðŸ“ The Interdependence Model: How to Choose AI Solutions That Align With Your Company Values\n",
      "   ðŸ“Š [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘] 56/70\n",
      "   ðŸ’¡ Breakdown:\n",
      "      â€¢ Usefulness: 9/10 | SEO Fit: 7/10 | Content Fit: 10/10\n",
      "      â€¢ Inspiration: 8/10 | Collaboration: 9/10\n",
      "      â€¢ Innovation: 8/10 | Difficulty (ease): 5/10\n",
      "   ðŸ“… Created: 2025-11-28 09:03:16\n",
      "   ðŸ”— Conversation: 28\n",
      "   ðŸ“ STATUS: Draft\n",
      "\n",
      "ðŸ¥ˆ ðŸ”´ ID: 14 | Score: 47/70 (67.1%)\n",
      "   ðŸ“ Custom AI vs SaaS for GDPR Compliance: A Decision Framework for European SMEs\n",
      "   ðŸ“Š [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 47/70\n",
      "   ðŸ’¡ Breakdown:\n",
      "      â€¢ Usefulness: 8/10 | SEO Fit: 9/10 | Content Fit: 7/10\n",
      "      â€¢ Inspiration: 5/10 | Collaboration: 9/10\n",
      "      â€¢ Innovation: 6/10 | Difficulty (ease): 3/10\n",
      "   ðŸ“… Created: 2025-11-28 09:03:16\n",
      "   ðŸ”— Conversation: 28\n",
      "   ðŸ“ STATUS: Draft\n",
      "\n",
      "ðŸ¥‰ ðŸ”´ ID: 15 | Score: 43/70 (61.4%)\n",
      "   ðŸ“ The Security Audit Checklist: What to Ask Before Implementing Any AI Automation Tool\n",
      "   ðŸ“Š [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 43/70\n",
      "   ðŸ’¡ Breakdown:\n",
      "      â€¢ Usefulness: 7/10 | SEO Fit: 8/10 | Content Fit: 6/10\n",
      "      â€¢ Inspiration: 5/10 | Collaboration: 7/10\n",
      "      â€¢ Innovation: 6/10 | Difficulty (ease): 4/10\n",
      "   ðŸ“… Created: 2025-11-28 09:03:16\n",
      "   ðŸ”— Conversation: 28\n",
      "   ðŸ“ STATUS: Draft\n",
      "\n",
      " 4. ðŸ”´ ID: 16 | Score: 43/70 (61.4%)\n",
      "   ðŸ“ Email Automation Without the Risk: How to Implement AI Communication Tools While Protecting Customer Data\n",
      "   ðŸ“Š [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 43/70\n",
      "   ðŸ’¡ Breakdown:\n",
      "      â€¢ Usefulness: 7/10 | SEO Fit: 8/10 | Content Fit: 6/10\n",
      "      â€¢ Inspiration: 5/10 | Collaboration: 8/10\n",
      "      â€¢ Innovation: 5/10 | Difficulty (ease): 4/10\n",
      "   ðŸ“… Created: 2025-11-28 09:03:16\n",
      "   ðŸ”— Conversation: 28\n",
      "   ðŸ“ STATUS: Draft\n",
      "\n",
      " 5. ðŸ”´ ID: 17 | Score: 43/70 (61.4%)\n",
      "   ðŸ“ From Uncertainty to Strategy: How to Build Your AI Adoption Roadmap Without Betting the Company\n",
      "   ðŸ“Š [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 43/70\n",
      "   ðŸ’¡ Breakdown:\n",
      "      â€¢ Usefulness: 7/10 | SEO Fit: 8/10 | Content Fit: 6/10\n",
      "      â€¢ Inspiration: 5/10 | Collaboration: 8/10\n",
      "      â€¢ Innovation: 5/10 | Difficulty (ease): 4/10\n",
      "   ðŸ“… Created: 2025-11-28 09:03:16\n",
      "   ðŸ”— Conversation: 28\n",
      "   ðŸ“ STATUS: Draft\n",
      "\n",
      "====================================================================================================\n",
      "ðŸ’¡ USAGE TIPS:\n",
      "   show_ideas_dashboard()              # Show all ideas\n",
      "   show_ideas_dashboard(28)            # Show ideas from conversation 28\n",
      "   show_ideas_dashboard(28, top_n=3)   # Show top 3 ideas only\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "ðŸ§ª Test 2: Quick view for all ideas\n",
      "\n",
      "====================================================================================================\n",
      "ðŸ“Š ALL IDEAS | Total: 17 ideas | Avg: 40.3/70\n",
      "====================================================================================================\n",
      "\n",
      "ðŸ¥‡ ðŸŸ¡ [ 13] 56/70 | The Interdependence Model: How to Choose AI Solutions That Align With Your \n",
      "ðŸ¥ˆ ðŸŸ¡ [  2] 52/70 | Test Blog Idea 2: Cost-Benefit Analysis of Custom AI\n",
      "ðŸ¥‰ ðŸŸ¡ [  1] 51/70 | Test Blog Idea 1: AI Automation for Small Business\n",
      " 4. ðŸ”´ [ 14] 47/70 | Custom AI vs SaaS for GDPR Compliance: A Decision Framework for European SM\n",
      " 5. ðŸ”´ [ 15] 43/70 | The Security Audit Checklist: What to Ask Before Implementing Any AI Automa\n",
      " 6. ðŸ”´ [ 16] 43/70 | Email Automation Without the Risk: How to Implement AI Communication Tools \n",
      " 7. ðŸ”´ [ 17] 43/70 | From Uncertainty to Strategy: How to Build Your AI Adoption Roadmap Without\n",
      " 8. ðŸ”´ [  3] 35/70 | Custom AI vs SaaS for SMEs: A Privacy-First Decision Framework\n",
      " 9. ðŸ”´ [  4] 35/70 | GDPR-Compliant AI Implementation: A Step-by-Step Roadmap for European Busin\n",
      "10. ðŸ”´ [  5] 35/70 | The Hidden Security Risks of AI Adoption (And How to Mitigate Them Before I\n",
      "11. ðŸ”´ [  6] 35/70 | Email Automation Without the Compliance Headache: Evaluating Copilot and Al\n",
      "12. ðŸ”´ [  7] 35/70 | Strategic AI Adoption for Competitive Advantage: How to Choose Efficiency G\n",
      "13. ðŸ”´ [  8] 35/70 | Custom AI vs SaaS for GDPR Compliance: Which Path Protects Your Business?\n",
      "14. ðŸ”´ [  9] 35/70 | The Hidden Risks of AI Adoption: A Checklist for Smart Implementation\n",
      "15. ðŸ”´ [ 10] 35/70 | Email Automation Done Right: Beyond Copilotâ€”Building Systems That Respect Y\n",
      "16. ðŸ”´ [ 11] 35/70 | AI Implementation Roadmap for SMEs: How to Stay Competitive Without Comprom\n",
      "17. ðŸ”´ [ 12] 35/70 | The Interdependence Advantage: How to Choose AI Tools That Amplify Human Ca\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "ðŸ§ª Test 3: Quick view for conversation 28\n",
      "\n",
      "====================================================================================================\n",
      "ðŸ“Š CONVERSATION 28 | Total: 5 ideas | Avg: 46.4/70\n",
      "====================================================================================================\n",
      "\n",
      "ðŸ¥‡ ðŸŸ¡ [ 13] 56/70 | The Interdependence Model: How to Choose AI Solutions That Align With Your \n",
      "ðŸ¥ˆ ðŸ”´ [ 14] 47/70 | Custom AI vs SaaS for GDPR Compliance: A Decision Framework for European SM\n",
      "ðŸ¥‰ ðŸ”´ [ 15] 43/70 | The Security Audit Checklist: What to Ask Before Implementing Any AI Automa\n",
      " 4. ðŸ”´ [ 16] 43/70 | Email Automation Without the Risk: How to Implement AI Communication Tools \n",
      " 5. ðŸ”´ [ 17] 43/70 | From Uncertainty to Strategy: How to Build Your AI Adoption Roadmap Without\n",
      "\n",
      "====================================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test 1: Full dashboard for conversation 28\n",
    "print(\"ðŸ§ª Test 1: Full dashboard for conversation 28\")\n",
    "show_ideas_dashboard(28)\n",
    "\n",
    "# Test 2: Quick view for all ideas\n",
    "print(\"\\nðŸ§ª Test 2: Quick view for all ideas\")\n",
    "quick_view()\n",
    "\n",
    "# Test 3: Quick view for conversation 28\n",
    "print(\"\\nðŸ§ª Test 3: Quick view for conversation 28\")\n",
    "quick_view(28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5b304522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… list_conversations() REPLACED with safe version\n"
     ]
    }
   ],
   "source": [
    "# Cell: FIXED list_conversations (Run this to replace the old one)\n",
    "def list_conversations():\n",
    "    \"\"\"Show all conversations in the database (safe version - NO audio_file_path)\"\"\"\n",
    "    \n",
    "    conversations = db.get_all_conversations()\n",
    "    \n",
    "    if not conversations:\n",
    "        print(\"âš ï¸  No conversations found in database\")\n",
    "        return\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 100)\n",
    "    print(\"ðŸ’¬ ALL CONVERSATIONS IN DATABASE\")\n",
    "    print(\"=\" * 100)\n",
    "    \n",
    "    for conv in conversations:\n",
    "        # Use the safe helper functions (NO direct attribute access)\n",
    "        conv_id = get_conv_attribute(conv, 'id', 'Unknown')\n",
    "        filename = get_conv_filename(conv)  # This handles missing audio_file_path\n",
    "        transcript = get_conv_attribute(conv, 'transcript_text', '')\n",
    "        transcript_len = len(transcript) if transcript else 0\n",
    "        created = get_conv_attribute(conv, 'created_at', 'Unknown')\n",
    "        \n",
    "        # Get idea count for this conversation\n",
    "        ideas = db.get_ideas_by_conversation(conv_id)\n",
    "        idea_count = len(ideas) if ideas else 0\n",
    "        \n",
    "        # Calculate average score if ideas exist\n",
    "        if ideas and idea_count > 0:\n",
    "            total_scores = []\n",
    "            for idea in ideas:\n",
    "                if isinstance(idea, dict):\n",
    "                    score = sum([idea.get('usefulness_potential', 0), idea.get('fitwith_seo_strategy', 0),\n",
    "                               idea.get('fitwith_content_strategy', 0), idea.get('inspiration_potential', 0),\n",
    "                               idea.get('collaboration_potential', 0), idea.get('innovation', 0), \n",
    "                               idea.get('difficulty', 0)])\n",
    "                else:\n",
    "                    score = sum([\n",
    "                        get_idea_attribute(idea, 'usefulness_potential', 0),\n",
    "                        get_idea_attribute(idea, 'fitwith_seo_strategy', 0),\n",
    "                        get_idea_attribute(idea, 'fitwith_content_strategy', 0),\n",
    "                        get_idea_attribute(idea, 'inspiration_potential', 0),\n",
    "                        get_idea_attribute(idea, 'collaboration_potential', 0),\n",
    "                        get_idea_attribute(idea, 'innovation', 0),\n",
    "                        get_idea_attribute(idea, 'difficulty', 0)\n",
    "                    ])\n",
    "                total_scores.append(score)\n",
    "            avg_score = sum(total_scores) / len(total_scores)\n",
    "            score_info = f\"Avg Score: {avg_score:.1f}/70\"\n",
    "        else:\n",
    "            score_info = \"No ideas yet\"\n",
    "        \n",
    "        print(f\"\\nðŸ“ ID: {conv_id}\")\n",
    "        print(f\"   ðŸŽ™ï¸  File: {filename}\")\n",
    "        print(f\"   ðŸ“ Transcript: {transcript_len} characters\")\n",
    "        print(f\"   ðŸ’¡ Ideas: {idea_count} | {score_info}\")\n",
    "        print(f\"   ðŸ“… Created: {created}\")\n",
    "        print(f\"   ðŸ”— View: show_ideas_dashboard({conv_id})\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 100)\n",
    "    print(f\"ðŸ’¡ Total Conversations: {len(conversations)}\")\n",
    "    print(\"=\" * 100 + \"\\n\")\n",
    "\n",
    "print(\"âœ… list_conversations() REPLACED with safe version\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bfb0f841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… select_conversation() ready\n"
     ]
    }
   ],
   "source": [
    "# Cell: Interactive Conversation Selector\n",
    "def select_conversation():\n",
    "    \"\"\"\n",
    "    Interactive menu to select a conversation to visualize\n",
    "    Returns the selected conversation ID\n",
    "    \"\"\"\n",
    "    \n",
    "    conversations = db.get_all_conversations()\n",
    "    \n",
    "    if not conversations:\n",
    "        print(\"âš ï¸  No conversations found in database\")\n",
    "        return None\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"ðŸ” SELECT A CONVERSATION TO VISUALIZE\")\n",
    "    print(\"=\" * 80 + \"\\n\")\n",
    "    \n",
    "    # Create a list with conversation details\n",
    "    conv_list = []\n",
    "    for conv in conversations:\n",
    "        if isinstance(conv, dict):\n",
    "            conv_id = conv.get('id')\n",
    "            filename = conv.get('audio_file_path', 'Unknown')\n",
    "            created = conv.get('created_at', 'Unknown')\n",
    "        else:\n",
    "            conv_id = conv.id\n",
    "            filename = conv.audio_file_path\n",
    "            created = conv.created_at\n",
    "        \n",
    "        # Get idea count\n",
    "        ideas = db.get_ideas_by_conversation(conv_id)\n",
    "        idea_count = len(ideas) if ideas else 0\n",
    "        \n",
    "        conv_list.append((conv_id, filename, idea_count, created))\n",
    "    \n",
    "    # Sort by ID (most recent first)\n",
    "    conv_list.sort(key=lambda x: x[0], reverse=True)\n",
    "    \n",
    "    # Display options\n",
    "    for i, (conv_id, filename, idea_count, created) in enumerate(conv_list, 1):\n",
    "        print(f\"{i}. [ID: {conv_id}] {filename}\")\n",
    "        print(f\"   ðŸ’¡ {idea_count} ideas | ðŸ“… {created}\")\n",
    "        print()\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Get user choice\n",
    "    try:\n",
    "        choice = input(f\"Enter number (1-{len(conv_list)}) or 'q' to quit: \").strip()\n",
    "        \n",
    "        if choice.lower() == 'q':\n",
    "            print(\"âŒ Cancelled\")\n",
    "            return None\n",
    "        \n",
    "        choice_num = int(choice)\n",
    "        if 1 <= choice_num <= len(conv_list):\n",
    "            selected_id = conv_list[choice_num - 1][0]\n",
    "            print(f\"\\nâœ… Selected Conversation ID: {selected_id}\")\n",
    "            return selected_id\n",
    "        else:\n",
    "            print(f\"âŒ Invalid choice. Please enter 1-{len(conv_list)}\")\n",
    "            return None\n",
    "            \n",
    "    except ValueError:\n",
    "        print(\"âŒ Invalid input. Please enter a number.\")\n",
    "        return None\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nâŒ Cancelled\")\n",
    "        return None\n",
    "\n",
    "print(\"âœ… select_conversation() ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ebcb1781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… smart_dashboard() ready\n"
     ]
    }
   ],
   "source": [
    "# Cell: Smart Dashboard with Auto-Detection\n",
    "def smart_dashboard(conversation_id=None, mode='latest'):\n",
    "    \"\"\"\n",
    "    Smart dashboard that can auto-select conversation\n",
    "    \n",
    "    Args:\n",
    "        conversation_id: Specific conversation ID (overrides mode)\n",
    "        mode: 'latest' = most recent, 'all' = all ideas, 'best' = highest scoring conversation\n",
    "    \"\"\"\n",
    "    \n",
    "    if conversation_id:\n",
    "        # User specified ID\n",
    "        show_ideas_dashboard(conversation_id)\n",
    "        return\n",
    "    \n",
    "    conversations = db.get_all_conversations()\n",
    "    \n",
    "    if not conversations:\n",
    "        print(\"âš ï¸  No conversations found\")\n",
    "        return\n",
    "    \n",
    "    if mode == 'latest':\n",
    "        # Show most recent conversation\n",
    "        latest = max(conversations, key=lambda c: c.id if not isinstance(c, dict) else c.get('id'))\n",
    "        latest_id = latest.id if not isinstance(latest, dict) else latest.get('id')\n",
    "        print(f\"ðŸ“Œ Showing LATEST conversation (ID: {latest_id})\")\n",
    "        show_ideas_dashboard(latest_id)\n",
    "        \n",
    "    elif mode == 'best':\n",
    "        # Find conversation with highest average score\n",
    "        best_conv_id = None\n",
    "        best_avg = 0\n",
    "        \n",
    "        for conv in conversations:\n",
    "            conv_id = conv.id if not isinstance(conv, dict) else conv.get('id')\n",
    "            ideas = db.get_ideas_by_conversation(conv_id)\n",
    "            \n",
    "            if ideas:\n",
    "                scores = []\n",
    "                for idea in ideas:\n",
    "                    if isinstance(idea, dict):\n",
    "                        score = sum([idea.get('usefulness_potential', 0), idea.get('fitwith_seo_strategy', 0),\n",
    "                                   idea.get('fitwith_content_strategy', 0), idea.get('inspiration_potential', 0),\n",
    "                                   idea.get('collaboration_potential', 0), idea.get('innovation', 0), \n",
    "                                   idea.get('difficulty', 0)])\n",
    "                    else:\n",
    "                        score = sum([idea.usefulness_potential, idea.fitwith_seo_strategy, idea.fitwith_content_strategy,\n",
    "                                   idea.inspiration_potential, idea.collaboration_potential, idea.innovation, idea.difficulty])\n",
    "                    scores.append(score)\n",
    "                \n",
    "                avg = sum(scores) / len(scores)\n",
    "                if avg > best_avg:\n",
    "                    best_avg = avg\n",
    "                    best_conv_id = conv_id\n",
    "        \n",
    "        if best_conv_id:\n",
    "            print(f\"ðŸ“Œ Showing BEST conversation (ID: {best_conv_id}, Avg: {best_avg:.1f}/70)\")\n",
    "            show_ideas_dashboard(best_conv_id)\n",
    "        else:\n",
    "            print(\"âš ï¸  No conversations with ideas found\")\n",
    "            \n",
    "    elif mode == 'all':\n",
    "        # Show all ideas\n",
    "        print(f\"ðŸ“Œ Showing ALL ideas from all conversations\")\n",
    "        show_ideas_dashboard()\n",
    "    \n",
    "    else:\n",
    "        print(f\"âŒ Unknown mode: {mode}. Use 'latest', 'best', or 'all'\")\n",
    "\n",
    "print(\"âœ… smart_dashboard() ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c80cede4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "ðŸ’¬ ALL CONVERSATIONS IN DATABASE\n",
      "====================================================================================================\n",
      "\n",
      "ðŸ“ ID: 28\n",
      "   ðŸŽ™ï¸  File: Conversation_28_2025-11-28\n",
      "   ðŸ“ Transcript: 0 characters\n",
      "   ðŸ’¡ Ideas: 5 | Avg Score: 46.4/70\n",
      "   ðŸ“… Created: 2025-11-28 09:02:37\n",
      "   ðŸ”— View: show_ideas_dashboard(28)\n",
      "\n",
      "ðŸ“ ID: 27\n",
      "   ðŸŽ™ï¸  File: Conversation_27_2025-11-28\n",
      "   ðŸ“ Transcript: 0 characters\n",
      "   ðŸ’¡ Ideas: 5 | Avg Score: 35.0/70\n",
      "   ðŸ“… Created: 2025-11-28 08:27:30\n",
      "   ðŸ”— View: show_ideas_dashboard(27)\n",
      "\n",
      "ðŸ“ ID: 26\n",
      "   ðŸŽ™ï¸  File: Conversation_26_2025-11-27\n",
      "   ðŸ“ Transcript: 0 characters\n",
      "   ðŸ’¡ Ideas: 5 | Avg Score: 35.0/70\n",
      "   ðŸ“… Created: 2025-11-27 09:11:49\n",
      "   ðŸ”— View: show_ideas_dashboard(26)\n",
      "\n",
      "ðŸ“ ID: 25\n",
      "   ðŸŽ™ï¸  File: Conversation_25_2025-11-26\n",
      "   ðŸ“ Transcript: 0 characters\n",
      "   ðŸ’¡ Ideas: 0 | No ideas yet\n",
      "   ðŸ“… Created: 2025-11-26 09:11:52\n",
      "   ðŸ”— View: show_ideas_dashboard(25)\n",
      "\n",
      "ðŸ“ ID: 24\n",
      "   ðŸŽ™ï¸  File: Conversation_24_2025-11-21\n",
      "   ðŸ“ Transcript: 0 characters\n",
      "   ðŸ’¡ Ideas: 0 | No ideas yet\n",
      "   ðŸ“… Created: 2025-11-21 09:58:56\n",
      "   ðŸ”— View: show_ideas_dashboard(24)\n",
      "\n",
      "ðŸ“ ID: 23\n",
      "   ðŸŽ™ï¸  File: Conversation_23_2025-11-19\n",
      "   ðŸ“ Transcript: 0 characters\n",
      "   ðŸ’¡ Ideas: 0 | No ideas yet\n",
      "   ðŸ“… Created: 2025-11-19 09:23:31\n",
      "   ðŸ”— View: show_ideas_dashboard(23)\n",
      "\n",
      "ðŸ“ ID: 22\n",
      "   ðŸŽ™ï¸  File: Conversation_22_2025-11-19\n",
      "   ðŸ“ Transcript: 0 characters\n",
      "   ðŸ’¡ Ideas: 0 | No ideas yet\n",
      "   ðŸ“… Created: 2025-11-19 09:22:11\n",
      "   ðŸ”— View: show_ideas_dashboard(22)\n",
      "\n",
      "ðŸ“ ID: 21\n",
      "   ðŸŽ™ï¸  File: Conversation_21_2025-11-19\n",
      "   ðŸ“ Transcript: 0 characters\n",
      "   ðŸ’¡ Ideas: 0 | No ideas yet\n",
      "   ðŸ“… Created: 2025-11-19 09:21:18\n",
      "   ðŸ”— View: show_ideas_dashboard(21)\n",
      "\n",
      "ðŸ“ ID: 20\n",
      "   ðŸŽ™ï¸  File: Conversation_20_2025-11-17\n",
      "   ðŸ“ Transcript: 0 characters\n",
      "   ðŸ’¡ Ideas: 0 | No ideas yet\n",
      "   ðŸ“… Created: 2025-11-17 08:54:02\n",
      "   ðŸ”— View: show_ideas_dashboard(20)\n",
      "\n",
      "ðŸ“ ID: 19\n",
      "   ðŸŽ™ï¸  File: Conversation_19_2025-11-17\n",
      "   ðŸ“ Transcript: 0 characters\n",
      "   ðŸ’¡ Ideas: 0 | No ideas yet\n",
      "   ðŸ“… Created: 2025-11-17 08:49:22\n",
      "   ðŸ”— View: show_ideas_dashboard(19)\n",
      "\n",
      "====================================================================================================\n",
      "ðŸ’¡ Total Conversations: 10\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "ðŸ“Š BLOG IDEAS DASHBOARD\n",
      "====================================================================================================\n",
      "ðŸ“ Showing ideas from Conversation ID: 28\n",
      "\n",
      "ðŸ“ˆ SUMMARY STATISTICS\n",
      "   Total Ideas: 5\n",
      "   Average Score: 46.4/70 (66.3%)\n",
      "   Highest Score: 56/70 (80.0%)\n",
      "   Lowest Score: 43/70 (61.4%)\n",
      "\n",
      "ðŸ“Š SCORE DISTRIBUTION\n",
      "   ðŸŸ¢ High (60-70):  0 ideas (0.0%)\n",
      "   ðŸŸ¡ Medium (50-59): 1 ideas (20.0%)\n",
      "   ðŸ”´ Low (<50):     4 ideas (80.0%)\n",
      "\n",
      "ðŸ† TOP 5 IDEAS\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "ðŸ¥‡ ðŸŸ¡ ID: 13 | Score: 56/70 (80.0%)\n",
      "   ðŸ“ The Interdependence Model: How to Choose AI Solutions That Align With Your Company Values\n",
      "   ðŸ“Š [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘] 56/70\n",
      "   ðŸ’¡ Breakdown:\n",
      "      â€¢ Usefulness: 9/10 | SEO Fit: 7/10 | Content Fit: 10/10\n",
      "      â€¢ Inspiration: 8/10 | Collaboration: 9/10\n",
      "      â€¢ Innovation: 8/10 | Difficulty (ease): 5/10\n",
      "   ðŸ“… Created: 2025-11-28 09:03:16\n",
      "   ðŸ”— Conversation: 28\n",
      "   ðŸ“ STATUS: Draft\n",
      "\n",
      "ðŸ¥ˆ ðŸ”´ ID: 14 | Score: 47/70 (67.1%)\n",
      "   ðŸ“ Custom AI vs SaaS for GDPR Compliance: A Decision Framework for European SMEs\n",
      "   ðŸ“Š [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 47/70\n",
      "   ðŸ’¡ Breakdown:\n",
      "      â€¢ Usefulness: 8/10 | SEO Fit: 9/10 | Content Fit: 7/10\n",
      "      â€¢ Inspiration: 5/10 | Collaboration: 9/10\n",
      "      â€¢ Innovation: 6/10 | Difficulty (ease): 3/10\n",
      "   ðŸ“… Created: 2025-11-28 09:03:16\n",
      "   ðŸ”— Conversation: 28\n",
      "   ðŸ“ STATUS: Draft\n",
      "\n",
      "ðŸ¥‰ ðŸ”´ ID: 15 | Score: 43/70 (61.4%)\n",
      "   ðŸ“ The Security Audit Checklist: What to Ask Before Implementing Any AI Automation Tool\n",
      "   ðŸ“Š [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 43/70\n",
      "   ðŸ’¡ Breakdown:\n",
      "      â€¢ Usefulness: 7/10 | SEO Fit: 8/10 | Content Fit: 6/10\n",
      "      â€¢ Inspiration: 5/10 | Collaboration: 7/10\n",
      "      â€¢ Innovation: 6/10 | Difficulty (ease): 4/10\n",
      "   ðŸ“… Created: 2025-11-28 09:03:16\n",
      "   ðŸ”— Conversation: 28\n",
      "   ðŸ“ STATUS: Draft\n",
      "\n",
      " 4. ðŸ”´ ID: 16 | Score: 43/70 (61.4%)\n",
      "   ðŸ“ Email Automation Without the Risk: How to Implement AI Communication Tools While Protecting Customer Data\n",
      "   ðŸ“Š [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 43/70\n",
      "   ðŸ’¡ Breakdown:\n",
      "      â€¢ Usefulness: 7/10 | SEO Fit: 8/10 | Content Fit: 6/10\n",
      "      â€¢ Inspiration: 5/10 | Collaboration: 8/10\n",
      "      â€¢ Innovation: 5/10 | Difficulty (ease): 4/10\n",
      "   ðŸ“… Created: 2025-11-28 09:03:16\n",
      "   ðŸ”— Conversation: 28\n",
      "   ðŸ“ STATUS: Draft\n",
      "\n",
      " 5. ðŸ”´ ID: 17 | Score: 43/70 (61.4%)\n",
      "   ðŸ“ From Uncertainty to Strategy: How to Build Your AI Adoption Roadmap Without Betting the Company\n",
      "   ðŸ“Š [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 43/70\n",
      "   ðŸ’¡ Breakdown:\n",
      "      â€¢ Usefulness: 7/10 | SEO Fit: 8/10 | Content Fit: 6/10\n",
      "      â€¢ Inspiration: 5/10 | Collaboration: 8/10\n",
      "      â€¢ Innovation: 5/10 | Difficulty (ease): 4/10\n",
      "   ðŸ“… Created: 2025-11-28 09:03:16\n",
      "   ðŸ”— Conversation: 28\n",
      "   ðŸ“ STATUS: Draft\n",
      "\n",
      "====================================================================================================\n",
      "ðŸ’¡ USAGE TIPS:\n",
      "   show_ideas_dashboard()              # Show all ideas\n",
      "   show_ideas_dashboard(28)            # Show ideas from conversation 28\n",
      "   show_ideas_dashboard(28, top_n=3)   # Show top 3 ideas only\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "ðŸ” SELECT A CONVERSATION TO VISUALIZE\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Conversation' object has no attribute 'audio_file_path'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[52]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m      9\u001b[39m show_ideas_dashboard(\u001b[32m28\u001b[39m)  \u001b[38;5;66;03m# Replace 28 with your chosen ID\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# ============================================\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# INTERACTIVE: Let the system guide you\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# ============================================\u001b[39;00m\n\u001b[32m     15\u001b[39m \n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# Interactive selection\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m selected_id = \u001b[43mselect_conversation\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m selected_id:\n\u001b[32m     19\u001b[39m     show_ideas_dashboard(selected_id)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 27\u001b[39m, in \u001b[36mselect_conversation\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     26\u001b[39m     conv_id = conv.id\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m     filename = \u001b[43mconv\u001b[49m\u001b[43m.\u001b[49m\u001b[43maudio_file_path\u001b[49m\n\u001b[32m     28\u001b[39m     created = conv.created_at\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# Get idea count\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/tech/ai_content_ops/.venv/lib/python3.13/site-packages/pydantic/main.py:991\u001b[39m, in \u001b[36mBaseModel.__getattr__\u001b[39m\u001b[34m(self, item)\u001b[39m\n\u001b[32m    988\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__getattribute__\u001b[39m(item)  \u001b[38;5;66;03m# Raises AttributeError if appropriate\u001b[39;00m\n\u001b[32m    989\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    990\u001b[39m     \u001b[38;5;66;03m# this is the current error\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m991\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m object has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'Conversation' object has no attribute 'audio_file_path'"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# SIMPLE: List all conversations and choose\n",
    "# ============================================\n",
    "\n",
    "# Step 1: See what conversations you have\n",
    "list_conversations()\n",
    "\n",
    "# Step 2: Pick one and visualize\n",
    "show_ideas_dashboard(28)  # Replace 28 with your chosen ID\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# INTERACTIVE: Let the system guide you\n",
    "# ============================================\n",
    "\n",
    "# Interactive selection\n",
    "selected_id = select_conversation()\n",
    "if selected_id:\n",
    "    show_ideas_dashboard(selected_id)\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# SMART: Auto-select interesting conversations\n",
    "# ============================================\n",
    "\n",
    "# Show latest conversation\n",
    "smart_dashboard(mode='latest')\n",
    "\n",
    "# Show conversation with best scores\n",
    "smart_dashboard(mode='best')\n",
    "\n",
    "# Show all ideas\n",
    "smart_dashboard(mode='all')\n",
    "\n",
    "# Or specify exact ID\n",
    "smart_dashboard(conversation_id=28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f042f68a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… explore_and_visualize() REPLACED with safe version\n"
     ]
    }
   ],
   "source": [
    "# Cell: FIXED explore_and_visualize (Run this to replace)\n",
    "def explore_and_visualize():\n",
    "    \"\"\"Complete workflow: list conversations, select, and visualize (SAFE version)\"\"\"\n",
    "    \n",
    "    print(\"ðŸ” STEP 1: Available Conversations\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    conversations = db.get_all_conversations()\n",
    "    \n",
    "    if not conversations:\n",
    "        print(\"âš ï¸  No conversations found\")\n",
    "        return\n",
    "    \n",
    "    # Show conversation list\n",
    "    conv_list = []\n",
    "    for conv in conversations:\n",
    "        # Use safe helpers (NO direct attribute access)\n",
    "        conv_id = get_conv_attribute(conv, 'id', 'Unknown')\n",
    "        filename = get_conv_filename(conv)  # This handles missing audio_file_path\n",
    "        \n",
    "        ideas = db.get_ideas_by_conversation(conv_id)\n",
    "        idea_count = len(ideas) if ideas else 0\n",
    "        \n",
    "        conv_list.append((conv_id, filename, idea_count))\n",
    "        print(f\"{len(conv_list)}. [ID: {conv_id}] {filename} ({idea_count} ideas)\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"ðŸŽ¯ STEP 2: Choose a conversation\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    try:\n",
    "        choice = input(f\"\\nEnter number (1-{len(conv_list)}), 'all' for everything, or 'q' to quit: \").strip()\n",
    "        \n",
    "        if choice.lower() == 'q':\n",
    "            print(\"âŒ Cancelled\")\n",
    "            return\n",
    "        \n",
    "        if choice.lower() == 'all':\n",
    "            print(\"\\nðŸ“Š Showing all ideas...\")\n",
    "            show_ideas_dashboard()\n",
    "        else:\n",
    "            choice_num = int(choice)\n",
    "            if 1 <= choice_num <= len(conv_list):\n",
    "                selected_id = conv_list[choice_num - 1][0]\n",
    "                print(f\"\\nðŸ“Š Showing conversation {selected_id}...\")\n",
    "                show_ideas_dashboard(selected_id)\n",
    "            else:\n",
    "                print(f\"âŒ Invalid choice\")\n",
    "    \n",
    "    except ValueError:\n",
    "        print(\"âŒ Invalid input\")\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nâŒ Cancelled\")\n",
    "\n",
    "print(\"âœ… explore_and_visualize() REPLACED with safe version\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "52c760b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” STEP 1: Available Conversations\n",
      "================================================================================\n",
      "1. [ID: 28] Conversation_28_2025-11-28 (5 ideas)\n",
      "2. [ID: 27] Conversation_27_2025-11-28 (5 ideas)\n",
      "3. [ID: 26] Conversation_26_2025-11-27 (5 ideas)\n",
      "4. [ID: 25] Conversation_25_2025-11-26 (0 ideas)\n",
      "5. [ID: 24] Conversation_24_2025-11-21 (0 ideas)\n",
      "6. [ID: 23] Conversation_23_2025-11-19 (0 ideas)\n",
      "7. [ID: 22] Conversation_22_2025-11-19 (0 ideas)\n",
      "8. [ID: 21] Conversation_21_2025-11-19 (0 ideas)\n",
      "9. [ID: 20] Conversation_20_2025-11-17 (0 ideas)\n",
      "10. [ID: 19] Conversation_19_2025-11-17 (0 ideas)\n",
      "\n",
      "================================================================================\n",
      "ðŸŽ¯ STEP 2: Choose a conversation\n",
      "================================================================================\n",
      "\n",
      "ðŸ“Š Showing conversation 24...\n",
      "\n",
      "====================================================================================================\n",
      "ðŸ“Š BLOG IDEAS DASHBOARD\n",
      "====================================================================================================\n",
      "ðŸ“ Showing ideas from Conversation ID: 24\n",
      "âš ï¸  No ideas found in database\n",
      "\n",
      "====================================================================================================\n",
      "ðŸ’¬ ALL CONVERSATIONS IN DATABASE\n",
      "====================================================================================================\n",
      "\n",
      "ðŸ“ ID: 28\n",
      "   ðŸŽ™ï¸  File: Conversation_28_2025-11-28\n",
      "   ðŸ“ Transcript: 0 characters\n",
      "   ðŸ’¡ Ideas: 5 | Avg Score: 46.4/70\n",
      "   ðŸ“… Created: 2025-11-28 09:02:37\n",
      "   ðŸ”— View: show_ideas_dashboard(28)\n",
      "\n",
      "ðŸ“ ID: 27\n",
      "   ðŸŽ™ï¸  File: Conversation_27_2025-11-28\n",
      "   ðŸ“ Transcript: 0 characters\n",
      "   ðŸ’¡ Ideas: 5 | Avg Score: 35.0/70\n",
      "   ðŸ“… Created: 2025-11-28 08:27:30\n",
      "   ðŸ”— View: show_ideas_dashboard(27)\n",
      "\n",
      "ðŸ“ ID: 26\n",
      "   ðŸŽ™ï¸  File: Conversation_26_2025-11-27\n",
      "   ðŸ“ Transcript: 0 characters\n",
      "   ðŸ’¡ Ideas: 5 | Avg Score: 35.0/70\n",
      "   ðŸ“… Created: 2025-11-27 09:11:49\n",
      "   ðŸ”— View: show_ideas_dashboard(26)\n",
      "\n",
      "ðŸ“ ID: 25\n",
      "   ðŸŽ™ï¸  File: Conversation_25_2025-11-26\n",
      "   ðŸ“ Transcript: 0 characters\n",
      "   ðŸ’¡ Ideas: 0 | No ideas yet\n",
      "   ðŸ“… Created: 2025-11-26 09:11:52\n",
      "   ðŸ”— View: show_ideas_dashboard(25)\n",
      "\n",
      "ðŸ“ ID: 24\n",
      "   ðŸŽ™ï¸  File: Conversation_24_2025-11-21\n",
      "   ðŸ“ Transcript: 0 characters\n",
      "   ðŸ’¡ Ideas: 0 | No ideas yet\n",
      "   ðŸ“… Created: 2025-11-21 09:58:56\n",
      "   ðŸ”— View: show_ideas_dashboard(24)\n",
      "\n",
      "ðŸ“ ID: 23\n",
      "   ðŸŽ™ï¸  File: Conversation_23_2025-11-19\n",
      "   ðŸ“ Transcript: 0 characters\n",
      "   ðŸ’¡ Ideas: 0 | No ideas yet\n",
      "   ðŸ“… Created: 2025-11-19 09:23:31\n",
      "   ðŸ”— View: show_ideas_dashboard(23)\n",
      "\n",
      "ðŸ“ ID: 22\n",
      "   ðŸŽ™ï¸  File: Conversation_22_2025-11-19\n",
      "   ðŸ“ Transcript: 0 characters\n",
      "   ðŸ’¡ Ideas: 0 | No ideas yet\n",
      "   ðŸ“… Created: 2025-11-19 09:22:11\n",
      "   ðŸ”— View: show_ideas_dashboard(22)\n",
      "\n",
      "ðŸ“ ID: 21\n",
      "   ðŸŽ™ï¸  File: Conversation_21_2025-11-19\n",
      "   ðŸ“ Transcript: 0 characters\n",
      "   ðŸ’¡ Ideas: 0 | No ideas yet\n",
      "   ðŸ“… Created: 2025-11-19 09:21:18\n",
      "   ðŸ”— View: show_ideas_dashboard(21)\n",
      "\n",
      "ðŸ“ ID: 20\n",
      "   ðŸŽ™ï¸  File: Conversation_20_2025-11-17\n",
      "   ðŸ“ Transcript: 0 characters\n",
      "   ðŸ’¡ Ideas: 0 | No ideas yet\n",
      "   ðŸ“… Created: 2025-11-17 08:54:02\n",
      "   ðŸ”— View: show_ideas_dashboard(20)\n",
      "\n",
      "ðŸ“ ID: 19\n",
      "   ðŸŽ™ï¸  File: Conversation_19_2025-11-17\n",
      "   ðŸ“ Transcript: 0 characters\n",
      "   ðŸ’¡ Ideas: 0 | No ideas yet\n",
      "   ðŸ“… Created: 2025-11-17 08:49:22\n",
      "   ðŸ”— View: show_ideas_dashboard(19)\n",
      "\n",
      "====================================================================================================\n",
      "ðŸ’¡ Total Conversations: 10\n",
      "====================================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Easiest way - interactive explorer\n",
    "explore_and_visualize()\n",
    "\n",
    "# Or just list them first\n",
    "list_conversations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "960369ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Inspecting Conversation model...\n",
      "============================================================\n",
      "âœ… Sample Conversation:\n",
      "   Type: <class 'database.models.Conversation'>\n",
      "   Fields: ['id', 'title', 'raw_text', 'source', 'word_count', 'created_at', 'status']\n",
      "\n",
      "ðŸ“‹ Field Details:\n",
      "      â€¢ id: <class 'int'>\n",
      "      â€¢ title: typing.Optional[str]\n",
      "      â€¢ raw_text: <class 'str'>\n",
      "      â€¢ source: <class 'str'>\n",
      "      â€¢ word_count: <class 'int'>\n",
      "      â€¢ created_at: <class 'datetime.datetime'>\n",
      "      â€¢ status: <class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7593/1689298502.py:19: PydanticDeprecatedSince211: Accessing the 'model_fields' attribute on the instance is deprecated. Instead, you should access this attribute from the model class. Deprecated in Pydantic V2.11 to be removed in V3.0.\n",
      "  print(f\"   Fields: {list(sample.model_fields.keys())}\")\n",
      "/tmp/ipykernel_7593/1689298502.py:21: PydanticDeprecatedSince211: Accessing the 'model_fields' attribute on the instance is deprecated. Instead, you should access this attribute from the model class. Deprecated in Pydantic V2.11 to be removed in V3.0.\n",
      "  for field_name, field_info in sample.model_fields.items():\n"
     ]
    }
   ],
   "source": [
    "# Cell: Inspect Conversation Model\n",
    "from database.models import Conversation\n",
    "\n",
    "# Check what fields Conversation actually has\n",
    "print(\"ðŸ” Inspecting Conversation model...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Try to get a sample conversation\n",
    "conversations = db.get_all_conversations()\n",
    "if conversations:\n",
    "    sample = conversations[0]\n",
    "    print(f\"âœ… Sample Conversation:\")\n",
    "    print(f\"   Type: {type(sample)}\")\n",
    "    \n",
    "    if isinstance(sample, dict):\n",
    "        print(f\"   Keys: {list(sample.keys())}\")\n",
    "    else:\n",
    "        # It's a Pydantic model\n",
    "        print(f\"   Fields: {list(sample.model_fields.keys())}\")\n",
    "        print(f\"\\nðŸ“‹ Field Details:\")\n",
    "        for field_name, field_info in sample.model_fields.items():\n",
    "            print(f\"      â€¢ {field_name}: {field_info.annotation}\")\n",
    "else:\n",
    "    print(\"âš ï¸  No conversations found to inspect\")\n",
    "    print(\"\\nðŸ’¡ Checking Conversation model definition instead...\")\n",
    "    print(f\"   Fields: {list(Conversation.model_fields.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "191a502f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Inspecting Conversation model...\n",
      "============================================================\n",
      "âœ… Conversation Model Fields:\n",
      "   Fields: ['id', 'title', 'raw_text', 'source', 'word_count', 'created_at', 'status']\n",
      "\n",
      "ðŸ“‹ Field Details:\n",
      "      â€¢ id: <class 'int'>\n",
      "      â€¢ title: typing.Optional[str]\n",
      "      â€¢ raw_text: <class 'str'>\n",
      "      â€¢ source: <class 'str'>\n",
      "      â€¢ word_count: <class 'int'>\n",
      "      â€¢ created_at: <class 'datetime.datetime'>\n",
      "      â€¢ status: <class 'str'>\n",
      "\n",
      "âœ… Sample Conversation Data:\n",
      "   Type: <class 'database.models.Conversation'>\n",
      "   Available attributes: ['id', 'title', 'raw_text', 'source', 'word_count', 'created_at', 'status']\n",
      "\n",
      "   Sample Values:\n",
      "      â€¢ id: 28\n",
      "      â€¢ title: Audio: blog_record_(purevitalize).wav\n",
      "      â€¢ raw_text: My name is Michael Chen. I'm the Chief Technology ...\n",
      "      â€¢ source: transcribed\n",
      "      â€¢ word_count: 298\n",
      "      â€¢ created_at: 2025-11-28 09:02:37\n",
      "      â€¢ status: pending\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Cell: Inspect Conversation Model (Pydantic v2.11 compatible)\n",
    "from database.models import Conversation\n",
    "\n",
    "print(\"ðŸ” Inspecting Conversation model...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Access model_fields from the CLASS, not the instance\n",
    "print(f\"âœ… Conversation Model Fields:\")\n",
    "print(f\"   Fields: {list(Conversation.model_fields.keys())}\")\n",
    "print(f\"\\nðŸ“‹ Field Details:\")\n",
    "for field_name, field_info in Conversation.model_fields.items():\n",
    "    print(f\"      â€¢ {field_name}: {field_info.annotation}\")\n",
    "\n",
    "# Try to get a sample conversation to see actual data\n",
    "conversations = db.get_all_conversations()\n",
    "if conversations:\n",
    "    sample = conversations[0]\n",
    "    print(f\"\\nâœ… Sample Conversation Data:\")\n",
    "    print(f\"   Type: {type(sample)}\")\n",
    "    \n",
    "    if isinstance(sample, dict):\n",
    "        print(f\"   Keys: {list(sample.keys())}\")\n",
    "        print(f\"\\n   Sample Values:\")\n",
    "        for key, value in sample.items():\n",
    "            if isinstance(value, str) and len(value) > 50:\n",
    "                print(f\"      â€¢ {key}: {value[:50]}...\")\n",
    "            else:\n",
    "                print(f\"      â€¢ {key}: {value}\")\n",
    "    else:\n",
    "        # It's a Pydantic model - use model_dump() instead of accessing fields\n",
    "        data = sample.model_dump()\n",
    "        print(f\"   Available attributes: {list(data.keys())}\")\n",
    "        print(f\"\\n   Sample Values:\")\n",
    "        for key, value in data.items():\n",
    "            if isinstance(value, str) and len(value) > 50:\n",
    "                print(f\"      â€¢ {key}: {value[:50]}...\")\n",
    "            else:\n",
    "                print(f\"      â€¢ {key}: {value}\")\n",
    "else:\n",
    "    print(\"\\nâš ï¸  No conversations found to inspect actual data\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "17f6d838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Safe helper functions ready (Pydantic v2.11 compatible)\n"
     ]
    }
   ],
   "source": [
    "# Cell: Safe Helper Functions (Updated)\n",
    "def get_conv_attribute(conv, attr_name, default='Unknown'):\n",
    "    \"\"\"Safely get attribute from conversation (works with dict or Pydantic model)\"\"\"\n",
    "    if isinstance(conv, dict):\n",
    "        return conv.get(attr_name, default)\n",
    "    else:\n",
    "        # For Pydantic models, use model_dump() to get all fields as dict\n",
    "        try:\n",
    "            data = conv.model_dump()\n",
    "            return data.get(attr_name, default)\n",
    "        except AttributeError:\n",
    "            # Fallback to getattr\n",
    "            return getattr(conv, attr_name, default)\n",
    "\n",
    "def get_conv_filename(conv):\n",
    "    \"\"\"Get filename from conversation, trying multiple possible attribute names\"\"\"\n",
    "    # Try common attribute names for audio file\n",
    "    possible_names = [\n",
    "        'audio_file_path',  # Most common\n",
    "        'file_path',        # Alternative\n",
    "        'filename',         # Simple name\n",
    "        'audio_file',       # Without path\n",
    "        'source_file',      # Source reference\n",
    "        'audio_path',       # Path variant\n",
    "        'file_name'         # Snake case variant\n",
    "    ]\n",
    "    \n",
    "    for attr in possible_names:\n",
    "        filename = get_conv_attribute(conv, attr, None)\n",
    "        if filename:\n",
    "            return filename\n",
    "    \n",
    "    # If nothing found, create a descriptive name from ID and timestamp\n",
    "    conv_id = get_conv_attribute(conv, 'id', 'unknown')\n",
    "    created = get_conv_attribute(conv, 'created_at', '')\n",
    "    \n",
    "    if created:\n",
    "        return f\"Conversation_{conv_id}_{str(created)[:10]}\"\n",
    "    else:\n",
    "        return f\"Conversation_{conv_id}\"\n",
    "\n",
    "def get_idea_attribute(idea, attr_name, default=0):\n",
    "    \"\"\"Safely get attribute from blog idea (works with dict or Pydantic model)\"\"\"\n",
    "    if isinstance(idea, dict):\n",
    "        return idea.get(attr_name, default)\n",
    "    else:\n",
    "        try:\n",
    "            data = idea.model_dump()\n",
    "            return data.get(attr_name, default)\n",
    "        except AttributeError:\n",
    "            return getattr(idea, attr_name, default)\n",
    "\n",
    "print(\"âœ… Safe helper functions ready (Pydantic v2.11 compatible)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ebdadbe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Running Conversation model inspection...\n",
      "\n",
      "============================================================\n",
      "ðŸ“‹ Conversation Model Fields (from class):\n",
      "   â€¢ id\n",
      "   â€¢ title\n",
      "   â€¢ raw_text\n",
      "   â€¢ source\n",
      "   â€¢ word_count\n",
      "   â€¢ created_at\n",
      "   â€¢ status\n",
      "\n",
      "âœ… Sample conversation available\n",
      "   ID: 28\n",
      "   Filename: Conversation_28_2025-11-28\n",
      "\n",
      "   All fields in sample:\n",
      "      â€¢ id\n",
      "      â€¢ title\n",
      "      â€¢ raw_text\n",
      "      â€¢ source\n",
      "      â€¢ word_count\n",
      "      â€¢ created_at\n",
      "      â€¢ status\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Run the inspection to see what fields are actually available\n",
    "print(\"ðŸ” Running Conversation model inspection...\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "from database.models import Conversation\n",
    "\n",
    "# Show model fields\n",
    "print(\"ðŸ“‹ Conversation Model Fields (from class):\")\n",
    "for field_name in Conversation.model_fields.keys():\n",
    "    print(f\"   â€¢ {field_name}\")\n",
    "\n",
    "# Get sample data\n",
    "conversations = db.get_all_conversations()\n",
    "if conversations:\n",
    "    sample = conversations[0]\n",
    "    print(f\"\\nâœ… Sample conversation available\")\n",
    "    print(f\"   ID: {get_conv_attribute(sample, 'id')}\")\n",
    "    print(f\"   Filename: {get_conv_filename(sample)}\")\n",
    "    \n",
    "    # Show all available data\n",
    "    if isinstance(sample, dict):\n",
    "        print(f\"\\n   All fields in sample:\")\n",
    "        for key in sample.keys():\n",
    "            print(f\"      â€¢ {key}\")\n",
    "    else:\n",
    "        data = sample.model_dump()\n",
    "        print(f\"\\n   All fields in sample:\")\n",
    "        for key in data.keys():\n",
    "            print(f\"      â€¢ {key}\")\n",
    "else:\n",
    "    print(\"\\nâš ï¸  No conversations in database yet\")\n",
    "\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "74c11f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Helper functions loaded: True\n",
      "\n",
      "ðŸ§ª Testing FIXED functions...\n",
      "\n",
      "1. List Conversations:\n",
      "\n",
      "====================================================================================================\n",
      "ðŸ’¬ ALL CONVERSATIONS IN DATABASE\n",
      "====================================================================================================\n",
      "\n",
      "ðŸ“ ID: 28\n",
      "   ðŸŽ™ï¸  File: Conversation_28_2025-11-28\n",
      "   ðŸ“ Transcript: 0 characters\n",
      "   ðŸ’¡ Ideas: 5 | Avg Score: 46.4/70\n",
      "   ðŸ“… Created: 2025-11-28 09:02:37\n",
      "   ðŸ”— View: show_ideas_dashboard(28)\n",
      "\n",
      "ðŸ“ ID: 27\n",
      "   ðŸŽ™ï¸  File: Conversation_27_2025-11-28\n",
      "   ðŸ“ Transcript: 0 characters\n",
      "   ðŸ’¡ Ideas: 5 | Avg Score: 35.0/70\n",
      "   ðŸ“… Created: 2025-11-28 08:27:30\n",
      "   ðŸ”— View: show_ideas_dashboard(27)\n",
      "\n",
      "ðŸ“ ID: 26\n",
      "   ðŸŽ™ï¸  File: Conversation_26_2025-11-27\n",
      "   ðŸ“ Transcript: 0 characters\n",
      "   ðŸ’¡ Ideas: 5 | Avg Score: 35.0/70\n",
      "   ðŸ“… Created: 2025-11-27 09:11:49\n",
      "   ðŸ”— View: show_ideas_dashboard(26)\n",
      "\n",
      "ðŸ“ ID: 25\n",
      "   ðŸŽ™ï¸  File: Conversation_25_2025-11-26\n",
      "   ðŸ“ Transcript: 0 characters\n",
      "   ðŸ’¡ Ideas: 0 | No ideas yet\n",
      "   ðŸ“… Created: 2025-11-26 09:11:52\n",
      "   ðŸ”— View: show_ideas_dashboard(25)\n",
      "\n",
      "ðŸ“ ID: 24\n",
      "   ðŸŽ™ï¸  File: Conversation_24_2025-11-21\n",
      "   ðŸ“ Transcript: 0 characters\n",
      "   ðŸ’¡ Ideas: 0 | No ideas yet\n",
      "   ðŸ“… Created: 2025-11-21 09:58:56\n",
      "   ðŸ”— View: show_ideas_dashboard(24)\n",
      "\n",
      "ðŸ“ ID: 23\n",
      "   ðŸŽ™ï¸  File: Conversation_23_2025-11-19\n",
      "   ðŸ“ Transcript: 0 characters\n",
      "   ðŸ’¡ Ideas: 0 | No ideas yet\n",
      "   ðŸ“… Created: 2025-11-19 09:23:31\n",
      "   ðŸ”— View: show_ideas_dashboard(23)\n",
      "\n",
      "ðŸ“ ID: 22\n",
      "   ðŸŽ™ï¸  File: Conversation_22_2025-11-19\n",
      "   ðŸ“ Transcript: 0 characters\n",
      "   ðŸ’¡ Ideas: 0 | No ideas yet\n",
      "   ðŸ“… Created: 2025-11-19 09:22:11\n",
      "   ðŸ”— View: show_ideas_dashboard(22)\n",
      "\n",
      "ðŸ“ ID: 21\n",
      "   ðŸŽ™ï¸  File: Conversation_21_2025-11-19\n",
      "   ðŸ“ Transcript: 0 characters\n",
      "   ðŸ’¡ Ideas: 0 | No ideas yet\n",
      "   ðŸ“… Created: 2025-11-19 09:21:18\n",
      "   ðŸ”— View: show_ideas_dashboard(21)\n",
      "\n",
      "ðŸ“ ID: 20\n",
      "   ðŸŽ™ï¸  File: Conversation_20_2025-11-17\n",
      "   ðŸ“ Transcript: 0 characters\n",
      "   ðŸ’¡ Ideas: 0 | No ideas yet\n",
      "   ðŸ“… Created: 2025-11-17 08:54:02\n",
      "   ðŸ”— View: show_ideas_dashboard(20)\n",
      "\n",
      "ðŸ“ ID: 19\n",
      "   ðŸŽ™ï¸  File: Conversation_19_2025-11-17\n",
      "   ðŸ“ Transcript: 0 characters\n",
      "   ðŸ’¡ Ideas: 0 | No ideas yet\n",
      "   ðŸ“… Created: 2025-11-17 08:49:22\n",
      "   ðŸ”— View: show_ideas_dashboard(19)\n",
      "\n",
      "====================================================================================================\n",
      "ðŸ’¡ Total Conversations: 10\n",
      "====================================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make sure helper functions are loaded first\n",
    "print(\"âœ… Helper functions loaded:\", \n",
    "      'get_conv_attribute' in dir() and \n",
    "      'get_conv_filename' in dir() and \n",
    "      'get_idea_attribute' in dir())\n",
    "\n",
    "# Now test\n",
    "print(\"\\nðŸ§ª Testing FIXED functions...\")\n",
    "print(\"\\n1. List Conversations:\")\n",
    "list_conversations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f3d96d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§ª Testing fixed functions...\n",
      "\n",
      "1. List Conversations:\n",
      "\n",
      "====================================================================================================\n",
      "ðŸ’¬ ALL CONVERSATIONS IN DATABASE\n",
      "====================================================================================================\n",
      "\n",
      "ðŸ“ ID: 28\n",
      "   ðŸŽ™ï¸  File: Conversation_28_2025-11-28\n",
      "   ðŸ“ Transcript: 0 characters\n",
      "   ðŸ’¡ Ideas: 5 | Avg Score: 46.4/70\n",
      "   ðŸ“… Created: 2025-11-28 09:02:37\n",
      "   ðŸ”— View: show_ideas_dashboard(28)\n",
      "\n",
      "ðŸ“ ID: 27\n",
      "   ðŸŽ™ï¸  File: Conversation_27_2025-11-28\n",
      "   ðŸ“ Transcript: 0 characters\n",
      "   ðŸ’¡ Ideas: 5 | Avg Score: 35.0/70\n",
      "   ðŸ“… Created: 2025-11-28 08:27:30\n",
      "   ðŸ”— View: show_ideas_dashboard(27)\n",
      "\n",
      "ðŸ“ ID: 26\n",
      "   ðŸŽ™ï¸  File: Conversation_26_2025-11-27\n",
      "   ðŸ“ Transcript: 0 characters\n",
      "   ðŸ’¡ Ideas: 5 | Avg Score: 35.0/70\n",
      "   ðŸ“… Created: 2025-11-27 09:11:49\n",
      "   ðŸ”— View: show_ideas_dashboard(26)\n",
      "\n",
      "ðŸ“ ID: 25\n",
      "   ðŸŽ™ï¸  File: Conversation_25_2025-11-26\n",
      "   ðŸ“ Transcript: 0 characters\n",
      "   ðŸ’¡ Ideas: 0 | No ideas yet\n",
      "   ðŸ“… Created: 2025-11-26 09:11:52\n",
      "   ðŸ”— View: show_ideas_dashboard(25)\n",
      "\n",
      "ðŸ“ ID: 24\n",
      "   ðŸŽ™ï¸  File: Conversation_24_2025-11-21\n",
      "   ðŸ“ Transcript: 0 characters\n",
      "   ðŸ’¡ Ideas: 0 | No ideas yet\n",
      "   ðŸ“… Created: 2025-11-21 09:58:56\n",
      "   ðŸ”— View: show_ideas_dashboard(24)\n",
      "\n",
      "ðŸ“ ID: 23\n",
      "   ðŸŽ™ï¸  File: Conversation_23_2025-11-19\n",
      "   ðŸ“ Transcript: 0 characters\n",
      "   ðŸ’¡ Ideas: 0 | No ideas yet\n",
      "   ðŸ“… Created: 2025-11-19 09:23:31\n",
      "   ðŸ”— View: show_ideas_dashboard(23)\n",
      "\n",
      "ðŸ“ ID: 22\n",
      "   ðŸŽ™ï¸  File: Conversation_22_2025-11-19\n",
      "   ðŸ“ Transcript: 0 characters\n",
      "   ðŸ’¡ Ideas: 0 | No ideas yet\n",
      "   ðŸ“… Created: 2025-11-19 09:22:11\n",
      "   ðŸ”— View: show_ideas_dashboard(22)\n",
      "\n",
      "ðŸ“ ID: 21\n",
      "   ðŸŽ™ï¸  File: Conversation_21_2025-11-19\n",
      "   ðŸ“ Transcript: 0 characters\n",
      "   ðŸ’¡ Ideas: 0 | No ideas yet\n",
      "   ðŸ“… Created: 2025-11-19 09:21:18\n",
      "   ðŸ”— View: show_ideas_dashboard(21)\n",
      "\n",
      "ðŸ“ ID: 20\n",
      "   ðŸŽ™ï¸  File: Conversation_20_2025-11-17\n",
      "   ðŸ“ Transcript: 0 characters\n",
      "   ðŸ’¡ Ideas: 0 | No ideas yet\n",
      "   ðŸ“… Created: 2025-11-17 08:54:02\n",
      "   ðŸ”— View: show_ideas_dashboard(20)\n",
      "\n",
      "ðŸ“ ID: 19\n",
      "   ðŸŽ™ï¸  File: Conversation_19_2025-11-17\n",
      "   ðŸ“ Transcript: 0 characters\n",
      "   ðŸ’¡ Ideas: 0 | No ideas yet\n",
      "   ðŸ“… Created: 2025-11-17 08:49:22\n",
      "   ðŸ”— View: show_ideas_dashboard(19)\n",
      "\n",
      "====================================================================================================\n",
      "ðŸ’¡ Total Conversations: 10\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "2. Explore and Visualize:\n",
      "ðŸ” STEP 1: Available Conversations\n",
      "================================================================================\n",
      "1. [ID: 28] Conversation_28_2025-11-28 (5 ideas)\n",
      "2. [ID: 27] Conversation_27_2025-11-28 (5 ideas)\n",
      "3. [ID: 26] Conversation_26_2025-11-27 (5 ideas)\n",
      "4. [ID: 25] Conversation_25_2025-11-26 (0 ideas)\n",
      "5. [ID: 24] Conversation_24_2025-11-21 (0 ideas)\n",
      "6. [ID: 23] Conversation_23_2025-11-19 (0 ideas)\n",
      "7. [ID: 22] Conversation_22_2025-11-19 (0 ideas)\n",
      "8. [ID: 21] Conversation_21_2025-11-19 (0 ideas)\n",
      "9. [ID: 20] Conversation_20_2025-11-17 (0 ideas)\n",
      "10. [ID: 19] Conversation_19_2025-11-17 (0 ideas)\n",
      "\n",
      "================================================================================\n",
      "ðŸŽ¯ STEP 2: Choose a conversation\n",
      "================================================================================\n",
      "\n",
      "ðŸ“Š Showing conversation 26...\n",
      "\n",
      "====================================================================================================\n",
      "ðŸ“Š BLOG IDEAS DASHBOARD\n",
      "====================================================================================================\n",
      "ðŸ“ Showing ideas from Conversation ID: 26\n",
      "\n",
      "ðŸ“ˆ SUMMARY STATISTICS\n",
      "   Total Ideas: 5\n",
      "   Average Score: 35.0/70 (50.0%)\n",
      "   Highest Score: 35/70 (50.0%)\n",
      "   Lowest Score: 35/70 (50.0%)\n",
      "\n",
      "ðŸ“Š SCORE DISTRIBUTION\n",
      "   ðŸŸ¢ High (60-70):  0 ideas (0.0%)\n",
      "   ðŸŸ¡ Medium (50-59): 0 ideas (0.0%)\n",
      "   ðŸ”´ Low (<50):     5 ideas (100.0%)\n",
      "\n",
      "ðŸ† TOP 5 IDEAS\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "ðŸ¥‡ ðŸ”´ ID: 3 | Score: 35/70 (50.0%)\n",
      "   ðŸ“ Custom AI vs SaaS for SMEs: A Privacy-First Decision Framework\n",
      "   ðŸ“Š [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 35/70\n",
      "   ðŸ’¡ Breakdown:\n",
      "      â€¢ Usefulness: 5/10 | SEO Fit: 5/10 | Content Fit: 5/10\n",
      "      â€¢ Inspiration: 5/10 | Collaboration: 5/10\n",
      "      â€¢ Innovation: 5/10 | Difficulty (ease): 5/10\n",
      "   ðŸ“… Created: 2025-11-27 09:12:04\n",
      "   ðŸ”— Conversation: 26\n",
      "   ðŸ“ STATUS: Draft\n",
      "\n",
      "ðŸ¥ˆ ðŸ”´ ID: 4 | Score: 35/70 (50.0%)\n",
      "   ðŸ“ GDPR-Compliant AI Implementation: A Step-by-Step Roadmap for European Businesses\n",
      "   ðŸ“Š [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 35/70\n",
      "   ðŸ’¡ Breakdown:\n",
      "      â€¢ Usefulness: 5/10 | SEO Fit: 5/10 | Content Fit: 5/10\n",
      "      â€¢ Inspiration: 5/10 | Collaboration: 5/10\n",
      "      â€¢ Innovation: 5/10 | Difficulty (ease): 5/10\n",
      "   ðŸ“… Created: 2025-11-27 09:12:04\n",
      "   ðŸ”— Conversation: 26\n",
      "   ðŸ“ STATUS: Draft\n",
      "\n",
      "ðŸ¥‰ ðŸ”´ ID: 5 | Score: 35/70 (50.0%)\n",
      "   ðŸ“ The Hidden Security Risks of AI Adoption (And How to Mitigate Them Before Implementation)\n",
      "   ðŸ“Š [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 35/70\n",
      "   ðŸ’¡ Breakdown:\n",
      "      â€¢ Usefulness: 5/10 | SEO Fit: 5/10 | Content Fit: 5/10\n",
      "      â€¢ Inspiration: 5/10 | Collaboration: 5/10\n",
      "      â€¢ Innovation: 5/10 | Difficulty (ease): 5/10\n",
      "   ðŸ“… Created: 2025-11-27 09:12:04\n",
      "   ðŸ”— Conversation: 26\n",
      "   ðŸ“ STATUS: Draft\n",
      "\n",
      " 4. ðŸ”´ ID: 6 | Score: 35/70 (50.0%)\n",
      "   ðŸ“ Email Automation Without the Compliance Headache: Evaluating Copilot and Alternatives for Regulated Industries\n",
      "   ðŸ“Š [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 35/70\n",
      "   ðŸ’¡ Breakdown:\n",
      "      â€¢ Usefulness: 5/10 | SEO Fit: 5/10 | Content Fit: 5/10\n",
      "      â€¢ Inspiration: 5/10 | Collaboration: 5/10\n",
      "      â€¢ Innovation: 5/10 | Difficulty (ease): 5/10\n",
      "   ðŸ“… Created: 2025-11-27 09:12:04\n",
      "   ðŸ”— Conversation: 26\n",
      "   ðŸ“ STATUS: Draft\n",
      "\n",
      " 5. ðŸ”´ ID: 7 | Score: 35/70 (50.0%)\n",
      "   ðŸ“ Strategic AI Adoption for Competitive Advantage: How to Choose Efficiency Gains That Actually Matter\n",
      "   ðŸ“Š [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 35/70\n",
      "   ðŸ’¡ Breakdown:\n",
      "      â€¢ Usefulness: 5/10 | SEO Fit: 5/10 | Content Fit: 5/10\n",
      "      â€¢ Inspiration: 5/10 | Collaboration: 5/10\n",
      "      â€¢ Innovation: 5/10 | Difficulty (ease): 5/10\n",
      "   ðŸ“… Created: 2025-11-27 09:12:04\n",
      "   ðŸ”— Conversation: 26\n",
      "   ðŸ“ STATUS: Draft\n",
      "\n",
      "====================================================================================================\n",
      "ðŸ’¡ USAGE TIPS:\n",
      "   show_ideas_dashboard()              # Show all ideas\n",
      "   show_ideas_dashboard(28)            # Show ideas from conversation 28\n",
      "   show_ideas_dashboard(28, top_n=3)   # Show top 3 ideas only\n",
      "====================================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test the fixed functions\n",
    "print(\"ðŸ§ª Testing fixed functions...\")\n",
    "print(\"\\n1. List Conversations:\")\n",
    "list_conversations()\n",
    "\n",
    "print(\"\\n2. Explore and Visualize:\")\n",
    "explore_and_visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8037915e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‹ Conversation model fields:\n",
      "['id', 'title', 'raw_text', 'source', 'word_count', 'created_at', 'status']\n",
      "\n",
      "âœ… Sample conversation data:\n",
      "   â€¢ id: 28\n",
      "   â€¢ title: Audio: blog_record_(purevitalize).wav\n",
      "   â€¢ raw_text: My name is Michael Chen. I'm the Chief Technology ...\n",
      "   â€¢ source: transcribed\n",
      "   â€¢ word_count: 298\n",
      "   â€¢ created_at: 2025-11-28 09:02:37\n",
      "   â€¢ status: pending\n"
     ]
    }
   ],
   "source": [
    "# Cell: Quick inspection\n",
    "from database.models import Conversation\n",
    "\n",
    "print(\"ðŸ“‹ Conversation model fields:\")\n",
    "print(list(Conversation.model_fields.keys()))\n",
    "\n",
    "# Get a sample\n",
    "conversations = db.get_all_conversations()\n",
    "if conversations:\n",
    "    sample = conversations[0]\n",
    "    print(f\"\\nâœ… Sample conversation data:\")\n",
    "    data = sample.model_dump() if hasattr(sample, 'model_dump') else sample\n",
    "    for key, value in data.items():\n",
    "        if isinstance(value, str) and len(value) > 50:\n",
    "            print(f\"   â€¢ {key}: {value[:50]}...\")\n",
    "        else:\n",
    "            print(f\"   â€¢ {key}: {value}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
