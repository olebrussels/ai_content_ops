{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94470f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“ Current directory: /home/manuel/Documents/tech/ai_content_ops/notebooks\n",
      "ðŸ“ Current directory name: notebooks\n",
      "ðŸ“ Project root: /home/manuel/Documents/tech/ai_content_ops\n",
      "ðŸ“ Database path: /home/manuel/Documents/tech/ai_content_ops/database\n",
      "âœ… Database folder exists: True\n",
      "âœ… Added to Python path: /home/manuel/Documents/tech/ai_content_ops\n",
      "\n",
      "ðŸ“‹ Python path (first 3):\n",
      "   1. /home/manuel/Documents/tech/ai_content_ops\n",
      "   2. /usr/lib/python313.zip\n",
      "   3. /usr/lib/python3.13\n",
      "âœ… Standard library imports loaded\n",
      "âœ… Loaded .env from: /home/manuel/Documents/tech/ai_content_ops/.env\n",
      "âœ… Third-party imports loaded\n",
      "âœ… Database imports loaded\n",
      "\n",
      "ðŸŽ‰ All imports loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CELL 1: IMPORTS & SETUP\n",
    "# ============================================================\n",
    "\n",
    "# --- PATH SETUP (MUST BE FIRST) ---\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import uuid\n",
    "\n",
    "# Get current directory (should be notebooks/)\n",
    "current_dir = Path.cwd()\n",
    "print(f\"ðŸ“ Current directory: {current_dir}\")\n",
    "print(f\"ðŸ“ Current directory name: {current_dir.name}\")\n",
    "\n",
    "# Go up one level to project root\n",
    "project_root = current_dir.parent\n",
    "print(f\"ðŸ“ Project root: {project_root}\")\n",
    "\n",
    "# Verify database folder exists\n",
    "database_path = project_root / 'database'\n",
    "print(f\"ðŸ“ Database path: {database_path}\")\n",
    "print(f\"âœ… Database folder exists: {database_path.exists()}\")\n",
    "\n",
    "# Add project root to Python path\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "    print(f\"âœ… Added to Python path: {project_root}\")\n",
    "else:\n",
    "    print(f\"âœ… Already in Python path\")\n",
    "\n",
    "print(f\"\\nðŸ“‹ Python path (first 3):\")\n",
    "for i, p in enumerate(sys.path[:3], 1):\n",
    "    print(f\"   {i}. {p}\")\n",
    "\n",
    "\n",
    "# --- STANDARD LIBRARY IMPORTS ---\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import sqlite3\n",
    "import glob\n",
    "from typing import TypedDict, Optional, List, Dict, Any\n",
    "from datetime import datetime\n",
    "from enum import Enum\n",
    "from typing import Optional\n",
    "\n",
    "print(\"âœ… Standard library imports loaded\")\n",
    "\n",
    "\n",
    "# --- ENVIRONMENT & CONFIGURATION ---\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from project root\n",
    "env_path = project_root / '.env'\n",
    "if env_path.exists():\n",
    "    load_dotenv(env_path)\n",
    "    print(f\"âœ… Loaded .env from: {env_path}\")\n",
    "else:\n",
    "    print(f\"âš ï¸  .env not found at: {env_path}\")\n",
    "\n",
    "\n",
    "# --- THIRD-PARTY ML/AI ---\n",
    "import assemblyai as aai\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langgraph.graph import StateGraph\n",
    "from pydantic import BaseModel, Field, field_validator\n",
    "from langchain_core.messages import SystemMessage, HumanMessage  \n",
    "import json\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "print(\"âœ… Third-party imports loaded\")\n",
    "\n",
    "\n",
    "# --- DATABASE IMPORTS ---\n",
    "from database.db_operations import db\n",
    "from database.models import Conversation, ConversationCreate\n",
    "\n",
    "print(\"âœ… Database imports loaded\")\n",
    "print(\"\\nðŸŽ‰ All imports loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb001904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AssemblyAI API Key loaded: âœ…\n",
      "Key starts with: 972365f41d...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Cell 2 \n",
    "\n",
    "# Test API key\n",
    "assemblyai_key = os.getenv('ASSEMBLYAI_API_KEY')\n",
    "print(f\"AssemblyAI API Key loaded: {'âœ…' if assemblyai_key else 'âŒ'}\")\n",
    "print(f\"Key starts with: {assemblyai_key[:10] if assemblyai_key else 'None'}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08a6571a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… LangSmith tracing enabled\n",
      "   Project: ai_content_ops\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CELL 3: LANGSMITH TRACING SETUP (OPTIONAL)\n",
    "# ============================================================\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables if not already loaded\n",
    "load_dotenv()\n",
    "\n",
    "# Get LangSmith API key from environment\n",
    "langsmith_api_key = os.getenv(\"LANGSMITH_API_KEY\")\n",
    "\n",
    "if langsmith_api_key:\n",
    "    # Enable LangSmith tracing\n",
    "    os.environ[\"LANGSMITH_API_KEY\"] = langsmith_api_key\n",
    "    os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "    os.environ[\"LANGCHAIN_PROJECT\"] = \"ai_content_ops_n9\"\n",
    "    print(\"âœ… LangSmith tracing enabled\")\n",
    "    print(f\"   Project: ai_content_ops\")\n",
    "else:\n",
    "    print(\"âš ï¸  LANGSMITH_API_KEY not found in .env\")\n",
    "    print(\"   LangSmith tracing disabled\")\n",
    "    print(\"   ðŸ’¡ Add LANGSMITH_API_KEY to your .env file to enable tracing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cc1fee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Tables in app.db:\n",
      "\n",
      "ðŸ”§ conversations:\n",
      "   - id (INTEGER)\n",
      "   - title (TEXT)\n",
      "   - raw_text (TEXT)\n",
      "   - source (TEXT)\n",
      "   - word_count (INTEGER)\n",
      "   - created_at (DATETIME)\n",
      "   - status (TEXT)\n",
      "\n",
      "ðŸ”§ sqlite_sequence:\n",
      "   - name ()\n",
      "   - seq ()\n",
      "\n",
      "ðŸ”§ blog_post_ideas:\n",
      "   - id (INTEGER)\n",
      "   - conversation_id (INTEGER)\n",
      "   - title (TEXT)\n",
      "   - description (TEXT)\n",
      "   - usefulness_potential (INTEGER)\n",
      "   - fitwith_seo_strategy (INTEGER)\n",
      "   - fitwith_content_strategy (INTEGER)\n",
      "   - inspiration_potential (INTEGER)\n",
      "   - collaboration_potential (INTEGER)\n",
      "   - innovation (INTEGER)\n",
      "   - difficulty (INTEGER)\n",
      "   - total_score (INTEGER)\n",
      "   - sent_to_prod (BOOLEAN)\n",
      "   - raw_llm_response (TEXT)\n",
      "   - created_at (DATETIME)\n",
      "\n",
      "ðŸ”§ processing_status:\n",
      "   - id (INTEGER)\n",
      "   - conversation_id (INTEGER)\n",
      "   - stage (TEXT)\n",
      "   - status (TEXT)\n",
      "   - error_message (TEXT)\n",
      "   - started_at (DATETIME)\n",
      "   - completed_at (DATETIME)\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Database Connection Test\n",
    "\n",
    "conn = sqlite3.connect(\"data/app.db\")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Get all table names\n",
    "cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "tables = cursor.fetchall()\n",
    "\n",
    "print(\"ðŸ“Š Tables in app.db:\")\n",
    "for table in tables:\n",
    "    table_name = table[0]\n",
    "    \n",
    "    # Get column info for each table\n",
    "    cursor.execute(f\"PRAGMA table_info({table_name})\")\n",
    "    columns = cursor.fetchall()\n",
    "    \n",
    "    print(f\"\\nðŸ”§ {table_name}:\")\n",
    "    for col in columns:\n",
    "        print(f\"   - {col[1]} ({col[2]})\")  # column_name (type)\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e30147df",
   "metadata": {},
   "outputs": [],
   "source": [
    "## cell 4. Pydantic Model for Structured Output\n",
    "\n",
    "\n",
    "\n",
    "class SpeakerRole(str, Enum):\n",
    "    \"\"\"Possible speaker roles in the conversation\"\"\"\n",
    "    CLIENT = \"client\"\n",
    "    INTERVIEWER = \"interviewer\"\n",
    "\n",
    "class Speaker(BaseModel):\n",
    "    \"\"\"Information about a person speaking in the conversation\"\"\"\n",
    "    name: Optional[str] = Field(default=None, description=\"Name of the speaker if mentioned\")\n",
    "    role: Optional[SpeakerRole] = Field(default=None, description=\"Role of the speaker in the conversation\")\n",
    "    company: Optional[str] = Field(default=None, description=\"Company they work for if mentioned\")\n",
    "\n",
    "class Challenge(BaseModel):\n",
    "    \"\"\"A challenge or problem mentioned in the conversation\"\"\"\n",
    "    description: Optional[str] = Field(default=None, description=\"Description of the challenge\")\n",
    "    impact: Optional[str] = Field(default=None, description=\"How this challenge affects them\")\n",
    "    urgency: Optional[str] = Field(default=None, description=\"Low, Medium, or High urgency\")\n",
    "\n",
    "class CurrentSolution(BaseModel):\n",
    "    \"\"\"How they currently solve their problems\"\"\"\n",
    "    solution: Optional[str] = Field(default=None, description=\"What they're currently doing\")\n",
    "    satisfaction_level: Optional[str] = Field(default=None, description=\"How satisfied they are: Very Satisfied, Satisfied, Neutral, Unsatisfied, Very Unsatisfied\")\n",
    "    limitations: Optional[List[str]] = Field(default=[], description=\"Limitations of current solution\")\n",
    "\n",
    "class Need(BaseModel):\n",
    "    \"\"\"A need identified using psychology frameworks like NVC\"\"\"\n",
    "    need_category: Optional[str] = Field(default=None, description=\"Category of need (e.g., autonomy, efficiency, security, connection)\")\n",
    "    description: Optional[str] = Field(default=None, description=\"Specific need description\")\n",
    "    intensity: Optional[str] = Field(default=None, description=\"Low, Medium, or High intensity\")\n",
    "\n",
    "class ExtractedInsights(BaseModel):\n",
    "    \"\"\"Complete structured output from conversation analysis\"\"\"\n",
    "    \n",
    "    # Speakers\n",
    "    speakers: Optional[List[Speaker]] = Field(default=[], description=\"People identified in the conversation\")\n",
    "    \n",
    "    # What they care about\n",
    "    core_values: Optional[List[str]] = Field(default=[], description=\"What this person/company cares about most\")\n",
    "    priorities: Optional[List[str]] = Field(default=[], description=\"Their current priorities and focus areas\")\n",
    "    \n",
    "    # Challenges\n",
    "    primary_challenges: Optional[List[Challenge]] = Field(default=[], description=\"Main problems they're facing\")\n",
    "    secondary_challenges: Optional[List[Challenge]] = Field(default=[], description=\"Secondary or related problems\")\n",
    "    \n",
    "    # Current solutions\n",
    "    current_solutions: Optional[List[CurrentSolution]] = Field(default=[], description=\"How they solve problems today\")\n",
    "    \n",
    "    # Needs analysis\n",
    "    psychological_needs: Optional[List[Need]] = Field(default=[], description=\"Underlying needs using NVC or similar frameworks\")\n",
    "\n",
    "class BlogPostStatus(Enum):\n",
    "    \"\"\"Publication status of the blog post\"\"\"\n",
    "    DRAFT = \"draft\"\n",
    "    PUBLISHED = \"published\"\n",
    "    ARCHIVED = \"archived\"\n",
    "\n",
    "class BlogPost(BaseModel):\n",
    "    \"\"\"A blog post that solves a problem from a human expert\"\"\"\n",
    "    id: Optional[str] = Field(default=None, description=\"Unique identifier for the blog post (UUID)\")\n",
    "    title: str = Field(..., min_length=1, max_length=255, description=\"Title of the blog post\")  # Required\n",
    "    content: str = Field(..., description=\"Full content of the blog post\")  # Required\n",
    "    issue: str = Field(..., description=\"What issue is being discussed in this post\")  # Required\n",
    "    angle: str = Field(..., description=\"Where Bigkids is positioned on this issue; the angle of the post\")  # Required\n",
    "    single_message: str = Field(..., description=\"The single message we want to pass; one idea for the reader to retain\")  # Required\n",
    "    user_story: str = Field(..., description=\"User story in agile format (e.g., 'As a tinkerer I would like to...')\")  # Required\n",
    "    seed_keyword: str = Field(..., description=\"Primary SEO seed keyword\")  # Required\n",
    "    call_to_action: Optional[str] = Field(default=None, description=\"Call to action for readers\")\n",
    "    keywords: Optional[List[str]] = Field(default=None, description=\"Additional keywords present in the article\")\n",
    "    status: Optional[BlogPostStatus] = Field(default=None, description=\"Publication status of the blog post\")\n",
    "    published_date: Optional[str] = Field(default=None, description=\"Date when the blog post was published (YYYY-MM-DD)\")\n",
    "    created_at: Optional[str] = Field(default=None, description=\"Timestamp when the record was created (ISO 8601)\")\n",
    "    updated_at: Optional[str] = Field(default=None, description=\"Timestamp when the record was last updated (ISO 8601)\")\n",
    "\n",
    "  # Optional: Auto-generate UUID if not provided\n",
    "    @field_validator('id', mode='before')  # Updated: field_validator with mode='before' (replaces pre=True)\n",
    "    @classmethod\n",
    "    def generate_uuid(cls, v):\n",
    "        return v or str(uuid.uuid4())\n",
    "\n",
    "\n",
    "class Plan(BaseModel):  # From your snippet\n",
    "    who: str = Field(description=\"Target reader of the blog post.\")\n",
    "    why: str = Field(description=\"Why are we writing this blog post.\")\n",
    "    what: str = Field(description=\"Main topics to cover.\")\n",
    "    the_issue: str = Field(description=\"Main issue or problem addressed.\")\n",
    "    where_we_stand: str = Field(description=\"Current position on the issue.\")\n",
    "    single_message: str = Field(description=\"Single most important message.\")\n",
    "    qa_pairs: List[Dict[str, str]] = Field(  # NEW: Added for your Q&A skeleton\n",
    "        default=[], description=\"List of dicts with 'question' and 'answer' to guide writer.\"\n",
    "    )\n",
    "    instructions: List[str] = Field(  # NEW: Added for writer instructions\n",
    "        default=[], description=\"Instructions to keep the writer focused.\"\n",
    "    )\n",
    "\n",
    "    @property\n",
    "    def plan(self) -> str:  # From your snippet, augmented\n",
    "        base = f\"Who: {self.who}\\nWhy: {self.why}\\nWhat: {self.what}\\nIssue: {self.the_issue}\\nWhere We Stand: {self.where_we_stand}\\nSingle Message: {self.single_message}\\n\"\n",
    "        qa_str = \"\\nQ&A Pairs:\\n\" + \"\\n\".join([f\"Q: {pair['question']} A: {pair['answer']}\" for pair in self.qa_pairs])\n",
    "        instr_str = \"\\nInstructions:\\n\" + \"\\n\".join(self.instructions)\n",
    "        return base + qa_str + instr_str\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89d86360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Simple RawBlogIdea model ready\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Raw Blog Idea Model (Simple)\n",
    "class RawBlogIdea(BaseModel):\n",
    "    \"\"\"Raw blog idea from creative agent\"\"\"\n",
    "    title: str\n",
    "    description: str\n",
    "    target_audience: str\n",
    "    content_angle: str\n",
    "    business_value: str\n",
    "\n",
    "print(\"âœ… Simple RawBlogIdea model ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77ecdfc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… RawBlogIdea model and validation ready\n"
     ]
    }
   ],
   "source": [
    "def validate_raw_blog_ideas(raw_ideas: List[Dict]) -> List[RawBlogIdea]:\n",
    "    \"\"\"Validate and convert raw JSON to Pydantic models\"\"\"\n",
    "    validated_ideas = []\n",
    "    \n",
    "    for idea in raw_ideas:\n",
    "        try:\n",
    "            validated_idea = RawBlogIdea(**idea)\n",
    "            validated_ideas.append(validated_idea)\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ Invalid blog idea skipped: {e}\")\n",
    "    \n",
    "    print(f\"âœ… Validated {len(validated_ideas)} out of {len(raw_ideas)} raw ideas\")\n",
    "    return validated_ideas\n",
    "\n",
    "print(\"âœ… RawBlogIdea model and validation ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "399dbbb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Updated AudioPipelineState for 6-node pipeline\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Update AudioPipelineState for 5-Node Pipeline\n",
    "class AudioPipelineState(TypedDict):\n",
    "    # File info\n",
    "    file_path: str\n",
    "    filename: str\n",
    "    \n",
    "    # Processing results\n",
    "    transcript_text: Optional[str]\n",
    "    conversation_id: Optional[int]\n",
    "    extracted_insights: Optional[ExtractedInsights]\n",
    "    raw_blog_ideas: Optional[List[Dict]]        # From creative agent (Node 4)\n",
    "    scored_blog_ideas: Optional[List[Dict]]     # From analyst agent (Node 5) \n",
    "    saved_idea_ids: Optional[List[int]]         # From database saver (Node 6) \n",
    "    selected_idea_id: Optional[int]  # NEW: Human-selected idea ID from HITL\n",
    "    selected_idea: Optional[Dict]    # NEW: The actual selected idea dict (for convenience)\n",
    "    strategy_context: Optional[Dict[str, str]]  # NEW: Loaded company/SEO/content strategies\n",
    "    blog_plan: Optional[Plan]       # NEW: Generated plan (Pydantic-structured)\n",
    "    # For future writing node\n",
    "    blog_post: Optional[BlogPost]       # NEW: e.g., {\"title\": str, \"content\": str}\n",
    "    \n",
    "    \n",
    "    # Status & error handling\n",
    "    status: str\n",
    "    error: Optional[str]\n",
    "\n",
    "print(\"âœ… Updated AudioPipelineState for 6-node pipeline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee2205ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def planning_agent_node(state: AudioPipelineState) -> AudioPipelineState:\n",
    "    \"\"\"Planning agent: Generates a blog post plan using strategies, insights, and selected idea.\"\"\"\n",
    "    # Load strategy context (from your snippet)\n",
    "    strategy_context = load_company_strategy_context()\n",
    "    state[\"strategy_context\"] = strategy_context\n",
    "    \n",
    "    # Access state data\n",
    "    insights = state.get(\"extracted_insights\")\n",
    "    transcript = state.get(\"transcript_text\", \"No transcript available\")\n",
    "    selected_idea = state.get(\"selected_idea\", {})  # Assumed populated post-HITL\n",
    "    insights_json = insights.model_dump() if insights else {}\n",
    "    \n",
    "    # Prompt template inspired by your plan_instructions, augmented with pipeline data\n",
    "    plan_instructions = \"\"\"You are tasked with creating a plan for a professional blog post for Big Kids Automation Agency. The plan is a skeleton with questions/answers and instructions to guide the writer.\n",
    "\n",
    "Follow these instructions carefully:\n",
    "\n",
    "1. Review the company business strategy: {company_strategy_content}\n",
    "\n",
    "2. Ensure the plan fits the company content strategy: {content_strategy_content}\n",
    "\n",
    "3. Ensure the plan fits the company SEO strategy: {seo_strategy_content}\n",
    "\n",
    "4. Review the extracted insights from the interview (pains, challenges, etc.): {insights_json}\n",
    "\n",
    "5. Review the interview transcript: {transcript}\n",
    "\n",
    "6. Base the plan on this human-selected blog idea: {selected_idea}\n",
    "\n",
    "7. Create a plan with: who, why, what, the_issue, where_we_stand, single_message. Add qa_pairs (5-10 Q&A from insights, e.g., 'question': 'What is the main challenge?', 'answer': '[From pains]') and instructions (e.g., 'Stay focused on automation benefits', 'Incorporate SEO keywords').\n",
    "\n",
    "8. If there's human feedback, incorporate it: {human_analyst_feedback}\n",
    "\"\"\"\n",
    "    \n",
    "    # Format the prompt (add human feedback if you extend state for it)\n",
    "    formatted_instructions = plan_instructions.format(\n",
    "        company_strategy_content=strategy_context.get('company_strategy', ''),\n",
    "        content_strategy_content=strategy_context.get('content_strategy', ''),\n",
    "        seo_strategy_content=strategy_context.get('seo_strategy', ''),\n",
    "        insights_json=json.dumps(insights_json),\n",
    "        transcript=transcript[:2000],  # Truncate if needed\n",
    "        selected_idea=json.dumps(selected_idea),\n",
    "        human_analyst_feedback=state.get('human_analyst_feedback', 'No feedback')  # Optional extension\n",
    "    )\n",
    "    \n",
    "    # Set up structured LLM (inspired by your snippet)\n",
    "    structured_llm = llm.with_structured_output(Plan)\n",
    "    \n",
    "    # Invoke (now with proper message classes available)\n",
    "    plan = structured_llm.invoke([SystemMessage(content=formatted_instructions), HumanMessage(content=\"Generate the blog post plan.\")])\n",
    "    \n",
    "    # Update state\n",
    "    state[\"blog_plan\"] = plan\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6aa8463",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class SpeakerRole(Enum):\n",
    "    CLIENT = 'client'\n",
    "    INTERVIEWER = 'interviewer'\n",
    "\n",
    "class Speaker(BaseModel):\n",
    "    name: str\n",
    "    role: SpeakerRole  # Enforces the Enum\n",
    "\n",
    "class Challenge(BaseModel):\n",
    "    description: str\n",
    "    impact: Optional[str] = None  # Adjust fields as per your real model\n",
    "\n",
    "class CurrentSolution(BaseModel):\n",
    "    method: str\n",
    "    effectiveness: Optional[str] = None\n",
    "\n",
    "class Need(BaseModel):\n",
    "    need: str\n",
    "    details: Optional[str] = None\n",
    "\n",
    "# Mock state with raw dicts for sub-models (Pydantic will coerce them)\n",
    "#mock_state = {\n",
    "#    \"extracted_insights\": ExtractedInsights(\n",
    "#        speakers=[{\"name\": \"John Doe\", \"role\": \"client\"}],  # Raw dict; use 'client' or 'interviewer' for role\n",
    "#        core_values=[\"Innovation\", \"Efficiency\"],  # Simple list of str (no sub-model needed)\n",
    "#        priorities=[\"Scaling automation\", \"Reducing costs\"],\n",
    "#        primary_challenges=[{\"description\": \"Data integration issues\", \"impact\": \"High\"}],  # Raw dict for Challenge\n",
    "#        secondary_challenges=[{\"description\": \"Team training\", \"impact\": \"Medium\"}],\n",
    "#        current_solutions=[{\"method\": \"Manual workflows\", \"effectiveness\": \"Low\"}],\n",
    "#        psychological_needs=[{\"need\": \"Security\", \"details\": \"Stable processes\"}]\n",
    "#    ),\n",
    "#    \"transcript_text\": \"Sample transcript: Interviewee discussed pains in automation, like integration challenges.\",\n",
    "#    \"selected_idea\": {\"title\": \"Test Idea: Overcoming Automation Pains\", \"description\": \"Blog on solutions from interview\"},\n",
    "    # Add other fields if needed for your node (e.g., \"human_analyst_feedback\": \"Incorporate more SEO\")\n",
    "#}\n",
    "\n",
    "# Run the node\n",
    "#result = planning_agent_node(mock_state)\n",
    "\n",
    "# Print the result (adjust based on your Plan model)\n",
    "#print(\"Generated Blog Plan:\")\n",
    "#if \"blog_plan\" in result and result[\"blog_plan\"]:\n",
    "#    print(result[\"blog_plan\"].plan)  # Uses the @property from Plan\n",
    "#else:\n",
    "#    print(\"No plan generatedâ€”check for errors in the node.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a87528a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def writing_agent_node(state: AudioPipelineState) -> AudioPipelineState:\n",
    "    \"\"\"Writing agent: Drafts a blog post implementing the plan, using strategies.\"\"\"\n",
    "    # Load strategy context\n",
    "    strategy_context = load_company_strategy_context()\n",
    "    state[\"strategy_context\"] = strategy_context  # Optional: Save to state for traceability\n",
    "    \n",
    "    # Access plan and other relevant state\n",
    "    blog_plan = state.get(\"blog_plan\")\n",
    "    if not blog_plan:\n",
    "        state[\"error\"] = \"No blog plan available for writing\"\n",
    "        return state\n",
    "    transcript = state.get(\"transcript_text\", \"No transcript available\")  # Optional context\n",
    "    insights = state.get(\"extracted_insights\")  # Optional\n",
    "    insights_json = insights.model_dump() if insights else {}\n",
    "    \n",
    "    # Prompt template: Instruct LLM to read strategies, plan, and generate per schema\n",
    "    writing_instructions = \"\"\"You are a professional blog writer for Big Kids Automation Agency. Draft a complete blog post that implements the provided plan and solves a problem from a human expert interview.\n",
    "\n",
    "Follow these instructions carefully:\n",
    "\n",
    "1. Review the company business strategy: {company_strategy_content}\n",
    "\n",
    "2. Ensure the post fits the company content strategy: {content_strategy_content}\n",
    "\n",
    "3. Ensure the post fits the company SEO strategy: {seo_strategy_content} (e.g., incorporate the seed_keyword and keywords naturally).\n",
    "\n",
    "4. Read and implement the blog plan: {blog_plan}. This includes who, why, what, the_issue, where_we_stand, single_message, qa_pairs, and instructions.\n",
    "\n",
    "5. Optionally, reference the interview transcript: {transcript} and extracted insights: {insights_json} for authentic details (e.g., quotes from speakers or challenges).\n",
    "\n",
    "6. Generate a blog post matching this exact schema:\n",
    "   - id: Auto-generated UUID\n",
    "   - title: Engaging title based on the plan\n",
    "   - content: Full, well-written post (800-1500 words, engaging, with sections implementing qa_pairs)\n",
    "   - issue: From the plan's the_issue\n",
    "   - angle: From the plan's where_we_stand\n",
    "   - single_message: From the plan's single_message\n",
    "   - user_story: Agile-style story based on the plan's who and why\n",
    "   - seed_keyword: Primary SEO keyword (align with SEO strategy)\n",
    "   - call_to_action: Optional, e.g., \"Contact us for automation solutions\"\n",
    "   - keywords: List of 5-10 additional keywords\n",
    "   - status: Set to \"draft\"\n",
    "   - published_date: Leave as null or set to today's date (YYYY-MM-DD)\n",
    "   - created_at and updated_at: Set to current ISO timestamp (e.g., 2023-10-01T12:00:00Z)\n",
    "\n",
    "Make the post professional, focused on automation benefits, and true to the plan.\n",
    "\"\"\"\n",
    "    \n",
    "    # Format the prompt\n",
    "    formatted_instructions = writing_instructions.format(\n",
    "        company_strategy_content=strategy_context.get('company_strategy', ''),\n",
    "        content_strategy_content=strategy_context.get('content_strategy', ''),\n",
    "        seo_strategy_content=strategy_context.get('seo_strategy', ''),\n",
    "        blog_plan=blog_plan.plan,  # Use the formatted string property for readability\n",
    "        transcript=transcript[:2000],  # Truncate if too long\n",
    "        insights_json=json.dumps(insights_json)\n",
    "    )\n",
    "    \n",
    "    # Set up structured LLM\n",
    "    structured_llm = llm.with_structured_output(BlogPost)\n",
    "    \n",
    "    # Invoke\n",
    "    blog_post = structured_llm.invoke([SystemMessage(content=formatted_instructions), HumanMessage(content=\"Draft the blog post implementing the plan.\")])\n",
    "    \n",
    "    # Update state\n",
    "    state[\"blog_post\"] = blog_post\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c1bd03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def idea_selection_hitl(state: AudioPipelineState) -> AudioPipelineState:\n",
    "    \"\"\"No-op node for human-in-the-loop idea selection. Interrupt here to choose an idea.\"\"\"\n",
    "    # In dev: Print ideas for human to see\n",
    "    print(\"HITL: Scored ideas:\", state.get(\"scored_blog_ideas\", []))\n",
    "    print(\"Saved idea IDs:\", state.get(\"saved_idea_ids\", []))\n",
    "    # The graph interrupts before this runs; human updates state externally (e.g., via checkpointer)\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46143d78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Individual strategy loader functions ready\n",
      "âœ… prepare_strategy_context_for_scoring() ready\n"
     ]
    }
   ],
   "source": [
    "# Cell: Individual Strategy Loader Function\n",
    "\n",
    "def load_company_strategy():\n",
    "    \"\"\"Load company strategy document\"\"\"\n",
    "    try:\n",
    "        company_strategy_path = \"../data/processed/company_strategy.mkd\"\n",
    "        if os.path.exists(company_strategy_path):\n",
    "            with open(company_strategy_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                content = f.read()\n",
    "            print(f\"âœ… Loaded company strategy ({len(content)} chars)\")\n",
    "            return content\n",
    "        else:\n",
    "            print(\"âš ï¸ Company strategy document not found\")\n",
    "            return \"Company strategy document not available.\"\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error loading company strategy: {e}\")\n",
    "        return \"Company strategy document not available.\"\n",
    "\n",
    "def load_seo_strategy():\n",
    "    \"\"\"Load SEO strategy document\"\"\"\n",
    "    try:\n",
    "        seo_strategy_path = \"../data/processed/seo_strategy.mkd\"\n",
    "        if os.path.exists(seo_strategy_path):\n",
    "            with open(seo_strategy_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                content = f.read()\n",
    "            print(f\"âœ… Loaded SEO strategy ({len(content)} chars)\")\n",
    "            return content\n",
    "        else:\n",
    "            print(\"âš ï¸ SEO strategy document not found\")\n",
    "            return \"SEO strategy document not available.\"\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error loading SEO strategy: {e}\")\n",
    "        return \"SEO strategy document not available.\"\n",
    "\n",
    "def load_content_strategy():\n",
    "    \"\"\"Load content strategy document\"\"\"\n",
    "    try:\n",
    "        content_strategy_path = \"../data/processed/content_strategy.mkd\"\n",
    "        if os.path.exists(content_strategy_path):\n",
    "            with open(content_strategy_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                content = f.read()\n",
    "            print(f\"âœ… Loaded content strategy ({len(content)} chars)\")\n",
    "            return content\n",
    "        else:\n",
    "            print(\"âš ï¸ Content strategy document not found\")\n",
    "            return \"Content strategy document not available.\"\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error loading content strategy: {e}\")\n",
    "        return \"Content strategy document not available.\"\n",
    "\n",
    "def prepare_strategy_context_for_scoring():\n",
    "    \"\"\"Prepare full strategy context for scoring (used by analyst agent)\"\"\"\n",
    "    return {\n",
    "        'company_strategy_summary': load_company_strategy(),\n",
    "        'seo_strategy_summary': load_seo_strategy(),\n",
    "        'content_strategy_summary': load_content_strategy()\n",
    "    }\n",
    "\n",
    "print(\"âœ… Individual strategy loader functions ready\")\n",
    "print(\"âœ… prepare_strategy_context_for_scoring() ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bcb6358b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ Company strategy document not found\n",
      "âœ… Loaded SEO strategy (1120 chars)\n",
      "âœ… Loaded content strategy (4473 chars)\n",
      "ðŸ“Š Strategy context keys: ['company_strategy', 'seo_strategy', 'content_strategy']\n",
      "ðŸ“Š Total context size: 5633 chars\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Updated Company Strategy Context Loader (3 Documents)\n",
    "def load_company_strategy_context():\n",
    "    \"\"\"Load company strategy, SEO strategy, and content strategy for context\"\"\"\n",
    "    \n",
    "    strategy_context = {}\n",
    "    \n",
    "    try:\n",
    "        # Load company strategy\n",
    "        company_strategy_path = \"../data/processed/company_strategy.mkd\"\n",
    "        if os.path.exists(company_strategy_path):\n",
    "            with open(company_strategy_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                strategy_context[\"company_strategy\"] = f.read()\n",
    "            print(f\"âœ… Loaded company strategy ({len(strategy_context['company_strategy'])} chars)\")\n",
    "        else:\n",
    "            strategy_context[\"company_strategy\"] = \"Company strategy document not available.\"\n",
    "            print(\"âš ï¸ Company strategy document not found\")\n",
    "        \n",
    "        # Load SEO strategy\n",
    "        seo_strategy_path = \"../data/processed/seo_strategy.mkd\"\n",
    "        if os.path.exists(seo_strategy_path):\n",
    "            with open(seo_strategy_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                strategy_context[\"seo_strategy\"] = f.read()\n",
    "            print(f\"âœ… Loaded SEO strategy ({len(strategy_context['seo_strategy'])} chars)\")\n",
    "        else:\n",
    "            strategy_context[\"seo_strategy\"] = \"SEO strategy document not available.\"\n",
    "            print(\"âš ï¸ SEO strategy document not found\")\n",
    "        \n",
    "        # Load content strategy (NEW)\n",
    "        content_strategy_path = \"../data/processed/content_strategy.mkd\"\n",
    "        if os.path.exists(content_strategy_path):\n",
    "            with open(content_strategy_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                strategy_context[\"content_strategy\"] = f.read()\n",
    "            print(f\"âœ… Loaded content strategy ({len(strategy_context['content_strategy'])} chars)\")\n",
    "        else:\n",
    "            strategy_context[\"content_strategy\"] = \"Content strategy document not available.\"\n",
    "            print(\"âš ï¸ Content strategy document not found\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error loading strategy documents: {e}\")\n",
    "        strategy_context = {\n",
    "            \"company_strategy\": \"Strategy document not available\",\n",
    "            \"seo_strategy\": \"SEO strategy document not available\", \n",
    "            \"content_strategy\": \"Content strategy document not available\"\n",
    "        }\n",
    "    \n",
    "    return strategy_context\n",
    "\n",
    "# Test loading all three documents\n",
    "strategy_context = load_company_strategy_context()\n",
    "print(f\"ðŸ“Š Strategy context keys: {list(strategy_context.keys())}\")\n",
    "print(f\"ðŸ“Š Total context size: {sum(len(v) for v in strategy_context.values() if isinstance(v, str))} chars\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dcad1d83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Batch processing function ready with full insights display\n"
     ]
    }
   ],
   "source": [
    "# Batch Processing Function (Updated with Full Insights Display)\n",
    "def process_audio_batch(audio_files: List[Path], pipeline) -> dict:\n",
    "    \"\"\"Process all audio files in batch with detailed insights display\"\"\"\n",
    "    \n",
    "    if not audio_files:\n",
    "        print(\"âŒ No files to process\")\n",
    "        return {\"processed\": [], \"failed\": [], \"total\": 0}\n",
    "    \n",
    "    print(f\"\\nðŸš€ STARTING BATCH PROCESSING - {len(audio_files)} files\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    processed_files = []\n",
    "    failed_files = []\n",
    "    results = []\n",
    "    \n",
    "    for i, file_path in enumerate(audio_files, 1):\n",
    "        print(f\"\\nðŸ“‚ Processing {i}/{len(audio_files)}: {file_path.name}\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        # Create initial state\n",
    "        initial_state = {\n",
    "            \"file_path\": str(file_path),\n",
    "            \"filename\": file_path.name,\n",
    "            \"transcript_text\": None,\n",
    "            \"conversation_id\": None,\n",
    "            \"extracted_insights\": None,  \n",
    "            \"error\": None,\n",
    "            \"status\": \"processing\"\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            # Run through pipeline\n",
    "            result = pipeline.invoke(initial_state)\n",
    "            \n",
    "            if result[\"status\"] in [\"completed\", \"insights_extracted\"]:\n",
    "                print(f\"âœ… SUCCESS: {file_path.name}\")\n",
    "                print(f\"   Conversation ID: {result['conversation_id']}\")\n",
    "                print(f\"   Transcript preview: {result['transcript_text'][:100]}...\")\n",
    "                \n",
    "                # FULL INSIGHTS DISPLAY\n",
    "                if result.get('extracted_insights'):\n",
    "                    insights = result['extracted_insights']\n",
    "                    print(f\"\\nðŸ§  === EXTRACTED INSIGHTS FOR: {file_path.name} ===\")\n",
    "                    print(\"=\" * 50)\n",
    "                    \n",
    "                    # Speakers\n",
    "                    if insights.speakers:\n",
    "                        print(\"ðŸ‘¥ SPEAKERS:\")\n",
    "                        for speaker in insights.speakers:\n",
    "                            print(f\"   â€¢ Name: {speaker.name or 'Unknown'}\")\n",
    "                            print(f\"     Role: {speaker.role or 'Unknown'}\")  \n",
    "                            print(f\"     Company: {speaker.company or 'Unknown'}\")\n",
    "                    \n",
    "                    # Core Values\n",
    "                    if insights.core_values:\n",
    "                        print(\"ðŸ’Ž CORE VALUES:\")\n",
    "                        for value in insights.core_values:\n",
    "                            print(f\"   â€¢ {value}\")\n",
    "                    \n",
    "                    # Priorities\n",
    "                    if insights.priorities:\n",
    "                        print(\"ðŸŽ¯ PRIORITIES:\")\n",
    "                        for priority in insights.priorities:\n",
    "                            print(f\"   â€¢ {priority}\")\n",
    "                    \n",
    "                    # Primary Challenges\n",
    "                    if insights.primary_challenges:\n",
    "                        print(\"ðŸ”¥ PRIMARY CHALLENGES:\")\n",
    "                        for challenge in insights.primary_challenges:\n",
    "                            print(f\"   â€¢ Challenge: {challenge.description}\")\n",
    "                            print(f\"     Impact: {challenge.impact}\")\n",
    "                            print(f\"     Urgency: {challenge.urgency}\")\n",
    "                    \n",
    "                    # Secondary Challenges\n",
    "                    if insights.secondary_challenges:\n",
    "                        print(\"âš ï¸  SECONDARY CHALLENGES:\")\n",
    "                        for challenge in insights.secondary_challenges:\n",
    "                            print(f\"   â€¢ Challenge: {challenge.description}\")\n",
    "                            print(f\"     Impact: {challenge.impact}\")\n",
    "                            print(f\"     Urgency: {challenge.urgency}\")\n",
    "                    \n",
    "                    # Current Solutions\n",
    "                    if insights.current_solutions:\n",
    "                        print(\"ðŸ”§ CURRENT SOLUTIONS:\")\n",
    "                        for solution in insights.current_solutions:\n",
    "                            print(f\"   â€¢ Solution: {solution.solution}\")\n",
    "                            print(f\"     Satisfaction: {solution.satisfaction_level}\")\n",
    "                            if solution.limitations:\n",
    "                                print(f\"     Limitations: {', '.join(solution.limitations)}\")\n",
    "                    \n",
    "                    # Psychological Needs\n",
    "                    if insights.psychological_needs:\n",
    "                        print(\"ðŸ§˜ PSYCHOLOGICAL NEEDS:\")\n",
    "                        for need in insights.psychological_needs:\n",
    "                            print(f\"   â€¢ {need.description}\")\n",
    "                            print(f\"     Category: {need.need_category}\")\n",
    "                            print(f\"     Intensity: {need.intensity}\")\n",
    "                    \n",
    "                    print(\"ðŸ§  === END INSIGHTS ===\")\n",
    "                    print(\"-\" * 50)\n",
    "                \n",
    "                processed_files.append(file_path)\n",
    "            else:\n",
    "                print(f\"âŒ FAILED: {file_path.name}\")\n",
    "                print(f\"   Status: {result.get('status', 'Unknown')}\")\n",
    "                print(f\"   Error: {result.get('error', 'Unknown error')}\")\n",
    "                failed_files.append(file_path)\n",
    "            \n",
    "            results.append(result)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ PIPELINE ERROR: {file_path.name}\")\n",
    "            print(f\"   Exception: {str(e)}\")\n",
    "            failed_files.append(file_path)\n",
    "            \n",
    "            results.append({\n",
    "                **initial_state,\n",
    "                \"error\": str(e),\n",
    "                \"status\": \"pipeline_error\"\n",
    "            })\n",
    "    \n",
    "    # Final Summary\n",
    "    print(f\"\\nðŸ“Š BATCH PROCESSING COMPLETE!\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"âœ… Successfully processed: {len(processed_files)}\")\n",
    "    print(f\"âŒ Failed: {len(failed_files)}\")\n",
    "    print(f\"ðŸ“ Total files: {len(audio_files)}\")\n",
    "    \n",
    "    if failed_files:\n",
    "        print(f\"\\nâŒ Failed files:\")\n",
    "        for failed_file in failed_files:\n",
    "            print(f\"   - {failed_file.name}\")\n",
    "    \n",
    "    return {\n",
    "        \"processed\": processed_files,\n",
    "        \"failed\": failed_files,\n",
    "        \"total\": len(audio_files),\n",
    "        \"results\": results\n",
    "    }\n",
    "\n",
    "print(\"âœ… Batch processing function ready with full insights display\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5b06e004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… File management functions defined\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Batch File Discovery and Management\n",
    "\n",
    "\n",
    "def find_audio_files_in_temp(temp_folder: Path = None) -> List[Path]:\n",
    "    \"\"\"Find all audio files in temp folder\"\"\"\n",
    "    \n",
    "    # Use default temp folder if not specified\n",
    "    if temp_folder is None:\n",
    "        temp_folder = project_root / 'data' / 'temp'\n",
    "    \n",
    "    # Ensure folder exists\n",
    "    temp_folder.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Check if folder exists\n",
    "    if not temp_folder.exists():\n",
    "        print(f\"âŒ Temp folder not found: {temp_folder}\")\n",
    "        return []\n",
    "    \n",
    "    # Find audio files\n",
    "    audio_extensions = ['*.wav', '*.mp3', '*.m4a']\n",
    "    audio_files = []\n",
    "    \n",
    "    for ext in audio_extensions:\n",
    "        files = list(temp_folder.glob(ext))\n",
    "        audio_files.extend(files)\n",
    "    \n",
    "    return sorted(audio_files)\n",
    "\n",
    "\n",
    "def display_batch_info(audio_files: List[Path]) -> bool:\n",
    "    \"\"\"Display information about the batch of files\"\"\"\n",
    "    \n",
    "    if not audio_files:\n",
    "        print(\"âŒ No audio files found in temp folder!\")\n",
    "        print(\"ðŸ’¡ TIP: Add .wav files to data/temp/ folder\")\n",
    "        return False\n",
    "    \n",
    "    total_size_mb = sum(f.stat().st_size for f in audio_files) / (1024 * 1024)\n",
    "    \n",
    "    print(f\"ðŸ“Š BATCH INFO:\")\n",
    "    print(f\"   Files to process: {len(audio_files)}\")\n",
    "    print(f\"   Total size: {total_size_mb:.1f} MB\")\n",
    "    print(f\"\\nðŸ“ Files found:\")\n",
    "    \n",
    "    for i, file_path in enumerate(audio_files, 1):\n",
    "        size_mb = file_path.stat().st_size / (1024 * 1024)\n",
    "        print(f\"   {i}. {file_path.name} ({size_mb:.1f} MB)\")\n",
    "    \n",
    "    return True\n",
    "\n",
    "\n",
    "print(\"âœ… File management functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c79e939f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Enhanced extract_insights_from_transcript with JSON repair\n"
     ]
    }
   ],
   "source": [
    "# Cell: Extract Insights Function - ENHANCED WITH JSON REPAIR\n",
    "def extract_insights_from_transcript(transcript: str) -> ExtractedInsights:\n",
    "    \"\"\"Extract structured insights using Anthropic Claude - ENHANCED WITH JSON REPAIR\"\"\"\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    Analyze this conversation transcript and extract structured insights:\n",
    "    \n",
    "    Transcript: {transcript}\n",
    "    \n",
    "    IMPORTANT: For speaker roles, use ONLY these exact values:\n",
    "    - \"client\" for the person being interviewed/consulted (CTO, CEO, Manager, business owner, etc.)\n",
    "    - \"interviewer\" for the person asking questions or conducting the interview\n",
    "    \n",
    "    Extract the following information in JSON format:\n",
    "    - speakers: List of people mentioned with name, role (client/interviewer only), company\n",
    "    - core_values: What they care about most  \n",
    "    - priorities: Current focus areas\n",
    "    - primary_challenges: Main problems they face with description, impact, urgency\n",
    "    - secondary_challenges: Secondary problems\n",
    "    - current_solutions: How they solve problems now with satisfaction level\n",
    "    - psychological_needs: Underlying needs with category, description, intensity\n",
    "    \n",
    "    Return ONLY valid JSON in this exact structure - no markdown, no code blocks:\n",
    "    {{\n",
    "        \"speakers\": [\n",
    "            {{\"name\": \"Manuel\", \"role\": \"client\", \"company\": \"Drone flytech\"}}\n",
    "        ],\n",
    "        \"core_values\": [\"efficiency\", \"transparency\"],\n",
    "        \"priorities\": [\"improving processes\"],\n",
    "        \"primary_challenges\": [\n",
    "            {{\n",
    "                \"description\": \"Tracking payment issues\",\n",
    "                \"impact\": \"Creates confusion in processes\", \n",
    "                \"urgency\": \"High\"\n",
    "            }}\n",
    "        ],\n",
    "        \"secondary_challenges\": [\n",
    "            {{\n",
    "                \"description\": \"Secondary challenge\",\n",
    "                \"impact\": \"Secondary impact\",\n",
    "                \"urgency\": \"Medium\"\n",
    "            }}\n",
    "        ],\n",
    "        \"current_solutions\": [\n",
    "            {{\n",
    "                \"solution\": \"Current approach\",\n",
    "                \"satisfaction_level\": \"Neutral\",\n",
    "                \"limitations\": [\"limitation1\", \"limitation2\"]\n",
    "            }}\n",
    "        ],\n",
    "        \"psychological_needs\": [\n",
    "            {{\n",
    "                \"need_category\": \"security\",\n",
    "                \"description\": \"Need for confidence\",\n",
    "                \"intensity\": \"High\"\n",
    "            }}\n",
    "        ]\n",
    "    }}\n",
    "    \n",
    "    Remember: \n",
    "    - Use \"client\" for the interviewee (even if they're CTO/CEO)\n",
    "    - Use \"interviewer\" for the person asking questions\n",
    "    - Use exact urgency values: \"Low\", \"Medium\", \"High\"\n",
    "    - Use exact satisfaction levels: \"Very Satisfied\", \"Satisfied\", \"Neutral\", \"Unsatisfied\", \"Very Unsatisfied\"\n",
    "    - Use exact intensity values: \"Low\", \"Medium\", \"High\"\n",
    "    - Ensure all strings are properly closed with quotes\n",
    "    - Do not truncate the response - complete all JSON structures\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Use the Claude LLM you already set up\n",
    "        response = llm.invoke(prompt)\n",
    "        \n",
    "        print(f\"ðŸ“ Raw response length: {len(response.content)} chars\")\n",
    "        print(f\"ðŸ“ Response starts with: {response.content[:50]}...\")\n",
    "        \n",
    "        # Clean markdown code blocks\n",
    "        content = response.content.strip()\n",
    "        if content.startswith('```json'):\n",
    "            print(\"ðŸ”§ Removing JSON markdown blocks...\")\n",
    "            content = content.replace('```json', '').replace('```', '').strip()\n",
    "        elif content.startswith('```'):\n",
    "            print(\"ðŸ”§ Removing generic markdown blocks...\")\n",
    "            content = content.replace('```', '').strip()\n",
    "        \n",
    "        # Extract JSON boundaries\n",
    "        first_brace = content.find('{')\n",
    "        if first_brace > 0:\n",
    "            content = content[first_brace:]\n",
    "        \n",
    "        last_brace = content.rfind('}')\n",
    "        if last_brace > 0 and last_brace < len(content) - 1:\n",
    "            content = content[:last_brace + 1]\n",
    "        \n",
    "        print(f\"ðŸ”§ Cleaned content starts with: {content[:50]}...\")\n",
    "        \n",
    "        # === ENHANCED: Try parsing with auto-repair ===\n",
    "        try:\n",
    "            insights_data = json.loads(content)\n",
    "            print(\"âœ… JSON parsed successfully\")\n",
    "            \n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"âš ï¸  JSON parsing error: {e}\")\n",
    "            print(f\"   Error at position: {e.pos}\")\n",
    "            \n",
    "            # Show context around error\n",
    "            start = max(0, e.pos - 80)\n",
    "            end = min(len(content), e.pos + 80)\n",
    "            print(f\"   Context: ...{content[start:end]}...\")\n",
    "            \n",
    "            print(\"\\nðŸ”§ Attempting JSON auto-repair...\")\n",
    "            \n",
    "            import re\n",
    "            \n",
    "            # Repair strategy based on error type\n",
    "            repaired = content\n",
    "            \n",
    "            if \"Unterminated string\" in str(e):\n",
    "                print(\"   â†’ Fixing unterminated string...\")\n",
    "                # Add closing quote at error position\n",
    "                repaired = content[:e.pos] + '\"'\n",
    "                \n",
    "                # Close any open structures after the fix\n",
    "                partial = content[:e.pos]\n",
    "                open_braces = partial.count('{')\n",
    "                close_braces = partial.count('}')\n",
    "                open_brackets = partial.count('[')\n",
    "                close_brackets = partial.count(']')\n",
    "                \n",
    "                if open_brackets > close_brackets:\n",
    "                    repaired += ']' * (open_brackets - close_brackets)\n",
    "                    print(f\"   â†’ Added {open_brackets - close_brackets} closing bracket(s)\")\n",
    "                \n",
    "                if open_braces > close_braces:\n",
    "                    repaired += '}' * (open_braces - close_braces)\n",
    "                    print(f\"   â†’ Added {open_braces - close_braces} closing brace(s)\")\n",
    "            \n",
    "            else:\n",
    "                # Generic repairs\n",
    "                # Fix 1: Remove trailing commas\n",
    "                repaired = re.sub(r',\\s*}', '}', repaired)\n",
    "                repaired = re.sub(r',\\s*]', ']', repaired)\n",
    "                \n",
    "                # Fix 2: Balance brackets\n",
    "                open_braces = repaired.count('{')\n",
    "                close_braces = repaired.count('}')\n",
    "                open_brackets = repaired.count('[')\n",
    "                close_brackets = repaired.count(']')\n",
    "                \n",
    "                if open_brackets > close_brackets:\n",
    "                    repaired += ']' * (open_brackets - close_brackets)\n",
    "                    print(f\"   â†’ Added {open_brackets - close_brackets} closing bracket(s)\")\n",
    "                \n",
    "                if open_braces > close_braces:\n",
    "                    repaired += '}' * (open_braces - close_braces)\n",
    "                    print(f\"   â†’ Added {open_braces - close_braces} closing brace(s)\")\n",
    "            \n",
    "            # Try parsing repaired JSON\n",
    "            try:\n",
    "                insights_data = json.loads(repaired)\n",
    "                print(\"âœ… Auto-repair successful!\")\n",
    "                \n",
    "            except json.JSONDecodeError as e2:\n",
    "                print(f\"âŒ Auto-repair failed: {e2}\")\n",
    "                \n",
    "                # Last resort: Extract partial valid data\n",
    "                print(\"\\nðŸ”§ Last resort: Extracting partial data...\")\n",
    "                \n",
    "                # Find last complete object before error\n",
    "                try:\n",
    "                    safe_end = content[:e.pos].rfind('}')\n",
    "                    if safe_end > 0:\n",
    "                        partial = content[:safe_end + 1]\n",
    "                        \n",
    "                        # Balance remaining brackets\n",
    "                        open_braces = partial.count('{')\n",
    "                        close_braces = partial.count('}')\n",
    "                        if open_braces > close_braces:\n",
    "                            partial += '}' * (open_braces - close_braces)\n",
    "                        \n",
    "                        insights_data = json.loads(partial)\n",
    "                        print(\"âœ… Partial extraction successful!\")\n",
    "                    else:\n",
    "                        raise ValueError(\"No valid JSON found\")\n",
    "                        \n",
    "                except Exception as e3:\n",
    "                    print(f\"âŒ Partial extraction failed: {e3}\")\n",
    "                    print(f\"\\nðŸ“ Problematic response (first 1000 chars):\")\n",
    "                    print(content[:1000])\n",
    "                    raise e  # Re-raise original error\n",
    "        \n",
    "        # === Validate and fill missing fields ===\n",
    "        required_fields = {\n",
    "            'speakers': [],\n",
    "            'core_values': [],\n",
    "            'priorities': [],\n",
    "            'primary_challenges': [],\n",
    "            'secondary_challenges': [],\n",
    "            'current_solutions': [],\n",
    "            'psychological_needs': []\n",
    "        }\n",
    "        \n",
    "        for field, default in required_fields.items():\n",
    "            if field not in insights_data:\n",
    "                print(f\"âš ï¸  Missing field '{field}', using default: {default}\")\n",
    "                insights_data[field] = default\n",
    "        \n",
    "        # Fix speaker roles (ensure only 'client' or 'interviewer')\n",
    "        for speaker in insights_data.get('speakers', []):\n",
    "            if 'role' not in speaker or speaker['role'] not in ['interviewer', 'client']:\n",
    "                print(f\"âš ï¸  Invalid role for {speaker.get('name', 'unknown')}, defaulting to 'client'\")\n",
    "                speaker['role'] = 'client'\n",
    "        \n",
    "        # Convert to Pydantic model\n",
    "        result = ExtractedInsights(**insights_data)\n",
    "        \n",
    "        print(f\"âœ… Successfully extracted insights!\")\n",
    "        print(f\"   Speakers: {len(result.speakers)}\")\n",
    "        print(f\"   Challenges: {len(result.primary_challenges)}\")\n",
    "        print(f\"   Needs: {len(result.psychological_needs)}\")\n",
    "        print(f\"   Values: {len(result.core_values)}\")\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"âŒ Final JSON parsing error: {e}\")\n",
    "        print(f\"ðŸ“ Raw response (first 500 chars): {response.content[:500]}...\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error in extraction: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        raise\n",
    "\n",
    "print(\"âœ… Enhanced extract_insights_from_transcript with JSON repair\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b1b52ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fixed creative agent function ready\n"
     ]
    }
   ],
   "source": [
    "# Cell: Fixed Creative Agent Function\n",
    "def generate_blog_ideas_from_insights(insights: ExtractedInsights, strategy_context: dict) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Fixed creative agent that handles Claude's markdown JSON response\n",
    "    \"\"\"\n",
    "    \n",
    "    creative_prompt = f\"\"\"\n",
    "    You are a creative content strategist for Big Kids Automation, a company that helps businesses implement AI and automation solutions.\n",
    "    \n",
    "    COMPANY CONTEXT:\n",
    "    {strategy_context.get('company_strategy', 'Strategy not available')[:1000]}...\n",
    "    \n",
    "    SEO STRATEGY:\n",
    "    {strategy_context.get('seo_strategy', 'SEO strategy not available')[:500]}...\n",
    "    \n",
    "    CONVERSATION INSIGHTS TO WORK FROM:\n",
    "    \n",
    "    Speakers: {[f\"{s.name} ({s.role}) from {s.company}\" for s in insights.speakers] if insights.speakers else \"Unknown speakers\"}\n",
    "    \n",
    "    Core Values: {\", \".join(insights.core_values) if insights.core_values else \"None identified\"}\n",
    "    \n",
    "    Priorities: {\", \".join(insights.priorities) if insights.priorities else \"None identified\"}\n",
    "    \n",
    "    Primary Challenges:\n",
    "    {chr(10).join([f\"- {c.description} (Impact: {c.impact}, Urgency: {c.urgency})\" for c in insights.primary_challenges]) if insights.primary_challenges else \"None identified\"}\n",
    "    \n",
    "    Current Solutions:\n",
    "    {chr(10).join([f\"- {s.solution} (Satisfaction: {s.satisfaction_level})\" for s in insights.current_solutions]) if insights.current_solutions else \"None identified\"}\n",
    "    \n",
    "    Psychological Needs:\n",
    "    {chr(10).join([f\"- {n.description} ({n.need_category}, {n.intensity} intensity)\" for n in insights.psychological_needs]) if insights.psychological_needs else \"None identified\"}\n",
    "    \n",
    "    TASK:\n",
    "    Generate 4-5 creative blog post ideas that:\n",
    "    1. Address the challenges and needs identified in this conversation\n",
    "    2. Align with Big Kids Automation's mission to help businesses with AI/automation\n",
    "    3. Provide value to potential clients facing similar challenges\n",
    "    4. Support our SEO and content marketing strategy\n",
    "    5. Are actionable and practical, not just theoretical\n",
    "    \n",
    "    For each blog post idea, provide:\n",
    "    - title: Clear, engaging title that includes relevant keywords\n",
    "    - description: 2-3 sentence description of what the post will cover\n",
    "    - target_audience: Who this post is primarily for\n",
    "    - content_angle: The unique angle or approach this post takes\n",
    "    - business_value: How this post helps our business goals\n",
    "    \n",
    "    IMPORTANT: Return ONLY the JSON array, no markdown formatting, no code blocks, no explanatory text.\n",
    "    \n",
    "    Format:\n",
    "    [\n",
    "        {{\n",
    "            \"title\": \"How AI Proposal Systems Balance Speed with Brand Differentiation\",\n",
    "            \"description\": \"A practical guide showing how modern AI-powered proposal systems solve the common problem of maintaining company uniqueness while leveraging automation. Includes real case studies and implementation steps.\",\n",
    "            \"target_audience\": \"Business development directors and proposal managers at consulting firms\",\n",
    "            \"content_angle\": \"Problem-solution with real case studies\",\n",
    "            \"business_value\": \"Attracts prospects struggling with proposal automation while maintaining differentiation\"\n",
    "        }}\n",
    "    ]\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Generate ideas using Claude\n",
    "        response = llm.invoke(creative_prompt)\n",
    "        raw_content = response.content.strip()\n",
    "        \n",
    "        print(f\"ðŸ“ Raw response length: {len(raw_content)} chars\")\n",
    "        print(f\"ðŸ“ Response starts with: {raw_content[:50]}...\")\n",
    "        \n",
    "        # Handle markdown code blocks\n",
    "        if raw_content.startswith('```'):\n",
    "            print(\"ðŸ”§ Removing markdown code blocks...\")\n",
    "            # Remove ```json and ``` wrappers\n",
    "            lines = raw_content.split('\\n')\n",
    "            # Remove first line if it's ```json or ```\n",
    "            if lines[0].startswith('```'):\n",
    "                lines = lines[1:]\n",
    "            # Remove last line if it's ```\n",
    "            if lines and lines[-1].strip() == '```':\n",
    "                lines = lines[:-1]\n",
    "            raw_content = '\\n'.join(lines).strip()\n",
    "            print(f\"ðŸ”§ Cleaned content starts with: {raw_content[:50]}...\")\n",
    "        \n",
    "        # Parse JSON response\n",
    "        blog_ideas = json.loads(raw_content)\n",
    "        \n",
    "        print(f\"âœ… Creative agent successfully parsed {len(blog_ideas)} blog ideas\")\n",
    "        return blog_ideas\n",
    "        \n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"âŒ JSON parsing error in creative agent: {e}\")\n",
    "        print(f\"ðŸ“ Cleaned content: {raw_content[:500]}...\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error in creative agent: {e}\")\n",
    "        return []\n",
    "\n",
    "print(\"âœ… Fixed creative agent function ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b0e67228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Updated LLM scoring engine with content strategy context\n"
     ]
    }
   ],
   "source": [
    "# Cell 17: Updated Scoring Engine with Content Strategy Context\n",
    "def score_blog_idea_with_llm(idea: dict, strategy_context: dict, conversation_context: str = \"\") -> dict:\n",
    "    \"\"\"Score a single blog idea using LLM with all three strategy contexts\"\"\"\n",
    "    \n",
    "    scoring_prompt = f\"\"\"\n",
    "    You are an expert content strategist for Big Kids Automation. Score this blog post idea on a 1-10 scale using our strategic context.\n",
    "    \n",
    "    COMPANY STRATEGY:\n",
    "    {strategy_context.get('company_strategy_summary', 'Not available')}\n",
    "    \n",
    "    SEO STRATEGY:\n",
    "    {strategy_context.get('seo_strategy_summary', 'Not available')}\n",
    "    \n",
    "    CONTENT STRATEGY:\n",
    "    {strategy_context.get('content_strategy_summary', 'Not available')}\n",
    "    \n",
    "    BLOG IDEA TO SCORE:\n",
    "    Title: {idea.get('title', 'No title')}\n",
    "    Description: {idea.get('description', 'No description')}\n",
    "    Target Audience: {idea.get('target_audience', 'Unknown')}\n",
    "    Business Value: {idea.get('business_value', 'Unknown')}\n",
    "    Content Angle: {idea.get('content_angle', 'Unknown')}\n",
    "    \n",
    "    CONVERSATION CONTEXT:\n",
    "    {conversation_context[:300] if conversation_context else 'No context available'}...\n",
    "    \n",
    "    SCORING INSTRUCTIONS:\n",
    "    Rate each criterion from 1-10 (10 = excellent, 1 = poor):\n",
    "    \n",
    "    1. usefulness_potential: How useful will this be to readers with real problems?\n",
    "    2. fitwith_seo_strategy: How well does this align with our SEO keywords and strategy?\n",
    "    3. fitwith_content_strategy: How well does this fit our content strategy, voice, and approach?\n",
    "    4. inspiration_potential: How likely to inspire readers to take meaningful action?\n",
    "    5. collaboration_potential: How likely to generate leads/prospects who contact us?\n",
    "    6. innovation: How unique is this topic compared to existing content?\n",
    "    7. difficulty: How complex/time-consuming will this be to write? (1=very hard, 10=easy)\n",
    "    \n",
    "    Return ONLY valid JSON with your scores and brief reasoning:\n",
    "    {{\n",
    "        \"usefulness_potential\": 8,\n",
    "        \"fitwith_seo_strategy\": 7,\n",
    "        \"fitwith_content_strategy\": 9,\n",
    "        \"inspiration_potential\": 6,\n",
    "        \"collaboration_potential\": 8,\n",
    "        \"innovation\": 7,\n",
    "        \"difficulty\": 4,\n",
    "        \"reasoning\": \"This idea scores well because it aligns with our content strategy focus on...\"\n",
    "    }}\n",
    "    \"\"\"\n",
    "    \n",
    "    # ... rest of the function stays the same\n",
    "    try:\n",
    "        response = llm.invoke(scoring_prompt)\n",
    "        \n",
    "        content = response.content.strip()\n",
    "        if content.startswith('```json'):\n",
    "            content = content.replace('```json', '').replace('```', '').strip()\n",
    "        \n",
    "        scores = json.loads(content)\n",
    "        \n",
    "        # Validate scores are in range\n",
    "        for criterion in ['usefulness_potential', 'fitwith_seo_strategy', 'fitwith_content_strategy', \n",
    "                         'inspiration_potential', 'collaboration_potential', 'innovation', 'difficulty']:\n",
    "            if criterion in scores:\n",
    "                scores[criterion] = max(1, min(10, scores[criterion]))\n",
    "        \n",
    "        # Calculate total score\n",
    "        total_score = sum([\n",
    "            scores.get('usefulness_potential', 5),\n",
    "            scores.get('fitwith_seo_strategy', 5),\n",
    "            scores.get('fitwith_content_strategy', 5),\n",
    "            scores.get('inspiration_potential', 5),\n",
    "            scores.get('collaboration_potential', 5),\n",
    "            scores.get('innovation', 5),\n",
    "            scores.get('difficulty', 5)\n",
    "        ])\n",
    "        \n",
    "        scores['total_score'] = total_score\n",
    "        return scores\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error scoring idea: {e}\")\n",
    "        return {\n",
    "            \"usefulness_potential\": 5, \"fitwith_seo_strategy\": 5, \"fitwith_content_strategy\": 5,\n",
    "            \"inspiration_potential\": 5, \"collaboration_potential\": 5, \"innovation\": 5,\n",
    "            \"difficulty\": 5, \"total_score\": 35, \"reasoning\": f\"Default scores due to error: {str(e)}\"\n",
    "        }\n",
    "\n",
    "print(\"âœ… Updated LLM scoring engine with content strategy context\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3972ba82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… LangGraph nodes defined\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Define LangGraph Nodes\n",
    "def transcription_node(state: AudioPipelineState) -> AudioPipelineState:\n",
    "    \"\"\"Node 1: Transcribe audio file with AssemblyAI\"\"\"\n",
    "    try:\n",
    "        print(f\"ðŸŽ™ï¸ Transcribing: {state['filename']}\")\n",
    "        \n",
    "        # Configure transcriber\n",
    "        transcriber = aai.Transcriber()\n",
    "        \n",
    "        # Transcribe the file\n",
    "        transcript = transcriber.transcribe(state['file_path'])\n",
    "        \n",
    "        if transcript.status == aai.TranscriptStatus.error:\n",
    "            return {\n",
    "                **state,\n",
    "                \"error\": f\"AssemblyAI error: {transcript.error}\",\n",
    "                \"status\": \"transcription_failed\"\n",
    "            }\n",
    "        \n",
    "        return {\n",
    "            **state,\n",
    "            \"transcript_text\": transcript.text,\n",
    "            \"status\": \"transcribed\"\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            **state,\n",
    "            \"error\": f\"Transcription error: {str(e)}\",\n",
    "            \"status\": \"transcription_failed\"\n",
    "        }\n",
    "\n",
    "def database_saver_node_conversations(state: AudioPipelineState) -> AudioPipelineState:\n",
    "    \"\"\"Node 2: Save transcript to database\"\"\"\n",
    "    try:\n",
    "        print(f\"ðŸ’¾ Saving to database: {state['filename']}\")\n",
    "        \n",
    "        # Create conversation object\n",
    "        conversation = ConversationCreate(\n",
    "            title=f\"Audio: {state['filename']}\",\n",
    "            raw_text=state['transcript_text'],\n",
    "            source=\"transcribed\"\n",
    "        )\n",
    "        \n",
    "        # Save to database\n",
    "        conversation_id = db.create_conversation(conversation)\n",
    "        \n",
    "        return {\n",
    "            **state,\n",
    "            \"conversation_id\": conversation_id,\n",
    "            \"status\": \"completed\"\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            **state,\n",
    "            \"error\": f\"Database error: {str(e)}\",\n",
    "            \"status\": \"database_failed\"\n",
    "        }\n",
    "\n",
    "print(\"âœ… LangGraph nodes defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d0edabd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… pain_extractor_node fixed (now checks database for transcript)\n"
     ]
    }
   ],
   "source": [
    "# Cell: Fixed pain_extractor_node (minimal change)\n",
    "def pain_extractor_node(state: AudioPipelineState) -> AudioPipelineState:\n",
    "    \"\"\"\n",
    "    LangGraph node: Extract structured insights from conversation transcript\n",
    "    FIXED: Falls back to database if transcript_text not in state\n",
    "    \"\"\"\n",
    "    print(\"ðŸ§  Starting pain extraction...\")\n",
    "    \n",
    "    try:\n",
    "        # Try to get transcript from state first\n",
    "        transcript = state.get('transcript_text')\n",
    "        \n",
    "        # ADDED: If not in state, get from database using conversation_id\n",
    "        if not transcript:\n",
    "            conversation_id = state.get('conversation_id')\n",
    "            if conversation_id:\n",
    "                print(f\"   ðŸ“ Transcript not in state, loading from database (conversation {conversation_id})...\")\n",
    "                conv = db.get_conversation(conversation_id)\n",
    "                if conv:\n",
    "                    # Try raw_text field (your database schema)\n",
    "                    transcript = get_conv_attribute(conv, 'raw_text', None)\n",
    "                    if transcript:\n",
    "                        print(f\"   âœ… Loaded transcript from database ({len(transcript)} chars)\")\n",
    "                    else:\n",
    "                        print(f\"   âš ï¸  No raw_text found in conversation\")\n",
    "        \n",
    "        # If still no transcript, fail\n",
    "        if not transcript:\n",
    "            print(\"âŒ No transcript available\")\n",
    "            return {\n",
    "                **state,\n",
    "                \"error\": \"No transcript available for pain extraction\",\n",
    "                \"status\": \"error\"\n",
    "            }\n",
    "        \n",
    "        # Extract insights using OpenAI structured output\n",
    "        insights = extract_insights_from_transcript(transcript)\n",
    "        \n",
    "        if insights:\n",
    "            print(f\"âœ… Extracted insights: {len(insights.primary_challenges)} primary challenges, {len(insights.speakers)} speakers\")\n",
    "            \n",
    "            return {\n",
    "                **state,\n",
    "                \"extracted_insights\": insights,\n",
    "                \"status\": \"insights_extracted\"\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                **state,\n",
    "                \"error\": \"Failed to extract insights from transcript\",\n",
    "                \"status\": \"error\"\n",
    "            }\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Pain extraction failed: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return {\n",
    "            **state,\n",
    "            \"error\": f\"Pain extraction error: {str(e)}\",\n",
    "            \"status\": \"error\"\n",
    "        }\n",
    "\n",
    "print(\"âœ… pain_extractor_node fixed (now checks database for transcript)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8a0137a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Creative agent node RELOADED\n"
     ]
    }
   ],
   "source": [
    "# Cell: Creative Agent Node - FORCE RELOAD\n",
    "def creative_agent_node(state: AudioPipelineState) -> AudioPipelineState:\n",
    "    \"\"\"Creative agent that generates raw blog ideas\"\"\"\n",
    "    \n",
    "    try:\n",
    "        print(\"ðŸŽ¨ Starting creative blog idea generation...\")\n",
    "        \n",
    "        insights = state.get('extracted_insights')\n",
    "        if not insights:\n",
    "            return {**state, \"error\": \"No insights available\", \"status\": \"error\"}\n",
    "        \n",
    "        print(f\"ðŸ“Š Working with insights: {len(insights.primary_challenges)} challenges\")\n",
    "        \n",
    "        # Load strategy context\n",
    "        strategy_context = load_company_strategy_context()\n",
    "        \n",
    "        # Generate ideas (returns JSON list)\n",
    "        raw_ideas_json = generate_blog_ideas_from_insights(insights, strategy_context)\n",
    "        \n",
    "        if not raw_ideas_json:\n",
    "            return {**state, \"error\": \"No ideas generated\", \"status\": \"error\"}\n",
    "        \n",
    "        # Convert to Pydantic for validation\n",
    "        validated_ideas = []\n",
    "        for idea_json in raw_ideas_json:\n",
    "            try:\n",
    "                idea = RawBlogIdea(**idea_json)\n",
    "                validated_ideas.append(idea)\n",
    "            except Exception as e:\n",
    "                print(f\"âš ï¸ Skipping invalid idea: {e}\")\n",
    "        \n",
    "        if validated_ideas:\n",
    "            print(f\"ðŸŽ‰ Generated {len(validated_ideas)} valid blog ideas\")\n",
    "            \n",
    "            # Convert back to dict for state storage\n",
    "            ideas_as_dicts = [idea.model_dump() for idea in validated_ideas]\n",
    "            \n",
    "            return {\n",
    "                **state,\n",
    "                \"raw_blog_ideas\": ideas_as_dicts,\n",
    "                \"status\": \"ideas_generated\"\n",
    "            }\n",
    "        else:\n",
    "            return {**state, \"error\": \"No valid ideas after validation\", \"status\": \"error\"}\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Creative agent error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return {**state, \"error\": str(e), \"status\": \"error\"}\n",
    "\n",
    "print(\"âœ… Creative agent node RELOADED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "180267b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def writing_agent_node(state: AudioPipelineState) -> AudioPipelineState:\n",
    "    \"\"\"Future node: Generate blog post from plan.\"\"\"\n",
    "    plan = state.get(\"blog_plan\")\n",
    "    if not plan:\n",
    "        return state  # Skip if no plan\n",
    "    instructions = f\"Write a full blog post for Big Kids Automation Agency using this plan: {plan.plan}\"\n",
    "    # Structured LLM (inspired by your snippet)\n",
    "    structured_llm = llm.with_structured_output(BlogPost)  # Use your BlogPost model\n",
    "    blog_post = structured_llm.invoke([SystemMessage(content=instructions), HumanMessage(content=\"Write the post.\")])\n",
    "    \n",
    "    # Updated: Store the FULL BlogPost instance (not just a dict)\n",
    "    state[\"blog_post\"] = blog_post  # Now includes id, issue, angle, etc.\n",
    "    \n",
    "    return state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dbc0740a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Analyst agent node FIXED for Pydantic objects\n"
     ]
    }
   ],
   "source": [
    "# Cell 19: Analyst Agent Node - FIXED for Pydantic Objects\n",
    "def analyst_agent_node(state: AudioPipelineState) -> AudioPipelineState:\n",
    "    \"\"\"\n",
    "    LangGraph node that scores blog ideas using company strategy context\n",
    "    Input: state[\"raw_blog_ideas\"] \n",
    "    Output: state[\"scored_blog_ideas\"]\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        print(\"ðŸ” Starting analyst agent - scoring blog ideas...\")\n",
    "        \n",
    "        # Check current status\n",
    "        current_status = state.get('status', '')\n",
    "        print(f\"ðŸ“Š Input status: {current_status}\")\n",
    "        \n",
    "        # Check if we have raw blog ideas to score\n",
    "        raw_ideas = state.get('raw_blog_ideas')\n",
    "        if not raw_ideas:\n",
    "            return {\n",
    "                **state,\n",
    "                \"error\": \"No raw blog ideas available for scoring\",\n",
    "                \"status\": \"error\"\n",
    "            }\n",
    "        \n",
    "        print(f\"ðŸ“Š Found {len(raw_ideas)} blog ideas to score\")\n",
    "        \n",
    "        # Load strategy context for scoring\n",
    "        print(\"ðŸ“š Loading strategy context...\")\n",
    "        strategy_context = prepare_strategy_context_for_scoring()\n",
    "        \n",
    "        # Get conversation context for better scoring\n",
    "        conversation_context = state.get('transcript_text', '')\n",
    "        \n",
    "        # Score each blog idea\n",
    "        scored_ideas = []\n",
    "        for i, idea in enumerate(raw_ideas, 1):\n",
    "            # FIXED: Handle both Pydantic objects and dicts properly\n",
    "            if hasattr(idea, 'title'):\n",
    "                # It's a Pydantic object - convert to dict first\n",
    "                idea_dict = idea.model_dump() if hasattr(idea, 'model_dump') else idea.__dict__\n",
    "                title_preview = idea.title[:50]\n",
    "            else:\n",
    "                # It's already a dict\n",
    "                idea_dict = idea\n",
    "                title_preview = idea.get('title', 'No title')[:50]\n",
    "            \n",
    "            print(f\"ðŸ” Scoring idea {i}/{len(raw_ideas)}: {title_preview}...\")\n",
    "            \n",
    "            # Score the idea (now always working with dict)\n",
    "            scores = score_blog_idea_with_llm(idea_dict, strategy_context, conversation_context)\n",
    "            \n",
    "            # Combine original idea with scores\n",
    "            scored_idea = {\n",
    "                **idea_dict,  # Original idea data (now definitely a dict)\n",
    "                **scores      # Scoring data\n",
    "            }\n",
    "            \n",
    "            scored_ideas.append(scored_idea)\n",
    "            \n",
    "            print(f\"   âœ… Scored: {scores.get('total_score', 0)}/70 points\")\n",
    "        \n",
    "        # Sort by total score (highest first)\n",
    "        scored_ideas.sort(key=lambda x: x.get('total_score', 0), reverse=True)\n",
    "        \n",
    "        print(f\"\\nðŸŽ‰ Analyst agent completed scoring!\")\n",
    "        print(f\"ðŸ“Š Scored {len(scored_ideas)} ideas\")\n",
    "        \n",
    "        if scored_ideas:\n",
    "            print(f\"ðŸ† Top idea: '{scored_ideas[0].get('title', 'Unknown')[:50]}...' ({scored_ideas[0].get('total_score', 0)}/70)\")\n",
    "            print(f\"ðŸ“‰ Lowest idea: '{scored_ideas[-1].get('title', 'Unknown')[:50]}...' ({scored_ideas[-1].get('total_score', 0)}/70)\")\n",
    "        \n",
    "        return {\n",
    "            **state,\n",
    "            \"scored_blog_ideas\": scored_ideas,\n",
    "            \"status\": \"ideas_scored\"\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error in analyst agent node: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        \n",
    "        return {\n",
    "            **state,\n",
    "            \"error\": f\"Analyst agent error: {str(e)}\",\n",
    "            \"status\": \"error\"\n",
    "        }\n",
    "\n",
    "print(\"âœ… Analyst agent node FIXED for Pydantic objects\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f5cabeaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… AssemblyAI connection successful\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 4: Test AssemblyAI Connection\n",
    "# Configure AssemblyAI\n",
    "aai.settings.api_key = os.getenv('ASSEMBLYAI_API_KEY')\n",
    "\n",
    "# Test with a simple transcription (we'll use a file from temp folder)\n",
    "def test_assemblyai_connection():\n",
    "    \"\"\"Test if AssemblyAI is working\"\"\"\n",
    "    try:\n",
    "        # Just test the API key is valid\n",
    "        transcriber = aai.Transcriber()\n",
    "        print(\"âœ… AssemblyAI connection successful\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ AssemblyAI connection failed: {e}\")\n",
    "        return False\n",
    "\n",
    "test_assemblyai_connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8762d70d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Database saver node (blog ideas) ready - FIXED RETURN\n"
     ]
    }
   ],
   "source": [
    "# Cell: Database Saver Node for BLOG IDEAS (Node 6) - FIXED RETURN\n",
    "from database.models import BlogPostIdeaCreate\n",
    "\n",
    "def database_saver_node(state: AudioPipelineState) -> AudioPipelineState:\n",
    "    \"\"\"\n",
    "    LangGraph node that saves scored blog ideas to database\n",
    "    Input: state[\"scored_blog_ideas\"]\n",
    "    Output: state[\"saved_idea_ids\"]\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        print(\"ðŸ’¾ Starting database saver - saving scored blog ideas...\")\n",
    "        \n",
    "        scored_ideas = state.get('scored_blog_ideas')\n",
    "        conversation_id = state.get('conversation_id')\n",
    "        \n",
    "        if not scored_ideas:\n",
    "            print(\"âŒ No scored blog ideas available to save\")\n",
    "            return {\n",
    "                **state,\n",
    "                \"error\": \"No scored blog ideas available to save\",\n",
    "                \"status\": \"error\"\n",
    "            }\n",
    "        \n",
    "        if not conversation_id:\n",
    "            print(\"âŒ No conversation_id available for linking ideas\")\n",
    "            return {\n",
    "                **state,\n",
    "                \"error\": \"No conversation_id available for linking ideas\",\n",
    "                \"status\": \"error\"\n",
    "            }\n",
    "        \n",
    "        print(f\"ðŸ“Š Found {len(scored_ideas)} scored ideas to save\")\n",
    "        print(f\"ðŸ”— Linking ideas to conversation_id: {conversation_id}\")\n",
    "        \n",
    "        saved_idea_ids = []\n",
    "        failed_count = 0\n",
    "        \n",
    "        for i, scored_idea in enumerate(scored_ideas, 1):\n",
    "            try:\n",
    "                # Calculate total_score if not present\n",
    "                if 'total_score' not in scored_idea:\n",
    "                    scored_idea['total_score'] = sum([\n",
    "                        scored_idea.get('usefulness_potential', 0),\n",
    "                        scored_idea.get('fitwith_seo_strategy', 0),\n",
    "                        scored_idea.get('fitwith_content_strategy', 0),\n",
    "                        scored_idea.get('inspiration_potential', 0),\n",
    "                        scored_idea.get('collaboration_potential', 0),\n",
    "                        scored_idea.get('innovation', 0),\n",
    "                        scored_idea.get('difficulty', 0)\n",
    "                    ])\n",
    "                \n",
    "                blog_idea = BlogPostIdeaCreate(\n",
    "                    conversation_id=conversation_id,\n",
    "                    title=scored_idea.get('title', 'Untitled'),\n",
    "                    description=scored_idea.get('description', ''),\n",
    "                    usefulness_potential=scored_idea.get('usefulness_potential', 5),\n",
    "                    fitwith_seo_strategy=scored_idea.get('fitwith_seo_strategy', 5),\n",
    "                    fitwith_content_strategy=scored_idea.get('fitwith_content_strategy', 5),\n",
    "                    inspiration_potential=scored_idea.get('inspiration_potential', 5),\n",
    "                    collaboration_potential=scored_idea.get('collaboration_potential', 5),\n",
    "                    innovation=scored_idea.get('innovation', 5),\n",
    "                    difficulty=scored_idea.get('difficulty', 5),\n",
    "                    sent_to_prod=False,\n",
    "                    raw_llm_response=scored_idea.get('reasoning', None)\n",
    "                )\n",
    "                \n",
    "                idea_id = db.create_blog_post_idea(blog_idea)\n",
    "                saved_idea_ids.append(idea_id)\n",
    "                \n",
    "                print(f\"   âœ… Saved idea {i}: '{scored_idea.get('title', 'Unknown')[:50]}...' (ID: {idea_id})\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"   âŒ Failed to save idea {i}: {e}\")\n",
    "                failed_count += 1\n",
    "        \n",
    "        if saved_idea_ids:\n",
    "            print(f\"\\nðŸŽ‰ Database saver completed!\")\n",
    "            print(f\"âœ… Successfully saved: {len(saved_idea_ids)} ideas\")\n",
    "            if failed_count > 0:\n",
    "                print(f\"âš ï¸  Failed to save: {failed_count} ideas\")\n",
    "            \n",
    "            # FIXED: Explicitly return saved_idea_ids in the state\n",
    "            return {\n",
    "                **state,\n",
    "                \"saved_idea_ids\": saved_idea_ids,  # â† This is the critical line\n",
    "                \"status\": \"ideas_saved_to_db\"\n",
    "            }\n",
    "        else:\n",
    "            print(\"âŒ Failed to save any ideas to database\")\n",
    "            return {\n",
    "                **state,\n",
    "                \"saved_idea_ids\": [],  # Return empty list instead of None\n",
    "                \"error\": \"Failed to save any ideas to database\",\n",
    "                \"status\": \"error\"\n",
    "            }\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error in database saver node: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        \n",
    "        return {\n",
    "            **state,\n",
    "            \"saved_idea_ids\": [],  # Return empty list on error\n",
    "            \"error\": f\"Database saver error: {str(e)}\",\n",
    "            \"status\": \"error\"\n",
    "        }\n",
    "\n",
    "print(\"âœ… Database saver node (blog ideas) ready - FIXED RETURN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8c379c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Pipeline compiled (8 nodes, with HITL interrupt)\n"
     ]
    }
   ],
   "source": [
    "# Cell 21: Updated Pipeline Builder - Now with 8 Nodes\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "def build_pipeline():\n",
    "    workflow = StateGraph(AudioPipelineState)\n",
    "    # Existing nodes \n",
    "    workflow.add_node(\"transcribe\", transcription_node)\n",
    "    workflow.add_node(\"save_to_db\", database_saver_node_conversations)  \n",
    "    workflow.add_node(\"extract_insights\", pain_extractor_node)\n",
    "    workflow.add_node(\"creative_agent\", creative_agent_node)\n",
    "    workflow.add_node(\"analyst_agent\", analyst_agent_node)\n",
    "    workflow.add_node(\"save_ideas\", database_saver_node)\n",
    "    workflow.add_node(\"idea_selection_hitl\", idea_selection_hitl)\n",
    "    workflow.add_node(\"planning_agent\", planning_agent_node)\n",
    "    workflow.add_node(\"writing_agent\", writing_agent_node)\n",
    "    \n",
    "    # Existing edges\n",
    "    workflow.add_edge(\"transcribe\", \"save_to_db\")\n",
    "    workflow.add_edge(\"save_to_db\", \"extract_insights\")\n",
    "    workflow.add_edge(\"extract_insights\", \"creative_agent\")\n",
    "    workflow.add_edge(\"creative_agent\", \"analyst_agent\")    \n",
    "    workflow.add_edge(\"analyst_agent\", \"save_ideas\")\n",
    "    workflow.add_edge(\"save_ideas\", \"idea_selection_hitl\")\n",
    "    workflow.add_edge(\"idea_selection_hitl\", \"planning_agent\")\n",
    "    workflow.add_edge(\"planning_agent\", \"writing_agent\")\n",
    "    \n",
    "    workflow.set_entry_point(\"transcribe\")\n",
    "    workflow.set_finish_point(\"writing_agent\")\n",
    "    \n",
    "    # Compile with checkpointer for HITL persistence\n",
    "    memory = MemorySaver()\n",
    "    return workflow.compile(checkpointer=memory, interrupt_before=[\"idea_selection_hitl\"])\n",
    "\n",
    "\n",
    "# In builder: Add node and edge\n",
    "\n",
    "#\n",
    "#workflow.set_finish_point(\"writing_agent\")\n",
    "\n",
    "# Rebuild\n",
    "pipeline = build_pipeline()\n",
    "print(\"âœ… Pipeline compiled (8 nodes, with HITL interrupt)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2e18e44f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Anthropic LSLM initialized with Claude Haiku 4.5\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Setup Anthropic LLM for Insights Extraction (FIXED)\n",
    "\n",
    "\n",
    "# Initialize Anthropic with correct model name\n",
    "anthropic_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "if not anthropic_key:\n",
    "    print(\"âš ï¸  ANTHROPIC_API_KEY not found in .env file\")\n",
    "    print(\"Please add: ANTHROPIC_API_KEY=your_key_here\")\n",
    "else:\n",
    "    llm = ChatAnthropic(\n",
    "        model=\"claude-haiku-4-5\",  # â† Updated model name\n",
    "        api_key=anthropic_key,\n",
    "        temperature=0.7,\n",
    "        max_tokens=8192,\n",
    "    )\n",
    "    print(\"âœ… Anthropic LSLM initialized with Claude Haiku 4.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6b3cea20",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3. PainExtractor Node Implementation\n",
    "\n",
    "# System prompt\n",
    "PAIN_EXTRACTOR_SYSTEM_PROMPT = \"\"\"\n",
    "You are a UX researcher and business analyst for BigKids Automation. Your job is listening to transcripts from interviews with users and potential clients. \n",
    "\n",
    "You pay special attention to problems that users have regarding how their company is automating, using web apps and AI to save time and move towards a more ethical and sovereign tech infrastructure.\n",
    "\n",
    "You will be given the transcript of an interview with a user or potential client.\n",
    "\n",
    "Your task is to extract structured information about:\n",
    "- Who is speaking and their role\n",
    "- What this person cares about (values, priorities)\n",
    "- Their main primary and secondary challenges\n",
    "- How they are solving problems today\n",
    "- Are there AI agents that can assist them?\n",
    "- Their underlying psychological needs (using frameworks like NVC - Non-Violent Communication)\n",
    "\n",
    "Focus on automation, web apps, AI, time-saving, ethical tech, and sovereign infrastructure themes.\n",
    "\n",
    "Be thorough but concise. \n",
    "\n",
    "IMPORTANT: Only extract information that is explicitly mentioned in the transcript. \n",
    "If information is not clearly stated, leave the field empty/null rather than guessing or inferring.\n",
    "Do not hallucinate or make assumptions about missing information.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4465cb3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ Company strategy document not found\n",
      "âœ… Loaded SEO strategy (1120 chars)\n",
      "âœ… Loaded content strategy (4473 chars)\n",
      "âœ… Enhanced strategy context for scoring with 3 documents\n",
      "   Company strategy: 40 chars\n",
      "   SEO strategy: 1120 chars\n",
      "   Content strategy: 4473 chars\n"
     ]
    }
   ],
   "source": [
    "# Cell 16: Enhanced Strategy Context for Scoring (Updated for 3 Documents)\n",
    "def prepare_strategy_context_for_scoring():\n",
    "    \"\"\"Prepare strategy context for scoring using all three strategy documents\"\"\"\n",
    "    \n",
    "    # Load all three strategy documents\n",
    "    strategy_context = load_company_strategy_context()\n",
    "    \n",
    "    # Add scoring guidelines\n",
    "    strategy_context[\"scoring_guidelines\"] = \"\"\"\n",
    "    SCORING CRITERIA (1-10 scale):\n",
    "    \n",
    "    1. usefulness_potential: How useful will this post be to readers with problems?\n",
    "    2. fitwith_seo_strategy: How well does this align with our SEO strategy and keywords?\n",
    "    3. fitwith_content_strategy: How well does this fit our content strategy and voice?\n",
    "    4. inspiration_potential: How likely is this to inspire readers to take action?\n",
    "    5. collaboration_potential: How likely is this to encourage prospects to contact us?\n",
    "    6. innovation: How unique/differentiated is this topic (10 = very unique)?\n",
    "    7. difficulty: How complex is this to write (1 = very complex, 10 = easy)?\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create summaries for LLM prompt efficiency (all three documents)\n",
    "    if strategy_context.get('company_strategy'):\n",
    "        strategy_context[\"company_strategy_summary\"] = strategy_context['company_strategy'][:800] + \"...\"\n",
    "    \n",
    "    if strategy_context.get('seo_strategy'):\n",
    "        strategy_context[\"seo_strategy_summary\"] = strategy_context['seo_strategy'][:600] + \"...\"\n",
    "    \n",
    "    if strategy_context.get('content_strategy'):  # NEW\n",
    "        strategy_context[\"content_strategy_summary\"] = strategy_context['content_strategy'][:600] + \"...\"\n",
    "    \n",
    "    print(f\"âœ… Enhanced strategy context for scoring with 3 documents\")\n",
    "    print(f\"   Company strategy: {len(strategy_context.get('company_strategy', ''))} chars\")\n",
    "    print(f\"   SEO strategy: {len(strategy_context.get('seo_strategy', ''))} chars\")\n",
    "    print(f\"   Content strategy: {len(strategy_context.get('content_strategy', ''))} chars\")\n",
    "    \n",
    "    return strategy_context\n",
    "\n",
    "# Test the enhanced context\n",
    "enhanced_context = prepare_strategy_context_for_scoring()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e7786fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§ª Testing three-document strategy loading...\n",
      "âš ï¸ Company strategy document not found\n",
      "âœ… Loaded SEO strategy (1120 chars)\n",
      "âœ… Loaded content strategy (4473 chars)\n",
      "âœ… Enhanced strategy context for scoring with 3 documents\n",
      "   Company strategy: 40 chars\n",
      "   SEO strategy: 1120 chars\n",
      "   Content strategy: 4473 chars\n",
      "\n",
      "ðŸ“Š DOCUMENT SUMMARY:\n",
      "   company_strategy: âš ï¸ Missing/Short (40 chars)\n",
      "   seo_strategy: âœ… Loaded (1120 chars)\n",
      "   content_strategy: âœ… Loaded (4473 chars)\n"
     ]
    }
   ],
   "source": [
    "# Cell: Fixed Test Function (No Duplicate Loading)\n",
    "def test_three_document_loading():\n",
    "    \"\"\"Test loading all three strategy documents (optimized)\"\"\"\n",
    "    \n",
    "    print(\"ðŸ§ª Testing three-document strategy loading...\")\n",
    "    \n",
    "    # Load documents once and enhance\n",
    "    enhanced = prepare_strategy_context_for_scoring()  # This calls load_company_strategy_context() internally\n",
    "    \n",
    "    print(f\"\\nðŸ“Š DOCUMENT SUMMARY:\")\n",
    "    for doc_type in ['company_strategy', 'seo_strategy', 'content_strategy']:\n",
    "        if doc_type in enhanced:\n",
    "            length = len(enhanced[doc_type]) if enhanced[doc_type] else 0\n",
    "            status = \"âœ… Loaded\" if length > 100 else \"âš ï¸ Missing/Short\"\n",
    "            print(f\"   {doc_type}: {status} ({length} chars)\")\n",
    "    \n",
    "    return enhanced\n",
    "\n",
    "# Test with no duplicates\n",
    "test_context = test_three_document_loading()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cda619a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Ready to test complete 9-node pipeline\n",
      "ðŸ’¡ Run the cell below to execute the test\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CELL 22: EXECUTE COMPLETE 9-NODE PIPELINE TEST (WITH HITL)\n",
    "# ============================================================\n",
    "\n",
    "import uuid  # For generating unique thread_ids\n",
    "\n",
    "def test_complete_9_node_pipeline():\n",
    "    \"\"\"Test the complete 8-node pipeline: Audio â†’ Transcribe â†’ Save â†’ Insights â†’ Ideas â†’ Scoring â†’ Save Ideas â†’ HITL â†’ Planning â†’ (Optional) Writing\"\"\"\n",
    "    print(\"ðŸ§ª EXECUTING COMPLETE 9-NODE PIPELINE TEST...\")\n",
    "    print(\"Audio â†’ Transcribe â†’ Save â†’ Insights â†’ Ideas â†’ Scoring â†’ Save Ideas â†’ HITL â†’ Planning â†’ (Optional) Writing\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    # Find audio files\n",
    "    audio_files = find_audio_files_in_temp()\n",
    "    if not audio_files:\n",
    "        print(\"âŒ No audio files found in data/temp/\")\n",
    "        print(\"ðŸ’¡ Add .wav files to data/temp/ and run this cell again\")\n",
    "        return None\n",
    "    print(f\"ðŸ“ Found {len(audio_files)} audio file(s)\")\n",
    "    print(f\"ðŸŽ¯ Testing with: {audio_files[0].name}\")\n",
    "    print(f\"ðŸ“Š File size: {audio_files[0].stat().st_size / 1024:.1f} KB\")\n",
    "    \n",
    "    # Create initial state for 8-node pipeline (extended from your 6-node version)\n",
    "    initial_state = {\n",
    "        \"file_path\": str(audio_files[0]),\n",
    "        \"filename\": audio_files[0].name,\n",
    "        \"transcript_text\": None,\n",
    "        \"conversation_id\": None,\n",
    "        \"extracted_insights\": None,\n",
    "        \"raw_blog_ideas\": None,\n",
    "        \"scored_blog_ideas\": None,\n",
    "        \"saved_idea_ids\": None,\n",
    "        \"selected_idea_id\": None,     # NEW: For HITL\n",
    "        \"selected_idea\": None,        # NEW: For HITL\n",
    "        \"strategy_context\": None,     # NEW: For planning\n",
    "        \"blog_plan\": None,            # NEW: For planning\n",
    "        \"blog_post\": None,            # NEW: For future writing (optional)\n",
    "        \"error\": None,\n",
    "        \"status\": \"processing\"\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        print(\"\\nðŸŽ¬ STARTING COMPLETE PIPELINE EXECUTION...\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # Generate unique thread_id for persistence\n",
    "        thread_id = str(uuid.uuid4())\n",
    "        config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "        \n",
    "        # Run the pipeline up to the interrupt (after Node 6)\n",
    "        print(\"ðŸƒ Running up to HITL interrupt...\")\n",
    "        pipeline.invoke(initial_state, config=config)\n",
    "        \n",
    "        # Simulate HITL: Get current state, prompt for selection, update, and resume\n",
    "        print(\"\\nðŸ¤ HITL SIMULATION: Paused for idea selection\")\n",
    "        current_state = pipeline.get_state(config).values\n",
    "        scored_ideas = current_state.get(\"scored_blog_ideas\", [])\n",
    "        saved_ids = current_state.get(\"saved_idea_ids\", [])\n",
    "        print(f\"   Available Ideas (Saved IDs): {saved_ids}\")\n",
    "        print(f\"   Scored Ideas Preview: {[idea.get('title', 'No title') for idea in scored_ideas]}\")\n",
    "        \n",
    "        # Prompt for human input (in dev; replace with UI/API in prod)\n",
    "        selected_id = int(input(\"Enter selected idea ID (from saved_ids): \"))  # Or hardcoded for auto-test: e.g., saved_ids[0]\n",
    "        selected_idea = next((idea for idea in scored_ideas if idea.get(\"id\") == selected_id), {})  # Adjust key if needed\n",
    "        \n",
    "        # Update state with selection\n",
    "        updated_state = current_state.copy()\n",
    "        updated_state[\"selected_idea_id\"] = selected_id\n",
    "        updated_state[\"selected_idea\"] = selected_idea\n",
    "        pipeline.update_state(config, updated_state)\n",
    "        print(f\"   âœ… HITL Complete: Selected Idea ID {selected_id}\")\n",
    "        \n",
    "        # Resume the pipeline (runs HITL node, planning, and optional writing)\n",
    "        print(\"ðŸƒ Resuming pipeline from HITL...\")\n",
    "        final_state = pipeline.invoke(None, config=config)  # None as input to resume\n",
    "        \n",
    "        print(f\"\\nðŸ“Š COMPLETE PIPELINE RESULTS:\")\n",
    "        print(\"=\" * 60)\n",
    "        print(f\"ðŸŽ¯ Final Status: {final_state.get('status')}\")\n",
    "        print(f\"ðŸ“ Conversation ID: {final_state.get('conversation_id')}\")\n",
    "        print(f\"ðŸ’¾ Saved Blog Idea IDs: {final_state.get('saved_idea_ids')}\")\n",
    "        \n",
    "        # Check all pipeline stages (extended for new nodes)\n",
    "        print(f\"\\nðŸ“‹ STAGE RESULTS:\")\n",
    "        stages = [\n",
    "            (\"ðŸŽ™ï¸  Transcription\", final_state.get('transcript_text')),\n",
    "            (\"ðŸ’¾ Database Save (Conversation)\", final_state.get('conversation_id')),\n",
    "            (\"ðŸ§  Insights Extraction\", final_state.get('extracted_insights')),\n",
    "            (\"ðŸŽ¨ Blog Ideas Generation\", final_state.get('raw_blog_ideas')),\n",
    "            (\"ðŸ” Blog Ideas Scoring\", final_state.get('scored_blog_ideas')),\n",
    "            (\"ðŸ’¾ Database Save (Ideas)\", final_state.get('saved_idea_ids')),\n",
    "            (\"ðŸ¤ HITL Idea Selection\", final_state.get('selected_idea_id') is not None),  \n",
    "            (\"ðŸ“ Planning\", final_state.get('blog_plan')),  \n",
    "            (\"âœï¸ Writing\", final_state.get('blog_post'))  \n",
    "        ]\n",
    "        all_passed = True\n",
    "        for stage_name, stage_data in stages:\n",
    "            status = \"âœ…\" if stage_data else \"âŒ\"\n",
    "            print(f\"   {stage_name}: {status}\")\n",
    "            if not stage_data:\n",
    "                all_passed = False\n",
    "        \n",
    "        # Show detailed results if all stages passed\n",
    "        if all_passed and final_state.get('scored_blog_ideas') and final_state.get('saved_idea_ids'):\n",
    "            scored_ideas = final_state['scored_blog_ideas']\n",
    "            saved_ids = final_state['saved_idea_ids']\n",
    "            print(f\"\\nðŸŽ‰ COMPLETE SUCCESS! Pipeline generated, scored, saved, selected, and planned {len(saved_ids)} blog ideas\")\n",
    "            print(\"=\" * 80)\n",
    "            \n",
    "            # Existing sections (conversation, insights, DB summary, top ideas) -- unchanged from your code\n",
    "            # (Insert your existing print blocks here for conversation details, insights summary, DB save summary, and top scored ideas)\n",
    "            \n",
    "            # NEW: Show HITL and planning results\n",
    "            print(f\"\\nðŸ¤ HITL Selection:\")\n",
    "            print(f\"   Selected Idea ID: {final_state.get('selected_idea_id')}\")\n",
    "            print(f\"   Selected Idea Title: {final_state.get('selected_idea', {}).get('title', 'N/A')}\")\n",
    "            \n",
    "            print(f\"\\nðŸ“ Generated Blog Plan:\")\n",
    "            blog_plan = final_state.get('blog_plan')\n",
    "            if blog_plan:\n",
    "                print(blog_plan.plan)  # Uses the @property from Plan\n",
    "                print(f\"   Q&A Pairs Count: {len(blog_plan.qa_pairs)}\")\n",
    "                print(f\"   Instructions Count: {len(blog_plan.instructions)}\")\n",
    "            else:\n",
    "                print(\"   No plan generated\")\n",
    "            \n",
    "            # NEW: If writing node is enabled\n",
    "            # blog_post = final_state.get('blog_post')\n",
    "            # if blog_post:\n",
    "            #     print(f\"\\nâœï¸ Generated Blog Post:\")\n",
    "            #     print(f\"   Title: {blog_post.get('title')}\")\n",
    "            #     print(f\"   Content Preview: {blog_post.get('content')[:200]}...\")\n",
    "            \n",
    "            print(\"=\" * 80)\n",
    "            print(\"ðŸŽ‰ COMPLETE 9-NODE PIPELINE: SUCCESS!\")\n",
    "            print(\"âœ… All stages completed successfully\")\n",
    "            print(f\"ðŸ’¾ Conversation saved (ID: {final_state.get('conversation_id')})\")\n",
    "            print(f\"ðŸ’¾ {len(saved_ids)} blog ideas saved to database\")\n",
    "            print(f\"ðŸ”— Ideas linked to conversation for traceability\")\n",
    "            \n",
    "            # Extended NEXT STEPS\n",
    "            print(f\"\\nðŸ’¡ NEXT STEPS:\")\n",
    "            print(f\"   â€¢ Query saved ideas: db.get_blog_post_ideas_by_conversation({final_state.get('conversation_id')})\")\n",
    "            print(f\"   â€¢ View conversation: db.get_conversation({final_state.get('conversation_id')})\")\n",
    "            print(f\"   â€¢ Access specific idea: db.get_blog_post_idea({saved_ids[0]})\")\n",
    "            print(f\"   â€¢ Review plan: Access final_state['blog_plan']\")\n",
    "        \n",
    "        else:\n",
    "            # Something failed (unchanged from your code)\n",
    "            print(\"\\nâŒ PIPELINE INCOMPLETE\")\n",
    "            print(\"=\" * 50)\n",
    "            if final_state.get('error'):\n",
    "                print(f\"âŒ Error: {final_state.get('error')}\")\n",
    "            else:\n",
    "                print(\"âŒ Pipeline stopped but no error message provided\")\n",
    "            # Extended DEBUG INFO\n",
    "            print(f\"\\nðŸ” DEBUG INFO:\")\n",
    "            print(f\"   Transcript exists: {bool(final_state.get('transcript_text'))}\")\n",
    "            if final_state.get('transcript_text'):\n",
    "                print(f\"   Transcript preview: {final_state.get('transcript_text')[:100]}...\")\n",
    "            print(f\"   Conversation ID: {final_state.get('conversation_id')}\")\n",
    "            print(f\"   Insights exist: {bool(final_state.get('extracted_insights'))}\")\n",
    "            print(f\"   Raw ideas exist: {bool(final_state.get('raw_blog_ideas'))}\")\n",
    "            if final_state.get('raw_blog_ideas'):\n",
    "                print(f\"   Raw ideas count: {len(final_state.get('raw_blog_ideas'))}\")\n",
    "            print(f\"   Scored ideas exist: {bool(final_state.get('scored_blog_ideas'))}\")\n",
    "            if final_state.get('scored_blog_ideas'):\n",
    "                print(f\"   Scored ideas count: {len(final_state.get('scored_blog_ideas'))}\")\n",
    "            print(f\"   Saved idea IDs exist: {bool(final_state.get('saved_idea_ids'))}\")\n",
    "            if final_state.get('saved_idea_ids'):\n",
    "                print(f\"   Saved ideas count: {len(final_state.get('saved_idea_ids'))}\")\n",
    "            # NEW: Debug for new fields\n",
    "            print(f\"   Selected Idea ID: {final_state.get('selected_idea_id')}\")\n",
    "            print(f\"   Blog Plan exists: {bool(final_state.get('blog_plan'))}\")\n",
    "            if final_state.get('blog_post'):\n",
    "                blog_post = final_state['blog_post']\n",
    "                print(f\"\\nâœï¸ Generated Blog Post:\")\n",
    "                print(f\"   Title: {blog_post.title}\")\n",
    "                print(f\"   Issue: {blog_post.issue}\")\n",
    "                print(f\"   Single Message: {blog_post.single_message}\")\n",
    "                print(f\"   Content Preview: {blog_post.content[:200]}...\")  # Truncate for brevity\n",
    "                print(f\"   Status: {blog_post.status}\")\n",
    "        \n",
    "        return final_state\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"\\nâŒ COMPLETE PIPELINE FAILED WITH EXCEPTION:\")\n",
    "        print(f\"   {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "# ============================================================\n",
    "# RUN THE TEST\n",
    "# ============================================================\n",
    "\n",
    "print(\"ðŸš€ Ready to test complete 9-node pipeline\")\n",
    "print(\"ðŸ’¡ Run the cell below to execute the test\\n\")\n",
    "\n",
    "# Uncomment the line below to run automatically, or run it manually\n",
    "# test_result = test_complete_8_node_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "61b3158d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§ª EXECUTING COMPLETE 9-NODE PIPELINE TEST...\n",
      "Audio â†’ Transcribe â†’ Save â†’ Insights â†’ Ideas â†’ Scoring â†’ Save Ideas â†’ HITL â†’ Planning â†’ (Optional) Writing\n",
      "------------------------------------------------------------\n",
      "ðŸ“ Found 1 audio file(s)\n",
      "ðŸŽ¯ Testing with: blog_record (2026-01-07 15_11_23).wav\n",
      "ðŸ“Š File size: 133727.3 KB\n",
      "\n",
      "ðŸŽ¬ STARTING COMPLETE PIPELINE EXECUTION...\n",
      "============================================================\n",
      "ðŸƒ Running up to HITL interrupt...\n",
      "ðŸŽ™ï¸ Transcribing: blog_record (2026-01-07 15_11_23).wav\n",
      "ðŸ’¾ Saving to database: blog_record (2026-01-07 15_11_23).wav\n",
      "ðŸ§  Starting pain extraction...\n",
      "ðŸ“ Raw response length: 6715 chars\n",
      "ðŸ“ Response starts with: ```json\n",
      "{\n",
      "    \"speakers\": [\n",
      "        {\n",
      "            ...\n",
      "ðŸ”§ Removing JSON markdown blocks...\n",
      "ðŸ”§ Cleaned content starts with: {\n",
      "    \"speakers\": [\n",
      "        {\n",
      "            \"name\": ...\n",
      "âœ… JSON parsed successfully\n",
      "âœ… Successfully extracted insights!\n",
      "   Speakers: 2\n",
      "   Challenges: 4\n",
      "   Needs: 7\n",
      "   Values: 7\n",
      "âœ… Extracted insights: 4 primary challenges, 2 speakers\n",
      "ðŸŽ¨ Starting creative blog idea generation...\n",
      "ðŸ“Š Working with insights: 4 challenges\n",
      "âš ï¸ Company strategy document not found\n",
      "âœ… Loaded SEO strategy (1120 chars)\n",
      "âœ… Loaded content strategy (4473 chars)\n",
      "ðŸ“ Raw response length: 4292 chars\n",
      "ðŸ“ Response starts with: ```json\n",
      "[\n",
      "    {\n",
      "        \"title\": \"Building Privacy...\n",
      "ðŸ”§ Removing markdown code blocks...\n",
      "ðŸ”§ Cleaned content starts with: [\n",
      "    {\n",
      "        \"title\": \"Building Privacy-First A...\n",
      "âœ… Creative agent successfully parsed 5 blog ideas\n",
      "ðŸŽ‰ Generated 5 valid blog ideas\n",
      "ðŸ” Starting analyst agent - scoring blog ideas...\n",
      "ðŸ“Š Input status: ideas_generated\n",
      "ðŸ“Š Found 5 blog ideas to score\n",
      "ðŸ“š Loading strategy context...\n",
      "âš ï¸ Company strategy document not found\n",
      "âœ… Loaded SEO strategy (1120 chars)\n",
      "âœ… Loaded content strategy (4473 chars)\n",
      "âœ… Enhanced strategy context for scoring with 3 documents\n",
      "   Company strategy: 40 chars\n",
      "   SEO strategy: 1120 chars\n",
      "   Content strategy: 4473 chars\n",
      "ðŸ” Scoring idea 1/5: Building Privacy-First Automation: How to Implemen...\n",
      "   âœ… Scored: 53/70 points\n",
      "ðŸ” Scoring idea 2/5: The Single Point of Failure Problem: Using AI Auto...\n",
      "   âœ… Scored: 49/70 points\n",
      "ðŸ” Scoring idea 3/5: Evaluating Data Storage Locations: A Compliance Ch...\n",
      "   âœ… Scored: 43/70 points\n",
      "ðŸ” Scoring idea 4/5: Reducing Tech Giant Dependency: A Roadmap for SMEs...\n",
      "   âœ… Scored: 45/70 points\n",
      "ðŸ” Scoring idea 5/5: Custom AI Solutions vs. SaaS Platforms: When to Bu...\n",
      "   âœ… Scored: 51/70 points\n",
      "\n",
      "ðŸŽ‰ Analyst agent completed scoring!\n",
      "ðŸ“Š Scored 5 ideas\n",
      "ðŸ† Top idea: 'Building Privacy-First Automation: How to Implemen...' (53/70)\n",
      "ðŸ“‰ Lowest idea: 'Evaluating Data Storage Locations: A Compliance Ch...' (43/70)\n",
      "ðŸ’¾ Starting database saver - saving scored blog ideas...\n",
      "ðŸ“Š Found 5 scored ideas to save\n",
      "ðŸ”— Linking ideas to conversation_id: 41\n",
      "   âœ… Saved idea 1: 'Building Privacy-First Automation: How to Implemen...' (ID: 68)\n",
      "   âœ… Saved idea 2: 'Custom AI Solutions vs. SaaS Platforms: When to Bu...' (ID: 69)\n",
      "   âœ… Saved idea 3: 'The Single Point of Failure Problem: Using AI Auto...' (ID: 70)\n",
      "   âœ… Saved idea 4: 'Reducing Tech Giant Dependency: A Roadmap for SMEs...' (ID: 71)\n",
      "   âœ… Saved idea 5: 'Evaluating Data Storage Locations: A Compliance Ch...' (ID: 72)\n",
      "\n",
      "ðŸŽ‰ Database saver completed!\n",
      "âœ… Successfully saved: 5 ideas\n",
      "\n",
      "ðŸ¤ HITL SIMULATION: Paused for idea selection\n",
      "   Available Ideas (Saved IDs): [68, 69, 70, 71, 72]\n",
      "   Scored Ideas Preview: ['Building Privacy-First Automation: How to Implement AI Without Compromising Data Security', 'Custom AI Solutions vs. SaaS Platforms: When to Build vs. Buy for Privacy-Critical Operations', 'The Single Point of Failure Problem: Using AI Automation to Distribute Technical Knowledge Across Your Team', 'Reducing Tech Giant Dependency: A Roadmap for SMEs to Build Independent Digital Infrastructure', 'Evaluating Data Storage Locations: A Compliance Checklist for GDPR-Compliant AI Implementation']\n",
      "   âœ… HITL Complete: Selected Idea ID 70\n",
      "ðŸƒ Resuming pipeline from HITL...\n",
      "HITL: Scored ideas: [{'title': 'Building Privacy-First Automation: How to Implement AI Without Compromising Data Security', 'description': 'A practical guide to implementing business automation and AI solutions while maintaining GDPR compliance and data privacy. Covers migrating away from surveillance-based platforms, evaluating privacy-compliant alternatives, and automating workflows without sacrificing ethical standards.', 'target_audience': 'Mission-driven organizations, NGOs, and SMEs handling sensitive data who need automation but refuse to compromise on privacy values', 'content_angle': 'Values-aligned automation strategy with step-by-step migration framework', 'business_value': 'Positions Big Kids Automation as the trusted partner for ethically-conscious businesses; captures growing market of privacy-focused organizations', 'usefulness_potential': 8, 'fitwith_seo_strategy': 6, 'fitwith_content_strategy': 9, 'inspiration_potential': 8, 'collaboration_potential': 9, 'innovation': 8, 'difficulty': 5, 'reasoning': \"Strong alignment with core content strategy (trust, transparency, comprehension) and mission to help SMEs understand GenAI thoughtfully. Excellent fit for values-aligned organizations like All4Climate. However, 'privacy-first automation' is somewhat tangential to primary SEO keywords (doesn't directly target AI/automation business value keywords). The angle is innovative and differentiatedâ€”few automation vendors address privacy-first implementation. High collaboration potential: privacy-conscious SMEs and mission-driven orgs are quality leads. Slightly higher difficulty due to need for GDPR/compliance accuracy. Consider strengthening SEO by connecting privacy benefits to business automation ROI and including long-tail keywords like 'AI implementation risks for SMEs' naturally.\", 'total_score': 53}, {'title': 'Custom AI Solutions vs. SaaS Platforms: When to Build vs. Buy for Privacy-Critical Operations', 'description': 'Compares the trade-offs between custom-built AI automation and SaaS solutions specifically for organizations with strict privacy requirements. Includes decision matrix, cost analysis, and guidance on when proprietary solutions justify the investment.', 'target_audience': 'Technical leaders and CFOs at organizations with sensitive data requirements evaluating automation investments', 'content_angle': 'Data-driven comparison with decision framework tailored to privacy-conscious buyers', 'business_value': 'Supports both custom solution sales and positions Big Kids as honest advisor; captures organizations in active evaluation phase', 'usefulness_potential': 8, 'fitwith_seo_strategy': 9, 'fitwith_content_strategy': 7, 'fitwith_content_strategy_reasoning': \"Addresses business value of GenAI and supports SME decision-making, but leans heavily toward 'buy' narrative (SaaS) rather than emphasizing understanding, trust, and transparency in tool relationships that define the core mission\", 'inspiration_potential': 6, 'collaboration_potential': 9, 'innovation': 7, 'difficulty': 5, 'overall_reasoning': \"Strong SEO and lead generation fit with a highly relevant long-tail keyword match ('custom AI solutions vs SaaS platforms'). Targets high-value decision-makers (CFOs/technical leaders) in active evaluation phase. However, the content angle risks positioning Big Kids as a vendor advisor rather than a curious, educational partner focused on comprehension and trust. The privacy-critical angle is timely and differentiating. Execution requires solid research and decision frameworks but is achievable. Recommend reframing to emphasize how organizations can *understand and evaluate* their options with transparency rather than positioning as a sales enablement piece.\", 'recommendation': \"PROCEED WITH ANGLE ADJUSTMENT - Reframe from 'when to build vs buy' sales comparison to 'how to evaluate AI solutions with confidence: understanding privacy, costs, and technical implications' to better align with the mission of building trust through comprehension.\", 'total_score': 51}, {'title': 'The Single Point of Failure Problem: Using AI Automation to Distribute Technical Knowledge Across Your Team', 'description': 'Explores how organizations can use workflow automation, documentation systems, and AI tools to democratize technical knowledge and reduce dependency on individual experts. Includes frameworks for knowledge transfer and automation that builds organizational resilience.', 'target_audience': 'Operations managers and leaders at lean organizations where one person holds critical technical responsibilities', 'content_angle': 'Organizational resilience through strategic automation and knowledge distribution', 'business_value': 'Addresses urgent pain point for resource-constrained organizations; demonstrates how automation creates business continuity, not just efficiency', 'usefulness_potential': 8, 'fitwith_seo_strategy': 6, 'fitwith_content_strategy': 9, 'inspiration_potential': 8, 'collaboration_potential': 8, 'difficulty': 5, 'reasoning': \"Strong alignment with content strategy's core mission around trust, transparency, and organizational comprehension of tech tools. Directly addresses SME pain points and demonstrates GenAI's transformative potential beyond efficiency metrics. The 'single point of failure' framing is emotionally resonant and actionable. However, SEO fit is moderateâ€”the title targets a specific pain point rather than high-intent keywords like 'business automation' or 'AI implementation.' Consider incorporating long-tail keywords (e.g., 'AI knowledge management for small teams') to improve search visibility. The topic requires substantial research on knowledge transfer frameworks and real case studies, adding complexity. Excellent lead generation potential for operations-focused prospects facing resource constraints.\", 'total_score': 49}, {'title': 'Reducing Tech Giant Dependency: A Roadmap for SMEs to Build Independent Digital Infrastructure', 'description': \"Strategic guide for organizations ready to reduce reliance on Facebook, Google, and other surveillance-based platforms. Covers alternative tools for communication, automation, and visibility, plus a phased implementation roadmap that doesn't require abandoning reach or efficiency.\", 'target_audience': 'Founders and leaders of values-driven SMEs, nonprofits, and activist organizations frustrated with platform dependency', 'content_angle': 'Practical independence strategy with realistic alternatives and implementation timeline', 'business_value': 'Attracts mission-driven businesses actively seeking to align tech choices with values; positions Big Kids as enabler of ethical independence', 'usefulness_potential': 7, 'fitwith_seo_strategy': 4, 'fitwith_content_strategy': 6, 'inspiration_potential': 8, 'collaboration_potential': 7, 'innovation': 8, 'difficulty': 5, 'reasoning': \"This idea has strong inspirational and innovation potential, particularly for values-driven SMEs like All4Climate. However, it significantly diverges from Big Kids Automation's core SEO strategy, which focuses on GenAI, business automation, and digital transformation keywords. The post targets platform independence rather than automation efficiency or GenAI implementation. While it aligns with the transparency/trust mission, it doesn't advance the GenAI business value positioning or address how SMEs can 'deliver better services with digital automation.' The audience overlap exists (mission-driven SMEs) but the content angle shifts focus away from automation solutions toward platform avoidance. Best suited as a thought leadership/brand-building piece rather than a lead-generation SEO asset. Consider repositioning to: 'Building Transparent Automation Stacks: How SMEs Can Choose Ethical GenAI Tools Over Surveillance Platforms' to better bridge both strategies.\", 'total_score': 45}, {'title': 'Evaluating Data Storage Locations: A Compliance Checklist for GDPR-Compliant AI Implementation', 'description': 'A detailed checklist and decision framework for vetting where your data actually lives when using AI and automation platforms. Covers red flags in vendor claims, how to verify server locations, and questions to ask before trusting any tech provider with sensitive information.', 'target_audience': 'Compliance officers, data protection leads, and decision-makers at organizations handling EU citizen data or operating under GDPR', 'content_angle': 'Practical due diligence guide with transparency-focused vendor evaluation framework', 'business_value': 'Establishes Big Kids Automation as transparent and compliance-focused; captures organizations actively auditing their tech stack', 'usefulness_potential': 8, 'fitwith_seo_strategy': 5, 'fitwith_content_strategy': 7, 'inspiration_potential': 6, 'collaboration_potential': 7, 'innovation': 6, 'difficulty': 4, 'reasoning': \"This post scores moderately well but has notable gaps. USEFULNESS is strongâ€”compliance officers face real pain points around data governance. FIT WITH SEO STRATEGY is weak (5): the topic doesn't align with your core keywords (AI benefits, automation implementation, GenAI tools). It's compliance-focused rather than business-value-focused, missing your long-tail keywords about SME efficiency and AI implementation. FIT WITH CONTENT STRATEGY is decent (7): it supports 'trust and transparency' messaging, but doesn't advance the core mission of helping SMEs understand GenAI's business potential or deliver better services. INSPIRATION POTENTIAL is moderate (6)â€”it's defensive/risk-mitigation content rather than aspirational. COLLABORATION POTENTIAL is solid (7)â€”compliance officers are decision-makers who contact vendors. INNOVATION is average (6)â€”compliance checklists exist; your angle adds some differentiation but isn't groundbreaking. DIFFICULTY is low (4)â€”straightforward checklist format. RECOMMENDATION: Consider repositioning this as 'How to Evaluate AI Vendors for Trust & Transparency' to connect compliance rigor to your core business value proposition, or shelve it in favor of content that drives SMEs toward GenAI adoption.\", 'total_score': 43}]\n",
      "Saved idea IDs: [68, 69, 70, 71, 72]\n",
      "âš ï¸ Company strategy document not found\n",
      "âœ… Loaded SEO strategy (1120 chars)\n",
      "âœ… Loaded content strategy (4473 chars)\n",
      "\n",
      "ðŸ“Š COMPLETE PIPELINE RESULTS:\n",
      "============================================================\n",
      "ðŸŽ¯ Final Status: ideas_saved_to_db\n",
      "ðŸ“ Conversation ID: 41\n",
      "ðŸ’¾ Saved Blog Idea IDs: [68, 69, 70, 71, 72]\n",
      "\n",
      "ðŸ“‹ STAGE RESULTS:\n",
      "   ðŸŽ™ï¸  Transcription: âœ…\n",
      "   ðŸ’¾ Database Save (Conversation): âœ…\n",
      "   ðŸ§  Insights Extraction: âœ…\n",
      "   ðŸŽ¨ Blog Ideas Generation: âœ…\n",
      "   ðŸ” Blog Ideas Scoring: âœ…\n",
      "   ðŸ’¾ Database Save (Ideas): âœ…\n",
      "   ðŸ¤ HITL Idea Selection: âœ…\n",
      "   ðŸ“ Planning: âœ…\n",
      "   âœï¸ Writing: âœ…\n",
      "\n",
      "ðŸŽ‰ COMPLETE SUCCESS! Pipeline generated, scored, saved, selected, and planned 5 blog ideas\n",
      "================================================================================\n",
      "\n",
      "ðŸ¤ HITL Selection:\n",
      "   Selected Idea ID: 70\n",
      "   Selected Idea Title: N/A\n",
      "\n",
      "ðŸ“ Generated Blog Plan:\n",
      "Who: SME owners and managers, particularly those running mission-driven organizations (like NGOs and activist groups) who are frustrated with their current tech stack, concerned about data privacy and GDPR compliance, and seeking alternatives to Big Tech solutions. Specifically, decision-makers who feel trapped between operational necessity and ethical values.\n",
      "Why: To demonstrate how automation and GenAI can help mission-driven SMEs reduce dependency on untrustworthy tech giants, improve data privacy compliance, and free up their limited technical resources to focus on their core mission. This positions Big Kids Automation Agency as a trusted partner that understands the unique challenges of values-aligned organizations seeking sustainable, ethical tech infrastructure.\n",
      "What: 1) The data privacy crisis facing SMEs relying on Big Tech platforms (Google Suite, Facebook, etc.)\n",
      "2) GDPR compliance challenges and risks for organizations handling sensitive stakeholder data\n",
      "3) How custom automation solutions can replace dependency on SaaS giants with privacy-aligned alternatives\n",
      "4) Practical strategies for distributing technical knowledge to reduce single-points-of-failure in small teams\n",
      "5) Real-world case studies of mission-driven organizations successfully transitioning to ethical tech stacks\n",
      "6) The organizational and technical considerations when moving from Big Tech to custom solutions\n",
      "Issue: Mission-driven SMEs (NGOs, activist groups, social enterprises) face an impossible choice: use Big Tech platforms that compromise their values and expose stakeholder data to privacy risks, or struggle with limited alternatives that lack reach and visibility. They lack the technical expertise and financial resources to build sustainable, GDPR-compliant, values-aligned technology infrastructure. Single individuals often become bottlenecks, creating organizational fragility.\n",
      "Where We Stand: Many SMEs are trapped in a cycle of dissatisfaction: they're using Google Suite, Open Collective, and social media platforms they don't trust because they see no viable alternatives. They recognize the data privacy risks and GDPR exposure but feel powerless to change without significant investment. Technical knowledge is concentrated in one person, making the organization vulnerable. There's a hunger for change but uncertainty about how to execute it.\n",
      "Single Message: Mission-driven SMEs can break free from Big Tech dependency through thoughtful automation and custom solutionsâ€”building ethical, GDPR-compliant tech infrastructure that protects stakeholder data while freeing up limited resources to focus on what matters: their mission.\n",
      "\n",
      "Q&A Pairs:\n",
      "Q: What are the main data privacy risks SMEs face when using Big Tech platforms? A: Organizations using Google Suite, Facebook, and similar platforms expose sensitive stakeholder data (donor information, activist identities, financial records) to unauthorized access, data mining, and potential GDPR violations. Data storage locations may not meet compliance standards, and terms of service allow data sharing without explicit consent.\n",
      "Q: Why is GDPR compliance critical for mission-driven organizations? A: Mission-driven SMEs often manage sensitive personal data of vulnerable populations (activists, donors, community members). GDPR violations carry significant legal and financial penalties, damage organizational trust, and undermine the values these organizations stand for. Compliance is both a legal requirement and an ethical imperative.\n",
      "Q: What's the cost of having a single technical person managing all IT infrastructure? A: Single-person technical bottlenecks create organizational fragility: if that person becomes unavailable, the entire organization loses capacity to manage data, platforms, and operations. This limits resilience, scalability, and the organization's ability to pursue its mission effectively.\n",
      "Q: How can automation help SMEs reduce dependency on Big Tech? A: Custom automation solutions can replace Big Tech services with privacy-aligned alternatives: automating document management instead of Google Drive, building custom data workflows instead of relying on proprietary platforms, and creating self-hosted infrastructure that keeps data under organizational control.\n",
      "Q: What's the first step for SMEs wanting to transition away from Big Tech? A: Start by mapping your current tech stack, identifying which tools handle sensitive data, and prioritizing GDPR compliance gaps. Then audit which processes could be automated or replaced with privacy-aligned solutions. Focus on high-impact, manageable changes rather than attempting a complete overhaul.\n",
      "Q: How can small teams distribute technical knowledge to reduce dependency on one person? A: Implement documentation practices, create simple automation workflows that non-technical team members can understand and modify, use no-code/low-code tools where appropriate, and establish regular knowledge-sharing sessions. The goal is building organizational capacity, not making everyone a developer.\n",
      "Q: What's the relationship between automation and organizational values alignment? A: When SMEs build their own tools or use values-aligned platforms, their technology choices reinforce their mission. This creates authentic alignment between how they operate and what they believe in, building trust with stakeholders and reducing the cognitive dissonance of using platforms they don't trust.\n",
      "Q: Can mission-driven SMEs afford custom automation solutions? A: Custom solutions don't require massive investment upfront. Starting with high-impact, manageable automation projects yields ROI through freed-up time and reduced operational friction. As organizations mature, they can progressively build more sophisticated infrastructure.\n",
      "Instructions:\n",
      "Keep the tone enthusiastic but preciseâ€”avoid filler words; every sentence must deliver value. This is a one-person agency with legal training; precision matters.\n",
      "Stay focused on the business value: how automation and GenAI free up time for SMEs to focus on their mission, not on technical details.\n",
      "Incorporate long-tail SEO keywords naturally: 'GDPR-compliant automation for SMEs', 'privacy-aligned tech alternatives', 'custom AI solutions vs SaaS platforms', 'business process automation for small companies', 'AI implementation risks for mission-driven organizations'.\n",
      "Use the All4Climate interview as a grounding example but generalize insights to apply to broader mission-driven SME audience (NGOs, social enterprises, activist groups).\n",
      "Emphasize the agency's unique positioning: software-agnostic, values-aligned, encouraging SMEs to build capacity and move from SaaS dependency to custom solutions.\n",
      "Address both technical and organizational considerations: data privacy, GDPR compliance, knowledge distribution, organizational resilience.\n",
      "Highlight the emotional/psychological needs: security, autonomy, control, trust, relief from frustration, resilience, values alignment.\n",
      "Include practical takeaways: what SMEs can do immediately vs. longer-term infrastructure changes.\n",
      "Avoid promoting specific platforms or brands; focus on principles and approaches.\n",
      "Break established patternsâ€”challenge the assumption that Big Tech is inevitable or that custom solutions are unaffordable for SMEs.\n",
      "Include a reflection on ethics and the cost of convenience (choosing Big Tech over values alignment).\n",
      "   Q&A Pairs Count: 8\n",
      "   Instructions Count: 11\n",
      "================================================================================\n",
      "ðŸŽ‰ COMPLETE 9-NODE PIPELINE: SUCCESS!\n",
      "âœ… All stages completed successfully\n",
      "ðŸ’¾ Conversation saved (ID: 41)\n",
      "ðŸ’¾ 5 blog ideas saved to database\n",
      "ðŸ”— Ideas linked to conversation for traceability\n",
      "\n",
      "ðŸ’¡ NEXT STEPS:\n",
      "   â€¢ Query saved ideas: db.get_blog_post_ideas_by_conversation(41)\n",
      "   â€¢ View conversation: db.get_conversation(41)\n",
      "   â€¢ Access specific idea: db.get_blog_post_idea(68)\n",
      "   â€¢ Review plan: Access final_state['blog_plan']\n"
     ]
    }
   ],
   "source": [
    "# Uncomment the line below to run automatically, or run it manually\n",
    "test_result = test_complete_9_node_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "754fc718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formatted Blog Plan:\n",
      "\n",
      "Who: SME owners and managers, particularly those running mission-driven organizations (like NGOs and activist groups) who are frustrated with their current tech stack, concerned about data privacy and GDPR compliance, and seeking alternatives to Big Tech solutions. Specifically, decision-makers who feel trapped between operational necessity and ethical values.\n",
      "Why: To demonstrate how automation and GenAI can help mission-driven SMEs reduce dependency on untrustworthy tech giants, improve data privacy compliance, and free up their limited technical resources to focus on their core mission. This positions Big Kids Automation Agency as a trusted partner that understands the unique challenges of values-aligned organizations seeking sustainable, ethical tech infrastructure.\n",
      "What: 1) The data privacy crisis facing SMEs relying on Big Tech platforms (Google Suite, Facebook, etc.)\n",
      "2) GDPR compliance challenges and risks for organizations handling sensitive stakeholder data\n",
      "3) How custom automation solutions can replace dependency on SaaS giants with privacy-aligned alternatives\n",
      "4) Practical strategies for distributing technical knowledge to reduce single-points-of-failure in small teams\n",
      "5) Real-world case studies of mission-driven organizations successfully transitioning to ethical tech stacks\n",
      "6) The organizational and technical considerations when moving from Big Tech to custom solutions\n",
      "Issue: Mission-driven SMEs (NGOs, activist groups, social enterprises) face an impossible choice: use Big Tech platforms that compromise their values and expose stakeholder data to privacy risks, or struggle with limited alternatives that lack reach and visibility. They lack the technical expertise and financial resources to build sustainable, GDPR-compliant, values-aligned technology infrastructure. Single individuals often become bottlenecks, creating organizational fragility.\n",
      "Where We Stand: Many SMEs are trapped in a cycle of dissatisfaction: they're using Google Suite, Open Collective, and social media platforms they don't trust because they see no viable alternatives. They recognize the data privacy risks and GDPR exposure but feel powerless to change without significant investment. Technical knowledge is concentrated in one person, making the organization vulnerable. There's a hunger for change but uncertainty about how to execute it.\n",
      "Single Message: Mission-driven SMEs can break free from Big Tech dependency through thoughtful automation and custom solutionsâ€”building ethical, GDPR-compliant tech infrastructure that protects stakeholder data while freeing up limited resources to focus on what matters: their mission.\n",
      "\n",
      "Q&A Pairs:\n",
      "Q: What are the main data privacy risks SMEs face when using Big Tech platforms? A: Organizations using Google Suite, Facebook, and similar platforms expose sensitive stakeholder data (donor information, activist identities, financial records) to unauthorized access, data mining, and potential GDPR violations. Data storage locations may not meet compliance standards, and terms of service allow data sharing without explicit consent.\n",
      "Q: Why is GDPR compliance critical for mission-driven organizations? A: Mission-driven SMEs often manage sensitive personal data of vulnerable populations (activists, donors, community members). GDPR violations carry significant legal and financial penalties, damage organizational trust, and undermine the values these organizations stand for. Compliance is both a legal requirement and an ethical imperative.\n",
      "Q: What's the cost of having a single technical person managing all IT infrastructure? A: Single-person technical bottlenecks create organizational fragility: if that person becomes unavailable, the entire organization loses capacity to manage data, platforms, and operations. This limits resilience, scalability, and the organization's ability to pursue its mission effectively.\n",
      "Q: How can automation help SMEs reduce dependency on Big Tech? A: Custom automation solutions can replace Big Tech services with privacy-aligned alternatives: automating document management instead of Google Drive, building custom data workflows instead of relying on proprietary platforms, and creating self-hosted infrastructure that keeps data under organizational control.\n",
      "Q: What's the first step for SMEs wanting to transition away from Big Tech? A: Start by mapping your current tech stack, identifying which tools handle sensitive data, and prioritizing GDPR compliance gaps. Then audit which processes could be automated or replaced with privacy-aligned solutions. Focus on high-impact, manageable changes rather than attempting a complete overhaul.\n",
      "Q: How can small teams distribute technical knowledge to reduce dependency on one person? A: Implement documentation practices, create simple automation workflows that non-technical team members can understand and modify, use no-code/low-code tools where appropriate, and establish regular knowledge-sharing sessions. The goal is building organizational capacity, not making everyone a developer.\n",
      "Q: What's the relationship between automation and organizational values alignment? A: When SMEs build their own tools or use values-aligned platforms, their technology choices reinforce their mission. This creates authentic alignment between how they operate and what they believe in, building trust with stakeholders and reducing the cognitive dissonance of using platforms they don't trust.\n",
      "Q: Can mission-driven SMEs afford custom automation solutions? A: Custom solutions don't require massive investment upfront. Starting with high-impact, manageable automation projects yields ROI through freed-up time and reduced operational friction. As organizations mature, they can progressively build more sophisticated infrastructure.\n",
      "Instructions:\n",
      "Keep the tone enthusiastic but preciseâ€”avoid filler words; every sentence must deliver value. This is a one-person agency with legal training; precision matters.\n",
      "Stay focused on the business value: how automation and GenAI free up time for SMEs to focus on their mission, not on technical details.\n",
      "Incorporate long-tail SEO keywords naturally: 'GDPR-compliant automation for SMEs', 'privacy-aligned tech alternatives', 'custom AI solutions vs SaaS platforms', 'business process automation for small companies', 'AI implementation risks for mission-driven organizations'.\n",
      "Use the All4Climate interview as a grounding example but generalize insights to apply to broader mission-driven SME audience (NGOs, social enterprises, activist groups).\n",
      "Emphasize the agency's unique positioning: software-agnostic, values-aligned, encouraging SMEs to build capacity and move from SaaS dependency to custom solutions.\n",
      "Address both technical and organizational considerations: data privacy, GDPR compliance, knowledge distribution, organizational resilience.\n",
      "Highlight the emotional/psychological needs: security, autonomy, control, trust, relief from frustration, resilience, values alignment.\n",
      "Include practical takeaways: what SMEs can do immediately vs. longer-term infrastructure changes.\n",
      "Avoid promoting specific platforms or brands; focus on principles and approaches.\n",
      "Break established patternsâ€”challenge the assumption that Big Tech is inevitable or that custom solutions are unaffordable for SMEs.\n",
      "Include a reflection on ethics and the cost of convenience (choosing Big Tech over values alignment).\n",
      "\n",
      "Individual Fields:\n",
      "Who: SME owners and managers, particularly those running mission-driven organizations (like NGOs and activist groups) who are frustrated with their current tech stack, concerned about data privacy and GDPR compliance, and seeking alternatives to Big Tech solutions. Specifically, decision-makers who feel trapped between operational necessity and ethical values.\n",
      "Why: To demonstrate how automation and GenAI can help mission-driven SMEs reduce dependency on untrustworthy tech giants, improve data privacy compliance, and free up their limited technical resources to focus on their core mission. This positions Big Kids Automation Agency as a trusted partner that understands the unique challenges of values-aligned organizations seeking sustainable, ethical tech infrastructure.\n",
      "What: 1) The data privacy crisis facing SMEs relying on Big Tech platforms (Google Suite, Facebook, etc.)\n",
      "2) GDPR compliance challenges and risks for organizations handling sensitive stakeholder data\n",
      "3) How custom automation solutions can replace dependency on SaaS giants with privacy-aligned alternatives\n",
      "4) Practical strategies for distributing technical knowledge to reduce single-points-of-failure in small teams\n",
      "5) Real-world case studies of mission-driven organizations successfully transitioning to ethical tech stacks\n",
      "6) The organizational and technical considerations when moving from Big Tech to custom solutions\n",
      "The Issue: Mission-driven SMEs (NGOs, activist groups, social enterprises) face an impossible choice: use Big Tech platforms that compromise their values and expose stakeholder data to privacy risks, or struggle with limited alternatives that lack reach and visibility. They lack the technical expertise and financial resources to build sustainable, GDPR-compliant, values-aligned technology infrastructure. Single individuals often become bottlenecks, creating organizational fragility.\n",
      "Where We Stand: Many SMEs are trapped in a cycle of dissatisfaction: they're using Google Suite, Open Collective, and social media platforms they don't trust because they see no viable alternatives. They recognize the data privacy risks and GDPR exposure but feel powerless to change without significant investment. Technical knowledge is concentrated in one person, making the organization vulnerable. There's a hunger for change but uncertainty about how to execute it.\n",
      "Single Message: Mission-driven SMEs can break free from Big Tech dependency through thoughtful automation and custom solutionsâ€”building ethical, GDPR-compliant tech infrastructure that protects stakeholder data while freeing up limited resources to focus on what matters: their mission.\n",
      "\n",
      "Q&A Pairs:\n",
      "  Q: What are the main data privacy risks SMEs face when using Big Tech platforms?  A: Organizations using Google Suite, Facebook, and similar platforms expose sensitive stakeholder data (donor information, activist identities, financial records) to unauthorized access, data mining, and potential GDPR violations. Data storage locations may not meet compliance standards, and terms of service allow data sharing without explicit consent.\n",
      "  Q: Why is GDPR compliance critical for mission-driven organizations?  A: Mission-driven SMEs often manage sensitive personal data of vulnerable populations (activists, donors, community members). GDPR violations carry significant legal and financial penalties, damage organizational trust, and undermine the values these organizations stand for. Compliance is both a legal requirement and an ethical imperative.\n",
      "  Q: What's the cost of having a single technical person managing all IT infrastructure?  A: Single-person technical bottlenecks create organizational fragility: if that person becomes unavailable, the entire organization loses capacity to manage data, platforms, and operations. This limits resilience, scalability, and the organization's ability to pursue its mission effectively.\n",
      "  Q: How can automation help SMEs reduce dependency on Big Tech?  A: Custom automation solutions can replace Big Tech services with privacy-aligned alternatives: automating document management instead of Google Drive, building custom data workflows instead of relying on proprietary platforms, and creating self-hosted infrastructure that keeps data under organizational control.\n",
      "  Q: What's the first step for SMEs wanting to transition away from Big Tech?  A: Start by mapping your current tech stack, identifying which tools handle sensitive data, and prioritizing GDPR compliance gaps. Then audit which processes could be automated or replaced with privacy-aligned solutions. Focus on high-impact, manageable changes rather than attempting a complete overhaul.\n",
      "  Q: How can small teams distribute technical knowledge to reduce dependency on one person?  A: Implement documentation practices, create simple automation workflows that non-technical team members can understand and modify, use no-code/low-code tools where appropriate, and establish regular knowledge-sharing sessions. The goal is building organizational capacity, not making everyone a developer.\n",
      "  Q: What's the relationship between automation and organizational values alignment?  A: When SMEs build their own tools or use values-aligned platforms, their technology choices reinforce their mission. This creates authentic alignment between how they operate and what they believe in, building trust with stakeholders and reducing the cognitive dissonance of using platforms they don't trust.\n",
      "  Q: Can mission-driven SMEs afford custom automation solutions?  A: Custom solutions don't require massive investment upfront. Starting with high-impact, manageable automation projects yields ROI through freed-up time and reduced operational friction. As organizations mature, they can progressively build more sophisticated infrastructure.\n",
      "\n",
      "Instructions:\n",
      "  - Keep the tone enthusiastic but preciseâ€”avoid filler words; every sentence must deliver value. This is a one-person agency with legal training; precision matters.\n",
      "  - Stay focused on the business value: how automation and GenAI free up time for SMEs to focus on their mission, not on technical details.\n",
      "  - Incorporate long-tail SEO keywords naturally: 'GDPR-compliant automation for SMEs', 'privacy-aligned tech alternatives', 'custom AI solutions vs SaaS platforms', 'business process automation for small companies', 'AI implementation risks for mission-driven organizations'.\n",
      "  - Use the All4Climate interview as a grounding example but generalize insights to apply to broader mission-driven SME audience (NGOs, social enterprises, activist groups).\n",
      "  - Emphasize the agency's unique positioning: software-agnostic, values-aligned, encouraging SMEs to build capacity and move from SaaS dependency to custom solutions.\n",
      "  - Address both technical and organizational considerations: data privacy, GDPR compliance, knowledge distribution, organizational resilience.\n",
      "  - Highlight the emotional/psychological needs: security, autonomy, control, trust, relief from frustration, resilience, values alignment.\n",
      "  - Include practical takeaways: what SMEs can do immediately vs. longer-term infrastructure changes.\n",
      "  - Avoid promoting specific platforms or brands; focus on principles and approaches.\n",
      "  - Break established patternsâ€”challenge the assumption that Big Tech is inevitable or that custom solutions are unaffordable for SMEs.\n",
      "  - Include a reflection on ethics and the cost of convenience (choosing Big Tech over values alignment).\n",
      "\n",
      "Plan as Dict:\n",
      "{'who': 'SME owners and managers, particularly those running mission-driven organizations (like NGOs and activist groups) who are frustrated with their current tech stack, concerned about data privacy and GDPR compliance, and seeking alternatives to Big Tech solutions. Specifically, decision-makers who feel trapped between operational necessity and ethical values.', 'why': 'To demonstrate how automation and GenAI can help mission-driven SMEs reduce dependency on untrustworthy tech giants, improve data privacy compliance, and free up their limited technical resources to focus on their core mission. This positions Big Kids Automation Agency as a trusted partner that understands the unique challenges of values-aligned organizations seeking sustainable, ethical tech infrastructure.', 'what': '1) The data privacy crisis facing SMEs relying on Big Tech platforms (Google Suite, Facebook, etc.)\\n2) GDPR compliance challenges and risks for organizations handling sensitive stakeholder data\\n3) How custom automation solutions can replace dependency on SaaS giants with privacy-aligned alternatives\\n4) Practical strategies for distributing technical knowledge to reduce single-points-of-failure in small teams\\n5) Real-world case studies of mission-driven organizations successfully transitioning to ethical tech stacks\\n6) The organizational and technical considerations when moving from Big Tech to custom solutions', 'the_issue': 'Mission-driven SMEs (NGOs, activist groups, social enterprises) face an impossible choice: use Big Tech platforms that compromise their values and expose stakeholder data to privacy risks, or struggle with limited alternatives that lack reach and visibility. They lack the technical expertise and financial resources to build sustainable, GDPR-compliant, values-aligned technology infrastructure. Single individuals often become bottlenecks, creating organizational fragility.', 'where_we_stand': \"Many SMEs are trapped in a cycle of dissatisfaction: they're using Google Suite, Open Collective, and social media platforms they don't trust because they see no viable alternatives. They recognize the data privacy risks and GDPR exposure but feel powerless to change without significant investment. Technical knowledge is concentrated in one person, making the organization vulnerable. There's a hunger for change but uncertainty about how to execute it.\", 'single_message': 'Mission-driven SMEs can break free from Big Tech dependency through thoughtful automation and custom solutionsâ€”building ethical, GDPR-compliant tech infrastructure that protects stakeholder data while freeing up limited resources to focus on what matters: their mission.', 'qa_pairs': [{'question': 'What are the main data privacy risks SMEs face when using Big Tech platforms?', 'answer': 'Organizations using Google Suite, Facebook, and similar platforms expose sensitive stakeholder data (donor information, activist identities, financial records) to unauthorized access, data mining, and potential GDPR violations. Data storage locations may not meet compliance standards, and terms of service allow data sharing without explicit consent.'}, {'question': 'Why is GDPR compliance critical for mission-driven organizations?', 'answer': 'Mission-driven SMEs often manage sensitive personal data of vulnerable populations (activists, donors, community members). GDPR violations carry significant legal and financial penalties, damage organizational trust, and undermine the values these organizations stand for. Compliance is both a legal requirement and an ethical imperative.'}, {'question': \"What's the cost of having a single technical person managing all IT infrastructure?\", 'answer': \"Single-person technical bottlenecks create organizational fragility: if that person becomes unavailable, the entire organization loses capacity to manage data, platforms, and operations. This limits resilience, scalability, and the organization's ability to pursue its mission effectively.\"}, {'question': 'How can automation help SMEs reduce dependency on Big Tech?', 'answer': 'Custom automation solutions can replace Big Tech services with privacy-aligned alternatives: automating document management instead of Google Drive, building custom data workflows instead of relying on proprietary platforms, and creating self-hosted infrastructure that keeps data under organizational control.'}, {'question': \"What's the first step for SMEs wanting to transition away from Big Tech?\", 'answer': 'Start by mapping your current tech stack, identifying which tools handle sensitive data, and prioritizing GDPR compliance gaps. Then audit which processes could be automated or replaced with privacy-aligned solutions. Focus on high-impact, manageable changes rather than attempting a complete overhaul.'}, {'question': 'How can small teams distribute technical knowledge to reduce dependency on one person?', 'answer': 'Implement documentation practices, create simple automation workflows that non-technical team members can understand and modify, use no-code/low-code tools where appropriate, and establish regular knowledge-sharing sessions. The goal is building organizational capacity, not making everyone a developer.'}, {'question': \"What's the relationship between automation and organizational values alignment?\", 'answer': \"When SMEs build their own tools or use values-aligned platforms, their technology choices reinforce their mission. This creates authentic alignment between how they operate and what they believe in, building trust with stakeholders and reducing the cognitive dissonance of using platforms they don't trust.\"}, {'question': 'Can mission-driven SMEs afford custom automation solutions?', 'answer': \"Custom solutions don't require massive investment upfront. Starting with high-impact, manageable automation projects yields ROI through freed-up time and reduced operational friction. As organizations mature, they can progressively build more sophisticated infrastructure.\"}], 'instructions': ['Keep the tone enthusiastic but preciseâ€”avoid filler words; every sentence must deliver value. This is a one-person agency with legal training; precision matters.', 'Stay focused on the business value: how automation and GenAI free up time for SMEs to focus on their mission, not on technical details.', \"Incorporate long-tail SEO keywords naturally: 'GDPR-compliant automation for SMEs', 'privacy-aligned tech alternatives', 'custom AI solutions vs SaaS platforms', 'business process automation for small companies', 'AI implementation risks for mission-driven organizations'.\", 'Use the All4Climate interview as a grounding example but generalize insights to apply to broader mission-driven SME audience (NGOs, social enterprises, activist groups).', \"Emphasize the agency's unique positioning: software-agnostic, values-aligned, encouraging SMEs to build capacity and move from SaaS dependency to custom solutions.\", 'Address both technical and organizational considerations: data privacy, GDPR compliance, knowledge distribution, organizational resilience.', 'Highlight the emotional/psychological needs: security, autonomy, control, trust, relief from frustration, resilience, values alignment.', 'Include practical takeaways: what SMEs can do immediately vs. longer-term infrastructure changes.', 'Avoid promoting specific platforms or brands; focus on principles and approaches.', 'Break established patternsâ€”challenge the assumption that Big Tech is inevitable or that custom solutions are unaffordable for SMEs.', 'Include a reflection on ethics and the cost of convenience (choosing Big Tech over values alignment).']}\n",
      "\n",
      "Saved to blog_plan.json\n"
     ]
    }
   ],
   "source": [
    "# Assuming you ran: test_result = test_complete_8_node_pipeline()\n",
    "# If not, re-run it now with assignment\n",
    "\n",
    "if test_result and 'blog_plan' in test_result:\n",
    "    blog_plan = test_result['blog_plan']  # Access the Plan instance\n",
    "    \n",
    "    # Option 1: Print the formatted plan (using the @property)\n",
    "    print(\"Formatted Blog Plan:\\n\")\n",
    "    print(blog_plan.plan)  # This outputs the nice string with sections, Q&A, and instructions\n",
    "    \n",
    "    # Option 2: Print individual fields for detailed review\n",
    "    print(\"\\nIndividual Fields:\")\n",
    "    print(f\"Who: {blog_plan.who}\")\n",
    "    print(f\"Why: {blog_plan.why}\")\n",
    "    print(f\"What: {blog_plan.what}\")\n",
    "    print(f\"The Issue: {blog_plan.the_issue}\")\n",
    "    print(f\"Where We Stand: {blog_plan.where_we_stand}\")\n",
    "    print(f\"Single Message: {blog_plan.single_message}\")\n",
    "    print(\"\\nQ&A Pairs:\")\n",
    "    for pair in blog_plan.qa_pairs:\n",
    "        print(f\"  Q: {pair['question']}  A: {pair['answer']}\")\n",
    "    print(\"\\nInstructions:\")\n",
    "    for instr in blog_plan.instructions:\n",
    "        print(f\"  - {instr}\")\n",
    "    \n",
    "    # Option 3: Convert to dict/JSON for export or further processing\n",
    "    plan_dict = blog_plan.model_dump()  # Pydantic method to get a dict\n",
    "    print(\"\\nPlan as Dict:\")\n",
    "    print(plan_dict)\n",
    "    \n",
    "    # Bonus: Save to file (e.g., for external review)\n",
    "    import json\n",
    "    with open(\"blog_plan.json\", \"w\") as f:\n",
    "        json.dump(plan_dict, f, indent=4)\n",
    "    print(\"\\nSaved to blog_plan.json\")\n",
    "else:\n",
    "    print(\"No blog_plan foundâ€”check if the test completed successfully or re-run it.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "033bea0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… list_conversations() ready (standalone version)\n"
     ]
    }
   ],
   "source": [
    "# Cell: Simple list_conversations - No helper functions needed\n",
    "def list_conversations():\n",
    "    \"\"\"\n",
    "    List all conversations in the database\n",
    "    Simple version that works without helper functions\n",
    "    \"\"\"\n",
    "    \n",
    "    conversations = db.get_all_conversations()\n",
    "    \n",
    "    if not conversations:\n",
    "        print(\"âš ï¸  No conversations found in database\")\n",
    "        return\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 100)\n",
    "    print(\"ðŸ’¬ ALL CONVERSATIONS IN DATABASE\")\n",
    "    print(\"=\" * 100)\n",
    "    \n",
    "    for conv in conversations:\n",
    "        # Handle both dict and Pydantic model\n",
    "        if isinstance(conv, dict):\n",
    "            conv_id = conv.get('id', 'Unknown')\n",
    "            title = conv.get('title', 'Untitled')\n",
    "            raw_text = conv.get('raw_text', '')\n",
    "            created = conv.get('created_at', 'Unknown')\n",
    "            word_count = conv.get('word_count', 0)\n",
    "        else:\n",
    "            # It's a Pydantic model - use model_dump()\n",
    "            data = conv.model_dump()\n",
    "            conv_id = data.get('id', 'Unknown')\n",
    "            title = data.get('title', 'Untitled')\n",
    "            raw_text = data.get('raw_text', '')\n",
    "            created = data.get('created_at', 'Unknown')\n",
    "            word_count = data.get('word_count', 0)\n",
    "        \n",
    "        transcript_len = len(raw_text) if raw_text else 0\n",
    "        \n",
    "        # Get idea count for this conversation\n",
    "        ideas = db.get_ideas_by_conversation(conv_id)\n",
    "        idea_count = len(ideas) if ideas else 0\n",
    "        \n",
    "        # Calculate average score if ideas exist\n",
    "        if ideas and idea_count > 0:\n",
    "            total_scores = []\n",
    "            for idea in ideas:\n",
    "                if isinstance(idea, dict):\n",
    "                    score = sum([\n",
    "                        idea.get('usefulness_potential', 0),\n",
    "                        idea.get('fitwith_seo_strategy', 0),\n",
    "                        idea.get('fitwith_content_strategy', 0),\n",
    "                        idea.get('inspiration_potential', 0),\n",
    "                        idea.get('collaboration_potential', 0),\n",
    "                        idea.get('innovation', 0),\n",
    "                        idea.get('difficulty', 0)\n",
    "                    ])\n",
    "                else:\n",
    "                    data = idea.model_dump() if hasattr(idea, 'model_dump') else idea.__dict__\n",
    "                    score = sum([\n",
    "                        data.get('usefulness_potential', 0),\n",
    "                        data.get('fitwith_seo_strategy', 0),\n",
    "                        data.get('fitwith_content_strategy', 0),\n",
    "                        data.get('inspiration_potential', 0),\n",
    "                        data.get('collaboration_potential', 0),\n",
    "                        data.get('innovation', 0),\n",
    "                        data.get('difficulty', 0)\n",
    "                    ])\n",
    "                total_scores.append(score)\n",
    "            \n",
    "            avg_score = sum(total_scores) / len(total_scores)\n",
    "            score_info = f\"Avg Score: {avg_score:.1f}/70\"\n",
    "        else:\n",
    "            score_info = \"No ideas yet\"\n",
    "        \n",
    "        print(f\"\\nðŸ“ ID: {conv_id}\")\n",
    "        print(f\"   ðŸ“ Title: {title}\")\n",
    "        print(f\"   ðŸ“„ Transcript: {transcript_len} chars ({word_count} words)\")\n",
    "        print(f\"   ðŸ’¡ Ideas: {idea_count} | {score_info}\")\n",
    "        print(f\"   ðŸ“… Created: {created}\")\n",
    "        print(f\"   ðŸ” View: quick_view({conv_id})\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 100)\n",
    "    print(f\"ðŸ’¡ Total Conversations: {len(conversations)}\")\n",
    "    print(\"=\" * 100 + \"\\n\")\n",
    "\n",
    "print(\"âœ… list_conversations() ready (standalone version)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ab25c7d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "ðŸ’¬ ALL CONVERSATIONS IN DATABASE\n",
      "====================================================================================================\n",
      "\n",
      "ðŸ“ ID: 41\n",
      "   ðŸ“ Title: Audio: blog_record (2026-01-07 15_11_23).wav\n",
      "   ðŸ“„ Transcript: 10553 chars (1910 words)\n",
      "   ðŸ’¡ Ideas: 5 | Avg Score: 48.2/70\n",
      "   ðŸ“… Created: 2026-01-08 09:59:41\n",
      "   ðŸ” View: quick_view(41)\n",
      "\n",
      "ðŸ“ ID: 40\n",
      "   ðŸ“ Title: Audio: blog_record (2026-01-07 15_11_23).wav\n",
      "   ðŸ“„ Transcript: 10553 chars (1910 words)\n",
      "   ðŸ’¡ Ideas: 5 | Avg Score: 43.6/70\n",
      "   ðŸ“… Created: 2026-01-08 09:43:49\n",
      "   ðŸ” View: quick_view(40)\n",
      "\n",
      "ðŸ“ ID: 39\n",
      "   ðŸ“ Title: Audio: blog_ecord (2025-12-24 10_13_55).wav\n",
      "   ðŸ“„ Transcript: 1704 chars (268 words)\n",
      "   ðŸ’¡ Ideas: 5 | Avg Score: 48.4/70\n",
      "   ðŸ“… Created: 2025-12-24 09:22:03\n",
      "   ðŸ” View: quick_view(39)\n",
      "\n",
      "ðŸ“ ID: 38\n",
      "   ðŸ“ Title: Audio: blog_ecord (2025-12-24 10_13_55).wav\n",
      "   ðŸ“„ Transcript: 1704 chars (268 words)\n",
      "   ðŸ’¡ Ideas: 5 | Avg Score: 47.2/70\n",
      "   ðŸ“… Created: 2025-12-24 09:18:42\n",
      "   ðŸ” View: quick_view(38)\n",
      "\n",
      "ðŸ“ ID: 37\n",
      "   ðŸ“ Title: Audio: blog_ecord (2025-12-01 19_47_21).wav\n",
      "   ðŸ“„ Transcript: 4993 chars (908 words)\n",
      "   ðŸ’¡ Ideas: 5 | Avg Score: 46.2/70\n",
      "   ðŸ“… Created: 2025-12-22 10:09:55\n",
      "   ðŸ” View: quick_view(37)\n",
      "\n",
      "ðŸ“ ID: 36\n",
      "   ðŸ“ Title: Audio: blog_ecord (2025-12-01 19_47_21).wav\n",
      "   ðŸ“„ Transcript: 4993 chars (908 words)\n",
      "   ðŸ’¡ Ideas: 5 | Avg Score: 44.0/70\n",
      "   ðŸ“… Created: 2025-12-19 10:46:28\n",
      "   ðŸ” View: quick_view(36)\n",
      "\n",
      "ðŸ“ ID: 35\n",
      "   ðŸ“ Title: Audio: blog_ecord (2025-12-01 19_47_21).wav\n",
      "   ðŸ“„ Transcript: 4984 chars (906 words)\n",
      "   ðŸ’¡ Ideas: 5 | Avg Score: 44.8/70\n",
      "   ðŸ“… Created: 2025-12-18 10:05:18\n",
      "   ðŸ” View: quick_view(35)\n",
      "\n",
      "ðŸ“ ID: 34\n",
      "   ðŸ“ Title: Audio: blog_ecord (2025-12-01 19_47_21).wav\n",
      "   ðŸ“„ Transcript: 4993 chars (908 words)\n",
      "   ðŸ’¡ Ideas: 5 | Avg Score: 42.8/70\n",
      "   ðŸ“… Created: 2025-12-17 08:52:30\n",
      "   ðŸ” View: quick_view(34)\n",
      "\n",
      "ðŸ“ ID: 33\n",
      "   ðŸ“ Title: Audio: blog_ecord (2025-12-01 19_47_21).wav\n",
      "   ðŸ“„ Transcript: 4993 chars (908 words)\n",
      "   ðŸ’¡ Ideas: 5 | Avg Score: 44.2/70\n",
      "   ðŸ“… Created: 2025-12-01 19:18:25\n",
      "   ðŸ” View: quick_view(33)\n",
      "\n",
      "ðŸ“ ID: 32\n",
      "   ðŸ“ Title: Audio: blog_record (2025-12-01 10_40_21).wav\n",
      "   ðŸ“„ Transcript: 4469 chars (762 words)\n",
      "   ðŸ’¡ Ideas: 5 | Avg Score: 43.0/70\n",
      "   ðŸ“… Created: 2025-12-01 09:48:12\n",
      "   ðŸ” View: quick_view(32)\n",
      "\n",
      "ðŸ“ ID: 31\n",
      "   ðŸ“ Title: Audio: blog_cord (2025-12-01 09_58_37).wav\n",
      "   ðŸ“„ Transcript: 3133 chars (509 words)\n",
      "   ðŸ’¡ Ideas: 5 | Avg Score: 47.2/70\n",
      "   ðŸ“… Created: 2025-12-01 09:34:58\n",
      "   ðŸ” View: quick_view(31)\n",
      "\n",
      "ðŸ“ ID: 30\n",
      "   ðŸ“ Title: Audio: blog_cord (2025-12-01 09_58_37).wav\n",
      "   ðŸ“„ Transcript: 3133 chars (509 words)\n",
      "   ðŸ’¡ Ideas: 0 | No ideas yet\n",
      "   ðŸ“… Created: 2025-12-01 09:22:54\n",
      "   ðŸ” View: quick_view(30)\n",
      "\n",
      "ðŸ“ ID: 29\n",
      "   ðŸ“ Title: Audio: blog_cord (2025-12-01 09_58_37).wav\n",
      "   ðŸ“„ Transcript: 3133 chars (509 words)\n",
      "   ðŸ’¡ Ideas: 0 | No ideas yet\n",
      "   ðŸ“… Created: 2025-12-01 09:09:26\n",
      "   ðŸ” View: quick_view(29)\n",
      "\n",
      "ðŸ“ ID: 28\n",
      "   ðŸ“ Title: Audio: blog_record_(purevitalize).wav\n",
      "   ðŸ“„ Transcript: 1790 chars (298 words)\n",
      "   ðŸ’¡ Ideas: 5 | Avg Score: 46.4/70\n",
      "   ðŸ“… Created: 2025-11-28 09:02:37\n",
      "   ðŸ” View: quick_view(28)\n",
      "\n",
      "ðŸ“ ID: 27\n",
      "   ðŸ“ Title: Audio: blog_record_(purevitalize).wav\n",
      "   ðŸ“„ Transcript: 1790 chars (298 words)\n",
      "   ðŸ’¡ Ideas: 5 | Avg Score: 35.0/70\n",
      "   ðŸ“… Created: 2025-11-28 08:27:30\n",
      "   ðŸ” View: quick_view(27)\n",
      "\n",
      "ðŸ“ ID: 26\n",
      "   ðŸ“ Title: Audio: blog_record_(purevitalize).wav\n",
      "   ðŸ“„ Transcript: 1790 chars (298 words)\n",
      "   ðŸ’¡ Ideas: 5 | Avg Score: 35.0/70\n",
      "   ðŸ“… Created: 2025-11-27 09:11:49\n",
      "   ðŸ” View: quick_view(26)\n",
      "\n",
      "ðŸ“ ID: 25\n",
      "   ðŸ“ Title: Audio: blog_record_(purevitalize).wav\n",
      "   ðŸ“„ Transcript: 1790 chars (298 words)\n",
      "   ðŸ’¡ Ideas: 0 | No ideas yet\n",
      "   ðŸ“… Created: 2025-11-26 09:11:52\n",
      "   ðŸ” View: quick_view(25)\n",
      "\n",
      "ðŸ“ ID: 24\n",
      "   ðŸ“ Title: Audio: blog_record_(purevitalize).wav\n",
      "   ðŸ“„ Transcript: 1790 chars (298 words)\n",
      "   ðŸ’¡ Ideas: 0 | No ideas yet\n",
      "   ðŸ“… Created: 2025-11-21 09:58:56\n",
      "   ðŸ” View: quick_view(24)\n",
      "\n",
      "ðŸ“ ID: 23\n",
      "   ðŸ“ Title: Audio: blog_record_(purevitalize).wav\n",
      "   ðŸ“„ Transcript: 1790 chars (298 words)\n",
      "   ðŸ’¡ Ideas: 0 | No ideas yet\n",
      "   ðŸ“… Created: 2025-11-19 09:23:31\n",
      "   ðŸ” View: quick_view(23)\n",
      "\n",
      "ðŸ“ ID: 22\n",
      "   ðŸ“ Title: Audio: blog_record_(purevitalize).wav\n",
      "   ðŸ“„ Transcript: 1790 chars (298 words)\n",
      "   ðŸ’¡ Ideas: 0 | No ideas yet\n",
      "   ðŸ“… Created: 2025-11-19 09:22:11\n",
      "   ðŸ” View: quick_view(22)\n",
      "\n",
      "ðŸ“ ID: 21\n",
      "   ðŸ“ Title: Audio: blog_record_(purevitalize).wav\n",
      "   ðŸ“„ Transcript: 1790 chars (298 words)\n",
      "   ðŸ’¡ Ideas: 0 | No ideas yet\n",
      "   ðŸ“… Created: 2025-11-19 09:21:18\n",
      "   ðŸ” View: quick_view(21)\n",
      "\n",
      "ðŸ“ ID: 20\n",
      "   ðŸ“ Title: Audio: blog_record_(purevitalize).wav\n",
      "   ðŸ“„ Transcript: 1790 chars (298 words)\n",
      "   ðŸ’¡ Ideas: 0 | No ideas yet\n",
      "   ðŸ“… Created: 2025-11-17 08:54:02\n",
      "   ðŸ” View: quick_view(20)\n",
      "\n",
      "ðŸ“ ID: 19\n",
      "   ðŸ“ Title: Audio: blog_record_(purevitalize).wav\n",
      "   ðŸ“„ Transcript: 1790 chars (298 words)\n",
      "   ðŸ’¡ Ideas: 0 | No ideas yet\n",
      "   ðŸ“… Created: 2025-11-17 08:49:22\n",
      "   ðŸ” View: quick_view(19)\n",
      "\n",
      "====================================================================================================\n",
      "ðŸ’¡ Total Conversations: 23\n",
      "====================================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Or just list them first\n",
    "list_conversations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "603ff83b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Terminal dashboard ready (using db.get_all_ideas and db.get_ideas_by_conversation)\n"
     ]
    }
   ],
   "source": [
    "# Cell: Terminal Dashboard - Using Existing DB Methods\n",
    "def show_ideas_dashboard(conversation_id=None, top_n=10):\n",
    "    \"\"\"\n",
    "    Beautiful terminal dashboard showing scored blog ideas\n",
    "    Uses existing db.get_all_ideas() or db.get_ideas_by_conversation()\n",
    "    \n",
    "    Args:\n",
    "        conversation_id: Show ideas for specific conversation (None = all ideas)\n",
    "        top_n: Number of top ideas to show\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 100)\n",
    "    print(\"ðŸ“Š BLOG IDEAS DASHBOARD\")\n",
    "    print(\"=\" * 100)\n",
    "    \n",
    "    # Get ideas using existing methods\n",
    "    if conversation_id:\n",
    "        ideas = db.get_ideas_by_conversation(conversation_id)\n",
    "        print(f\"ðŸ“ Showing ideas from Conversation ID: {conversation_id}\")\n",
    "    else:\n",
    "        ideas = db.get_all_ideas()\n",
    "        print(f\"ðŸ“ Showing ALL ideas from database\")\n",
    "    \n",
    "    if not ideas:\n",
    "        print(\"âš ï¸  No ideas found in database\")\n",
    "        return\n",
    "    \n",
    "    # Calculate scores and sort\n",
    "    scored_ideas = []\n",
    "    for idea in ideas:\n",
    "        # Handle both dict and object formats\n",
    "        if isinstance(idea, dict):\n",
    "            total = sum([\n",
    "                idea.get('usefulness_potential', 0),\n",
    "                idea.get('fitwith_seo_strategy', 0),\n",
    "                idea.get('fitwith_content_strategy', 0),\n",
    "                idea.get('inspiration_potential', 0),\n",
    "                idea.get('collaboration_potential', 0),\n",
    "                idea.get('innovation', 0),\n",
    "                idea.get('difficulty', 0)\n",
    "            ])\n",
    "        else:\n",
    "            total = sum([\n",
    "                idea.usefulness_potential,\n",
    "                idea.fitwith_seo_strategy,\n",
    "                idea.fitwith_content_strategy,\n",
    "                idea.inspiration_potential,\n",
    "                idea.collaboration_potential,\n",
    "                idea.innovation,\n",
    "                idea.difficulty\n",
    "            ])\n",
    "        scored_ideas.append((idea, total))\n",
    "    \n",
    "    # Sort by total score (highest first)\n",
    "    scored_ideas.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Show summary stats\n",
    "    all_scores = [s[1] for s in scored_ideas]\n",
    "    avg_score = sum(all_scores) / len(all_scores)\n",
    "    \n",
    "    print(f\"\\nðŸ“ˆ SUMMARY STATISTICS\")\n",
    "    print(f\"   Total Ideas: {len(scored_ideas)}\")\n",
    "    print(f\"   Average Score: {avg_score:.1f}/70 ({avg_score/70*100:.1f}%)\")\n",
    "    print(f\"   Highest Score: {scored_ideas[0][1]}/70 ({scored_ideas[0][1]/70*100:.1f}%)\")\n",
    "    print(f\"   Lowest Score: {scored_ideas[-1][1]}/70 ({scored_ideas[-1][1]/70*100:.1f}%)\")\n",
    "    \n",
    "    # Show score distribution\n",
    "    high_scores = sum(1 for s in all_scores if s >= 60)\n",
    "    medium_scores = sum(1 for s in all_scores if 50 <= s < 60)\n",
    "    low_scores = sum(1 for s in all_scores if s < 50)\n",
    "    \n",
    "    print(f\"\\nðŸ“Š SCORE DISTRIBUTION\")\n",
    "    print(f\"   ðŸŸ¢ High (60-70):  {high_scores} ideas ({high_scores/len(all_scores)*100:.1f}%)\")\n",
    "    print(f\"   ðŸŸ¡ Medium (50-59): {medium_scores} ideas ({medium_scores/len(all_scores)*100:.1f}%)\")\n",
    "    print(f\"   ðŸ”´ Low (<50):     {low_scores} ideas ({low_scores/len(all_scores)*100:.1f}%)\")\n",
    "    \n",
    "    # Show top ideas\n",
    "    display_count = min(top_n, len(scored_ideas))\n",
    "    print(f\"\\nðŸ† TOP {display_count} IDEAS\")\n",
    "    print(\"-\" * 100)\n",
    "    \n",
    "    for rank, (idea, total_score) in enumerate(scored_ideas[:top_n], 1):\n",
    "        # Handle both dict and object formats\n",
    "        if isinstance(idea, dict):\n",
    "            idea_id = idea.get('id')\n",
    "            title = idea.get('title', 'Untitled')\n",
    "            usefulness = idea.get('usefulness_potential', 0)\n",
    "            seo = idea.get('fitwith_seo_strategy', 0)\n",
    "            content = idea.get('fitwith_content_strategy', 0)\n",
    "            inspiration = idea.get('inspiration_potential', 0)\n",
    "            collaboration = idea.get('collaboration_potential', 0)\n",
    "            innovation = idea.get('innovation', 0)\n",
    "            difficulty = idea.get('difficulty', 0)\n",
    "            created_at = idea.get('created_at', 'Unknown')\n",
    "            conv_id = idea.get('conversation_id', 'N/A')\n",
    "            sent_to_prod = idea.get('sent_to_prod', False)\n",
    "        else:\n",
    "            idea_id = idea.id\n",
    "            title = idea.title\n",
    "            usefulness = idea.usefulness_potential\n",
    "            seo = idea.fitwith_seo_strategy\n",
    "            content = idea.fitwith_content_strategy\n",
    "            inspiration = idea.inspiration_potential\n",
    "            collaboration = idea.collaboration_potential\n",
    "            innovation = idea.innovation\n",
    "            difficulty = idea.difficulty\n",
    "            created_at = idea.created_at\n",
    "            conv_id = idea.conversation_id\n",
    "            sent_to_prod = idea.sent_to_prod\n",
    "        \n",
    "        # Create score bar\n",
    "        bar_length = 35\n",
    "        percentage = total_score / 70\n",
    "        filled = int(percentage * bar_length)\n",
    "        bar = \"â–ˆ\" * filled + \"â–‘\" * (bar_length - filled)\n",
    "        \n",
    "        # Medal emoji for top 3\n",
    "        medal = {1: \"ðŸ¥‡\", 2: \"ðŸ¥ˆ\", 3: \"ðŸ¥‰\"}.get(rank, f\"{rank:2d}.\")\n",
    "        \n",
    "        # Color indicator based on score\n",
    "        if total_score >= 60:\n",
    "            indicator = \"ðŸŸ¢\"  # High score\n",
    "        elif total_score >= 50:\n",
    "            indicator = \"ðŸŸ¡\"  # Medium score\n",
    "        else:\n",
    "            indicator = \"ðŸ”´\"  # Low score\n",
    "        \n",
    "        print(f\"\\n{medal} {indicator} ID: {idea_id} | Score: {total_score}/70 ({percentage*100:.1f}%)\")\n",
    "        print(f\"   ðŸ“ {title}\")\n",
    "        print(f\"   ðŸ“Š [{bar}] {total_score}/70\")\n",
    "        print(f\"   ðŸ’¡ Breakdown:\")\n",
    "        print(f\"      â€¢ Usefulness: {usefulness}/10 | SEO Fit: {seo}/10 | Content Fit: {content}/10\")\n",
    "        print(f\"      â€¢ Inspiration: {inspiration}/10 | Collaboration: {collaboration}/10\")\n",
    "        print(f\"      â€¢ Innovation: {innovation}/10 | Difficulty (ease): {difficulty}/10\")\n",
    "        print(f\"   ðŸ“… Created: {created_at}\")\n",
    "        print(f\"   ðŸ”— Conversation: {conv_id}\")\n",
    "        \n",
    "        if sent_to_prod:\n",
    "            print(f\"   âœ… STATUS: SENT TO PRODUCTION\")\n",
    "        else:\n",
    "            print(f\"   ðŸ“ STATUS: Draft\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 100)\n",
    "    print(\"ðŸ’¡ USAGE TIPS:\")\n",
    "    print(\"   show_ideas_dashboard()              # Show all ideas\")\n",
    "    print(\"   show_ideas_dashboard(28)            # Show ideas from conversation 28\")\n",
    "    print(\"   show_ideas_dashboard(28, top_n=3)   # Show top 3 ideas only\")\n",
    "    print(\"=\" * 100 + \"\\n\")\n",
    "\n",
    "print(\"âœ… Terminal dashboard ready (using db.get_all_ideas and db.get_ideas_by_conversation)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e004553b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Quick view function ready\n"
     ]
    }
   ],
   "source": [
    "# Cell: Quick View - Compact Dashboard\n",
    "def quick_view(conversation_id=None):\n",
    "    \"\"\"Quick compact view of scored ideas\"\"\"\n",
    "    \n",
    "    ideas = db.get_ideas_by_conversation(conversation_id) if conversation_id else db.get_all_ideas()\n",
    "    \n",
    "    if not ideas:\n",
    "        print(\"âš ï¸  No ideas found\")\n",
    "        return\n",
    "    \n",
    "    # Score and sort\n",
    "    scored = []\n",
    "    for idea in ideas:\n",
    "        if isinstance(idea, dict):\n",
    "            total = sum([idea.get('usefulness_potential', 0), idea.get('fitwith_seo_strategy', 0),\n",
    "                        idea.get('fitwith_content_strategy', 0), idea.get('inspiration_potential', 0),\n",
    "                        idea.get('collaboration_potential', 0), idea.get('innovation', 0), idea.get('difficulty', 0)])\n",
    "            scored.append((idea, total))\n",
    "        else:\n",
    "            total = sum([idea.usefulness_potential, idea.fitwith_seo_strategy, idea.fitwith_content_strategy,\n",
    "                        idea.inspiration_potential, idea.collaboration_potential, idea.innovation, idea.difficulty])\n",
    "            scored.append((idea, total))\n",
    "    \n",
    "    scored.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    print(f\"\\n{'='*100}\")\n",
    "    print(f\"ðŸ“Š {'CONVERSATION ' + str(conversation_id) if conversation_id else 'ALL IDEAS'} | Total: {len(scored)} ideas | Avg: {sum(s[1] for s in scored)/len(scored):.1f}/70\")\n",
    "    print(f\"{'='*100}\\n\")\n",
    "    \n",
    "    for rank, (idea, score) in enumerate(scored, 1):\n",
    "        if isinstance(idea, dict):\n",
    "            idea_id, title = idea.get('id'), idea.get('title', 'Untitled')\n",
    "        else:\n",
    "            idea_id, title = idea.id, idea.title\n",
    "        \n",
    "        medal = {1: \"ðŸ¥‡\", 2: \"ðŸ¥ˆ\", 3: \"ðŸ¥‰\"}.get(rank, f\"{rank:2d}.\")\n",
    "        indicator = \"ðŸŸ¢\" if score >= 60 else \"ðŸŸ¡\" if score >= 50 else \"ðŸ”´\"\n",
    "        \n",
    "        print(f\"{medal} {indicator} [{idea_id:3d}] {score:2d}/70 | {title[:75]}\")\n",
    "    \n",
    "    print(f\"\\n{'='*100}\\n\")\n",
    "\n",
    "print(\"âœ… Quick view function ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e508f9ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§ª Test 1: Full dashboard for conversation 39\n",
      "\n",
      "====================================================================================================\n",
      "ðŸ“Š BLOG IDEAS DASHBOARD\n",
      "====================================================================================================\n",
      "ðŸ“ Showing ideas from Conversation ID: 39\n",
      "\n",
      "ðŸ“ˆ SUMMARY STATISTICS\n",
      "   Total Ideas: 5\n",
      "   Average Score: 48.4/70 (69.1%)\n",
      "   Highest Score: 54/70 (77.1%)\n",
      "   Lowest Score: 41/70 (58.6%)\n",
      "\n",
      "ðŸ“Š SCORE DISTRIBUTION\n",
      "   ðŸŸ¢ High (60-70):  0 ideas (0.0%)\n",
      "   ðŸŸ¡ Medium (50-59): 2 ideas (40.0%)\n",
      "   ðŸ”´ Low (<50):     3 ideas (60.0%)\n",
      "\n",
      "ðŸ† TOP 5 IDEAS\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "ðŸ¥‡ ðŸŸ¡ ID: 58 | Score: 54/70 (77.1%)\n",
      "   ðŸ“ AI Implementation for Financial Independence: How to Evaluate Solutions That Respect Your Autonomy\n",
      "   ðŸ“Š [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 54/70\n",
      "   ðŸ’¡ Breakdown:\n",
      "      â€¢ Usefulness: 9/10 | SEO Fit: 6/10 | Content Fit: 9/10\n",
      "      â€¢ Inspiration: 8/10 | Collaboration: 9/10\n",
      "      â€¢ Innovation: 8/10 | Difficulty (ease): 5/10\n",
      "   ðŸ“… Created: 2025-12-24 09:22:35\n",
      "   ðŸ”— Conversation: 39\n",
      "   ðŸ“ STATUS: Draft\n",
      "\n",
      "ðŸ¥ˆ ðŸŸ¡ ID: 59 | Score: 51/70 (72.9%)\n",
      "   ðŸ“ Breaking Free from Vendor Lock-in: Custom AI Solutions vs SaaS for Financial Services\n",
      "   ðŸ“Š [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 51/70\n",
      "   ðŸ’¡ Breakdown:\n",
      "      â€¢ Usefulness: 8/10 | SEO Fit: 9/10 | Content Fit: 6/10\n",
      "      â€¢ Inspiration: 7/10 | Collaboration: 9/10\n",
      "      â€¢ Innovation: 7/10 | Difficulty (ease): 5/10\n",
      "   ðŸ“… Created: 2025-12-24 09:22:35\n",
      "   ðŸ”— Conversation: 39\n",
      "   ðŸ“ STATUS: Draft\n",
      "\n",
      "ðŸ¥‰ ðŸ”´ ID: 60 | Score: 48/70 (68.6%)\n",
      "   ðŸ“ The Hidden Costs of SaaS Lock-in: Why Financial Services Need Strategic Data Autonomy\n",
      "   ðŸ“Š [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 48/70\n",
      "   ðŸ’¡ Breakdown:\n",
      "      â€¢ Usefulness: 8/10 | SEO Fit: 5/10 | Content Fit: 7/10\n",
      "      â€¢ Inspiration: 7/10 | Collaboration: 8/10\n",
      "      â€¢ Innovation: 8/10 | Difficulty (ease): 5/10\n",
      "   ðŸ“… Created: 2025-12-24 09:22:35\n",
      "   ðŸ”— Conversation: 39\n",
      "   ðŸ“ STATUS: Draft\n",
      "\n",
      " 4. ðŸ”´ ID: 61 | Score: 48/70 (68.6%)\n",
      "   ðŸ“ Implementing Custom AI Without Sacrificing Security: A Financial Institution's Playbook\n",
      "   ðŸ“Š [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 48/70\n",
      "   ðŸ’¡ Breakdown:\n",
      "      â€¢ Usefulness: 8/10 | SEO Fit: 7/10 | Content Fit: 6/10\n",
      "      â€¢ Inspiration: 7/10 | Collaboration: 9/10\n",
      "      â€¢ Innovation: 8/10 | Difficulty (ease): 3/10\n",
      "   ðŸ“… Created: 2025-12-24 09:22:35\n",
      "   ðŸ”— Conversation: 39\n",
      "   ðŸ“ STATUS: Draft\n",
      "\n",
      " 5. ðŸ”´ ID: 62 | Score: 41/70 (58.6%)\n",
      "   ðŸ“ On-Premises AI Implementation: Maintaining Compliance While Gaining Strategic Control\n",
      "   ðŸ“Š [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 41/70\n",
      "   ðŸ’¡ Breakdown:\n",
      "      â€¢ Usefulness: 8/10 | SEO Fit: 6/10 | Content Fit: 5/10\n",
      "      â€¢ Inspiration: 6/10 | Collaboration: 8/10\n",
      "      â€¢ Innovation: 5/10 | Difficulty (ease): 3/10\n",
      "   ðŸ“… Created: 2025-12-24 09:22:35\n",
      "   ðŸ”— Conversation: 39\n",
      "   ðŸ“ STATUS: Draft\n",
      "\n",
      "====================================================================================================\n",
      "ðŸ’¡ USAGE TIPS:\n",
      "   show_ideas_dashboard()              # Show all ideas\n",
      "   show_ideas_dashboard(28)            # Show ideas from conversation 28\n",
      "   show_ideas_dashboard(28, top_n=3)   # Show top 3 ideas only\n",
      "====================================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test 1: Full dashboard for conversation 37\n",
    "print(\"ðŸ§ª Test 1: Full dashboard for conversation 39\")\n",
    "show_ideas_dashboard(39)\n",
    "\n",
    "# Test 2: Quick view for all ideas\n",
    "#print(\"\\nðŸ§ª Test 2: Quick view for all ideas\")\n",
    "#quick_view()\n",
    "\n",
    "# Test 3: Quick view for conversation 33\n",
    "#print(\"\\nðŸ§ª Test 3: Quick view for conversation 33\")\n",
    "#quick_view(33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dbc0cb6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Blog Post (Full Schema):\n",
      "\n",
      "ID: None\n",
      "Title: Breaking Free from Big Tech: How Mission-Driven SMEs Can Build Ethical, GDPR-Compliant Infrastructure\n",
      "Issue: Mission-driven SMEs (NGOs, activist groups, social enterprises) face an impossible choice: use Big Tech platforms that compromise their values and expose stakeholder data to privacy risks, or struggle with limited alternatives that lack reach and visibility. They lack the technical expertise and financial resources to build sustainable, GDPR-compliant, values-aligned technology infrastructure. Single individuals often become bottlenecks, creating organizational fragility.\n",
      "Angle: Big Kids Automation Agency positions custom automation and thoughtful tech solutions as a path for mission-driven SMEs to break free from Big Tech dependency, achieve GDPR compliance, and build organizational autonomyâ€”without requiring massive investment or technical expertise. We emphasize that this is achievable, values-aligned, and ultimately less risky than the status quo.\n",
      "Single Message: Mission-driven SMEs can break free from Big Tech dependency through thoughtful automation and custom solutionsâ€”building ethical, GDPR-compliant tech infrastructure that protects stakeholder data while freeing up limited resources to focus on what matters: their mission.\n",
      "User Story: As an SME owner or manager running a mission-driven organization, I want to build ethical, GDPR-compliant technology infrastructure that protects stakeholder data and aligns with my values, so that I can operate consistently with my mission, reduce legal exposure, and create organizational resilience without requiring massive technical expertise or capital investment.\n",
      "Seed Keyword: GDPR-compliant automation for SMEs\n",
      "Call to Action: Start your tech stack audit today. Map which tools handle sensitive data and which ones create GDPR compliance gaps. If you're frustrated with Big Tech platforms and ready to explore values-aligned alternatives, let's talk about what's possible for your organization.\n",
      "Keywords: privacy-aligned tech alternatives, custom AI solutions vs SaaS platforms, business process automation for small companies, AI implementation risks for mission-driven organizations, breaking free from Big Tech, ethical technology infrastructure, data privacy compliance SMEs, custom automation solutions, organizational resilience, values-aligned technology\n",
      "Status: BlogPostStatus.PUBLISHED\n",
      "Published Date: None\n",
      "Created At: None\n",
      "Updated At: None\n",
      "\n",
      "Full Content:\n",
      "\n",
      "You're running an NGO, activist group, or social enterprise. Your mission mattersâ€”it drives every decision you make. But every day, you face a contradiction that gnaws at you: your organization's values demand data privacy and ethical operations, yet you're dependent on Google Suite, Facebook, and other Big Tech platforms you fundamentally don't trust.\n",
      "\n",
      "You're not alone in this frustration. Mission-driven SMEs across the world are trapped in the same impossible choice: compromise your values by using platforms that mine stakeholder data, or struggle with limited alternatives that lack reach and visibility. Meanwhile, your technical knowledge sits in one person's head, creating organizational fragility. If that person leaves or becomes unavailable, your entire operation grinds to a halt.\n",
      "\n",
      "This isn't a technology problem disguised as a values problem. It's a business problem that demands a business solution.\n",
      "\n",
      "## The Data Privacy Crisis No One Talks About\n",
      "\n",
      "When you use Google Suite, Facebook, or similar platforms, you're not just choosing a convenience tool. You're making a decision about who controls sensitive stakeholder data: activists' identities, donor information, financial records, community member contact details. That data doesn't stay on your computer or your server. It flows to Big Tech's data centers, where it becomes fuel for their advertising and AI training systems.\n",
      "\n",
      "The cost of this convenience is paid by your stakeholders, not by youâ€”and often without their knowledge or explicit consent.\n",
      "\n",
      "For mission-driven organizations, this creates a specific vulnerability. You're often working with vulnerable populations: activists facing persecution, donors supporting unpopular causes, community members in precarious situations. A data breach isn't just an inconvenience. It's a betrayal of trust that can have real-world consequences.\n",
      "\n",
      "GDPR compliance adds another layer of complexity. If your organization processes personal data of EU residentsâ€”which many international NGOs and activist groups doâ€”you're legally required to implement data protection measures, limit data processing to stated purposes, and maintain records of consent. Big Tech's terms of service don't align with these requirements. Using Google Suite or Facebook as your primary infrastructure creates compliance gaps that expose your organization to significant fines and reputational damage.\n",
      "\n",
      "The question isn't whether Big Tech platforms are convenient. They are. The question is: what's the actual cost of that convenience when measured against your organization's values and legal obligations?\n",
      "\n",
      "## Why Single-Person Bottlenecks Destroy Organizational Resilience\n",
      "\n",
      "Many mission-driven SMEs have one technical personâ€”often a founder or early staff memberâ€”who manages everything: email systems, data storage, donor databases, website hosting, automation workflows. This person is invaluable. They're also a single point of failure.\n",
      "\n",
      "If they leave, get sick, or become overwhelmed, your organization loses operational capacity. You can't onboard new team members because no one else understands the infrastructure. You can't scale because technical knowledge isn't documented or distributed. You can't innovate because all technical resources are consumed by maintenance.\n",
      "\n",
      "This isn't a personal failure. It's a structural problem created by resource constraints and the assumption that technical infrastructure is too complex for non-technical people to understand.\n",
      "\n",
      "But what if it didn't have to be this way?\n",
      "\n",
      "## How Automation and Custom Solutions Create Organizational Autonomy\n",
      "\n",
      "Here's what many mission-driven SMEs don't realize: you don't need a massive technical team or significant capital investment to build ethical, GDPR-compliant infrastructure. You need thoughtful automation and custom solutions designed around your actual workflows.\n",
      "\n",
      "Consider what's possible:\n",
      "\n",
      "**Replace Google Drive with privacy-aligned document management.** Automated workflows can organize, archive, and retrieve documents based on rules you define. Your data stays on infrastructure you control. Non-technical team members can use simple interfaces to manage documents without understanding the underlying automation.\n",
      "\n",
      "**Build custom data workflows instead of relying on proprietary platforms.** Instead of using Facebook's donor management tools or Google Forms for sensitive surveys, you can implement custom workflows that capture data exactly as you need it, store it securely, and process it according to GDPR requirements. Automation handles the heavy lifting; your team focuses on mission.\n",
      "\n",
      "**Automate compliance and audit trails.** GDPR compliance isn't just about protecting dataâ€”it's about proving you're protecting data. Custom automation can generate audit logs, track consent, document data processing decisions, and create compliance reports without manual effort.\n",
      "\n",
      "**Distribute technical knowledge through documentation and no-code tools.** Not every team member needs to be a developer. But with proper documentation and thoughtfully designed workflows, non-technical people can understand, modify, and maintain systems. This transforms your single technical person from a bottleneck into a capacity builder.\n",
      "\n",
      "The business value is concrete: freed-up time, reduced operational friction, organizational resilience, and authentic values alignment. Your technical infrastructure becomes an expression of your mission, not a compromise to it.\n",
      "\n",
      "## The Real Cost of Waiting\n",
      "\n",
      "There's a psychology to staying with Big Tech platforms even when you don't trust them. It feels safer than the unknown. You know Google Suite works. You know Facebook reaches people. The alternativeâ€”building custom solutionsâ€”feels risky, expensive, and technically complex.\n",
      "\n",
      "But this calculus ignores the actual risks you're already taking.\n",
      "\n",
      "Every month you delay, you're accumulating GDPR compliance gaps. Every data point stored in Google's systems increases your exposure. Every workflow dependent on a single technical person makes your organization more fragile. The \"safety\" of Big Tech is an illusion; it's just a familiar risk you've stopped questioning.\n",
      "\n",
      "Meanwhile, the alternative isn't as expensive or complex as you think.\n",
      "\n",
      "Mission-driven SMEs successfully transition to ethical tech stacks through phased approaches: start with high-impact, manageable automation projects that yield immediate ROI through freed-up time. As your organization matures and your team develops technical capacity, progressively build more sophisticated infrastructure. You're not attempting a complete overhaul; you're making strategic moves that compound over time.\n",
      "\n",
      "## A Practical Framework for Breaking Free\n",
      "\n",
      "If you're ready to move beyond frustration and toward action, here's where to start:\n",
      "\n",
      "**1. Map Your Current Tech Stack**\n",
      "Document every tool your organization uses. Which ones handle sensitive data? Which ones create GDPR compliance gaps? Which ones consume the most staff time? This audit reveals where change will have the most impact.\n",
      "\n",
      "**2. Prioritize GDPR Compliance Gaps**\n",
      "Not all changes are equal. Focus first on tools that handle sensitive personal data and create legal exposure. This protects your organization and your stakeholders immediately.\n",
      "\n",
      "**3. Identify High-Impact Automation Opportunities**\n",
      "Which workflows consume the most time? Which ones are repetitive and rule-based? Which ones could be handled by non-technical people if the right tools existed? Start here. These are your quick wins.\n",
      "\n",
      "**4. Choose Software-Agnostic Partners**\n",
      "Work with consultants and agencies that understand your values and aren't trying to lock you into proprietary platforms. You need partners who help you build capacity, not dependency. The goal is organizational autonomy, not vendor lock-in.\n",
      "\n",
      "**5. Document and Distribute Knowledge**\n",
      "As you implement new systems, document how they work in language your team can understand. Create simple runbooks for common tasks. Share knowledge regularly. Your technical person becomes a multiplier, not a bottleneck.\n",
      "\n",
      "**6. Measure What Matters**\n",
      "Track not just technical metrics but business outcomes: hours freed up for mission-critical work, GDPR compliance improvements, staff confidence in systems, organizational resilience. These are the measures that prove ROI.\n",
      "\n",
      "## The Emotional Reality Behind the Technical Decision\n",
      "\n",
      "Let's be honest: choosing Big Tech despite your values creates cognitive dissonance. You spend your days advocating for privacy, autonomy, and ethical operationsâ€”then you store your stakeholder data in systems designed to exploit those exact things. This contradiction is exhausting. It erodes trust in your organization and trust in yourself.\n",
      "\n",
      "Breaking free from Big Tech isn't just a technical migration. It's a return to values alignment. It's the relief of operating consistently with what you believe. It's the confidence of knowing your stakeholders' data is genuinely protected, not just claimed to be protected.\n",
      "\n",
      "For mission-driven organizations, this alignment is a competitive advantage. Stakeholders trust you more. Team members feel more connected to the mission. You can authentically advocate for the values you're fighting for, because your infrastructure reflects those values.\n",
      "\n",
      "## You Don't Have to Choose Between Mission and Technology\n",
      "\n",
      "The narrative that mission-driven SMEs must accept Big Tech dependency is false. You can build ethical, GDPR-compliant, values-aligned technology infrastructure. You can distribute technical knowledge across your team. You can create organizational resilience that doesn't depend on a single person.\n",
      "\n",
      "It requires thoughtful planning, strategic prioritization, and partners who understand your unique constraints. But it's achievable. And the cost of waitingâ€”in legal exposure, values compromise, and organizational fragilityâ€”is higher than the cost of change.\n",
      "\n",
      "Your mission is too important to be held hostage by platforms you don't trust. It's time to build infrastructure that matches your values.\n"
     ]
    }
   ],
   "source": [
    "if test_result and \"blog_post\" in test_result:\n",
    "    post = test_result[\"blog_post\"]  # Now a full BlogPost instance\n",
    "    print(\"Generated Blog Post (Full Schema):\\n\")\n",
    "    print(f\"ID: {post.id}\")\n",
    "    print(f\"Title: {post.title}\")\n",
    "    print(f\"Issue: {post.issue}\")\n",
    "    print(f\"Angle: {post.angle}\")\n",
    "    print(f\"Single Message: {post.single_message}\")\n",
    "    print(f\"User Story: {post.user_story}\")\n",
    "    print(f\"Seed Keyword: {post.seed_keyword}\")\n",
    "    print(f\"Call to Action: {post.call_to_action}\")\n",
    "    print(f\"Keywords: {', '.join(post.keywords) if post.keywords else 'None'}\")\n",
    "    print(f\"Status: {post.status}\")\n",
    "    print(f\"Published Date: {post.published_date}\")\n",
    "    print(f\"Created At: {post.created_at}\")\n",
    "    print(f\"Updated At: {post.updated_at}\")\n",
    "    print(\"\\nFull Content:\\n\")\n",
    "    print(post.content)  # The complete blog text\n",
    "else:\n",
    "    print(\"No blog_post found.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
