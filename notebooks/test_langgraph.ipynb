{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb001904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AssemblyAI API Key loaded: ‚úÖ\n",
      "Key starts with: 972365f41d...\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Setup and Imports\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Add project root to Python path\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv(project_root / '.env')\n",
    "\n",
    "# Test API key\n",
    "assemblyai_key = os.getenv('ASSEMBLYAI_API_KEY')\n",
    "print(f\"AssemblyAI API Key loaded: {'‚úÖ' if assemblyai_key else '‚ùå'}\")\n",
    "print(f\"Key starts with: {assemblyai_key[:10] if assemblyai_key else 'None'}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cc1fee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Tables in app.db:\n",
      "\n",
      "üîß conversations:\n",
      "   - id (INTEGER)\n",
      "   - title (TEXT)\n",
      "   - raw_text (TEXT)\n",
      "   - source (TEXT)\n",
      "   - word_count (INTEGER)\n",
      "   - created_at (DATETIME)\n",
      "   - status (TEXT)\n",
      "\n",
      "üîß sqlite_sequence:\n",
      "   - name ()\n",
      "   - seq ()\n",
      "\n",
      "üîß blog_post_ideas:\n",
      "   - id (INTEGER)\n",
      "   - conversation_id (INTEGER)\n",
      "   - title (TEXT)\n",
      "   - description (TEXT)\n",
      "   - usefulness_potential (INTEGER)\n",
      "   - fitwith_seo_strategy (INTEGER)\n",
      "   - fitwith_content_strategy (INTEGER)\n",
      "   - inspiration_potential (INTEGER)\n",
      "   - collaboration_potential (INTEGER)\n",
      "   - innovation (INTEGER)\n",
      "   - difficulty (INTEGER)\n",
      "   - total_score (INTEGER)\n",
      "   - sent_to_prod (BOOLEAN)\n",
      "   - raw_llm_response (TEXT)\n",
      "   - created_at (DATETIME)\n",
      "\n",
      "üîß processing_status:\n",
      "   - id (INTEGER)\n",
      "   - conversation_id (INTEGER)\n",
      "   - stage (TEXT)\n",
      "   - status (TEXT)\n",
      "   - error_message (TEXT)\n",
      "   - started_at (DATETIME)\n",
      "   - completed_at (DATETIME)\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect(\"data/app.db\")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Get all table names\n",
    "cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "tables = cursor.fetchall()\n",
    "\n",
    "print(\"üìä Tables in app.db:\")\n",
    "for table in tables:\n",
    "    table_name = table[0]\n",
    "    \n",
    "    # Get column info for each table\n",
    "    cursor.execute(f\"PRAGMA table_info({table_name})\")\n",
    "    columns = cursor.fetchall()\n",
    "    \n",
    "    print(f\"\\nüîß {table_name}:\")\n",
    "    for col in columns:\n",
    "        print(f\"   - {col[1]} ({col[2]})\")  # column_name (type)\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30f9e880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All imports successful\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Import Dependencies\n",
    "import assemblyai as aai\n",
    "from langgraph.graph import StateGraph\n",
    "from typing import TypedDict, Optional, List  # ‚Üê Added List here\n",
    "import glob\n",
    "import time\n",
    "from pathlib import Path  # ‚Üê Also added Path here\n",
    "\n",
    "# Import our database\n",
    "from database.db_operations import db\n",
    "from database.models import ConversationCreate\n",
    "\n",
    "print(\"‚úÖ All imports successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e30147df",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. Pydantic Model for Structured Output\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Optional\n",
    "from enum import Enum\n",
    "\n",
    "class SpeakerRole(str, Enum):\n",
    "    \"\"\"Possible speaker roles in the conversation\"\"\"\n",
    "    CLIENT = \"client\"\n",
    "    INTERVIEWER = \"interviewer\"\n",
    "\n",
    "class Speaker(BaseModel):\n",
    "    \"\"\"Information about a person speaking in the conversation\"\"\"\n",
    "    name: Optional[str] = Field(default=None, description=\"Name of the speaker if mentioned\")\n",
    "    role: Optional[SpeakerRole] = Field(default=None, description=\"Role of the speaker in the conversation\")\n",
    "    company: Optional[str] = Field(default=None, description=\"Company they work for if mentioned\")\n",
    "\n",
    "class Challenge(BaseModel):\n",
    "    \"\"\"A challenge or problem mentioned in the conversation\"\"\"\n",
    "    description: Optional[str] = Field(default=None, description=\"Description of the challenge\")\n",
    "    impact: Optional[str] = Field(default=None, description=\"How this challenge affects them\")\n",
    "    urgency: Optional[str] = Field(default=None, description=\"Low, Medium, or High urgency\")\n",
    "\n",
    "class CurrentSolution(BaseModel):\n",
    "    \"\"\"How they currently solve their problems\"\"\"\n",
    "    solution: Optional[str] = Field(default=None, description=\"What they're currently doing\")\n",
    "    satisfaction_level: Optional[str] = Field(default=None, description=\"How satisfied they are: Very Satisfied, Satisfied, Neutral, Unsatisfied, Very Unsatisfied\")\n",
    "    limitations: Optional[List[str]] = Field(default=[], description=\"Limitations of current solution\")\n",
    "\n",
    "class Need(BaseModel):\n",
    "    \"\"\"A need identified using psychology frameworks like NVC\"\"\"\n",
    "    need_category: Optional[str] = Field(default=None, description=\"Category of need (e.g., autonomy, efficiency, security, connection)\")\n",
    "    description: Optional[str] = Field(default=None, description=\"Specific need description\")\n",
    "    intensity: Optional[str] = Field(default=None, description=\"Low, Medium, or High intensity\")\n",
    "\n",
    "class ExtractedInsights(BaseModel):\n",
    "    \"\"\"Complete structured output from conversation analysis\"\"\"\n",
    "    \n",
    "    # Speakers\n",
    "    speakers: Optional[List[Speaker]] = Field(default=[], description=\"People identified in the conversation\")\n",
    "    \n",
    "    # What they care about\n",
    "    core_values: Optional[List[str]] = Field(default=[], description=\"What this person/company cares about most\")\n",
    "    priorities: Optional[List[str]] = Field(default=[], description=\"Their current priorities and focus areas\")\n",
    "    \n",
    "    # Challenges\n",
    "    primary_challenges: Optional[List[Challenge]] = Field(default=[], description=\"Main problems they're facing\")\n",
    "    secondary_challenges: Optional[List[Challenge]] = Field(default=[], description=\"Secondary or related problems\")\n",
    "    \n",
    "    # Current solutions\n",
    "    current_solutions: Optional[List[CurrentSolution]] = Field(default=[], description=\"How they solve problems today\")\n",
    "    \n",
    "    # Needs analysis\n",
    "    psychological_needs: Optional[List[Need]] = Field(default=[], description=\"Underlying needs using NVC or similar frameworks\")\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19fad4ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ State defined\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Define LangGraph State\n",
    "class AudioPipelineState(TypedDict):\n",
    "    file_path: str\n",
    "    filename: str\n",
    "    transcript_text: Optional[str]\n",
    "    conversation_id: Optional[int]\n",
    "    extracted_insights: Optional[ExtractedInsights]  # ‚Üê NEW: Using our Pydantic model\n",
    "    error: Optional[str]\n",
    "    status: str\n",
    "\n",
    "print(\"‚úÖ State defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5cabeaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ AssemblyAI connection successful\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 4: Test AssemblyAI Connection\n",
    "# Configure AssemblyAI\n",
    "aai.settings.api_key = os.getenv('ASSEMBLYAI_API_KEY')\n",
    "\n",
    "# Test with a simple transcription (we'll use a file from temp folder)\n",
    "def test_assemblyai_connection():\n",
    "    \"\"\"Test if AssemblyAI is working\"\"\"\n",
    "    try:\n",
    "        # Just test the API key is valid\n",
    "        transcriber = aai.Transcriber()\n",
    "        print(\"‚úÖ AssemblyAI connection successful\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå AssemblyAI connection failed: {e}\")\n",
    "        return False\n",
    "\n",
    "test_assemblyai_connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01335e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä BATCH PROCESSING INFO:\n",
      "   Files to process: 1\n",
      "   Total size: 321.2 MB\n",
      "\n",
      "üìÅ Files found:\n",
      "   1. blog_record_(christian).wav (321.2 MB)\n",
      "\n",
      "üöÄ Ready to process 1 files!\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Batch File Discovery and Management\n",
    "def find_audio_files(temp_folder: Path) -> List[Path]:\n",
    "    \"\"\"Find all audio files in temp folder\"\"\"\n",
    "    audio_extensions = ['*.wav', '*.mp3', '*.m4a']\n",
    "    audio_files = []\n",
    "    \n",
    "    for ext in audio_extensions:\n",
    "        audio_files.extend(temp_folder.glob(ext))\n",
    "    \n",
    "    return sorted(audio_files)\n",
    "\n",
    "def display_batch_info(audio_files: List[Path]):\n",
    "    \"\"\"Display information about the batch of files\"\"\"\n",
    "    if not audio_files:\n",
    "        print(\"‚ùå No audio files found in temp folder!\")\n",
    "        return False\n",
    "    \n",
    "    total_size_mb = sum(f.stat().st_size for f in audio_files) / (1024 * 1024)\n",
    "    \n",
    "    print(f\"üìä BATCH PROCESSING INFO:\")\n",
    "    print(f\"   Files to process: {len(audio_files)}\")\n",
    "    print(f\"   Total size: {total_size_mb:.1f} MB\")\n",
    "    print(f\"\\nüìÅ Files found:\")\n",
    "    \n",
    "    for i, file_path in enumerate(audio_files, 1):\n",
    "        size_mb = file_path.stat().st_size / (1024 * 1024)\n",
    "        print(f\"   {i}. {file_path.name} ({size_mb:.1f} MB)\")\n",
    "    \n",
    "    return True\n",
    "\n",
    "def cleanup_processed_files(processed_files: List[Path]):\n",
    "    \"\"\"Delete all successfully processed files\"\"\"\n",
    "    print(f\"\\nüóëÔ∏è CLEANUP: Deleting {len(processed_files)} processed files...\")\n",
    "    deleted_count = 0\n",
    "    \n",
    "    for file_path in processed_files:\n",
    "        try:\n",
    "            file_path.unlink()  # Delete file\n",
    "            print(f\"   ‚úÖ Deleted: {file_path.name}\")\n",
    "            deleted_count += 1\n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå Failed to delete {file_path.name}: {e}\")\n",
    "    \n",
    "    print(f\"üóëÔ∏è Cleanup complete: {deleted_count}/{len(processed_files)} files deleted\")\n",
    "\n",
    "# Discover files in temp folder\n",
    "temp_folder = project_root / 'data' / 'temp'\n",
    "temp_folder.mkdir(parents=True, exist_ok=True)  # Ensure folder exists\n",
    "\n",
    "audio_files = find_audio_files(temp_folder)\n",
    "files_available = display_batch_info(audio_files)\n",
    "\n",
    "if files_available:\n",
    "    print(f\"\\nüöÄ Ready to process {len(audio_files)} files!\")\n",
    "else:\n",
    "    print(\"\\nüí° TIP: Add .wav files to data/temp/ folder for testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c90af3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Batch processing function ready with full insights display\n"
     ]
    }
   ],
   "source": [
    "# Batch Processing Function (Updated with Full Insights Display)\n",
    "def process_audio_batch(audio_files: List[Path], pipeline) -> dict:\n",
    "    \"\"\"Process all audio files in batch with detailed insights display\"\"\"\n",
    "    \n",
    "    if not audio_files:\n",
    "        print(\"‚ùå No files to process\")\n",
    "        return {\"processed\": [], \"failed\": [], \"total\": 0}\n",
    "    \n",
    "    print(f\"\\nüöÄ STARTING BATCH PROCESSING - {len(audio_files)} files\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    processed_files = []\n",
    "    failed_files = []\n",
    "    results = []\n",
    "    \n",
    "    for i, file_path in enumerate(audio_files, 1):\n",
    "        print(f\"\\nüìÇ Processing {i}/{len(audio_files)}: {file_path.name}\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        # Create initial state\n",
    "        initial_state = {\n",
    "            \"file_path\": str(file_path),\n",
    "            \"filename\": file_path.name,\n",
    "            \"transcript_text\": None,\n",
    "            \"conversation_id\": None,\n",
    "            \"extracted_insights\": None,  \n",
    "            \"error\": None,\n",
    "            \"status\": \"processing\"\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            # Run through pipeline\n",
    "            result = pipeline.invoke(initial_state)\n",
    "            \n",
    "            if result[\"status\"] in [\"completed\", \"insights_extracted\"]:\n",
    "                print(f\"‚úÖ SUCCESS: {file_path.name}\")\n",
    "                print(f\"   Conversation ID: {result['conversation_id']}\")\n",
    "                print(f\"   Transcript preview: {result['transcript_text'][:100]}...\")\n",
    "                \n",
    "                # FULL INSIGHTS DISPLAY\n",
    "                if result.get('extracted_insights'):\n",
    "                    insights = result['extracted_insights']\n",
    "                    print(f\"\\nüß† === EXTRACTED INSIGHTS FOR: {file_path.name} ===\")\n",
    "                    print(\"=\" * 50)\n",
    "                    \n",
    "                    # Speakers\n",
    "                    if insights.speakers:\n",
    "                        print(\"üë• SPEAKERS:\")\n",
    "                        for speaker in insights.speakers:\n",
    "                            print(f\"   ‚Ä¢ Name: {speaker.name or 'Unknown'}\")\n",
    "                            print(f\"     Role: {speaker.role or 'Unknown'}\")  \n",
    "                            print(f\"     Company: {speaker.company or 'Unknown'}\")\n",
    "                    \n",
    "                    # Core Values\n",
    "                    if insights.core_values:\n",
    "                        print(\"üíé CORE VALUES:\")\n",
    "                        for value in insights.core_values:\n",
    "                            print(f\"   ‚Ä¢ {value}\")\n",
    "                    \n",
    "                    # Priorities\n",
    "                    if insights.priorities:\n",
    "                        print(\"üéØ PRIORITIES:\")\n",
    "                        for priority in insights.priorities:\n",
    "                            print(f\"   ‚Ä¢ {priority}\")\n",
    "                    \n",
    "                    # Primary Challenges\n",
    "                    if insights.primary_challenges:\n",
    "                        print(\"üî• PRIMARY CHALLENGES:\")\n",
    "                        for challenge in insights.primary_challenges:\n",
    "                            print(f\"   ‚Ä¢ Challenge: {challenge.description}\")\n",
    "                            print(f\"     Impact: {challenge.impact}\")\n",
    "                            print(f\"     Urgency: {challenge.urgency}\")\n",
    "                    \n",
    "                    # Secondary Challenges\n",
    "                    if insights.secondary_challenges:\n",
    "                        print(\"‚ö†Ô∏è  SECONDARY CHALLENGES:\")\n",
    "                        for challenge in insights.secondary_challenges:\n",
    "                            print(f\"   ‚Ä¢ Challenge: {challenge.description}\")\n",
    "                            print(f\"     Impact: {challenge.impact}\")\n",
    "                            print(f\"     Urgency: {challenge.urgency}\")\n",
    "                    \n",
    "                    # Current Solutions\n",
    "                    if insights.current_solutions:\n",
    "                        print(\"üîß CURRENT SOLUTIONS:\")\n",
    "                        for solution in insights.current_solutions:\n",
    "                            print(f\"   ‚Ä¢ Solution: {solution.solution}\")\n",
    "                            print(f\"     Satisfaction: {solution.satisfaction_level}\")\n",
    "                            if solution.limitations:\n",
    "                                print(f\"     Limitations: {', '.join(solution.limitations)}\")\n",
    "                    \n",
    "                    # Psychological Needs\n",
    "                    if insights.psychological_needs:\n",
    "                        print(\"üßò PSYCHOLOGICAL NEEDS:\")\n",
    "                        for need in insights.psychological_needs:\n",
    "                            print(f\"   ‚Ä¢ {need.description}\")\n",
    "                            print(f\"     Category: {need.need_category}\")\n",
    "                            print(f\"     Intensity: {need.intensity}\")\n",
    "                    \n",
    "                    print(\"üß† === END INSIGHTS ===\")\n",
    "                    print(\"-\" * 50)\n",
    "                \n",
    "                processed_files.append(file_path)\n",
    "            else:\n",
    "                print(f\"‚ùå FAILED: {file_path.name}\")\n",
    "                print(f\"   Status: {result.get('status', 'Unknown')}\")\n",
    "                print(f\"   Error: {result.get('error', 'Unknown error')}\")\n",
    "                failed_files.append(file_path)\n",
    "            \n",
    "            results.append(result)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå PIPELINE ERROR: {file_path.name}\")\n",
    "            print(f\"   Exception: {str(e)}\")\n",
    "            failed_files.append(file_path)\n",
    "            \n",
    "            results.append({\n",
    "                **initial_state,\n",
    "                \"error\": str(e),\n",
    "                \"status\": \"pipeline_error\"\n",
    "            })\n",
    "    \n",
    "    # Final Summary\n",
    "    print(f\"\\nüìä BATCH PROCESSING COMPLETE!\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"‚úÖ Successfully processed: {len(processed_files)}\")\n",
    "    print(f\"‚ùå Failed: {len(failed_files)}\")\n",
    "    print(f\"üìÅ Total files: {len(audio_files)}\")\n",
    "    \n",
    "    if failed_files:\n",
    "        print(f\"\\n‚ùå Failed files:\")\n",
    "        for failed_file in failed_files:\n",
    "            print(f\"   - {failed_file.name}\")\n",
    "    \n",
    "    return {\n",
    "        \"processed\": processed_files,\n",
    "        \"failed\": failed_files,\n",
    "        \"total\": len(audio_files),\n",
    "        \"results\": results\n",
    "    }\n",
    "\n",
    "print(\"‚úÖ Batch processing function ready with full insights display\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "419ae62d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ LangGraph nodes defined\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Define LangGraph Nodes\n",
    "def transcription_node(state: AudioPipelineState) -> AudioPipelineState:\n",
    "    \"\"\"Node 1: Transcribe audio file with AssemblyAI\"\"\"\n",
    "    try:\n",
    "        print(f\"üéôÔ∏è Transcribing: {state['filename']}\")\n",
    "        \n",
    "        # Configure transcriber\n",
    "        transcriber = aai.Transcriber()\n",
    "        \n",
    "        # Transcribe the file\n",
    "        transcript = transcriber.transcribe(state['file_path'])\n",
    "        \n",
    "        if transcript.status == aai.TranscriptStatus.error:\n",
    "            return {\n",
    "                **state,\n",
    "                \"error\": f\"AssemblyAI error: {transcript.error}\",\n",
    "                \"status\": \"transcription_failed\"\n",
    "            }\n",
    "        \n",
    "        return {\n",
    "            **state,\n",
    "            \"transcript_text\": transcript.text,\n",
    "            \"status\": \"transcribed\"\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            **state,\n",
    "            \"error\": f\"Transcription error: {str(e)}\",\n",
    "            \"status\": \"transcription_failed\"\n",
    "        }\n",
    "\n",
    "def database_saver_node(state: AudioPipelineState) -> AudioPipelineState:\n",
    "    \"\"\"Node 2: Save transcript to database\"\"\"\n",
    "    try:\n",
    "        print(f\"üíæ Saving to database: {state['filename']}\")\n",
    "        \n",
    "        # Create conversation object\n",
    "        conversation = ConversationCreate(\n",
    "            title=f\"Audio: {state['filename']}\",\n",
    "            raw_text=state['transcript_text'],\n",
    "            source=\"transcribed\"\n",
    "        )\n",
    "        \n",
    "        # Save to database\n",
    "        conversation_id = db.create_conversation(conversation)\n",
    "        \n",
    "        return {\n",
    "            **state,\n",
    "            \"conversation_id\": conversation_id,\n",
    "            \"status\": \"completed\"\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            **state,\n",
    "            \"error\": f\"Database error: {str(e)}\",\n",
    "            \"status\": \"database_failed\"\n",
    "        }\n",
    "\n",
    "print(\"‚úÖ LangGraph nodes defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c379c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ LangGraph pipeline compiled (3 nodes: transcribe ‚Üí save_to_db ‚Üí extract_insights)\n"
     ]
    }
   ],
   "source": [
    "# Cell: Build Current Pipeline (3 Nodes)\n",
    "def build_pipeline():\n",
    "    \"\"\"Build the current LangGraph workflow with transcription, save, and insights\"\"\"\n",
    "    workflow = StateGraph(AudioPipelineState)\n",
    "    \n",
    "    # Add current nodes\n",
    "    workflow.add_node(\"transcribe\", transcription_node)\n",
    "    workflow.add_node(\"save_to_db\", database_saver_node)  \n",
    "    workflow.add_node(\"extract_insights\", pain_extractor_node)\n",
    "    \n",
    "    # Chain them together\n",
    "    workflow.add_edge(\"transcribe\", \"save_to_db\")\n",
    "    workflow.add_edge(\"save_to_db\", \"extract_insights\")\n",
    "    \n",
    "    workflow.set_entry_point(\"transcribe\")\n",
    "    workflow.set_finish_point(\"extract_insights\")\n",
    "    \n",
    "    return workflow.compile()\n",
    "\n",
    "# Build the pipeline\n",
    "pipeline = build_pipeline()\n",
    "print(\"‚úÖ LangGraph pipeline compiled (3 nodes: transcribe ‚Üí save_to_db ‚Üí extract_insights)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47a45a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Found 0 conversations to delete:\n",
      "‚ùå Deletion cancelled\n"
     ]
    }
   ],
   "source": [
    "# Cell: Clean Conversations Table\n",
    "def clean_conversations_table():\n",
    "    \"\"\"Delete all records from conversations table\"\"\"\n",
    "    \n",
    "    # First show what will be deleted\n",
    "    conversations = db.get_all_conversations()\n",
    "    print(f\"üìä Found {len(conversations)} conversations to delete:\")\n",
    "    for conv in conversations[:5]:  # Show first 5\n",
    "        print(f\"  - ID {conv.id}: {conv.title}\")\n",
    "    if len(conversations) > 5:\n",
    "        print(f\"  ... and {len(conversations) - 5} more\")\n",
    "    \n",
    "    # Ask for confirmation\n",
    "    response = input(f\"\\n‚ùì Delete all {len(conversations)} conversations? (y/N): \")\n",
    "    \n",
    "    if response.lower() in ['y', 'yes']:\n",
    "        conn = db.get_connection()\n",
    "        try:\n",
    "            cursor = conn.cursor()\n",
    "            \n",
    "            # Delete all conversations (this will also delete related blog_post_ideas due to foreign key)\n",
    "            cursor.execute(\"DELETE FROM blog_post_ideas\")\n",
    "            cursor.execute(\"DELETE FROM processing_status\") \n",
    "            cursor.execute(\"DELETE FROM conversations\")\n",
    "            conn.commit()\n",
    "            \n",
    "            print(\"‚úÖ All conversations deleted!\")\n",
    "            print(\"‚úÖ Related blog ideas deleted!\")\n",
    "            print(\"‚úÖ Processing status cleared!\")\n",
    "            \n",
    "        finally:\n",
    "            conn.close()\n",
    "    else:\n",
    "        print(\"‚ùå Deletion cancelled\")\n",
    "\n",
    "# Run the cleaner\n",
    "clean_conversations_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4cb00a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Starting batch processing...\n",
      "\n",
      "üöÄ STARTING BATCH PROCESSING - 1 files\n",
      "============================================================\n",
      "\n",
      "üìÇ Processing 1/1: blog_record_(christian).wav\n",
      "----------------------------------------\n",
      "üéôÔ∏è Transcribing: blog_record_(christian).wav\n",
      "üíæ Saving to database: blog_record_(christian).wav\n",
      "üß† Starting pain extraction...\n",
      "‚úÖ Extracted insights: 2 primary challenges, 1 speakers\n",
      "‚úÖ SUCCESS: blog_record_(christian).wav\n",
      "   Conversation ID: 11\n",
      "   Transcript preview: So you can start telling your name and the company for which you work and what do you do in your com...\n",
      "\n",
      "üß† === EXTRACTED INSIGHTS FOR: blog_record_(christian).wav ===\n",
      "==================================================\n",
      "üë• SPEAKERS:\n",
      "   ‚Ä¢ Name: Chris\n",
      "     Role: SpeakerRole.CLIENT\n",
      "     Company: Fast Track\n",
      "üíé CORE VALUES:\n",
      "   ‚Ä¢ strengths-based consulting\n",
      "   ‚Ä¢ differentiation\n",
      "   ‚Ä¢ creativity\n",
      "üéØ PRIORITIES:\n",
      "   ‚Ä¢ using AI to streamline proposal writing process\n",
      "   ‚Ä¢ developing creative and differentiated proposals\n",
      "üî• PRIMARY CHALLENGES:\n",
      "   ‚Ä¢ Challenge: Balancing the need to differentiate proposals with the constraints of request for proposal (RFP) structures\n",
      "     Impact: Difficulty in creating winning proposals\n",
      "     Urgency: High\n",
      "   ‚Ä¢ Challenge: Limitations of current AI capabilities in providing creative and differentiated proposal content\n",
      "     Impact: Reliance on manual, time-consuming proposal drafting process\n",
      "     Urgency: High\n",
      "‚ö†Ô∏è  SECONDARY CHALLENGES:\n",
      "   ‚Ä¢ Challenge: Streamlining the proposal drafting process across multiple contributors and constraints\n",
      "     Impact: Inefficiencies in proposal development\n",
      "     Urgency: Medium\n",
      "üîß CURRENT SOLUTIONS:\n",
      "   ‚Ä¢ Solution: Using AI tools (e.g., Copilot, Perplexity) for research, summarization, and text generation\n",
      "     Satisfaction: Neutral\n",
      "     Limitations: AI lacks the ability to capture the company's unique values and methodology, AI is limited in providing creative and differentiated proposal content\n",
      "   ‚Ä¢ Solution: Collaborative proposal drafting using Microsoft 365 tools\n",
      "     Satisfaction: Satisfied\n",
      "     Limitations: Inefficiencies in managing multiple contributors and constraints\n",
      "üßò PSYCHOLOGICAL NEEDS:\n",
      "   ‚Ä¢ Reducing time and effort spent on proposal drafting\n",
      "     Category: efficiency\n",
      "     Intensity: High\n",
      "   ‚Ä¢ Ability to create unique and creative proposals that align with the company's values and methodology\n",
      "     Category: differentiation\n",
      "     Intensity: High\n",
      "üß† === END INSIGHTS ===\n",
      "--------------------------------------------------\n",
      "\n",
      "üìä BATCH PROCESSING COMPLETE!\n",
      "============================================================\n",
      "‚úÖ Successfully processed: 1\n",
      "‚ùå Failed: 0\n",
      "üìÅ Total files: 1\n",
      "\n",
      "üìä BATCH PROCESSING COMPLETE!\n",
      "============================================================\n",
      "‚úÖ Successfully processed: 1\n",
      "‚ùå Failed: 0\n",
      "üìÅ Total files: 1\n",
      "\n",
      "üóëÔ∏è CLEANUP: Deleting 1 processed files...\n",
      "   ‚úÖ Deleted: blog_record_(christian).wav\n",
      "üóëÔ∏è Cleanup complete: 1/1 files deleted\n",
      "\n",
      "üéâ Batch processing complete!\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: Execute Batch Processing with Cleanup\n",
    "if files_available:\n",
    "    print(\"üéØ Starting batch processing...\")\n",
    "    \n",
    "    # Process all files\n",
    "    batch_results = process_audio_batch(audio_files, pipeline)\n",
    "    \n",
    "    # Display summary\n",
    "    print(f\"\\nüìä BATCH PROCESSING COMPLETE!\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"‚úÖ Successfully processed: {len(batch_results['processed'])}\")\n",
    "    print(f\"‚ùå Failed: {len(batch_results['failed'])}\")\n",
    "    print(f\"üìÅ Total files: {batch_results['total']}\")\n",
    "    \n",
    "    # Show failed files\n",
    "    if batch_results['failed']:\n",
    "        print(f\"\\n‚ùå Failed files:\")\n",
    "        for file_path in batch_results['failed']:\n",
    "            print(f\"   - {file_path.name}\")\n",
    "    \n",
    "    # Cleanup successfully processed files\n",
    "    if batch_results['processed']:\n",
    "        confirm = input(f\"\\nüóëÔ∏è Delete {len(batch_results['processed'])} processed files? (y/N): \")\n",
    "        if confirm.lower() in ['y', 'yes']:\n",
    "            cleanup_processed_files(batch_results['processed'])\n",
    "        else:\n",
    "            print(\"üîß Files kept in temp folder for inspection\")\n",
    "    \n",
    "    print(\"\\nüéâ Batch processing complete!\")\n",
    "    \n",
    "else:\n",
    "    print(\"üí° Add audio files to data/temp/ folder and rerun this cell\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eeaef0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Anthropic LLM initialized with Claude 3 Haiku (March 2024)\n"
     ]
    }
   ],
   "source": [
    "# Cell: Setup Anthropic LLM (UPDATED)\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "import json\n",
    "\n",
    "# Initialize Anthropic with correct current model name\n",
    "anthropic_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "if not anthropic_key:\n",
    "    print(\"‚ö†Ô∏è  ANTHROPIC_API_KEY not found in .env file\")\n",
    "    print(\"Please add: ANTHROPIC_API_KEY=your_key_here\")\n",
    "else:\n",
    "    llm = ChatAnthropic(\n",
    "        model=\"claude-3-haiku-20240307\",  # ‚Üê Try this model instead\n",
    "        api_key=anthropic_key,\n",
    "        temperature=0.1\n",
    "    )\n",
    "    print(\"‚úÖ Anthropic LLM initialized with Claude 3 Haiku (March 2024)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2ab15ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Claude model test successful!\n",
      "Response: Hello, I am Claude and I am working!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test Cell: Verify Model Works\n",
    "def test_claude_model():\n",
    "    \"\"\"Test if the Claude model is accessible\"\"\"\n",
    "    try:\n",
    "        test_response = llm.invoke(\"Say 'Hello, I am Claude and I am working!'\")\n",
    "        print(\"‚úÖ Claude model test successful!\")\n",
    "        print(f\"Response: {test_response.content}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Claude model test failed: {e}\")\n",
    "        return False\n",
    "\n",
    "# Run the test\n",
    "test_claude_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b3cea20",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3. PainExtractor Node Implementation\n",
    "\n",
    "\n",
    "import openai\n",
    "import json\n",
    "from typing import Dict, Any\n",
    "\n",
    "# System prompt\n",
    "PAIN_EXTRACTOR_SYSTEM_PROMPT = \"\"\"\n",
    "You are a UX researcher and business analyst for BigKids Automation. Your job is listening to transcripts from interviews with users and potential clients. \n",
    "\n",
    "You pay special attention to problems that users have regarding how their company is automating, using web apps and AI to save time and move towards a more ethical and sovereign tech infrastructure.\n",
    "\n",
    "You will be given the transcript of an interview with a user or potential client.\n",
    "\n",
    "Your task is to extract structured information about:\n",
    "- Who is speaking and their role\n",
    "- What this person cares about (values, priorities)\n",
    "- Their main primary and secondary challenges\n",
    "- How they are solving problems today\n",
    "- Are there AI agents that can assist them?\n",
    "- Their underlying psychological needs (using frameworks like NVC - Non-Violent Communication)\n",
    "\n",
    "Focus on automation, web apps, AI, time-saving, ethical tech, and sovereign infrastructure themes.\n",
    "\n",
    "Be thorough but concise. \n",
    "\n",
    "IMPORTANT: Only extract information that is explicitly mentioned in the transcript. \n",
    "If information is not clearly stated, leave the field empty/null rather than guessing or inferring.\n",
    "Do not hallucinate or make assumptions about missing information.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "819a4829",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_insights_from_transcript(transcript: str) -> ExtractedInsights:\n",
    "    \"\"\"Extract structured insights using Anthropic Claude with proper JSON structure\"\"\"\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    Analyze this conversation transcript and extract structured insights in the exact JSON format below:\n",
    "\n",
    "    Transcript: {transcript}\n",
    "\n",
    "    Return ONLY valid JSON in this exact structure:\n",
    "    {{\n",
    "        \"speakers\": [\n",
    "            {{\n",
    "                \"name\": \"Hugo\",\n",
    "                \"role\": \"client\", \n",
    "                \"company\": \"Drone flytech\"\n",
    "            }}\n",
    "        ],\n",
    "        \"core_values\": [\"efficiency\", \"transparency\"],\n",
    "        \"priorities\": [\"improving financial processes\"],\n",
    "        \"primary_challenges\": [\n",
    "            {{\n",
    "                \"description\": \"Tracking who paid which invoice\",\n",
    "                \"impact\": \"Creates confusion in financial processes\",\n",
    "                \"urgency\": \"High\"\n",
    "            }}\n",
    "        ],\n",
    "        \"secondary_challenges\": [],\n",
    "        \"current_solutions\": [\n",
    "            {{\n",
    "                \"solution\": \"Using MoneyOak software\",\n",
    "                \"satisfaction_level\": \"Unsatisfied\", \n",
    "                \"limitations\": [\"inadequate functionality\", \"limited visibility\"]\n",
    "            }}\n",
    "        ],\n",
    "        \"psychological_needs\": [\n",
    "            {{\n",
    "                \"need_category\": \"security\",\n",
    "                \"description\": \"Confidence in financial operations\",\n",
    "                \"intensity\": \"High\"\n",
    "            }}\n",
    "        ]\n",
    "    }}\n",
    "\n",
    "    Important: \n",
    "    - Return ONLY the JSON, no other text\n",
    "    - Use exact field names as shown\n",
    "    - For urgency use: \"Low\", \"Medium\", or \"High\"\n",
    "    - For satisfaction_level use: \"Very Satisfied\", \"Satisfied\", \"Neutral\", \"Unsatisfied\", \"Very Unsatisfied\"\n",
    "    - For intensity use: \"Low\", \"Medium\", or \"High\"\n",
    "    - For speaker role use: \"client\" or \"interviewer\"\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Use the Claude LLM\n",
    "        response = llm.invoke(prompt)\n",
    "        \n",
    "        # Parse the JSON response\n",
    "        insights_data = json.loads(response.content)\n",
    "        \n",
    "        # Convert to Pydantic model\n",
    "        return ExtractedInsights(**insights_data)\n",
    "        \n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"‚ùå JSON parsing error: {e}\")\n",
    "        print(f\"üìù Raw response: {response.content[:500]}...\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error in LLM call: {e}\")\n",
    "        raise\n",
    "def pain_extractor_node(state: AudioPipelineState) -> AudioPipelineState:\n",
    "    \"\"\"\n",
    "    LangGraph node: Extract structured insights from conversation transcript\n",
    "    \"\"\"\n",
    "    print(\"üß† Starting pain extraction...\")\n",
    "    \n",
    "    try:\n",
    "        # Extract insights using OpenAI structured output\n",
    "        insights = extract_insights_from_transcript(state['transcript_text'])\n",
    "        \n",
    "        if insights:\n",
    "            print(f\"‚úÖ Extracted insights: {len(insights.primary_challenges)} primary challenges, {len(insights.speakers)} speakers\")\n",
    "            \n",
    "            return {\n",
    "                **state,\n",
    "                \"extracted_insights\": insights,\n",
    "                \"status\": \"insights_extracted\"\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                **state,\n",
    "                \"error\": \"Failed to extract insights from transcript\",\n",
    "                \"status\": \"error\"\n",
    "            }\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Pain extraction failed: {e}\")\n",
    "        return {\n",
    "            **state,\n",
    "            \"error\": f\"Pain extraction error: {str(e)}\",\n",
    "            \"status\": \"error\"\n",
    "        }\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
