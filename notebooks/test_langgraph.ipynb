{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "94470f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Current directory: /home/manuel/Documents/tech/ai_content_ops/notebooks\n",
      "üìÅ Current directory name: notebooks\n",
      "üìÅ Project root: /home/manuel/Documents/tech/ai_content_ops\n",
      "üìÅ Database path: /home/manuel/Documents/tech/ai_content_ops/database\n",
      "‚úÖ Database folder exists: True\n",
      "‚úÖ Already in Python path\n",
      "\n",
      "üìã Python path (first 3):\n",
      "   1. /home/manuel/Documents/tech/ai_content_ops\n",
      "   2. /usr/lib/python313.zip\n",
      "   3. /usr/lib/python3.13\n",
      "‚úÖ Standard library imports loaded\n",
      "‚úÖ Loaded .env from: /home/manuel/Documents/tech/ai_content_ops/.env\n",
      "‚úÖ Third-party imports loaded\n",
      "‚úÖ Database imports loaded\n",
      "\n",
      "üéâ All imports loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CELL 1: IMPORTS & SETUP\n",
    "# ============================================================\n",
    "\n",
    "# --- PATH SETUP (MUST BE FIRST) ---\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Get current directory (should be notebooks/)\n",
    "current_dir = Path.cwd()\n",
    "print(f\"üìÅ Current directory: {current_dir}\")\n",
    "print(f\"üìÅ Current directory name: {current_dir.name}\")\n",
    "\n",
    "# Go up one level to project root\n",
    "project_root = current_dir.parent\n",
    "print(f\"üìÅ Project root: {project_root}\")\n",
    "\n",
    "# Verify database folder exists\n",
    "database_path = project_root / 'database'\n",
    "print(f\"üìÅ Database path: {database_path}\")\n",
    "print(f\"‚úÖ Database folder exists: {database_path.exists()}\")\n",
    "\n",
    "# Add project root to Python path\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "    print(f\"‚úÖ Added to Python path: {project_root}\")\n",
    "else:\n",
    "    print(f\"‚úÖ Already in Python path\")\n",
    "\n",
    "print(f\"\\nüìã Python path (first 3):\")\n",
    "for i, p in enumerate(sys.path[:3], 1):\n",
    "    print(f\"   {i}. {p}\")\n",
    "\n",
    "\n",
    "# --- STANDARD LIBRARY IMPORTS ---\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import sqlite3\n",
    "import glob\n",
    "from typing import TypedDict, Optional, List, Dict, Any\n",
    "from datetime import datetime\n",
    "from enum import Enum\n",
    "\n",
    "print(\"‚úÖ Standard library imports loaded\")\n",
    "\n",
    "\n",
    "# --- ENVIRONMENT & CONFIGURATION ---\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from project root\n",
    "env_path = project_root / '.env'\n",
    "if env_path.exists():\n",
    "    load_dotenv(env_path)\n",
    "    print(f\"‚úÖ Loaded .env from: {env_path}\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è  .env not found at: {env_path}\")\n",
    "\n",
    "\n",
    "# --- THIRD-PARTY ML/AI ---\n",
    "import assemblyai as aai\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langgraph.graph import StateGraph\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.messages import SystemMessage, HumanMessage  # NEW: Required for message structuring\n",
    "import json\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "print(\"‚úÖ Third-party imports loaded\")\n",
    "\n",
    "\n",
    "# --- DATABASE IMPORTS ---\n",
    "from database.db_operations import db\n",
    "from database.models import Conversation, ConversationCreate\n",
    "\n",
    "print(\"‚úÖ Database imports loaded\")\n",
    "print(\"\\nüéâ All imports loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb001904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AssemblyAI API Key loaded: ‚úÖ\n",
      "Key starts with: 972365f41d...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Cell 2 \n",
    "\n",
    "# Test API key\n",
    "assemblyai_key = os.getenv('ASSEMBLYAI_API_KEY')\n",
    "print(f\"AssemblyAI API Key loaded: {'‚úÖ' if assemblyai_key else '‚ùå'}\")\n",
    "print(f\"Key starts with: {assemblyai_key[:10] if assemblyai_key else 'None'}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08a6571a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ LangSmith tracing enabled\n",
      "   Project: ai_content_ops\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CELL 3: LANGSMITH TRACING SETUP (OPTIONAL)\n",
    "# ============================================================\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables if not already loaded\n",
    "load_dotenv()\n",
    "\n",
    "# Get LangSmith API key from environment\n",
    "langsmith_api_key = os.getenv(\"LANGSMITH_API_KEY\")\n",
    "\n",
    "if langsmith_api_key:\n",
    "    # Enable LangSmith tracing\n",
    "    os.environ[\"LANGSMITH_API_KEY\"] = langsmith_api_key\n",
    "    os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "    os.environ[\"LANGCHAIN_PROJECT\"] = \"ai_content_ops_n8\"\n",
    "    print(\"‚úÖ LangSmith tracing enabled\")\n",
    "    print(f\"   Project: ai_content_ops\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  LANGSMITH_API_KEY not found in .env\")\n",
    "    print(\"   LangSmith tracing disabled\")\n",
    "    print(\"   üí° Add LANGSMITH_API_KEY to your .env file to enable tracing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cc1fee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Tables in app.db:\n",
      "\n",
      "üîß conversations:\n",
      "   - id (INTEGER)\n",
      "   - title (TEXT)\n",
      "   - raw_text (TEXT)\n",
      "   - source (TEXT)\n",
      "   - word_count (INTEGER)\n",
      "   - created_at (DATETIME)\n",
      "   - status (TEXT)\n",
      "\n",
      "üîß sqlite_sequence:\n",
      "   - name ()\n",
      "   - seq ()\n",
      "\n",
      "üîß blog_post_ideas:\n",
      "   - id (INTEGER)\n",
      "   - conversation_id (INTEGER)\n",
      "   - title (TEXT)\n",
      "   - description (TEXT)\n",
      "   - usefulness_potential (INTEGER)\n",
      "   - fitwith_seo_strategy (INTEGER)\n",
      "   - fitwith_content_strategy (INTEGER)\n",
      "   - inspiration_potential (INTEGER)\n",
      "   - collaboration_potential (INTEGER)\n",
      "   - innovation (INTEGER)\n",
      "   - difficulty (INTEGER)\n",
      "   - total_score (INTEGER)\n",
      "   - sent_to_prod (BOOLEAN)\n",
      "   - raw_llm_response (TEXT)\n",
      "   - created_at (DATETIME)\n",
      "\n",
      "üîß processing_status:\n",
      "   - id (INTEGER)\n",
      "   - conversation_id (INTEGER)\n",
      "   - stage (TEXT)\n",
      "   - status (TEXT)\n",
      "   - error_message (TEXT)\n",
      "   - started_at (DATETIME)\n",
      "   - completed_at (DATETIME)\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Database Connection Test\n",
    "\n",
    "conn = sqlite3.connect(\"data/app.db\")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Get all table names\n",
    "cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "tables = cursor.fetchall()\n",
    "\n",
    "print(\"üìä Tables in app.db:\")\n",
    "for table in tables:\n",
    "    table_name = table[0]\n",
    "    \n",
    "    # Get column info for each table\n",
    "    cursor.execute(f\"PRAGMA table_info({table_name})\")\n",
    "    columns = cursor.fetchall()\n",
    "    \n",
    "    print(f\"\\nüîß {table_name}:\")\n",
    "    for col in columns:\n",
    "        print(f\"   - {col[1]} ({col[2]})\")  # column_name (type)\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e30147df",
   "metadata": {},
   "outputs": [],
   "source": [
    "## cell 4. Pydantic Model for Structured Output\n",
    "\n",
    "\n",
    "\n",
    "class SpeakerRole(str, Enum):\n",
    "    \"\"\"Possible speaker roles in the conversation\"\"\"\n",
    "    CLIENT = \"client\"\n",
    "    INTERVIEWER = \"interviewer\"\n",
    "\n",
    "class Speaker(BaseModel):\n",
    "    \"\"\"Information about a person speaking in the conversation\"\"\"\n",
    "    name: Optional[str] = Field(default=None, description=\"Name of the speaker if mentioned\")\n",
    "    role: Optional[SpeakerRole] = Field(default=None, description=\"Role of the speaker in the conversation\")\n",
    "    company: Optional[str] = Field(default=None, description=\"Company they work for if mentioned\")\n",
    "\n",
    "class Challenge(BaseModel):\n",
    "    \"\"\"A challenge or problem mentioned in the conversation\"\"\"\n",
    "    description: Optional[str] = Field(default=None, description=\"Description of the challenge\")\n",
    "    impact: Optional[str] = Field(default=None, description=\"How this challenge affects them\")\n",
    "    urgency: Optional[str] = Field(default=None, description=\"Low, Medium, or High urgency\")\n",
    "\n",
    "class CurrentSolution(BaseModel):\n",
    "    \"\"\"How they currently solve their problems\"\"\"\n",
    "    solution: Optional[str] = Field(default=None, description=\"What they're currently doing\")\n",
    "    satisfaction_level: Optional[str] = Field(default=None, description=\"How satisfied they are: Very Satisfied, Satisfied, Neutral, Unsatisfied, Very Unsatisfied\")\n",
    "    limitations: Optional[List[str]] = Field(default=[], description=\"Limitations of current solution\")\n",
    "\n",
    "class Need(BaseModel):\n",
    "    \"\"\"A need identified using psychology frameworks like NVC\"\"\"\n",
    "    need_category: Optional[str] = Field(default=None, description=\"Category of need (e.g., autonomy, efficiency, security, connection)\")\n",
    "    description: Optional[str] = Field(default=None, description=\"Specific need description\")\n",
    "    intensity: Optional[str] = Field(default=None, description=\"Low, Medium, or High intensity\")\n",
    "\n",
    "class ExtractedInsights(BaseModel):\n",
    "    \"\"\"Complete structured output from conversation analysis\"\"\"\n",
    "    \n",
    "    # Speakers\n",
    "    speakers: Optional[List[Speaker]] = Field(default=[], description=\"People identified in the conversation\")\n",
    "    \n",
    "    # What they care about\n",
    "    core_values: Optional[List[str]] = Field(default=[], description=\"What this person/company cares about most\")\n",
    "    priorities: Optional[List[str]] = Field(default=[], description=\"Their current priorities and focus areas\")\n",
    "    \n",
    "    # Challenges\n",
    "    primary_challenges: Optional[List[Challenge]] = Field(default=[], description=\"Main problems they're facing\")\n",
    "    secondary_challenges: Optional[List[Challenge]] = Field(default=[], description=\"Secondary or related problems\")\n",
    "    \n",
    "    # Current solutions\n",
    "    current_solutions: Optional[List[CurrentSolution]] = Field(default=[], description=\"How they solve problems today\")\n",
    "    \n",
    "    # Needs analysis\n",
    "    psychological_needs: Optional[List[Need]] = Field(default=[], description=\"Underlying needs using NVC or similar frameworks\")\n",
    "\n",
    "class Plan(BaseModel):  # From your snippet\n",
    "    who: str = Field(description=\"Target reader of the blog post.\")\n",
    "    why: str = Field(description=\"Why are we writing this blog post.\")\n",
    "    what: str = Field(description=\"Main topics to cover.\")\n",
    "    the_issue: str = Field(description=\"Main issue or problem addressed.\")\n",
    "    where_we_stand: str = Field(description=\"Current position on the issue.\")\n",
    "    single_message: str = Field(description=\"Single most important message.\")\n",
    "    qa_pairs: List[Dict[str, str]] = Field(  # NEW: Added for your Q&A skeleton\n",
    "        default=[], description=\"List of dicts with 'question' and 'answer' to guide writer.\"\n",
    "    )\n",
    "    instructions: List[str] = Field(  # NEW: Added for writer instructions\n",
    "        default=[], description=\"Instructions to keep the writer focused.\"\n",
    "    )\n",
    "\n",
    "    @property\n",
    "    def plan(self) -> str:  # From your snippet, augmented\n",
    "        base = f\"Who: {self.who}\\nWhy: {self.why}\\nWhat: {self.what}\\nIssue: {self.the_issue}\\nWhere We Stand: {self.where_we_stand}\\nSingle Message: {self.single_message}\\n\"\n",
    "        qa_str = \"\\nQ&A Pairs:\\n\" + \"\\n\".join([f\"Q: {pair['question']} A: {pair['answer']}\" for pair in self.qa_pairs])\n",
    "        instr_str = \"\\nInstructions:\\n\" + \"\\n\".join(self.instructions)\n",
    "        return base + qa_str + instr_str\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89d86360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Simple RawBlogIdea model ready\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Raw Blog Idea Model (Simple)\n",
    "class RawBlogIdea(BaseModel):\n",
    "    \"\"\"Raw blog idea from creative agent\"\"\"\n",
    "    title: str\n",
    "    description: str\n",
    "    target_audience: str\n",
    "    content_angle: str\n",
    "    business_value: str\n",
    "\n",
    "print(\"‚úÖ Simple RawBlogIdea model ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77ecdfc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ RawBlogIdea model and validation ready\n"
     ]
    }
   ],
   "source": [
    "def validate_raw_blog_ideas(raw_ideas: List[Dict]) -> List[RawBlogIdea]:\n",
    "    \"\"\"Validate and convert raw JSON to Pydantic models\"\"\"\n",
    "    validated_ideas = []\n",
    "    \n",
    "    for idea in raw_ideas:\n",
    "        try:\n",
    "            validated_idea = RawBlogIdea(**idea)\n",
    "            validated_ideas.append(validated_idea)\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Invalid blog idea skipped: {e}\")\n",
    "    \n",
    "    print(f\"‚úÖ Validated {len(validated_ideas)} out of {len(raw_ideas)} raw ideas\")\n",
    "    return validated_ideas\n",
    "\n",
    "print(\"‚úÖ RawBlogIdea model and validation ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "399dbbb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Updated AudioPipelineState for 6-node pipeline\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Update AudioPipelineState for 5-Node Pipeline\n",
    "class AudioPipelineState(TypedDict):\n",
    "    # File info\n",
    "    file_path: str\n",
    "    filename: str\n",
    "    \n",
    "    # Processing results\n",
    "    transcript_text: Optional[str]\n",
    "    conversation_id: Optional[int]\n",
    "    extracted_insights: Optional[ExtractedInsights]\n",
    "    raw_blog_ideas: Optional[List[Dict]]        # From creative agent (Node 4)\n",
    "    scored_blog_ideas: Optional[List[Dict]]     # From analyst agent (Node 5) \n",
    "    saved_idea_ids: Optional[List[int]]         # From database saver (Node 6) \n",
    "    selected_idea_id: Optional[int]  # NEW: Human-selected idea ID from HITL\n",
    "    selected_idea: Optional[Dict]    # NEW: The actual selected idea dict (for convenience)\n",
    "    strategy_context: Optional[Dict[str, str]]  # NEW: Loaded company/SEO/content strategies\n",
    "    blog_plan: Optional[Plan]       # NEW: Generated plan (Pydantic-structured)\n",
    "    # For future writing node\n",
    "    blog_post: Optional[Dict]       # NEW: e.g., {\"title\": str, \"content\": str}\n",
    "    \n",
    "    \n",
    "    # Status & error handling\n",
    "    status: str\n",
    "    error: Optional[str]\n",
    "\n",
    "print(\"‚úÖ Updated AudioPipelineState for 6-node pipeline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ee2205ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def planning_agent_node(state: AudioPipelineState) -> AudioPipelineState:\n",
    "    \"\"\"Planning agent: Generates a blog post plan using strategies, insights, and selected idea.\"\"\"\n",
    "    # Load strategy context (from your snippet)\n",
    "    strategy_context = load_company_strategy_context()\n",
    "    state[\"strategy_context\"] = strategy_context\n",
    "    \n",
    "    # Access state data\n",
    "    insights = state.get(\"extracted_insights\")\n",
    "    transcript = state.get(\"transcript_text\", \"No transcript available\")\n",
    "    selected_idea = state.get(\"selected_idea\", {})  # Assumed populated post-HITL\n",
    "    insights_json = insights.model_dump() if insights else {}\n",
    "    \n",
    "    # Prompt template inspired by your plan_instructions, augmented with pipeline data\n",
    "    plan_instructions = \"\"\"You are tasked with creating a plan for a professional blog post for Big Kids Automation Agency. The plan is a skeleton with questions/answers and instructions to guide the writer.\n",
    "\n",
    "Follow these instructions carefully:\n",
    "\n",
    "1. Review the company business strategy: {company_strategy_content}\n",
    "\n",
    "2. Ensure the plan fits the company content strategy: {content_strategy_content}\n",
    "\n",
    "3. Ensure the plan fits the company SEO strategy: {seo_strategy_content}\n",
    "\n",
    "4. Review the extracted insights from the interview (pains, challenges, etc.): {insights_json}\n",
    "\n",
    "5. Review the interview transcript: {transcript}\n",
    "\n",
    "6. Base the plan on this human-selected blog idea: {selected_idea}\n",
    "\n",
    "7. Create a plan with: who, why, what, the_issue, where_we_stand, single_message. Add qa_pairs (5-10 Q&A from insights, e.g., 'question': 'What is the main challenge?', 'answer': '[From pains]') and instructions (e.g., 'Stay focused on automation benefits', 'Incorporate SEO keywords').\n",
    "\n",
    "8. If there's human feedback, incorporate it: {human_analyst_feedback}\n",
    "\"\"\"\n",
    "    \n",
    "    # Format the prompt (add human feedback if you extend state for it)\n",
    "    formatted_instructions = plan_instructions.format(\n",
    "        company_strategy_content=strategy_context.get('company_strategy', ''),\n",
    "        content_strategy_content=strategy_context.get('content_strategy', ''),\n",
    "        seo_strategy_content=strategy_context.get('seo_strategy', ''),\n",
    "        insights_json=json.dumps(insights_json),\n",
    "        transcript=transcript[:2000],  # Truncate if needed\n",
    "        selected_idea=json.dumps(selected_idea),\n",
    "        human_analyst_feedback=state.get('human_analyst_feedback', 'No feedback')  # Optional extension\n",
    "    )\n",
    "    \n",
    "    # Set up structured LLM (inspired by your snippet)\n",
    "    structured_llm = llm.with_structured_output(Plan)\n",
    "    \n",
    "    # Invoke (now with proper message classes available)\n",
    "    plan = structured_llm.invoke([SystemMessage(content=formatted_instructions), HumanMessage(content=\"Generate the blog post plan.\")])\n",
    "    \n",
    "    # Update state\n",
    "    state[\"blog_plan\"] = plan\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e6aa8463",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "5 validation errors for ExtractedInsights\nspeakers.0\n  Input should be a valid dictionary or instance of Speaker [type=model_type, input_value=Speaker(name='John Doe', ...rRole.CLIENT: 'client'>), input_type=Speaker]\n    For further information visit https://errors.pydantic.dev/2.11/v/model_type\nprimary_challenges.0\n  Input should be a valid dictionary or instance of Challenge [type=model_type, input_value=Challenge(description='Da... issues', impact='High'), input_type=Challenge]\n    For further information visit https://errors.pydantic.dev/2.11/v/model_type\nsecondary_challenges.0\n  Input should be a valid dictionary or instance of Challenge [type=model_type, input_value=Challenge(description='Te...ining', impact='Medium'), input_type=Challenge]\n    For further information visit https://errors.pydantic.dev/2.11/v/model_type\ncurrent_solutions.0\n  Input should be a valid dictionary or instance of CurrentSolution [type=model_type, input_value=CurrentSolution(method='M...s', effectiveness='Low'), input_type=CurrentSolution]\n    For further information visit https://errors.pydantic.dev/2.11/v/model_type\npsychological_needs.0\n  Input should be a valid dictionary or instance of Need [type=model_type, input_value=Need(need='Security', details='Stable processes'), input_type=Need]\n    For further information visit https://errors.pydantic.dev/2.11/v/model_type",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValidationError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[46]\u001b[39m\u001b[32m, line 32\u001b[39m\n\u001b[32m     28\u001b[39m     details: Optional[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# Mock state with valid data (using kwargs and valid Enum for role)\u001b[39;00m\n\u001b[32m     31\u001b[39m mock_state = {\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mextracted_insights\u001b[39m\u001b[33m\"\u001b[39m: \u001b[43mExtractedInsights\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m        \u001b[49m\u001b[43mspeakers\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mSpeaker\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mJohn Doe\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrole\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mclient\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Valid role: 'client' or SpeakerRole.INTERVIEWER\u001b[39;49;00m\n\u001b[32m     34\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcore_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mInnovation\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mEfficiency\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Simple list of str\u001b[39;49;00m\n\u001b[32m     35\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpriorities\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mScaling automation\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mReducing costs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprimary_challenges\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChallenge\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mData integration issues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimpact\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mHigh\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[43m        \u001b[49m\u001b[43msecondary_challenges\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChallenge\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mTeam training\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimpact\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mMedium\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcurrent_solutions\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mCurrentSolution\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mManual workflows\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffectiveness\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mLow\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpsychological_needs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mNeed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mneed\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mSecurity\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdetails\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mStable processes\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m     41\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtranscript_text\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mSample transcript: Interviewee discussed pains in automation, like integration challenges.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     42\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mselected_idea\u001b[39m\u001b[33m\"\u001b[39m: {\u001b[33m\"\u001b[39m\u001b[33mtitle\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mTest Idea: Overcoming Automation Pains\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mdescription\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mBlog on solutions from interview\u001b[39m\u001b[33m\"\u001b[39m},\n\u001b[32m     43\u001b[39m     \u001b[38;5;66;03m# Add other fields if needed for your node (e.g., \"human_analyst_feedback\": \"Incorporate more SEO\")\u001b[39;00m\n\u001b[32m     44\u001b[39m }\n\u001b[32m     46\u001b[39m \u001b[38;5;66;03m# Run the node\u001b[39;00m\n\u001b[32m     47\u001b[39m result = planning_agent_node(mock_state)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/tech/ai_content_ops/.venv/lib/python3.13/site-packages/pydantic/main.py:253\u001b[39m, in \u001b[36mBaseModel.__init__\u001b[39m\u001b[34m(self, **data)\u001b[39m\n\u001b[32m    251\u001b[39m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[32m    252\u001b[39m __tracebackhide__ = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m253\u001b[39m validated_self = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n\u001b[32m    255\u001b[39m     warnings.warn(\n\u001b[32m    256\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mA custom validator is returning a value other than `self`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m    257\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mReturning anything other than `self` from a top level model validator isn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt supported when validating via `__init__`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    258\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    259\u001b[39m         stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m    260\u001b[39m     )\n",
      "\u001b[31mValidationError\u001b[39m: 5 validation errors for ExtractedInsights\nspeakers.0\n  Input should be a valid dictionary or instance of Speaker [type=model_type, input_value=Speaker(name='John Doe', ...rRole.CLIENT: 'client'>), input_type=Speaker]\n    For further information visit https://errors.pydantic.dev/2.11/v/model_type\nprimary_challenges.0\n  Input should be a valid dictionary or instance of Challenge [type=model_type, input_value=Challenge(description='Da... issues', impact='High'), input_type=Challenge]\n    For further information visit https://errors.pydantic.dev/2.11/v/model_type\nsecondary_challenges.0\n  Input should be a valid dictionary or instance of Challenge [type=model_type, input_value=Challenge(description='Te...ining', impact='Medium'), input_type=Challenge]\n    For further information visit https://errors.pydantic.dev/2.11/v/model_type\ncurrent_solutions.0\n  Input should be a valid dictionary or instance of CurrentSolution [type=model_type, input_value=CurrentSolution(method='M...s', effectiveness='Low'), input_type=CurrentSolution]\n    For further information visit https://errors.pydantic.dev/2.11/v/model_type\npsychological_needs.0\n  Input should be a valid dictionary or instance of Need [type=model_type, input_value=Need(need='Security', details='Stable processes'), input_type=Need]\n    For further information visit https://errors.pydantic.dev/2.11/v/model_type"
     ]
    }
   ],
   "source": [
    "# Ensure these are imported (add to your cell if not already)\n",
    "# from your_module import ExtractedInsights, Plan, Speaker, Challenge, CurrentSolution, Need  # Replace 'your_module' with where they're defined\n",
    "# Also ensure planning_agent_node is defined with the imports from my previous response\n",
    "\n",
    "# If you haven't defined the sub-models yet, here's a minimal example based on the error (add to your code if needed)\n",
    "from pydantic import BaseModel, Field\n",
    "from enum import Enum\n",
    "from typing import Optional\n",
    "\n",
    "class SpeakerRole(Enum):\n",
    "    CLIENT = 'client'\n",
    "    INTERVIEWER = 'interviewer'\n",
    "\n",
    "class Speaker(BaseModel):\n",
    "    name: str\n",
    "    role: SpeakerRole  # Enforces the Enum\n",
    "\n",
    "class Challenge(BaseModel):\n",
    "    description: str\n",
    "    impact: Optional[str] = None  # Adjust fields as per your real model\n",
    "\n",
    "class CurrentSolution(BaseModel):\n",
    "    method: str\n",
    "    effectiveness: Optional[str] = None\n",
    "\n",
    "class Need(BaseModel):\n",
    "    need: str\n",
    "    details: Optional[str] = None\n",
    "\n",
    "# Mock state with valid data (using kwargs and valid Enum for role)\n",
    "mock_state = {\n",
    "    \"extracted_insights\": ExtractedInsights(\n",
    "        speakers=[Speaker(name=\"John Doe\", role=\"client\")],  # Valid role: 'client' or SpeakerRole.INTERVIEWER\n",
    "        core_values=[\"Innovation\", \"Efficiency\"],  # Simple list of str\n",
    "        priorities=[\"Scaling automation\", \"Reducing costs\"],\n",
    "        primary_challenges=[Challenge(description=\"Data integration issues\", impact=\"High\")],\n",
    "        secondary_challenges=[Challenge(description=\"Team training\", impact=\"Medium\")],\n",
    "        current_solutions=[CurrentSolution(method=\"Manual workflows\", effectiveness=\"Low\")],\n",
    "        psychological_needs=[Need(need=\"Security\", details=\"Stable processes\")]\n",
    "    ),\n",
    "    \"transcript_text\": \"Sample transcript: Interviewee discussed pains in automation, like integration challenges.\",\n",
    "    \"selected_idea\": {\"title\": \"Test Idea: Overcoming Automation Pains\", \"description\": \"Blog on solutions from interview\"},\n",
    "    # Add other fields if needed for your node (e.g., \"human_analyst_feedback\": \"Incorporate more SEO\")\n",
    "}\n",
    "\n",
    "# Run the node\n",
    "result = planning_agent_node(mock_state)\n",
    "\n",
    "# Print the result (adjust based on your Plan model)\n",
    "print(\"Generated Blog Plan:\")\n",
    "if \"blog_plan\" in result and result[\"blog_plan\"]:\n",
    "    print(result[\"blog_plan\"].plan)  # Uses the @property from Plan\n",
    "else:\n",
    "    print(\"No plan generated‚Äîcheck for errors in the node.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f9d85ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded company strategy (6555 chars)\n",
      "‚úÖ Loaded SEO strategy (1120 chars)\n",
      "‚úÖ Loaded content strategy (4469 chars)\n",
      "who='SME owners and managers frustrated with current tools, hungry for change; management consultants; call for funding consultants; training organizations focused on digital literacy and workplace wellbeing' why='To educate SMEs on the business value of GenAI and automation, demonstrating how they can deliver better services, save time and money, increase employee happiness, and build a healthier relationship with their tech tools. This positions Big Kids Automation as a trusted guide in digital transformation rooted in care, curiosity, and real human needs.' what='Business value of GenAI and automation for SMEs; how to implement AI in small business workflows; custom AI solutions vs SaaS platforms; business process automation benefits and ROI; automation risks and considerations; real use cases of businesses using AI for efficiency; tools and best practices; failed experiments and lessons learned; ethics and responsible AI implementation; tutorials on automation techniques' the_issue='SMEs struggle with inefficient processes, tool sprawl, employee burnout from endless engagement systems, and lack of understanding about how to leverage GenAI and automation responsibly. They face the choice between expensive SaaS platforms and building custom solutions, without clear guidance on business value, implementation strategy, or organizational impact.' where_we_stand=\"Big Kids Automation is positioned as a feminist, care-centered automation consultancy that helps SMEs recognize tech tools as allies for transformation. We offer a unique approach combining design research, team workshops, custom automation flows, and training that raises awareness. We're software-agnostic, encouraging autonomy and in-house capacity building rather than vendor lock-in.\" single_message=\"GenAI and automation aren't just about working harder‚Äîthey're about working smarter and reclaiming time for what matters: better human connections, reduced burnout, and building a conscious, sovereign relationship with your technology.\" qa_pairs=[] instructions=[]\n"
     ]
    }
   ],
   "source": [
    "mock_state = {\n",
    "    \"extracted_insights\": ExtractedInsights(),  # Empty instance (all fields default to [])\n",
    "    \"transcript_text\": \"Sample transcript\",\n",
    "    \"selected_idea\": {\"title\": \"Test Idea\"}\n",
    "}\n",
    "result = planning_agent_node(mock_state)\n",
    "print(result.get(\"blog_plan\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c1bd03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def idea_selection_hitl(state: AudioPipelineState) -> AudioPipelineState:\n",
    "    \"\"\"No-op node for human-in-the-loop idea selection. Interrupt here to choose an idea.\"\"\"\n",
    "    # In dev: Print ideas for human to see\n",
    "    print(\"HITL: Scored ideas:\", state.get(\"scored_blog_ideas\", []))\n",
    "    print(\"Saved idea IDs:\", state.get(\"saved_idea_ids\", []))\n",
    "    # The graph interrupts before this runs; human updates state externally (e.g., via checkpointer)\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46143d78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Individual strategy loader functions ready\n",
      "‚úÖ prepare_strategy_context_for_scoring() ready\n"
     ]
    }
   ],
   "source": [
    "# Cell: Individual Strategy Loader Function\n",
    "\n",
    "def load_company_strategy():\n",
    "    \"\"\"Load company strategy document\"\"\"\n",
    "    try:\n",
    "        company_strategy_path = \"../data/processed/company_strategy.mkd\"\n",
    "        if os.path.exists(company_strategy_path):\n",
    "            with open(company_strategy_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                content = f.read()\n",
    "            print(f\"‚úÖ Loaded company strategy ({len(content)} chars)\")\n",
    "            return content\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è Company strategy document not found\")\n",
    "            return \"Company strategy document not available.\"\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error loading company strategy: {e}\")\n",
    "        return \"Company strategy document not available.\"\n",
    "\n",
    "def load_seo_strategy():\n",
    "    \"\"\"Load SEO strategy document\"\"\"\n",
    "    try:\n",
    "        seo_strategy_path = \"../data/processed/seo_strategy.mkd\"\n",
    "        if os.path.exists(seo_strategy_path):\n",
    "            with open(seo_strategy_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                content = f.read()\n",
    "            print(f\"‚úÖ Loaded SEO strategy ({len(content)} chars)\")\n",
    "            return content\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è SEO strategy document not found\")\n",
    "            return \"SEO strategy document not available.\"\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error loading SEO strategy: {e}\")\n",
    "        return \"SEO strategy document not available.\"\n",
    "\n",
    "def load_content_strategy():\n",
    "    \"\"\"Load content strategy document\"\"\"\n",
    "    try:\n",
    "        content_strategy_path = \"../data/processed/content_strategy.mkd\"\n",
    "        if os.path.exists(content_strategy_path):\n",
    "            with open(content_strategy_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                content = f.read()\n",
    "            print(f\"‚úÖ Loaded content strategy ({len(content)} chars)\")\n",
    "            return content\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è Content strategy document not found\")\n",
    "            return \"Content strategy document not available.\"\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error loading content strategy: {e}\")\n",
    "        return \"Content strategy document not available.\"\n",
    "\n",
    "def prepare_strategy_context_for_scoring():\n",
    "    \"\"\"Prepare full strategy context for scoring (used by analyst agent)\"\"\"\n",
    "    return {\n",
    "        'company_strategy_summary': load_company_strategy(),\n",
    "        'seo_strategy_summary': load_seo_strategy(),\n",
    "        'content_strategy_summary': load_content_strategy()\n",
    "    }\n",
    "\n",
    "print(\"‚úÖ Individual strategy loader functions ready\")\n",
    "print(\"‚úÖ prepare_strategy_context_for_scoring() ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bcb6358b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded company strategy (6555 chars)\n",
      "‚úÖ Loaded SEO strategy (1120 chars)\n",
      "‚úÖ Loaded content strategy (4469 chars)\n",
      "üìä Strategy context keys: ['company_strategy', 'seo_strategy', 'content_strategy']\n",
      "üìä Total context size: 12144 chars\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Updated Company Strategy Context Loader (3 Documents)\n",
    "def load_company_strategy_context():\n",
    "    \"\"\"Load company strategy, SEO strategy, and content strategy for context\"\"\"\n",
    "    \n",
    "    strategy_context = {}\n",
    "    \n",
    "    try:\n",
    "        # Load company strategy\n",
    "        company_strategy_path = \"../data/processed/company_strategy.mkd\"\n",
    "        if os.path.exists(company_strategy_path):\n",
    "            with open(company_strategy_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                strategy_context[\"company_strategy\"] = f.read()\n",
    "            print(f\"‚úÖ Loaded company strategy ({len(strategy_context['company_strategy'])} chars)\")\n",
    "        else:\n",
    "            strategy_context[\"company_strategy\"] = \"Company strategy document not available.\"\n",
    "            print(\"‚ö†Ô∏è Company strategy document not found\")\n",
    "        \n",
    "        # Load SEO strategy\n",
    "        seo_strategy_path = \"../data/processed/seo_strategy.mkd\"\n",
    "        if os.path.exists(seo_strategy_path):\n",
    "            with open(seo_strategy_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                strategy_context[\"seo_strategy\"] = f.read()\n",
    "            print(f\"‚úÖ Loaded SEO strategy ({len(strategy_context['seo_strategy'])} chars)\")\n",
    "        else:\n",
    "            strategy_context[\"seo_strategy\"] = \"SEO strategy document not available.\"\n",
    "            print(\"‚ö†Ô∏è SEO strategy document not found\")\n",
    "        \n",
    "        # Load content strategy (NEW)\n",
    "        content_strategy_path = \"../data/processed/content_strategy.mkd\"\n",
    "        if os.path.exists(content_strategy_path):\n",
    "            with open(content_strategy_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                strategy_context[\"content_strategy\"] = f.read()\n",
    "            print(f\"‚úÖ Loaded content strategy ({len(strategy_context['content_strategy'])} chars)\")\n",
    "        else:\n",
    "            strategy_context[\"content_strategy\"] = \"Content strategy document not available.\"\n",
    "            print(\"‚ö†Ô∏è Content strategy document not found\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error loading strategy documents: {e}\")\n",
    "        strategy_context = {\n",
    "            \"company_strategy\": \"Strategy document not available\",\n",
    "            \"seo_strategy\": \"SEO strategy document not available\", \n",
    "            \"content_strategy\": \"Content strategy document not available\"\n",
    "        }\n",
    "    \n",
    "    return strategy_context\n",
    "\n",
    "# Test loading all three documents\n",
    "strategy_context = load_company_strategy_context()\n",
    "print(f\"üìä Strategy context keys: {list(strategy_context.keys())}\")\n",
    "print(f\"üìä Total context size: {sum(len(v) for v in strategy_context.values() if isinstance(v, str))} chars\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dcad1d83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Batch processing function ready with full insights display\n"
     ]
    }
   ],
   "source": [
    "# Batch Processing Function (Updated with Full Insights Display)\n",
    "def process_audio_batch(audio_files: List[Path], pipeline) -> dict:\n",
    "    \"\"\"Process all audio files in batch with detailed insights display\"\"\"\n",
    "    \n",
    "    if not audio_files:\n",
    "        print(\"‚ùå No files to process\")\n",
    "        return {\"processed\": [], \"failed\": [], \"total\": 0}\n",
    "    \n",
    "    print(f\"\\nüöÄ STARTING BATCH PROCESSING - {len(audio_files)} files\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    processed_files = []\n",
    "    failed_files = []\n",
    "    results = []\n",
    "    \n",
    "    for i, file_path in enumerate(audio_files, 1):\n",
    "        print(f\"\\nüìÇ Processing {i}/{len(audio_files)}: {file_path.name}\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        # Create initial state\n",
    "        initial_state = {\n",
    "            \"file_path\": str(file_path),\n",
    "            \"filename\": file_path.name,\n",
    "            \"transcript_text\": None,\n",
    "            \"conversation_id\": None,\n",
    "            \"extracted_insights\": None,  \n",
    "            \"error\": None,\n",
    "            \"status\": \"processing\"\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            # Run through pipeline\n",
    "            result = pipeline.invoke(initial_state)\n",
    "            \n",
    "            if result[\"status\"] in [\"completed\", \"insights_extracted\"]:\n",
    "                print(f\"‚úÖ SUCCESS: {file_path.name}\")\n",
    "                print(f\"   Conversation ID: {result['conversation_id']}\")\n",
    "                print(f\"   Transcript preview: {result['transcript_text'][:100]}...\")\n",
    "                \n",
    "                # FULL INSIGHTS DISPLAY\n",
    "                if result.get('extracted_insights'):\n",
    "                    insights = result['extracted_insights']\n",
    "                    print(f\"\\nüß† === EXTRACTED INSIGHTS FOR: {file_path.name} ===\")\n",
    "                    print(\"=\" * 50)\n",
    "                    \n",
    "                    # Speakers\n",
    "                    if insights.speakers:\n",
    "                        print(\"üë• SPEAKERS:\")\n",
    "                        for speaker in insights.speakers:\n",
    "                            print(f\"   ‚Ä¢ Name: {speaker.name or 'Unknown'}\")\n",
    "                            print(f\"     Role: {speaker.role or 'Unknown'}\")  \n",
    "                            print(f\"     Company: {speaker.company or 'Unknown'}\")\n",
    "                    \n",
    "                    # Core Values\n",
    "                    if insights.core_values:\n",
    "                        print(\"üíé CORE VALUES:\")\n",
    "                        for value in insights.core_values:\n",
    "                            print(f\"   ‚Ä¢ {value}\")\n",
    "                    \n",
    "                    # Priorities\n",
    "                    if insights.priorities:\n",
    "                        print(\"üéØ PRIORITIES:\")\n",
    "                        for priority in insights.priorities:\n",
    "                            print(f\"   ‚Ä¢ {priority}\")\n",
    "                    \n",
    "                    # Primary Challenges\n",
    "                    if insights.primary_challenges:\n",
    "                        print(\"üî• PRIMARY CHALLENGES:\")\n",
    "                        for challenge in insights.primary_challenges:\n",
    "                            print(f\"   ‚Ä¢ Challenge: {challenge.description}\")\n",
    "                            print(f\"     Impact: {challenge.impact}\")\n",
    "                            print(f\"     Urgency: {challenge.urgency}\")\n",
    "                    \n",
    "                    # Secondary Challenges\n",
    "                    if insights.secondary_challenges:\n",
    "                        print(\"‚ö†Ô∏è  SECONDARY CHALLENGES:\")\n",
    "                        for challenge in insights.secondary_challenges:\n",
    "                            print(f\"   ‚Ä¢ Challenge: {challenge.description}\")\n",
    "                            print(f\"     Impact: {challenge.impact}\")\n",
    "                            print(f\"     Urgency: {challenge.urgency}\")\n",
    "                    \n",
    "                    # Current Solutions\n",
    "                    if insights.current_solutions:\n",
    "                        print(\"üîß CURRENT SOLUTIONS:\")\n",
    "                        for solution in insights.current_solutions:\n",
    "                            print(f\"   ‚Ä¢ Solution: {solution.solution}\")\n",
    "                            print(f\"     Satisfaction: {solution.satisfaction_level}\")\n",
    "                            if solution.limitations:\n",
    "                                print(f\"     Limitations: {', '.join(solution.limitations)}\")\n",
    "                    \n",
    "                    # Psychological Needs\n",
    "                    if insights.psychological_needs:\n",
    "                        print(\"üßò PSYCHOLOGICAL NEEDS:\")\n",
    "                        for need in insights.psychological_needs:\n",
    "                            print(f\"   ‚Ä¢ {need.description}\")\n",
    "                            print(f\"     Category: {need.need_category}\")\n",
    "                            print(f\"     Intensity: {need.intensity}\")\n",
    "                    \n",
    "                    print(\"üß† === END INSIGHTS ===\")\n",
    "                    print(\"-\" * 50)\n",
    "                \n",
    "                processed_files.append(file_path)\n",
    "            else:\n",
    "                print(f\"‚ùå FAILED: {file_path.name}\")\n",
    "                print(f\"   Status: {result.get('status', 'Unknown')}\")\n",
    "                print(f\"   Error: {result.get('error', 'Unknown error')}\")\n",
    "                failed_files.append(file_path)\n",
    "            \n",
    "            results.append(result)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå PIPELINE ERROR: {file_path.name}\")\n",
    "            print(f\"   Exception: {str(e)}\")\n",
    "            failed_files.append(file_path)\n",
    "            \n",
    "            results.append({\n",
    "                **initial_state,\n",
    "                \"error\": str(e),\n",
    "                \"status\": \"pipeline_error\"\n",
    "            })\n",
    "    \n",
    "    # Final Summary\n",
    "    print(f\"\\nüìä BATCH PROCESSING COMPLETE!\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"‚úÖ Successfully processed: {len(processed_files)}\")\n",
    "    print(f\"‚ùå Failed: {len(failed_files)}\")\n",
    "    print(f\"üìÅ Total files: {len(audio_files)}\")\n",
    "    \n",
    "    if failed_files:\n",
    "        print(f\"\\n‚ùå Failed files:\")\n",
    "        for failed_file in failed_files:\n",
    "            print(f\"   - {failed_file.name}\")\n",
    "    \n",
    "    return {\n",
    "        \"processed\": processed_files,\n",
    "        \"failed\": failed_files,\n",
    "        \"total\": len(audio_files),\n",
    "        \"results\": results\n",
    "    }\n",
    "\n",
    "print(\"‚úÖ Batch processing function ready with full insights display\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5b06e004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ File management functions defined\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Batch File Discovery and Management\n",
    "\n",
    "\n",
    "def find_audio_files_in_temp(temp_folder: Path = None) -> List[Path]:\n",
    "    \"\"\"Find all audio files in temp folder\"\"\"\n",
    "    \n",
    "    # Use default temp folder if not specified\n",
    "    if temp_folder is None:\n",
    "        temp_folder = project_root / 'data' / 'temp'\n",
    "    \n",
    "    # Ensure folder exists\n",
    "    temp_folder.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Check if folder exists\n",
    "    if not temp_folder.exists():\n",
    "        print(f\"‚ùå Temp folder not found: {temp_folder}\")\n",
    "        return []\n",
    "    \n",
    "    # Find audio files\n",
    "    audio_extensions = ['*.wav', '*.mp3', '*.m4a']\n",
    "    audio_files = []\n",
    "    \n",
    "    for ext in audio_extensions:\n",
    "        files = list(temp_folder.glob(ext))\n",
    "        audio_files.extend(files)\n",
    "    \n",
    "    return sorted(audio_files)\n",
    "\n",
    "\n",
    "def display_batch_info(audio_files: List[Path]) -> bool:\n",
    "    \"\"\"Display information about the batch of files\"\"\"\n",
    "    \n",
    "    if not audio_files:\n",
    "        print(\"‚ùå No audio files found in temp folder!\")\n",
    "        print(\"üí° TIP: Add .wav files to data/temp/ folder\")\n",
    "        return False\n",
    "    \n",
    "    total_size_mb = sum(f.stat().st_size for f in audio_files) / (1024 * 1024)\n",
    "    \n",
    "    print(f\"üìä BATCH INFO:\")\n",
    "    print(f\"   Files to process: {len(audio_files)}\")\n",
    "    print(f\"   Total size: {total_size_mb:.1f} MB\")\n",
    "    print(f\"\\nüìÅ Files found:\")\n",
    "    \n",
    "    for i, file_path in enumerate(audio_files, 1):\n",
    "        size_mb = file_path.stat().st_size / (1024 * 1024)\n",
    "        print(f\"   {i}. {file_path.name} ({size_mb:.1f} MB)\")\n",
    "    \n",
    "    return True\n",
    "\n",
    "\n",
    "print(\"‚úÖ File management functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c79e939f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Enhanced extract_insights_from_transcript with JSON repair\n"
     ]
    }
   ],
   "source": [
    "# Cell: Extract Insights Function - ENHANCED WITH JSON REPAIR\n",
    "def extract_insights_from_transcript(transcript: str) -> ExtractedInsights:\n",
    "    \"\"\"Extract structured insights using Anthropic Claude - ENHANCED WITH JSON REPAIR\"\"\"\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    Analyze this conversation transcript and extract structured insights:\n",
    "    \n",
    "    Transcript: {transcript}\n",
    "    \n",
    "    IMPORTANT: For speaker roles, use ONLY these exact values:\n",
    "    - \"client\" for the person being interviewed/consulted (CTO, CEO, Manager, business owner, etc.)\n",
    "    - \"interviewer\" for the person asking questions or conducting the interview\n",
    "    \n",
    "    Extract the following information in JSON format:\n",
    "    - speakers: List of people mentioned with name, role (client/interviewer only), company\n",
    "    - core_values: What they care about most  \n",
    "    - priorities: Current focus areas\n",
    "    - primary_challenges: Main problems they face with description, impact, urgency\n",
    "    - secondary_challenges: Secondary problems\n",
    "    - current_solutions: How they solve problems now with satisfaction level\n",
    "    - psychological_needs: Underlying needs with category, description, intensity\n",
    "    \n",
    "    Return ONLY valid JSON in this exact structure - no markdown, no code blocks:\n",
    "    {{\n",
    "        \"speakers\": [\n",
    "            {{\"name\": \"Manuel\", \"role\": \"client\", \"company\": \"Drone flytech\"}}\n",
    "        ],\n",
    "        \"core_values\": [\"efficiency\", \"transparency\"],\n",
    "        \"priorities\": [\"improving processes\"],\n",
    "        \"primary_challenges\": [\n",
    "            {{\n",
    "                \"description\": \"Tracking payment issues\",\n",
    "                \"impact\": \"Creates confusion in processes\", \n",
    "                \"urgency\": \"High\"\n",
    "            }}\n",
    "        ],\n",
    "        \"secondary_challenges\": [\n",
    "            {{\n",
    "                \"description\": \"Secondary challenge\",\n",
    "                \"impact\": \"Secondary impact\",\n",
    "                \"urgency\": \"Medium\"\n",
    "            }}\n",
    "        ],\n",
    "        \"current_solutions\": [\n",
    "            {{\n",
    "                \"solution\": \"Current approach\",\n",
    "                \"satisfaction_level\": \"Neutral\",\n",
    "                \"limitations\": [\"limitation1\", \"limitation2\"]\n",
    "            }}\n",
    "        ],\n",
    "        \"psychological_needs\": [\n",
    "            {{\n",
    "                \"need_category\": \"security\",\n",
    "                \"description\": \"Need for confidence\",\n",
    "                \"intensity\": \"High\"\n",
    "            }}\n",
    "        ]\n",
    "    }}\n",
    "    \n",
    "    Remember: \n",
    "    - Use \"client\" for the interviewee (even if they're CTO/CEO)\n",
    "    - Use \"interviewer\" for the person asking questions\n",
    "    - Use exact urgency values: \"Low\", \"Medium\", \"High\"\n",
    "    - Use exact satisfaction levels: \"Very Satisfied\", \"Satisfied\", \"Neutral\", \"Unsatisfied\", \"Very Unsatisfied\"\n",
    "    - Use exact intensity values: \"Low\", \"Medium\", \"High\"\n",
    "    - Ensure all strings are properly closed with quotes\n",
    "    - Do not truncate the response - complete all JSON structures\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Use the Claude LLM you already set up\n",
    "        response = llm.invoke(prompt)\n",
    "        \n",
    "        print(f\"üìù Raw response length: {len(response.content)} chars\")\n",
    "        print(f\"üìù Response starts with: {response.content[:50]}...\")\n",
    "        \n",
    "        # Clean markdown code blocks\n",
    "        content = response.content.strip()\n",
    "        if content.startswith('```json'):\n",
    "            print(\"üîß Removing JSON markdown blocks...\")\n",
    "            content = content.replace('```json', '').replace('```', '').strip()\n",
    "        elif content.startswith('```'):\n",
    "            print(\"üîß Removing generic markdown blocks...\")\n",
    "            content = content.replace('```', '').strip()\n",
    "        \n",
    "        # Extract JSON boundaries\n",
    "        first_brace = content.find('{')\n",
    "        if first_brace > 0:\n",
    "            content = content[first_brace:]\n",
    "        \n",
    "        last_brace = content.rfind('}')\n",
    "        if last_brace > 0 and last_brace < len(content) - 1:\n",
    "            content = content[:last_brace + 1]\n",
    "        \n",
    "        print(f\"üîß Cleaned content starts with: {content[:50]}...\")\n",
    "        \n",
    "        # === ENHANCED: Try parsing with auto-repair ===\n",
    "        try:\n",
    "            insights_data = json.loads(content)\n",
    "            print(\"‚úÖ JSON parsed successfully\")\n",
    "            \n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"‚ö†Ô∏è  JSON parsing error: {e}\")\n",
    "            print(f\"   Error at position: {e.pos}\")\n",
    "            \n",
    "            # Show context around error\n",
    "            start = max(0, e.pos - 80)\n",
    "            end = min(len(content), e.pos + 80)\n",
    "            print(f\"   Context: ...{content[start:end]}...\")\n",
    "            \n",
    "            print(\"\\nüîß Attempting JSON auto-repair...\")\n",
    "            \n",
    "            import re\n",
    "            \n",
    "            # Repair strategy based on error type\n",
    "            repaired = content\n",
    "            \n",
    "            if \"Unterminated string\" in str(e):\n",
    "                print(\"   ‚Üí Fixing unterminated string...\")\n",
    "                # Add closing quote at error position\n",
    "                repaired = content[:e.pos] + '\"'\n",
    "                \n",
    "                # Close any open structures after the fix\n",
    "                partial = content[:e.pos]\n",
    "                open_braces = partial.count('{')\n",
    "                close_braces = partial.count('}')\n",
    "                open_brackets = partial.count('[')\n",
    "                close_brackets = partial.count(']')\n",
    "                \n",
    "                if open_brackets > close_brackets:\n",
    "                    repaired += ']' * (open_brackets - close_brackets)\n",
    "                    print(f\"   ‚Üí Added {open_brackets - close_brackets} closing bracket(s)\")\n",
    "                \n",
    "                if open_braces > close_braces:\n",
    "                    repaired += '}' * (open_braces - close_braces)\n",
    "                    print(f\"   ‚Üí Added {open_braces - close_braces} closing brace(s)\")\n",
    "            \n",
    "            else:\n",
    "                # Generic repairs\n",
    "                # Fix 1: Remove trailing commas\n",
    "                repaired = re.sub(r',\\s*}', '}', repaired)\n",
    "                repaired = re.sub(r',\\s*]', ']', repaired)\n",
    "                \n",
    "                # Fix 2: Balance brackets\n",
    "                open_braces = repaired.count('{')\n",
    "                close_braces = repaired.count('}')\n",
    "                open_brackets = repaired.count('[')\n",
    "                close_brackets = repaired.count(']')\n",
    "                \n",
    "                if open_brackets > close_brackets:\n",
    "                    repaired += ']' * (open_brackets - close_brackets)\n",
    "                    print(f\"   ‚Üí Added {open_brackets - close_brackets} closing bracket(s)\")\n",
    "                \n",
    "                if open_braces > close_braces:\n",
    "                    repaired += '}' * (open_braces - close_braces)\n",
    "                    print(f\"   ‚Üí Added {open_braces - close_braces} closing brace(s)\")\n",
    "            \n",
    "            # Try parsing repaired JSON\n",
    "            try:\n",
    "                insights_data = json.loads(repaired)\n",
    "                print(\"‚úÖ Auto-repair successful!\")\n",
    "                \n",
    "            except json.JSONDecodeError as e2:\n",
    "                print(f\"‚ùå Auto-repair failed: {e2}\")\n",
    "                \n",
    "                # Last resort: Extract partial valid data\n",
    "                print(\"\\nüîß Last resort: Extracting partial data...\")\n",
    "                \n",
    "                # Find last complete object before error\n",
    "                try:\n",
    "                    safe_end = content[:e.pos].rfind('}')\n",
    "                    if safe_end > 0:\n",
    "                        partial = content[:safe_end + 1]\n",
    "                        \n",
    "                        # Balance remaining brackets\n",
    "                        open_braces = partial.count('{')\n",
    "                        close_braces = partial.count('}')\n",
    "                        if open_braces > close_braces:\n",
    "                            partial += '}' * (open_braces - close_braces)\n",
    "                        \n",
    "                        insights_data = json.loads(partial)\n",
    "                        print(\"‚úÖ Partial extraction successful!\")\n",
    "                    else:\n",
    "                        raise ValueError(\"No valid JSON found\")\n",
    "                        \n",
    "                except Exception as e3:\n",
    "                    print(f\"‚ùå Partial extraction failed: {e3}\")\n",
    "                    print(f\"\\nüìù Problematic response (first 1000 chars):\")\n",
    "                    print(content[:1000])\n",
    "                    raise e  # Re-raise original error\n",
    "        \n",
    "        # === Validate and fill missing fields ===\n",
    "        required_fields = {\n",
    "            'speakers': [],\n",
    "            'core_values': [],\n",
    "            'priorities': [],\n",
    "            'primary_challenges': [],\n",
    "            'secondary_challenges': [],\n",
    "            'current_solutions': [],\n",
    "            'psychological_needs': []\n",
    "        }\n",
    "        \n",
    "        for field, default in required_fields.items():\n",
    "            if field not in insights_data:\n",
    "                print(f\"‚ö†Ô∏è  Missing field '{field}', using default: {default}\")\n",
    "                insights_data[field] = default\n",
    "        \n",
    "        # Fix speaker roles (ensure only 'client' or 'interviewer')\n",
    "        for speaker in insights_data.get('speakers', []):\n",
    "            if 'role' not in speaker or speaker['role'] not in ['interviewer', 'client']:\n",
    "                print(f\"‚ö†Ô∏è  Invalid role for {speaker.get('name', 'unknown')}, defaulting to 'client'\")\n",
    "                speaker['role'] = 'client'\n",
    "        \n",
    "        # Convert to Pydantic model\n",
    "        result = ExtractedInsights(**insights_data)\n",
    "        \n",
    "        print(f\"‚úÖ Successfully extracted insights!\")\n",
    "        print(f\"   Speakers: {len(result.speakers)}\")\n",
    "        print(f\"   Challenges: {len(result.primary_challenges)}\")\n",
    "        print(f\"   Needs: {len(result.psychological_needs)}\")\n",
    "        print(f\"   Values: {len(result.core_values)}\")\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"‚ùå Final JSON parsing error: {e}\")\n",
    "        print(f\"üìù Raw response (first 500 chars): {response.content[:500]}...\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error in extraction: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        raise\n",
    "\n",
    "print(\"‚úÖ Enhanced extract_insights_from_transcript with JSON repair\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b1b52ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Fixed creative agent function ready\n"
     ]
    }
   ],
   "source": [
    "# Cell: Fixed Creative Agent Function\n",
    "def generate_blog_ideas_from_insights(insights: ExtractedInsights, strategy_context: dict) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Fixed creative agent that handles Claude's markdown JSON response\n",
    "    \"\"\"\n",
    "    \n",
    "    creative_prompt = f\"\"\"\n",
    "    You are a creative content strategist for Big Kids Automation, a company that helps businesses implement AI and automation solutions.\n",
    "    \n",
    "    COMPANY CONTEXT:\n",
    "    {strategy_context.get('company_strategy', 'Strategy not available')[:1000]}...\n",
    "    \n",
    "    SEO STRATEGY:\n",
    "    {strategy_context.get('seo_strategy', 'SEO strategy not available')[:500]}...\n",
    "    \n",
    "    CONVERSATION INSIGHTS TO WORK FROM:\n",
    "    \n",
    "    Speakers: {[f\"{s.name} ({s.role}) from {s.company}\" for s in insights.speakers] if insights.speakers else \"Unknown speakers\"}\n",
    "    \n",
    "    Core Values: {\", \".join(insights.core_values) if insights.core_values else \"None identified\"}\n",
    "    \n",
    "    Priorities: {\", \".join(insights.priorities) if insights.priorities else \"None identified\"}\n",
    "    \n",
    "    Primary Challenges:\n",
    "    {chr(10).join([f\"- {c.description} (Impact: {c.impact}, Urgency: {c.urgency})\" for c in insights.primary_challenges]) if insights.primary_challenges else \"None identified\"}\n",
    "    \n",
    "    Current Solutions:\n",
    "    {chr(10).join([f\"- {s.solution} (Satisfaction: {s.satisfaction_level})\" for s in insights.current_solutions]) if insights.current_solutions else \"None identified\"}\n",
    "    \n",
    "    Psychological Needs:\n",
    "    {chr(10).join([f\"- {n.description} ({n.need_category}, {n.intensity} intensity)\" for n in insights.psychological_needs]) if insights.psychological_needs else \"None identified\"}\n",
    "    \n",
    "    TASK:\n",
    "    Generate 4-5 creative blog post ideas that:\n",
    "    1. Address the challenges and needs identified in this conversation\n",
    "    2. Align with Big Kids Automation's mission to help businesses with AI/automation\n",
    "    3. Provide value to potential clients facing similar challenges\n",
    "    4. Support our SEO and content marketing strategy\n",
    "    5. Are actionable and practical, not just theoretical\n",
    "    \n",
    "    For each blog post idea, provide:\n",
    "    - title: Clear, engaging title that includes relevant keywords\n",
    "    - description: 2-3 sentence description of what the post will cover\n",
    "    - target_audience: Who this post is primarily for\n",
    "    - content_angle: The unique angle or approach this post takes\n",
    "    - business_value: How this post helps our business goals\n",
    "    \n",
    "    IMPORTANT: Return ONLY the JSON array, no markdown formatting, no code blocks, no explanatory text.\n",
    "    \n",
    "    Format:\n",
    "    [\n",
    "        {{\n",
    "            \"title\": \"How AI Proposal Systems Balance Speed with Brand Differentiation\",\n",
    "            \"description\": \"A practical guide showing how modern AI-powered proposal systems solve the common problem of maintaining company uniqueness while leveraging automation. Includes real case studies and implementation steps.\",\n",
    "            \"target_audience\": \"Business development directors and proposal managers at consulting firms\",\n",
    "            \"content_angle\": \"Problem-solution with real case studies\",\n",
    "            \"business_value\": \"Attracts prospects struggling with proposal automation while maintaining differentiation\"\n",
    "        }}\n",
    "    ]\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Generate ideas using Claude\n",
    "        response = llm.invoke(creative_prompt)\n",
    "        raw_content = response.content.strip()\n",
    "        \n",
    "        print(f\"üìù Raw response length: {len(raw_content)} chars\")\n",
    "        print(f\"üìù Response starts with: {raw_content[:50]}...\")\n",
    "        \n",
    "        # Handle markdown code blocks\n",
    "        if raw_content.startswith('```'):\n",
    "            print(\"üîß Removing markdown code blocks...\")\n",
    "            # Remove ```json and ``` wrappers\n",
    "            lines = raw_content.split('\\n')\n",
    "            # Remove first line if it's ```json or ```\n",
    "            if lines[0].startswith('```'):\n",
    "                lines = lines[1:]\n",
    "            # Remove last line if it's ```\n",
    "            if lines and lines[-1].strip() == '```':\n",
    "                lines = lines[:-1]\n",
    "            raw_content = '\\n'.join(lines).strip()\n",
    "            print(f\"üîß Cleaned content starts with: {raw_content[:50]}...\")\n",
    "        \n",
    "        # Parse JSON response\n",
    "        blog_ideas = json.loads(raw_content)\n",
    "        \n",
    "        print(f\"‚úÖ Creative agent successfully parsed {len(blog_ideas)} blog ideas\")\n",
    "        return blog_ideas\n",
    "        \n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"‚ùå JSON parsing error in creative agent: {e}\")\n",
    "        print(f\"üìù Cleaned content: {raw_content[:500]}...\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error in creative agent: {e}\")\n",
    "        return []\n",
    "\n",
    "print(\"‚úÖ Fixed creative agent function ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b0e67228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Updated LLM scoring engine with content strategy context\n"
     ]
    }
   ],
   "source": [
    "# Cell 17: Updated Scoring Engine with Content Strategy Context\n",
    "def score_blog_idea_with_llm(idea: dict, strategy_context: dict, conversation_context: str = \"\") -> dict:\n",
    "    \"\"\"Score a single blog idea using LLM with all three strategy contexts\"\"\"\n",
    "    \n",
    "    scoring_prompt = f\"\"\"\n",
    "    You are an expert content strategist for Big Kids Automation. Score this blog post idea on a 1-10 scale using our strategic context.\n",
    "    \n",
    "    COMPANY STRATEGY:\n",
    "    {strategy_context.get('company_strategy_summary', 'Not available')}\n",
    "    \n",
    "    SEO STRATEGY:\n",
    "    {strategy_context.get('seo_strategy_summary', 'Not available')}\n",
    "    \n",
    "    CONTENT STRATEGY:\n",
    "    {strategy_context.get('content_strategy_summary', 'Not available')}\n",
    "    \n",
    "    BLOG IDEA TO SCORE:\n",
    "    Title: {idea.get('title', 'No title')}\n",
    "    Description: {idea.get('description', 'No description')}\n",
    "    Target Audience: {idea.get('target_audience', 'Unknown')}\n",
    "    Business Value: {idea.get('business_value', 'Unknown')}\n",
    "    Content Angle: {idea.get('content_angle', 'Unknown')}\n",
    "    \n",
    "    CONVERSATION CONTEXT:\n",
    "    {conversation_context[:300] if conversation_context else 'No context available'}...\n",
    "    \n",
    "    SCORING INSTRUCTIONS:\n",
    "    Rate each criterion from 1-10 (10 = excellent, 1 = poor):\n",
    "    \n",
    "    1. usefulness_potential: How useful will this be to readers with real problems?\n",
    "    2. fitwith_seo_strategy: How well does this align with our SEO keywords and strategy?\n",
    "    3. fitwith_content_strategy: How well does this fit our content strategy, voice, and approach?\n",
    "    4. inspiration_potential: How likely to inspire readers to take meaningful action?\n",
    "    5. collaboration_potential: How likely to generate leads/prospects who contact us?\n",
    "    6. innovation: How unique is this topic compared to existing content?\n",
    "    7. difficulty: How complex/time-consuming will this be to write? (1=very hard, 10=easy)\n",
    "    \n",
    "    Return ONLY valid JSON with your scores and brief reasoning:\n",
    "    {{\n",
    "        \"usefulness_potential\": 8,\n",
    "        \"fitwith_seo_strategy\": 7,\n",
    "        \"fitwith_content_strategy\": 9,\n",
    "        \"inspiration_potential\": 6,\n",
    "        \"collaboration_potential\": 8,\n",
    "        \"innovation\": 7,\n",
    "        \"difficulty\": 4,\n",
    "        \"reasoning\": \"This idea scores well because it aligns with our content strategy focus on...\"\n",
    "    }}\n",
    "    \"\"\"\n",
    "    \n",
    "    # ... rest of the function stays the same\n",
    "    try:\n",
    "        response = llm.invoke(scoring_prompt)\n",
    "        \n",
    "        content = response.content.strip()\n",
    "        if content.startswith('```json'):\n",
    "            content = content.replace('```json', '').replace('```', '').strip()\n",
    "        \n",
    "        scores = json.loads(content)\n",
    "        \n",
    "        # Validate scores are in range\n",
    "        for criterion in ['usefulness_potential', 'fitwith_seo_strategy', 'fitwith_content_strategy', \n",
    "                         'inspiration_potential', 'collaboration_potential', 'innovation', 'difficulty']:\n",
    "            if criterion in scores:\n",
    "                scores[criterion] = max(1, min(10, scores[criterion]))\n",
    "        \n",
    "        # Calculate total score\n",
    "        total_score = sum([\n",
    "            scores.get('usefulness_potential', 5),\n",
    "            scores.get('fitwith_seo_strategy', 5),\n",
    "            scores.get('fitwith_content_strategy', 5),\n",
    "            scores.get('inspiration_potential', 5),\n",
    "            scores.get('collaboration_potential', 5),\n",
    "            scores.get('innovation', 5),\n",
    "            scores.get('difficulty', 5)\n",
    "        ])\n",
    "        \n",
    "        scores['total_score'] = total_score\n",
    "        return scores\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error scoring idea: {e}\")\n",
    "        return {\n",
    "            \"usefulness_potential\": 5, \"fitwith_seo_strategy\": 5, \"fitwith_content_strategy\": 5,\n",
    "            \"inspiration_potential\": 5, \"collaboration_potential\": 5, \"innovation\": 5,\n",
    "            \"difficulty\": 5, \"total_score\": 35, \"reasoning\": f\"Default scores due to error: {str(e)}\"\n",
    "        }\n",
    "\n",
    "print(\"‚úÖ Updated LLM scoring engine with content strategy context\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3972ba82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ LangGraph nodes defined\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Define LangGraph Nodes\n",
    "def transcription_node(state: AudioPipelineState) -> AudioPipelineState:\n",
    "    \"\"\"Node 1: Transcribe audio file with AssemblyAI\"\"\"\n",
    "    try:\n",
    "        print(f\"üéôÔ∏è Transcribing: {state['filename']}\")\n",
    "        \n",
    "        # Configure transcriber\n",
    "        transcriber = aai.Transcriber()\n",
    "        \n",
    "        # Transcribe the file\n",
    "        transcript = transcriber.transcribe(state['file_path'])\n",
    "        \n",
    "        if transcript.status == aai.TranscriptStatus.error:\n",
    "            return {\n",
    "                **state,\n",
    "                \"error\": f\"AssemblyAI error: {transcript.error}\",\n",
    "                \"status\": \"transcription_failed\"\n",
    "            }\n",
    "        \n",
    "        return {\n",
    "            **state,\n",
    "            \"transcript_text\": transcript.text,\n",
    "            \"status\": \"transcribed\"\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            **state,\n",
    "            \"error\": f\"Transcription error: {str(e)}\",\n",
    "            \"status\": \"transcription_failed\"\n",
    "        }\n",
    "\n",
    "def database_saver_node_conversations(state: AudioPipelineState) -> AudioPipelineState:\n",
    "    \"\"\"Node 2: Save transcript to database\"\"\"\n",
    "    try:\n",
    "        print(f\"üíæ Saving to database: {state['filename']}\")\n",
    "        \n",
    "        # Create conversation object\n",
    "        conversation = ConversationCreate(\n",
    "            title=f\"Audio: {state['filename']}\",\n",
    "            raw_text=state['transcript_text'],\n",
    "            source=\"transcribed\"\n",
    "        )\n",
    "        \n",
    "        # Save to database\n",
    "        conversation_id = db.create_conversation(conversation)\n",
    "        \n",
    "        return {\n",
    "            **state,\n",
    "            \"conversation_id\": conversation_id,\n",
    "            \"status\": \"completed\"\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            **state,\n",
    "            \"error\": f\"Database error: {str(e)}\",\n",
    "            \"status\": \"database_failed\"\n",
    "        }\n",
    "\n",
    "print(\"‚úÖ LangGraph nodes defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d0edabd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ pain_extractor_node fixed (now checks database for transcript)\n"
     ]
    }
   ],
   "source": [
    "# Cell: Fixed pain_extractor_node (minimal change)\n",
    "def pain_extractor_node(state: AudioPipelineState) -> AudioPipelineState:\n",
    "    \"\"\"\n",
    "    LangGraph node: Extract structured insights from conversation transcript\n",
    "    FIXED: Falls back to database if transcript_text not in state\n",
    "    \"\"\"\n",
    "    print(\"üß† Starting pain extraction...\")\n",
    "    \n",
    "    try:\n",
    "        # Try to get transcript from state first\n",
    "        transcript = state.get('transcript_text')\n",
    "        \n",
    "        # ADDED: If not in state, get from database using conversation_id\n",
    "        if not transcript:\n",
    "            conversation_id = state.get('conversation_id')\n",
    "            if conversation_id:\n",
    "                print(f\"   üìù Transcript not in state, loading from database (conversation {conversation_id})...\")\n",
    "                conv = db.get_conversation(conversation_id)\n",
    "                if conv:\n",
    "                    # Try raw_text field (your database schema)\n",
    "                    transcript = get_conv_attribute(conv, 'raw_text', None)\n",
    "                    if transcript:\n",
    "                        print(f\"   ‚úÖ Loaded transcript from database ({len(transcript)} chars)\")\n",
    "                    else:\n",
    "                        print(f\"   ‚ö†Ô∏è  No raw_text found in conversation\")\n",
    "        \n",
    "        # If still no transcript, fail\n",
    "        if not transcript:\n",
    "            print(\"‚ùå No transcript available\")\n",
    "            return {\n",
    "                **state,\n",
    "                \"error\": \"No transcript available for pain extraction\",\n",
    "                \"status\": \"error\"\n",
    "            }\n",
    "        \n",
    "        # Extract insights using OpenAI structured output\n",
    "        insights = extract_insights_from_transcript(transcript)\n",
    "        \n",
    "        if insights:\n",
    "            print(f\"‚úÖ Extracted insights: {len(insights.primary_challenges)} primary challenges, {len(insights.speakers)} speakers\")\n",
    "            \n",
    "            return {\n",
    "                **state,\n",
    "                \"extracted_insights\": insights,\n",
    "                \"status\": \"insights_extracted\"\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                **state,\n",
    "                \"error\": \"Failed to extract insights from transcript\",\n",
    "                \"status\": \"error\"\n",
    "            }\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Pain extraction failed: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return {\n",
    "            **state,\n",
    "            \"error\": f\"Pain extraction error: {str(e)}\",\n",
    "            \"status\": \"error\"\n",
    "        }\n",
    "\n",
    "print(\"‚úÖ pain_extractor_node fixed (now checks database for transcript)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8a0137a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Creative agent node RELOADED\n"
     ]
    }
   ],
   "source": [
    "# Cell: Creative Agent Node - FORCE RELOAD\n",
    "def creative_agent_node(state: AudioPipelineState) -> AudioPipelineState:\n",
    "    \"\"\"Creative agent that generates raw blog ideas\"\"\"\n",
    "    \n",
    "    try:\n",
    "        print(\"üé® Starting creative blog idea generation...\")\n",
    "        \n",
    "        insights = state.get('extracted_insights')\n",
    "        if not insights:\n",
    "            return {**state, \"error\": \"No insights available\", \"status\": \"error\"}\n",
    "        \n",
    "        print(f\"üìä Working with insights: {len(insights.primary_challenges)} challenges\")\n",
    "        \n",
    "        # Load strategy context\n",
    "        strategy_context = load_company_strategy_context()\n",
    "        \n",
    "        # Generate ideas (returns JSON list)\n",
    "        raw_ideas_json = generate_blog_ideas_from_insights(insights, strategy_context)\n",
    "        \n",
    "        if not raw_ideas_json:\n",
    "            return {**state, \"error\": \"No ideas generated\", \"status\": \"error\"}\n",
    "        \n",
    "        # Convert to Pydantic for validation\n",
    "        validated_ideas = []\n",
    "        for idea_json in raw_ideas_json:\n",
    "            try:\n",
    "                idea = RawBlogIdea(**idea_json)\n",
    "                validated_ideas.append(idea)\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è Skipping invalid idea: {e}\")\n",
    "        \n",
    "        if validated_ideas:\n",
    "            print(f\"üéâ Generated {len(validated_ideas)} valid blog ideas\")\n",
    "            \n",
    "            # Convert back to dict for state storage\n",
    "            ideas_as_dicts = [idea.model_dump() for idea in validated_ideas]\n",
    "            \n",
    "            return {\n",
    "                **state,\n",
    "                \"raw_blog_ideas\": ideas_as_dicts,\n",
    "                \"status\": \"ideas_generated\"\n",
    "            }\n",
    "        else:\n",
    "            return {**state, \"error\": \"No valid ideas after validation\", \"status\": \"error\"}\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Creative agent error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return {**state, \"error\": str(e), \"status\": \"error\"}\n",
    "\n",
    "print(\"‚úÖ Creative agent node RELOADED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "180267b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def writing_agent_node(state: AudioPipelineState) -> AudioPipelineState:\n",
    "    \"\"\"Future node: Generate blog post from plan.\"\"\"\n",
    "    plan = state.get(\"blog_plan\")\n",
    "    if not plan:\n",
    "        return state  # Skip if no plan\n",
    "    \n",
    "    instructions = f\"Write a full blog post for Big Kids Automation Agency using this plan: {plan.plan}\"\n",
    "    # Structured LLM (inspired by your snippet)\n",
    "    structured_llm = llm.with_structured_output(BlogPost)  # Use your BlogPost model\n",
    "    blog_post = structured_llm.invoke([SystemMessage(content=instructions), HumanMessage(content=\"Write the post.\")])\n",
    "    state[\"blog_post\"] = {\"title\": blog_post.title, \"content\": blog_post.content}\n",
    "    return state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dbc0740a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Analyst agent node FIXED for Pydantic objects\n"
     ]
    }
   ],
   "source": [
    "# Cell 19: Analyst Agent Node - FIXED for Pydantic Objects\n",
    "def analyst_agent_node(state: AudioPipelineState) -> AudioPipelineState:\n",
    "    \"\"\"\n",
    "    LangGraph node that scores blog ideas using company strategy context\n",
    "    Input: state[\"raw_blog_ideas\"] \n",
    "    Output: state[\"scored_blog_ideas\"]\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        print(\"üîç Starting analyst agent - scoring blog ideas...\")\n",
    "        \n",
    "        # Check current status\n",
    "        current_status = state.get('status', '')\n",
    "        print(f\"üìä Input status: {current_status}\")\n",
    "        \n",
    "        # Check if we have raw blog ideas to score\n",
    "        raw_ideas = state.get('raw_blog_ideas')\n",
    "        if not raw_ideas:\n",
    "            return {\n",
    "                **state,\n",
    "                \"error\": \"No raw blog ideas available for scoring\",\n",
    "                \"status\": \"error\"\n",
    "            }\n",
    "        \n",
    "        print(f\"üìä Found {len(raw_ideas)} blog ideas to score\")\n",
    "        \n",
    "        # Load strategy context for scoring\n",
    "        print(\"üìö Loading strategy context...\")\n",
    "        strategy_context = prepare_strategy_context_for_scoring()\n",
    "        \n",
    "        # Get conversation context for better scoring\n",
    "        conversation_context = state.get('transcript_text', '')\n",
    "        \n",
    "        # Score each blog idea\n",
    "        scored_ideas = []\n",
    "        for i, idea in enumerate(raw_ideas, 1):\n",
    "            # FIXED: Handle both Pydantic objects and dicts properly\n",
    "            if hasattr(idea, 'title'):\n",
    "                # It's a Pydantic object - convert to dict first\n",
    "                idea_dict = idea.model_dump() if hasattr(idea, 'model_dump') else idea.__dict__\n",
    "                title_preview = idea.title[:50]\n",
    "            else:\n",
    "                # It's already a dict\n",
    "                idea_dict = idea\n",
    "                title_preview = idea.get('title', 'No title')[:50]\n",
    "            \n",
    "            print(f\"üîç Scoring idea {i}/{len(raw_ideas)}: {title_preview}...\")\n",
    "            \n",
    "            # Score the idea (now always working with dict)\n",
    "            scores = score_blog_idea_with_llm(idea_dict, strategy_context, conversation_context)\n",
    "            \n",
    "            # Combine original idea with scores\n",
    "            scored_idea = {\n",
    "                **idea_dict,  # Original idea data (now definitely a dict)\n",
    "                **scores      # Scoring data\n",
    "            }\n",
    "            \n",
    "            scored_ideas.append(scored_idea)\n",
    "            \n",
    "            print(f\"   ‚úÖ Scored: {scores.get('total_score', 0)}/70 points\")\n",
    "        \n",
    "        # Sort by total score (highest first)\n",
    "        scored_ideas.sort(key=lambda x: x.get('total_score', 0), reverse=True)\n",
    "        \n",
    "        print(f\"\\nüéâ Analyst agent completed scoring!\")\n",
    "        print(f\"üìä Scored {len(scored_ideas)} ideas\")\n",
    "        \n",
    "        if scored_ideas:\n",
    "            print(f\"üèÜ Top idea: '{scored_ideas[0].get('title', 'Unknown')[:50]}...' ({scored_ideas[0].get('total_score', 0)}/70)\")\n",
    "            print(f\"üìâ Lowest idea: '{scored_ideas[-1].get('title', 'Unknown')[:50]}...' ({scored_ideas[-1].get('total_score', 0)}/70)\")\n",
    "        \n",
    "        return {\n",
    "            **state,\n",
    "            \"scored_blog_ideas\": scored_ideas,\n",
    "            \"status\": \"ideas_scored\"\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error in analyst agent node: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        \n",
    "        return {\n",
    "            **state,\n",
    "            \"error\": f\"Analyst agent error: {str(e)}\",\n",
    "            \"status\": \"error\"\n",
    "        }\n",
    "\n",
    "print(\"‚úÖ Analyst agent node FIXED for Pydantic objects\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f5cabeaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ AssemblyAI connection successful\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 4: Test AssemblyAI Connection\n",
    "# Configure AssemblyAI\n",
    "aai.settings.api_key = os.getenv('ASSEMBLYAI_API_KEY')\n",
    "\n",
    "# Test with a simple transcription (we'll use a file from temp folder)\n",
    "def test_assemblyai_connection():\n",
    "    \"\"\"Test if AssemblyAI is working\"\"\"\n",
    "    try:\n",
    "        # Just test the API key is valid\n",
    "        transcriber = aai.Transcriber()\n",
    "        print(\"‚úÖ AssemblyAI connection successful\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå AssemblyAI connection failed: {e}\")\n",
    "        return False\n",
    "\n",
    "test_assemblyai_connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8762d70d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Database saver node (blog ideas) ready - FIXED RETURN\n"
     ]
    }
   ],
   "source": [
    "# Cell: Database Saver Node for BLOG IDEAS (Node 6) - FIXED RETURN\n",
    "from database.models import BlogPostIdeaCreate\n",
    "\n",
    "def database_saver_node(state: AudioPipelineState) -> AudioPipelineState:\n",
    "    \"\"\"\n",
    "    LangGraph node that saves scored blog ideas to database\n",
    "    Input: state[\"scored_blog_ideas\"]\n",
    "    Output: state[\"saved_idea_ids\"]\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        print(\"üíæ Starting database saver - saving scored blog ideas...\")\n",
    "        \n",
    "        scored_ideas = state.get('scored_blog_ideas')\n",
    "        conversation_id = state.get('conversation_id')\n",
    "        \n",
    "        if not scored_ideas:\n",
    "            print(\"‚ùå No scored blog ideas available to save\")\n",
    "            return {\n",
    "                **state,\n",
    "                \"error\": \"No scored blog ideas available to save\",\n",
    "                \"status\": \"error\"\n",
    "            }\n",
    "        \n",
    "        if not conversation_id:\n",
    "            print(\"‚ùå No conversation_id available for linking ideas\")\n",
    "            return {\n",
    "                **state,\n",
    "                \"error\": \"No conversation_id available for linking ideas\",\n",
    "                \"status\": \"error\"\n",
    "            }\n",
    "        \n",
    "        print(f\"üìä Found {len(scored_ideas)} scored ideas to save\")\n",
    "        print(f\"üîó Linking ideas to conversation_id: {conversation_id}\")\n",
    "        \n",
    "        saved_idea_ids = []\n",
    "        failed_count = 0\n",
    "        \n",
    "        for i, scored_idea in enumerate(scored_ideas, 1):\n",
    "            try:\n",
    "                # Calculate total_score if not present\n",
    "                if 'total_score' not in scored_idea:\n",
    "                    scored_idea['total_score'] = sum([\n",
    "                        scored_idea.get('usefulness_potential', 0),\n",
    "                        scored_idea.get('fitwith_seo_strategy', 0),\n",
    "                        scored_idea.get('fitwith_content_strategy', 0),\n",
    "                        scored_idea.get('inspiration_potential', 0),\n",
    "                        scored_idea.get('collaboration_potential', 0),\n",
    "                        scored_idea.get('innovation', 0),\n",
    "                        scored_idea.get('difficulty', 0)\n",
    "                    ])\n",
    "                \n",
    "                blog_idea = BlogPostIdeaCreate(\n",
    "                    conversation_id=conversation_id,\n",
    "                    title=scored_idea.get('title', 'Untitled'),\n",
    "                    description=scored_idea.get('description', ''),\n",
    "                    usefulness_potential=scored_idea.get('usefulness_potential', 5),\n",
    "                    fitwith_seo_strategy=scored_idea.get('fitwith_seo_strategy', 5),\n",
    "                    fitwith_content_strategy=scored_idea.get('fitwith_content_strategy', 5),\n",
    "                    inspiration_potential=scored_idea.get('inspiration_potential', 5),\n",
    "                    collaboration_potential=scored_idea.get('collaboration_potential', 5),\n",
    "                    innovation=scored_idea.get('innovation', 5),\n",
    "                    difficulty=scored_idea.get('difficulty', 5),\n",
    "                    sent_to_prod=False,\n",
    "                    raw_llm_response=scored_idea.get('reasoning', None)\n",
    "                )\n",
    "                \n",
    "                idea_id = db.create_blog_post_idea(blog_idea)\n",
    "                saved_idea_ids.append(idea_id)\n",
    "                \n",
    "                print(f\"   ‚úÖ Saved idea {i}: '{scored_idea.get('title', 'Unknown')[:50]}...' (ID: {idea_id})\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"   ‚ùå Failed to save idea {i}: {e}\")\n",
    "                failed_count += 1\n",
    "        \n",
    "        if saved_idea_ids:\n",
    "            print(f\"\\nüéâ Database saver completed!\")\n",
    "            print(f\"‚úÖ Successfully saved: {len(saved_idea_ids)} ideas\")\n",
    "            if failed_count > 0:\n",
    "                print(f\"‚ö†Ô∏è  Failed to save: {failed_count} ideas\")\n",
    "            \n",
    "            # FIXED: Explicitly return saved_idea_ids in the state\n",
    "            return {\n",
    "                **state,\n",
    "                \"saved_idea_ids\": saved_idea_ids,  # ‚Üê This is the critical line\n",
    "                \"status\": \"ideas_saved_to_db\"\n",
    "            }\n",
    "        else:\n",
    "            print(\"‚ùå Failed to save any ideas to database\")\n",
    "            return {\n",
    "                **state,\n",
    "                \"saved_idea_ids\": [],  # Return empty list instead of None\n",
    "                \"error\": \"Failed to save any ideas to database\",\n",
    "                \"status\": \"error\"\n",
    "            }\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error in database saver node: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        \n",
    "        return {\n",
    "            **state,\n",
    "            \"saved_idea_ids\": [],  # Return empty list on error\n",
    "            \"error\": f\"Database saver error: {str(e)}\",\n",
    "            \"status\": \"error\"\n",
    "        }\n",
    "\n",
    "print(\"‚úÖ Database saver node (blog ideas) ready - FIXED RETURN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8c379c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Pipeline compiled (8 nodes, with HITL interrupt)\n"
     ]
    }
   ],
   "source": [
    "# Cell 21: Updated Pipeline Builder - Now with 8 Nodes\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "def build_pipeline():\n",
    "    workflow = StateGraph(AudioPipelineState)\n",
    "    # Existing nodes (transcribe, save_to_db, extract_insights, creative_agent, analyst_agent, save_ideas)\n",
    "    workflow.add_node(\"transcribe\", transcription_node)\n",
    "    workflow.add_node(\"save_to_db\", database_saver_node_conversations)  \n",
    "    workflow.add_node(\"extract_insights\", pain_extractor_node)\n",
    "    workflow.add_node(\"creative_agent\", creative_agent_node)\n",
    "    workflow.add_node(\"analyst_agent\", analyst_agent_node)\n",
    "    workflow.add_node(\"save_ideas\", database_saver_node)\n",
    "    \n",
    "    # NEW: HITL and planning\n",
    "    workflow.add_node(\"idea_selection_hitl\", idea_selection_hitl)\n",
    "    workflow.add_node(\"planning_agent\", planning_agent_node)\n",
    "    \n",
    "    # Existing edges\n",
    "    workflow.add_edge(\"transcribe\", \"save_to_db\")\n",
    "    workflow.add_edge(\"save_to_db\", \"extract_insights\")\n",
    "    workflow.add_edge(\"extract_insights\", \"creative_agent\")\n",
    "    workflow.add_edge(\"creative_agent\", \"analyst_agent\")    \n",
    "    workflow.add_edge(\"analyst_agent\", \"save_ideas\")\n",
    "    \n",
    "    # NEW: Edges with HITL\n",
    "    workflow.add_edge(\"save_ideas\", \"idea_selection_hitl\")\n",
    "    workflow.add_edge(\"idea_selection_hitl\", \"planning_agent\")\n",
    "    \n",
    "    workflow.set_entry_point(\"transcribe\")\n",
    "    workflow.set_finish_point(\"planning_agent\")\n",
    "    \n",
    "    # Compile with checkpointer for HITL persistence\n",
    "    memory = MemorySaver()\n",
    "    return workflow.compile(checkpointer=memory, interrupt_before=[\"idea_selection_hitl\"])\n",
    "\n",
    "\n",
    "# In builder: Add node and edge\n",
    "#workflow.add_node(\"writing_agent\", writing_agent_node)\n",
    "#workflow.add_edge(\"planning_agent\", \"writing_agent\")\n",
    "#workflow.set_finish_point(\"writing_agent\")\n",
    "\n",
    "# Rebuild\n",
    "pipeline = build_pipeline()\n",
    "print(\"‚úÖ Pipeline compiled (8 nodes, with HITL interrupt)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2e18e44f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Anthropic LLM initialized with Claude Haiku 4.5\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Setup Anthropic LLM for Insights Extraction (FIXED)\n",
    "\n",
    "\n",
    "# Initialize Anthropic with correct model name\n",
    "anthropic_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "if not anthropic_key:\n",
    "    print(\"‚ö†Ô∏è  ANTHROPIC_API_KEY not found in .env file\")\n",
    "    print(\"Please add: ANTHROPIC_API_KEY=your_key_here\")\n",
    "else:\n",
    "    llm = ChatAnthropic(\n",
    "        model=\"claude-haiku-4-5\",  # ‚Üê Updated model name\n",
    "        api_key=anthropic_key,\n",
    "        temperature=0.1\n",
    "    )\n",
    "    print(\"‚úÖ Anthropic LLM initialized with Claude Haiku 4.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6b3cea20",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3. PainExtractor Node Implementation\n",
    "\n",
    "# System prompt\n",
    "PAIN_EXTRACTOR_SYSTEM_PROMPT = \"\"\"\n",
    "You are a UX researcher and business analyst for BigKids Automation. Your job is listening to transcripts from interviews with users and potential clients. \n",
    "\n",
    "You pay special attention to problems that users have regarding how their company is automating, using web apps and AI to save time and move towards a more ethical and sovereign tech infrastructure.\n",
    "\n",
    "You will be given the transcript of an interview with a user or potential client.\n",
    "\n",
    "Your task is to extract structured information about:\n",
    "- Who is speaking and their role\n",
    "- What this person cares about (values, priorities)\n",
    "- Their main primary and secondary challenges\n",
    "- How they are solving problems today\n",
    "- Are there AI agents that can assist them?\n",
    "- Their underlying psychological needs (using frameworks like NVC - Non-Violent Communication)\n",
    "\n",
    "Focus on automation, web apps, AI, time-saving, ethical tech, and sovereign infrastructure themes.\n",
    "\n",
    "Be thorough but concise. \n",
    "\n",
    "IMPORTANT: Only extract information that is explicitly mentioned in the transcript. \n",
    "If information is not clearly stated, leave the field empty/null rather than guessing or inferring.\n",
    "Do not hallucinate or make assumptions about missing information.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4465cb3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded company strategy (6555 chars)\n",
      "‚úÖ Loaded SEO strategy (1120 chars)\n",
      "‚úÖ Loaded content strategy (4469 chars)\n",
      "‚úÖ Enhanced strategy context for scoring with 3 documents\n",
      "   Company strategy: 6555 chars\n",
      "   SEO strategy: 1120 chars\n",
      "   Content strategy: 4469 chars\n"
     ]
    }
   ],
   "source": [
    "# Cell 16: Enhanced Strategy Context for Scoring (Updated for 3 Documents)\n",
    "def prepare_strategy_context_for_scoring():\n",
    "    \"\"\"Prepare strategy context for scoring using all three strategy documents\"\"\"\n",
    "    \n",
    "    # Load all three strategy documents\n",
    "    strategy_context = load_company_strategy_context()\n",
    "    \n",
    "    # Add scoring guidelines\n",
    "    strategy_context[\"scoring_guidelines\"] = \"\"\"\n",
    "    SCORING CRITERIA (1-10 scale):\n",
    "    \n",
    "    1. usefulness_potential: How useful will this post be to readers with problems?\n",
    "    2. fitwith_seo_strategy: How well does this align with our SEO strategy and keywords?\n",
    "    3. fitwith_content_strategy: How well does this fit our content strategy and voice?\n",
    "    4. inspiration_potential: How likely is this to inspire readers to take action?\n",
    "    5. collaboration_potential: How likely is this to encourage prospects to contact us?\n",
    "    6. innovation: How unique/differentiated is this topic (10 = very unique)?\n",
    "    7. difficulty: How complex is this to write (1 = very complex, 10 = easy)?\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create summaries for LLM prompt efficiency (all three documents)\n",
    "    if strategy_context.get('company_strategy'):\n",
    "        strategy_context[\"company_strategy_summary\"] = strategy_context['company_strategy'][:800] + \"...\"\n",
    "    \n",
    "    if strategy_context.get('seo_strategy'):\n",
    "        strategy_context[\"seo_strategy_summary\"] = strategy_context['seo_strategy'][:600] + \"...\"\n",
    "    \n",
    "    if strategy_context.get('content_strategy'):  # NEW\n",
    "        strategy_context[\"content_strategy_summary\"] = strategy_context['content_strategy'][:600] + \"...\"\n",
    "    \n",
    "    print(f\"‚úÖ Enhanced strategy context for scoring with 3 documents\")\n",
    "    print(f\"   Company strategy: {len(strategy_context.get('company_strategy', ''))} chars\")\n",
    "    print(f\"   SEO strategy: {len(strategy_context.get('seo_strategy', ''))} chars\")\n",
    "    print(f\"   Content strategy: {len(strategy_context.get('content_strategy', ''))} chars\")\n",
    "    \n",
    "    return strategy_context\n",
    "\n",
    "# Test the enhanced context\n",
    "enhanced_context = prepare_strategy_context_for_scoring()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e7786fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Testing three-document strategy loading...\n",
      "‚úÖ Loaded company strategy (6555 chars)\n",
      "‚úÖ Loaded SEO strategy (1120 chars)\n",
      "‚úÖ Loaded content strategy (4469 chars)\n",
      "‚úÖ Enhanced strategy context for scoring with 3 documents\n",
      "   Company strategy: 6555 chars\n",
      "   SEO strategy: 1120 chars\n",
      "   Content strategy: 4469 chars\n",
      "\n",
      "üìä DOCUMENT SUMMARY:\n",
      "   company_strategy: ‚úÖ Loaded (6555 chars)\n",
      "   seo_strategy: ‚úÖ Loaded (1120 chars)\n",
      "   content_strategy: ‚úÖ Loaded (4469 chars)\n"
     ]
    }
   ],
   "source": [
    "# Cell: Fixed Test Function (No Duplicate Loading)\n",
    "def test_three_document_loading():\n",
    "    \"\"\"Test loading all three strategy documents (optimized)\"\"\"\n",
    "    \n",
    "    print(\"üß™ Testing three-document strategy loading...\")\n",
    "    \n",
    "    # Load documents once and enhance\n",
    "    enhanced = prepare_strategy_context_for_scoring()  # This calls load_company_strategy_context() internally\n",
    "    \n",
    "    print(f\"\\nüìä DOCUMENT SUMMARY:\")\n",
    "    for doc_type in ['company_strategy', 'seo_strategy', 'content_strategy']:\n",
    "        if doc_type in enhanced:\n",
    "            length = len(enhanced[doc_type]) if enhanced[doc_type] else 0\n",
    "            status = \"‚úÖ Loaded\" if length > 100 else \"‚ö†Ô∏è Missing/Short\"\n",
    "            print(f\"   {doc_type}: {status} ({length} chars)\")\n",
    "    \n",
    "    return enhanced\n",
    "\n",
    "# Test with no duplicates\n",
    "test_context = test_three_document_loading()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cda619a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Ready to test complete 8-node pipeline\n",
      "üí° Run the cell below to execute the test\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CELL 22: EXECUTE COMPLETE 8-NODE PIPELINE TEST (WITH HITL)\n",
    "# ============================================================\n",
    "\n",
    "import uuid  # For generating unique thread_ids\n",
    "\n",
    "def test_complete_8_node_pipeline():\n",
    "    \"\"\"Test the complete 8-node pipeline: Audio ‚Üí Transcribe ‚Üí Save ‚Üí Insights ‚Üí Ideas ‚Üí Scoring ‚Üí Save Ideas ‚Üí HITL ‚Üí Planning ‚Üí (Optional) Writing\"\"\"\n",
    "    print(\"üß™ EXECUTING COMPLETE 8-NODE PIPELINE TEST...\")\n",
    "    print(\"Audio ‚Üí Transcribe ‚Üí Save ‚Üí Insights ‚Üí Ideas ‚Üí Scoring ‚Üí Save Ideas ‚Üí HITL ‚Üí Planning ‚Üí (Optional) Writing\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    # Find audio files\n",
    "    audio_files = find_audio_files_in_temp()\n",
    "    if not audio_files:\n",
    "        print(\"‚ùå No audio files found in data/temp/\")\n",
    "        print(\"üí° Add .wav files to data/temp/ and run this cell again\")\n",
    "        return None\n",
    "    print(f\"üìÅ Found {len(audio_files)} audio file(s)\")\n",
    "    print(f\"üéØ Testing with: {audio_files[0].name}\")\n",
    "    print(f\"üìä File size: {audio_files[0].stat().st_size / 1024:.1f} KB\")\n",
    "    \n",
    "    # Create initial state for 8-node pipeline (extended from your 6-node version)\n",
    "    initial_state = {\n",
    "        \"file_path\": str(audio_files[0]),\n",
    "        \"filename\": audio_files[0].name,\n",
    "        \"transcript_text\": None,\n",
    "        \"conversation_id\": None,\n",
    "        \"extracted_insights\": None,\n",
    "        \"raw_blog_ideas\": None,\n",
    "        \"scored_blog_ideas\": None,\n",
    "        \"saved_idea_ids\": None,\n",
    "        \"selected_idea_id\": None,     # NEW: For HITL\n",
    "        \"selected_idea\": None,        # NEW: For HITL\n",
    "        \"strategy_context\": None,     # NEW: For planning\n",
    "        \"blog_plan\": None,            # NEW: For planning\n",
    "        \"blog_post\": None,            # NEW: For future writing (optional)\n",
    "        \"error\": None,\n",
    "        \"status\": \"processing\"\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        print(\"\\nüé¨ STARTING COMPLETE PIPELINE EXECUTION...\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # Generate unique thread_id for persistence\n",
    "        thread_id = str(uuid.uuid4())\n",
    "        config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "        \n",
    "        # Run the pipeline up to the interrupt (after Node 6)\n",
    "        print(\"üèÉ Running up to HITL interrupt...\")\n",
    "        pipeline.invoke(initial_state, config=config)\n",
    "        \n",
    "        # Simulate HITL: Get current state, prompt for selection, update, and resume\n",
    "        print(\"\\nü§ù HITL SIMULATION: Paused for idea selection\")\n",
    "        current_state = pipeline.get_state(config).values\n",
    "        scored_ideas = current_state.get(\"scored_blog_ideas\", [])\n",
    "        saved_ids = current_state.get(\"saved_idea_ids\", [])\n",
    "        print(f\"   Available Ideas (Saved IDs): {saved_ids}\")\n",
    "        print(f\"   Scored Ideas Preview: {[idea.get('title', 'No title') for idea in scored_ideas]}\")\n",
    "        \n",
    "        # Prompt for human input (in dev; replace with UI/API in prod)\n",
    "        selected_id = int(input(\"Enter selected idea ID (from saved_ids): \"))  # Or hardcoded for auto-test: e.g., saved_ids[0]\n",
    "        selected_idea = next((idea for idea in scored_ideas if idea.get(\"id\") == selected_id), {})  # Adjust key if needed\n",
    "        \n",
    "        # Update state with selection\n",
    "        updated_state = current_state.copy()\n",
    "        updated_state[\"selected_idea_id\"] = selected_id\n",
    "        updated_state[\"selected_idea\"] = selected_idea\n",
    "        pipeline.update_state(config, updated_state)\n",
    "        print(f\"   ‚úÖ HITL Complete: Selected Idea ID {selected_id}\")\n",
    "        \n",
    "        # Resume the pipeline (runs HITL node, planning, and optional writing)\n",
    "        print(\"üèÉ Resuming pipeline from HITL...\")\n",
    "        final_state = pipeline.invoke(None, config=config)  # None as input to resume\n",
    "        \n",
    "        print(f\"\\nüìä COMPLETE PIPELINE RESULTS:\")\n",
    "        print(\"=\" * 60)\n",
    "        print(f\"üéØ Final Status: {final_state.get('status')}\")\n",
    "        print(f\"üìù Conversation ID: {final_state.get('conversation_id')}\")\n",
    "        print(f\"üíæ Saved Blog Idea IDs: {final_state.get('saved_idea_ids')}\")\n",
    "        \n",
    "        # Check all pipeline stages (extended for new nodes)\n",
    "        print(f\"\\nüìã STAGE RESULTS:\")\n",
    "        stages = [\n",
    "            (\"üéôÔ∏è  Transcription\", final_state.get('transcript_text')),\n",
    "            (\"üíæ Database Save (Conversation)\", final_state.get('conversation_id')),\n",
    "            (\"üß† Insights Extraction\", final_state.get('extracted_insights')),\n",
    "            (\"üé® Blog Ideas Generation\", final_state.get('raw_blog_ideas')),\n",
    "            (\"üîç Blog Ideas Scoring\", final_state.get('scored_blog_ideas')),\n",
    "            (\"üíæ Database Save (Ideas)\", final_state.get('saved_idea_ids')),\n",
    "            (\"ü§ù HITL Idea Selection\", final_state.get('selected_idea_id') is not None),  # NEW\n",
    "            (\"üìù Planning\", final_state.get('blog_plan')),  # NEW\n",
    "            # (\"‚úçÔ∏è Writing\", final_state.get('blog_post'))  # NEW: Uncomment if writing node is added\n",
    "        ]\n",
    "        all_passed = True\n",
    "        for stage_name, stage_data in stages:\n",
    "            status = \"‚úÖ\" if stage_data else \"‚ùå\"\n",
    "            print(f\"   {stage_name}: {status}\")\n",
    "            if not stage_data:\n",
    "                all_passed = False\n",
    "        \n",
    "        # Show detailed results if all stages passed\n",
    "        if all_passed and final_state.get('scored_blog_ideas') and final_state.get('saved_idea_ids'):\n",
    "            scored_ideas = final_state['scored_blog_ideas']\n",
    "            saved_ids = final_state['saved_idea_ids']\n",
    "            print(f\"\\nüéâ COMPLETE SUCCESS! Pipeline generated, scored, saved, selected, and planned {len(saved_ids)} blog ideas\")\n",
    "            print(\"=\" * 80)\n",
    "            \n",
    "            # Existing sections (conversation, insights, DB summary, top ideas) -- unchanged from your code\n",
    "            # (Insert your existing print blocks here for conversation details, insights summary, DB save summary, and top scored ideas)\n",
    "            \n",
    "            # NEW: Show HITL and planning results\n",
    "            print(f\"\\nü§ù HITL Selection:\")\n",
    "            print(f\"   Selected Idea ID: {final_state.get('selected_idea_id')}\")\n",
    "            print(f\"   Selected Idea Title: {final_state.get('selected_idea', {}).get('title', 'N/A')}\")\n",
    "            \n",
    "            print(f\"\\nüìù Generated Blog Plan:\")\n",
    "            blog_plan = final_state.get('blog_plan')\n",
    "            if blog_plan:\n",
    "                print(blog_plan.plan)  # Uses the @property from Plan\n",
    "                print(f\"   Q&A Pairs Count: {len(blog_plan.qa_pairs)}\")\n",
    "                print(f\"   Instructions Count: {len(blog_plan.instructions)}\")\n",
    "            else:\n",
    "                print(\"   No plan generated\")\n",
    "            \n",
    "            # NEW: If writing node is enabled\n",
    "            # blog_post = final_state.get('blog_post')\n",
    "            # if blog_post:\n",
    "            #     print(f\"\\n‚úçÔ∏è Generated Blog Post:\")\n",
    "            #     print(f\"   Title: {blog_post.get('title')}\")\n",
    "            #     print(f\"   Content Preview: {blog_post.get('content')[:200]}...\")\n",
    "            \n",
    "            print(\"=\" * 80)\n",
    "            print(\"üéâ COMPLETE 8-NODE PIPELINE: SUCCESS!\")\n",
    "            print(\"‚úÖ All stages completed successfully\")\n",
    "            print(f\"üíæ Conversation saved (ID: {final_state.get('conversation_id')})\")\n",
    "            print(f\"üíæ {len(saved_ids)} blog ideas saved to database\")\n",
    "            print(f\"üîó Ideas linked to conversation for traceability\")\n",
    "            \n",
    "            # Extended NEXT STEPS\n",
    "            print(f\"\\nüí° NEXT STEPS:\")\n",
    "            print(f\"   ‚Ä¢ Query saved ideas: db.get_blog_post_ideas_by_conversation({final_state.get('conversation_id')})\")\n",
    "            print(f\"   ‚Ä¢ View conversation: db.get_conversation({final_state.get('conversation_id')})\")\n",
    "            print(f\"   ‚Ä¢ Access specific idea: db.get_blog_post_idea({saved_ids[0]})\")\n",
    "            print(f\"   ‚Ä¢ Review plan: Access final_state['blog_plan']\")\n",
    "        \n",
    "        else:\n",
    "            # Something failed (unchanged from your code)\n",
    "            print(\"\\n‚ùå PIPELINE INCOMPLETE\")\n",
    "            print(\"=\" * 50)\n",
    "            if final_state.get('error'):\n",
    "                print(f\"‚ùå Error: {final_state.get('error')}\")\n",
    "            else:\n",
    "                print(\"‚ùå Pipeline stopped but no error message provided\")\n",
    "            # Extended DEBUG INFO\n",
    "            print(f\"\\nüîç DEBUG INFO:\")\n",
    "            print(f\"   Transcript exists: {bool(final_state.get('transcript_text'))}\")\n",
    "            if final_state.get('transcript_text'):\n",
    "                print(f\"   Transcript preview: {final_state.get('transcript_text')[:100]}...\")\n",
    "            print(f\"   Conversation ID: {final_state.get('conversation_id')}\")\n",
    "            print(f\"   Insights exist: {bool(final_state.get('extracted_insights'))}\")\n",
    "            print(f\"   Raw ideas exist: {bool(final_state.get('raw_blog_ideas'))}\")\n",
    "            if final_state.get('raw_blog_ideas'):\n",
    "                print(f\"   Raw ideas count: {len(final_state.get('raw_blog_ideas'))}\")\n",
    "            print(f\"   Scored ideas exist: {bool(final_state.get('scored_blog_ideas'))}\")\n",
    "            if final_state.get('scored_blog_ideas'):\n",
    "                print(f\"   Scored ideas count: {len(final_state.get('scored_blog_ideas'))}\")\n",
    "            print(f\"   Saved idea IDs exist: {bool(final_state.get('saved_idea_ids'))}\")\n",
    "            if final_state.get('saved_idea_ids'):\n",
    "                print(f\"   Saved ideas count: {len(final_state.get('saved_idea_ids'))}\")\n",
    "            # NEW: Debug for new fields\n",
    "            print(f\"   Selected Idea ID: {final_state.get('selected_idea_id')}\")\n",
    "            print(f\"   Blog Plan exists: {bool(final_state.get('blog_plan'))}\")\n",
    "        \n",
    "        return final_state\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå COMPLETE PIPELINE FAILED WITH EXCEPTION:\")\n",
    "        print(f\"   {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "# ============================================================\n",
    "# RUN THE TEST\n",
    "# ============================================================\n",
    "\n",
    "print(\"üöÄ Ready to test complete 8-node pipeline\")\n",
    "print(\"üí° Run the cell below to execute the test\\n\")\n",
    "\n",
    "# Uncomment the line below to run automatically, or run it manually\n",
    "# test_result = test_complete_8_node_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "61b3158d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ EXECUTING COMPLETE 8-NODE PIPELINE TEST...\n",
      "Audio ‚Üí Transcribe ‚Üí Save ‚Üí Insights ‚Üí Ideas ‚Üí Scoring ‚Üí Save Ideas ‚Üí HITL ‚Üí Planning ‚Üí (Optional) Writing\n",
      "------------------------------------------------------------\n",
      "üìÅ Found 1 audio file(s)\n",
      "üéØ Testing with: blog_ecord (2025-12-01 19_47_21).wav\n",
      "üìä File size: 93975.4 KB\n",
      "\n",
      "üé¨ STARTING COMPLETE PIPELINE EXECUTION...\n",
      "============================================================\n",
      "üèÉ Running up to HITL interrupt...\n",
      "üéôÔ∏è Transcribing: blog_ecord (2025-12-01 19_47_21).wav\n",
      "üíæ Saving to database: blog_ecord (2025-12-01 19_47_21).wav\n",
      "üß† Starting pain extraction...\n",
      "üìù Raw response length: 3905 chars\n",
      "üìù Response starts with: ```json\n",
      "{\n",
      "    \"speakers\": [\n",
      "        {\n",
      "            ...\n",
      "üîß Removing JSON markdown blocks...\n",
      "üîß Cleaned content starts with: {\n",
      "    \"speakers\": [\n",
      "        {\n",
      "            \"name\": ...\n",
      "‚úÖ JSON parsed successfully\n",
      "‚úÖ Successfully extracted insights!\n",
      "   Speakers: 2\n",
      "   Challenges: 3\n",
      "   Needs: 5\n",
      "   Values: 4\n",
      "‚úÖ Extracted insights: 3 primary challenges, 2 speakers\n",
      "üé® Starting creative blog idea generation...\n",
      "üìä Working with insights: 3 challenges\n",
      "‚úÖ Loaded company strategy (6555 chars)\n",
      "‚úÖ Loaded SEO strategy (1120 chars)\n",
      "‚úÖ Loaded content strategy (4469 chars)\n",
      "üìù Raw response length: 4274 chars\n",
      "üìù Response starts with: ```json\n",
      "[\n",
      "    {\n",
      "        \"title\": \"From Local POC t...\n",
      "üîß Removing markdown code blocks...\n",
      "üîß Cleaned content starts with: [\n",
      "    {\n",
      "        \"title\": \"From Local POC to Produc...\n",
      "‚úÖ Creative agent successfully parsed 5 blog ideas\n",
      "üéâ Generated 5 valid blog ideas\n",
      "üîç Starting analyst agent - scoring blog ideas...\n",
      "üìä Input status: ideas_generated\n",
      "üìä Found 5 blog ideas to score\n",
      "üìö Loading strategy context...\n",
      "‚úÖ Loaded company strategy (6555 chars)\n",
      "‚úÖ Loaded SEO strategy (1120 chars)\n",
      "‚úÖ Loaded content strategy (4469 chars)\n",
      "‚úÖ Enhanced strategy context for scoring with 3 documents\n",
      "   Company strategy: 6555 chars\n",
      "   SEO strategy: 1120 chars\n",
      "   Content strategy: 4469 chars\n",
      "üîç Scoring idea 1/5: From Local POC to Production: Scaling RAG Systems ...\n",
      "   ‚úÖ Scored: 42/70 points\n",
      "üîç Scoring idea 2/5: SharePoint + AI: Building Knowledge Access Systems...\n",
      "   ‚úÖ Scored: 37/70 points\n",
      "üîç Scoring idea 3/5: Vector Database Optimization: How to Scale from 12...\n",
      "   ‚úÖ Scored: 37/70 points\n",
      "üîç Scoring idea 4/5: The 2-Month AI Implementation Sprint: How to Deliv...\n",
      "   ‚úÖ Scored: 49/70 points\n",
      "üîç Scoring idea 5/5: Closing the Technical Expertise Gap: Building Inte...\n",
      "   ‚úÖ Scored: 49/70 points\n",
      "\n",
      "üéâ Analyst agent completed scoring!\n",
      "üìä Scored 5 ideas\n",
      "üèÜ Top idea: 'The 2-Month AI Implementation Sprint: How to Deliv...' (49/70)\n",
      "üìâ Lowest idea: 'Vector Database Optimization: How to Scale from 12...' (37/70)\n",
      "üíæ Starting database saver - saving scored blog ideas...\n",
      "üìä Found 5 scored ideas to save\n",
      "üîó Linking ideas to conversation_id: 34\n",
      "   ‚úÖ Saved idea 1: 'The 2-Month AI Implementation Sprint: How to Deliv...' (ID: 33)\n",
      "   ‚úÖ Saved idea 2: 'Closing the Technical Expertise Gap: Building Inte...' (ID: 34)\n",
      "   ‚úÖ Saved idea 3: 'From Local POC to Production: Scaling RAG Systems ...' (ID: 35)\n",
      "   ‚úÖ Saved idea 4: 'SharePoint + AI: Building Knowledge Access Systems...' (ID: 36)\n",
      "   ‚úÖ Saved idea 5: 'Vector Database Optimization: How to Scale from 12...' (ID: 37)\n",
      "\n",
      "üéâ Database saver completed!\n",
      "‚úÖ Successfully saved: 5 ideas\n",
      "\n",
      "ü§ù HITL SIMULATION: Paused for idea selection\n",
      "   Available Ideas (Saved IDs): [33, 34, 35, 36, 37]\n",
      "   Scored Ideas Preview: ['The 2-Month AI Implementation Sprint: How to Deliver Results Without Burning Out Your Team', 'Closing the Technical Expertise Gap: Building Internal AI Capability Without Hiring Specialists', 'From Local POC to Production: Scaling RAG Systems Without Breaking Your Architecture', 'SharePoint + AI: Building Knowledge Access Systems Your Team Actually Wants to Use', 'Vector Database Optimization: How to Scale from 12 Documents to 500+ Without Losing Your Mind']\n",
      "   ‚úÖ HITL Complete: Selected Idea ID 34\n",
      "üèÉ Resuming pipeline from HITL...\n",
      "HITL: Scored ideas: [{'title': 'The 2-Month AI Implementation Sprint: How to Deliver Results Without Burning Out Your Team', 'description': 'Explores realistic timelines for AI implementation projects, how to scope work effectively under deadline pressure, and strategies for maintaining team competence-building while hitting aggressive delivery dates. Includes a framework for prioritizing features and managing stakeholder expectations.', 'target_audience': 'Project managers and innovation leads at insurance, financial services, and regulated industries with tight implementation windows', 'content_angle': 'Combines project management wisdom with care-centered approach; acknowledges real-world pressure while advocating for sustainable practices', 'business_value': 'Differentiates Big Kids through human-centered approach; appeals to values-driven organizations tired of burnout culture', 'usefulness_potential': 8, 'fitwith_seo_strategy': 6, 'fitwith_content_strategy': 9, 'inspiration_potential': 8, 'collaboration_potential': 7, 'innovation': 6, 'difficulty': 5, 'reasoning': \"Strong alignment with core values (care, work smart not hard, human-centered approach) and content strategy's focus on sustainable GenAI adoption. Directly addresses real SME pain points in regulated industries. However, SEO fit is moderate‚Äîthe topic doesn't strongly target our high-value keywords (GenAI business applications, AI implementation risks, custom solutions). The 2-month sprint angle is somewhat commoditized in PM content. Innovation is solid but not groundbreaking. Difficulty is moderate due to need for credible frameworks and regulated industry nuance. High collaboration potential with project managers and innovation leads in target verticals who face real burnout pressures. Recommend strengthening GenAI-specific angles and tying more explicitly to business value/transformation outcomes to boost SEO and innovation scores.\", 'total_score': 49}, {'title': 'Closing the Technical Expertise Gap: Building Internal AI Capability Without Hiring Specialists', 'description': 'Addresses how organizations can upskill existing teams in RAG, vector databases, and API integration through strategic partnerships and structured learning. Covers knowledge transfer strategies, when to bring in external expertise, and how to build sustainable internal capability.', 'target_audience': 'HR leaders, CTOs, and innovation managers at companies lacking dedicated AI teams but committed to building internal expertise', 'content_angle': 'Feminist IT and care-centered approach to capability building; emphasizes interdependence between humans and tools', 'business_value': 'Positions Big Kids as a partner in transformation, not just a vendor; opens door to longer-term advisory relationships', 'usefulness_potential': 8, 'fitwith_seo_strategy': 7, 'fitwith_content_strategy': 9, 'inspiration_potential': 7, 'collaboration_potential': 8, 'innovation': 6, 'difficulty': 4, 'reasoning': \"Strong alignment with core mission of building healthier human-tech interdependence and care-centered transformation. Directly addresses SME pain point (expertise gap) with practical solutions. Fits long-tail keywords well ('how to implement AI in small business workflows', 'custom AI solutions vs SaaS'). Feminist IT + care angle differentiates from typical vendor content and positions Big Kids as thoughtful partner. Real conversation context (Natalia's RAG project) validates audience need. Slightly lower innovation score due to capability-building being explored elsewhere, but angle is fresh. Moderate difficulty‚Äîrequires balancing technical depth with accessibility. High collaboration potential through advisory positioning.\", 'total_score': 49}, {'title': 'From Local POC to Production: Scaling RAG Systems Without Breaking Your Architecture', 'description': 'A practical guide to transitioning retrieval-augmented generation systems from proof-of-concept environments to production-ready cloud deployments. Covers common scaling pitfalls, infrastructure planning, and how to maintain performance when moving from dozens to thousands of documents.', 'target_audience': 'Technical leads and IT managers at mid-market companies implementing AI solutions for the first time', 'content_angle': 'Real-world scaling challenges with step-by-step solutions based on actual client experiences', 'business_value': 'Positions Big Kids as experts in the messy middle of AI implementation; captures prospects stuck between POC and production', 'usefulness_potential': 8, 'fitwith_seo_strategy': 6, 'fitwith_content_strategy': 5, 'inspiration_potential': 6, 'collaboration_potential': 7, 'innovation': 7, 'difficulty': 3, 'reasoning': \"Strong usefulness for technical practitioners stuck in the POC-to-production gap, with real business value. However, the piece leans heavily technical/infrastructure-focused, which misses our core strategy of building healthier human-tech relationships and curiosity-driven exploration. The angle is pragmatic but lacks the 'care' and 'playfulness' that define Big Kids' voice. SEO fit is moderate‚Äîcaptures long-tail keywords like 'AI implementation risks' but doesn't address the broader 'why' questions our content strategy emphasizes (understanding, trust, comprehension). The conversation context suggests this resonates with real practitioners (Natalia's RAG POC), which is valuable. Consider repositioning to emphasize decision-making frameworks, team alignment, and organizational readiness alongside technical scaling‚Äîthis would strengthen alignment with our mission to help organizations develop better relationships with tech tools.\", 'total_score': 42}, {'title': 'SharePoint + AI: Building Knowledge Access Systems Your Team Actually Wants to Use', 'description': 'Explores how to integrate AI-powered document retrieval with existing SharePoint ecosystems to democratize knowledge access. Addresses the technical integration challenges and the human side of adoption for Go-to-Market teams and beyond.', 'target_audience': 'Operations managers and knowledge workers at enterprises with existing SharePoint investments', 'content_angle': 'Bridges technical implementation with user adoption; emphasizes accessibility and practical problem-solving', 'business_value': \"Targets high-intent prospects already using SharePoint; demonstrates Big Kids' understanding of real enterprise constraints\", 'usefulness_potential': 7, 'fitwith_seo_strategy': 5, 'fitwith_content_strategy': 6, 'inspiration_potential': 5, 'collaboration_potential': 7, 'innovation': 4, 'difficulty': 3, 'reasoning': \"This idea has solid enterprise appeal and lead generation potential, but misses key strategic opportunities. Strengths: Addresses real pain points (knowledge access, adoption), targets high-intent prospects with existing tech investments, and demonstrates practical expertise. Weaknesses: Targets enterprises rather than SMEs (our core focus per content strategy); doesn't align with long-tail keywords (how to implement AI in small business workflows, GenAI for SME efficiency); feels like standard enterprise integration content rather than exploring the human-tech relationship philosophy central to Big Kids' mission; lacks the curiosity and playfulness that defines our voice; doesn't educate on GenAI's transformative potential broadly. The SharePoint-specific angle is somewhat commoditized in the market. Consider repositioning to explore how small teams can build knowledge systems with GenAI, or how to evaluate whether SharePoint + AI is the right choice (emphasizing comprehension and trust in tool selection).\", 'total_score': 37}, {'title': 'Vector Database Optimization: How to Scale from 12 Documents to 500+ Without Losing Your Mind', 'description': 'A technical deep-dive into embedding strategies, vector database architecture decisions, and cost-effective scaling approaches. Includes decision trees for choosing between different optimization techniques and real benchmarks from similar scaling projects.', 'target_audience': 'Data engineers and technical architects evaluating AI infrastructure for growing document management needs', 'content_angle': \"Practical technical guidance with honest trade-offs; emphasizes 'work smart, not hard' philosophy\", 'business_value': 'Establishes thought leadership in AI infrastructure; attracts technically sophisticated prospects evaluating solutions', 'usefulness_potential': 7, 'fitwith_seo_strategy': 6, 'fitwith_content_strategy': 4, 'inspiration_potential': 5, 'collaboration_potential': 7, 'difficulty': 3, 'reasoning': \"This post has strong technical utility and will attract data engineers (high usefulness, collaboration potential), but misaligns significantly with Big Kids Automation's core strategy. The piece is highly specialized infrastructure content that doesn't advance the company's mission around 'healthier interdependence between humans and tech' or 'innovation rooted in real human needs.' It reads as pure technical optimization rather than exploring the relationship between humans and tools, care, or organizational transformation. While it targets the right technical audience and covers long-tail keywords ('vector database optimization' fits SME AI infrastructure needs), it lacks the playfulness, curiosity about human impact, and feminist IT perspective that define the brand voice. The 'work smart, not hard' angle is present but feels surface-level. Better suited for a pure DevOps/AI infrastructure publication than Big Kids' positioning as a transformation-focused agency. Consider repositioning to explore: 'How RAG Systems Change Knowledge Work' or 'Building AI Document Systems That Respect User Privacy' to better align with company values.\", 'total_score': 37}]\n",
      "Saved idea IDs: [33, 34, 35, 36, 37]\n",
      "‚úÖ Loaded company strategy (6555 chars)\n",
      "‚úÖ Loaded SEO strategy (1120 chars)\n",
      "‚úÖ Loaded content strategy (4469 chars)\n",
      "\n",
      "‚ùå COMPLETE PIPELINE FAILED WITH EXCEPTION:\n",
      "   name 'SystemMessage' is not defined\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_7195/2394546660.py\", line 75, in test_complete_8_node_pipeline\n",
      "    final_state = pipeline.invoke(None, config=config)  # None as input to resume\n",
      "  File \"/home/manuel/Documents/tech/ai_content_ops/.venv/lib/python3.13/site-packages/langgraph/pregel/main.py\", line 3026, in invoke\n",
      "    for chunk in self.stream(\n",
      "                 ~~~~~~~~~~~^\n",
      "        input,\n",
      "        ^^^^^^\n",
      "    ...<10 lines>...\n",
      "        **kwargs,\n",
      "        ^^^^^^^^^\n",
      "    ):\n",
      "    ^\n",
      "  File \"/home/manuel/Documents/tech/ai_content_ops/.venv/lib/python3.13/site-packages/langgraph/pregel/main.py\", line 2647, in stream\n",
      "    for _ in runner.tick(\n",
      "             ~~~~~~~~~~~^\n",
      "        [t for t in loop.tasks.values() if not t.writes],\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<2 lines>...\n",
      "        schedule_task=loop.accept_push,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ):\n",
      "    ^\n",
      "  File \"/home/manuel/Documents/tech/ai_content_ops/.venv/lib/python3.13/site-packages/langgraph/pregel/_runner.py\", line 162, in tick\n",
      "    run_with_retry(\n",
      "    ~~~~~~~~~~~~~~^\n",
      "        t,\n",
      "        ^^\n",
      "    ...<10 lines>...\n",
      "        },\n",
      "        ^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/home/manuel/Documents/tech/ai_content_ops/.venv/lib/python3.13/site-packages/langgraph/pregel/_retry.py\", line 42, in run_with_retry\n",
      "    return task.proc.invoke(task.input, config)\n",
      "           ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/manuel/Documents/tech/ai_content_ops/.venv/lib/python3.13/site-packages/langgraph/_internal/_runnable.py\", line 657, in invoke\n",
      "    input = context.run(step.invoke, input, config, **kwargs)\n",
      "  File \"/home/manuel/Documents/tech/ai_content_ops/.venv/lib/python3.13/site-packages/langgraph/_internal/_runnable.py\", line 401, in invoke\n",
      "    ret = self.func(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_7195/2434117898.py\", line 54, in planning_agent_node\n",
      "    plan = structured_llm.invoke([SystemMessage(content=formatted_instructions), HumanMessage(content=\"Generate the blog post plan.\")])\n",
      "                                  ^^^^^^^^^^^^^\n",
      "NameError: name 'SystemMessage' is not defined\n",
      "During task with name 'planning_agent' and id '3145167c-a886-b546-ac3c-40059b07fc5f'\n"
     ]
    }
   ],
   "source": [
    "# Uncomment the line below to run automatically, or run it manually\n",
    "test_result = test_complete_8_node_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "033bea0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ list_conversations() ready (standalone version)\n"
     ]
    }
   ],
   "source": [
    "# Cell: Simple list_conversations - No helper functions needed\n",
    "def list_conversations():\n",
    "    \"\"\"\n",
    "    List all conversations in the database\n",
    "    Simple version that works without helper functions\n",
    "    \"\"\"\n",
    "    \n",
    "    conversations = db.get_all_conversations()\n",
    "    \n",
    "    if not conversations:\n",
    "        print(\"‚ö†Ô∏è  No conversations found in database\")\n",
    "        return\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 100)\n",
    "    print(\"üí¨ ALL CONVERSATIONS IN DATABASE\")\n",
    "    print(\"=\" * 100)\n",
    "    \n",
    "    for conv in conversations:\n",
    "        # Handle both dict and Pydantic model\n",
    "        if isinstance(conv, dict):\n",
    "            conv_id = conv.get('id', 'Unknown')\n",
    "            title = conv.get('title', 'Untitled')\n",
    "            raw_text = conv.get('raw_text', '')\n",
    "            created = conv.get('created_at', 'Unknown')\n",
    "            word_count = conv.get('word_count', 0)\n",
    "        else:\n",
    "            # It's a Pydantic model - use model_dump()\n",
    "            data = conv.model_dump()\n",
    "            conv_id = data.get('id', 'Unknown')\n",
    "            title = data.get('title', 'Untitled')\n",
    "            raw_text = data.get('raw_text', '')\n",
    "            created = data.get('created_at', 'Unknown')\n",
    "            word_count = data.get('word_count', 0)\n",
    "        \n",
    "        transcript_len = len(raw_text) if raw_text else 0\n",
    "        \n",
    "        # Get idea count for this conversation\n",
    "        ideas = db.get_ideas_by_conversation(conv_id)\n",
    "        idea_count = len(ideas) if ideas else 0\n",
    "        \n",
    "        # Calculate average score if ideas exist\n",
    "        if ideas and idea_count > 0:\n",
    "            total_scores = []\n",
    "            for idea in ideas:\n",
    "                if isinstance(idea, dict):\n",
    "                    score = sum([\n",
    "                        idea.get('usefulness_potential', 0),\n",
    "                        idea.get('fitwith_seo_strategy', 0),\n",
    "                        idea.get('fitwith_content_strategy', 0),\n",
    "                        idea.get('inspiration_potential', 0),\n",
    "                        idea.get('collaboration_potential', 0),\n",
    "                        idea.get('innovation', 0),\n",
    "                        idea.get('difficulty', 0)\n",
    "                    ])\n",
    "                else:\n",
    "                    data = idea.model_dump() if hasattr(idea, 'model_dump') else idea.__dict__\n",
    "                    score = sum([\n",
    "                        data.get('usefulness_potential', 0),\n",
    "                        data.get('fitwith_seo_strategy', 0),\n",
    "                        data.get('fitwith_content_strategy', 0),\n",
    "                        data.get('inspiration_potential', 0),\n",
    "                        data.get('collaboration_potential', 0),\n",
    "                        data.get('innovation', 0),\n",
    "                        data.get('difficulty', 0)\n",
    "                    ])\n",
    "                total_scores.append(score)\n",
    "            \n",
    "            avg_score = sum(total_scores) / len(total_scores)\n",
    "            score_info = f\"Avg Score: {avg_score:.1f}/70\"\n",
    "        else:\n",
    "            score_info = \"No ideas yet\"\n",
    "        \n",
    "        print(f\"\\nüìÅ ID: {conv_id}\")\n",
    "        print(f\"   üìù Title: {title}\")\n",
    "        print(f\"   üìÑ Transcript: {transcript_len} chars ({word_count} words)\")\n",
    "        print(f\"   üí° Ideas: {idea_count} | {score_info}\")\n",
    "        print(f\"   üìÖ Created: {created}\")\n",
    "        print(f\"   üîç View: quick_view({conv_id})\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 100)\n",
    "    print(f\"üí° Total Conversations: {len(conversations)}\")\n",
    "    print(\"=\" * 100 + \"\\n\")\n",
    "\n",
    "print(\"‚úÖ list_conversations() ready (standalone version)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab25c7d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "üí¨ ALL CONVERSATIONS IN DATABASE\n",
      "====================================================================================================\n",
      "\n",
      "üìÅ ID: 33\n",
      "   üìù Title: Audio: blog_ecord (2025-12-01 19_47_21).wav\n",
      "   üìÑ Transcript: 4993 chars (908 words)\n",
      "   üí° Ideas: 5 | Avg Score: 44.2/70\n",
      "   üìÖ Created: 2025-12-01 19:18:25\n",
      "   üîç View: quick_view(33)\n",
      "\n",
      "üìÅ ID: 32\n",
      "   üìù Title: Audio: blog_record (2025-12-01 10_40_21).wav\n",
      "   üìÑ Transcript: 4469 chars (762 words)\n",
      "   üí° Ideas: 5 | Avg Score: 43.0/70\n",
      "   üìÖ Created: 2025-12-01 09:48:12\n",
      "   üîç View: quick_view(32)\n",
      "\n",
      "üìÅ ID: 31\n",
      "   üìù Title: Audio: blog_cord (2025-12-01 09_58_37).wav\n",
      "   üìÑ Transcript: 3133 chars (509 words)\n",
      "   üí° Ideas: 5 | Avg Score: 47.2/70\n",
      "   üìÖ Created: 2025-12-01 09:34:58\n",
      "   üîç View: quick_view(31)\n",
      "\n",
      "üìÅ ID: 30\n",
      "   üìù Title: Audio: blog_cord (2025-12-01 09_58_37).wav\n",
      "   üìÑ Transcript: 3133 chars (509 words)\n",
      "   üí° Ideas: 0 | No ideas yet\n",
      "   üìÖ Created: 2025-12-01 09:22:54\n",
      "   üîç View: quick_view(30)\n",
      "\n",
      "üìÅ ID: 29\n",
      "   üìù Title: Audio: blog_cord (2025-12-01 09_58_37).wav\n",
      "   üìÑ Transcript: 3133 chars (509 words)\n",
      "   üí° Ideas: 0 | No ideas yet\n",
      "   üìÖ Created: 2025-12-01 09:09:26\n",
      "   üîç View: quick_view(29)\n",
      "\n",
      "üìÅ ID: 28\n",
      "   üìù Title: Audio: blog_record_(purevitalize).wav\n",
      "   üìÑ Transcript: 1790 chars (298 words)\n",
      "   üí° Ideas: 5 | Avg Score: 46.4/70\n",
      "   üìÖ Created: 2025-11-28 09:02:37\n",
      "   üîç View: quick_view(28)\n",
      "\n",
      "üìÅ ID: 27\n",
      "   üìù Title: Audio: blog_record_(purevitalize).wav\n",
      "   üìÑ Transcript: 1790 chars (298 words)\n",
      "   üí° Ideas: 5 | Avg Score: 35.0/70\n",
      "   üìÖ Created: 2025-11-28 08:27:30\n",
      "   üîç View: quick_view(27)\n",
      "\n",
      "üìÅ ID: 26\n",
      "   üìù Title: Audio: blog_record_(purevitalize).wav\n",
      "   üìÑ Transcript: 1790 chars (298 words)\n",
      "   üí° Ideas: 5 | Avg Score: 35.0/70\n",
      "   üìÖ Created: 2025-11-27 09:11:49\n",
      "   üîç View: quick_view(26)\n",
      "\n",
      "üìÅ ID: 25\n",
      "   üìù Title: Audio: blog_record_(purevitalize).wav\n",
      "   üìÑ Transcript: 1790 chars (298 words)\n",
      "   üí° Ideas: 0 | No ideas yet\n",
      "   üìÖ Created: 2025-11-26 09:11:52\n",
      "   üîç View: quick_view(25)\n",
      "\n",
      "üìÅ ID: 24\n",
      "   üìù Title: Audio: blog_record_(purevitalize).wav\n",
      "   üìÑ Transcript: 1790 chars (298 words)\n",
      "   üí° Ideas: 0 | No ideas yet\n",
      "   üìÖ Created: 2025-11-21 09:58:56\n",
      "   üîç View: quick_view(24)\n",
      "\n",
      "üìÅ ID: 23\n",
      "   üìù Title: Audio: blog_record_(purevitalize).wav\n",
      "   üìÑ Transcript: 1790 chars (298 words)\n",
      "   üí° Ideas: 0 | No ideas yet\n",
      "   üìÖ Created: 2025-11-19 09:23:31\n",
      "   üîç View: quick_view(23)\n",
      "\n",
      "üìÅ ID: 22\n",
      "   üìù Title: Audio: blog_record_(purevitalize).wav\n",
      "   üìÑ Transcript: 1790 chars (298 words)\n",
      "   üí° Ideas: 0 | No ideas yet\n",
      "   üìÖ Created: 2025-11-19 09:22:11\n",
      "   üîç View: quick_view(22)\n",
      "\n",
      "üìÅ ID: 21\n",
      "   üìù Title: Audio: blog_record_(purevitalize).wav\n",
      "   üìÑ Transcript: 1790 chars (298 words)\n",
      "   üí° Ideas: 0 | No ideas yet\n",
      "   üìÖ Created: 2025-11-19 09:21:18\n",
      "   üîç View: quick_view(21)\n",
      "\n",
      "üìÅ ID: 20\n",
      "   üìù Title: Audio: blog_record_(purevitalize).wav\n",
      "   üìÑ Transcript: 1790 chars (298 words)\n",
      "   üí° Ideas: 0 | No ideas yet\n",
      "   üìÖ Created: 2025-11-17 08:54:02\n",
      "   üîç View: quick_view(20)\n",
      "\n",
      "üìÅ ID: 19\n",
      "   üìù Title: Audio: blog_record_(purevitalize).wav\n",
      "   üìÑ Transcript: 1790 chars (298 words)\n",
      "   üí° Ideas: 0 | No ideas yet\n",
      "   üìÖ Created: 2025-11-17 08:49:22\n",
      "   üîç View: quick_view(19)\n",
      "\n",
      "====================================================================================================\n",
      "üí° Total Conversations: 15\n",
      "====================================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Or just list them first\n",
    "list_conversations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "603ff83b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Terminal dashboard ready (using db.get_all_ideas and db.get_ideas_by_conversation)\n"
     ]
    }
   ],
   "source": [
    "# Cell: Terminal Dashboard - Using Existing DB Methods\n",
    "def show_ideas_dashboard(conversation_id=None, top_n=10):\n",
    "    \"\"\"\n",
    "    Beautiful terminal dashboard showing scored blog ideas\n",
    "    Uses existing db.get_all_ideas() or db.get_ideas_by_conversation()\n",
    "    \n",
    "    Args:\n",
    "        conversation_id: Show ideas for specific conversation (None = all ideas)\n",
    "        top_n: Number of top ideas to show\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 100)\n",
    "    print(\"üìä BLOG IDEAS DASHBOARD\")\n",
    "    print(\"=\" * 100)\n",
    "    \n",
    "    # Get ideas using existing methods\n",
    "    if conversation_id:\n",
    "        ideas = db.get_ideas_by_conversation(conversation_id)\n",
    "        print(f\"üìÅ Showing ideas from Conversation ID: {conversation_id}\")\n",
    "    else:\n",
    "        ideas = db.get_all_ideas()\n",
    "        print(f\"üìÅ Showing ALL ideas from database\")\n",
    "    \n",
    "    if not ideas:\n",
    "        print(\"‚ö†Ô∏è  No ideas found in database\")\n",
    "        return\n",
    "    \n",
    "    # Calculate scores and sort\n",
    "    scored_ideas = []\n",
    "    for idea in ideas:\n",
    "        # Handle both dict and object formats\n",
    "        if isinstance(idea, dict):\n",
    "            total = sum([\n",
    "                idea.get('usefulness_potential', 0),\n",
    "                idea.get('fitwith_seo_strategy', 0),\n",
    "                idea.get('fitwith_content_strategy', 0),\n",
    "                idea.get('inspiration_potential', 0),\n",
    "                idea.get('collaboration_potential', 0),\n",
    "                idea.get('innovation', 0),\n",
    "                idea.get('difficulty', 0)\n",
    "            ])\n",
    "        else:\n",
    "            total = sum([\n",
    "                idea.usefulness_potential,\n",
    "                idea.fitwith_seo_strategy,\n",
    "                idea.fitwith_content_strategy,\n",
    "                idea.inspiration_potential,\n",
    "                idea.collaboration_potential,\n",
    "                idea.innovation,\n",
    "                idea.difficulty\n",
    "            ])\n",
    "        scored_ideas.append((idea, total))\n",
    "    \n",
    "    # Sort by total score (highest first)\n",
    "    scored_ideas.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Show summary stats\n",
    "    all_scores = [s[1] for s in scored_ideas]\n",
    "    avg_score = sum(all_scores) / len(all_scores)\n",
    "    \n",
    "    print(f\"\\nüìà SUMMARY STATISTICS\")\n",
    "    print(f\"   Total Ideas: {len(scored_ideas)}\")\n",
    "    print(f\"   Average Score: {avg_score:.1f}/70 ({avg_score/70*100:.1f}%)\")\n",
    "    print(f\"   Highest Score: {scored_ideas[0][1]}/70 ({scored_ideas[0][1]/70*100:.1f}%)\")\n",
    "    print(f\"   Lowest Score: {scored_ideas[-1][1]}/70 ({scored_ideas[-1][1]/70*100:.1f}%)\")\n",
    "    \n",
    "    # Show score distribution\n",
    "    high_scores = sum(1 for s in all_scores if s >= 60)\n",
    "    medium_scores = sum(1 for s in all_scores if 50 <= s < 60)\n",
    "    low_scores = sum(1 for s in all_scores if s < 50)\n",
    "    \n",
    "    print(f\"\\nüìä SCORE DISTRIBUTION\")\n",
    "    print(f\"   üü¢ High (60-70):  {high_scores} ideas ({high_scores/len(all_scores)*100:.1f}%)\")\n",
    "    print(f\"   üü° Medium (50-59): {medium_scores} ideas ({medium_scores/len(all_scores)*100:.1f}%)\")\n",
    "    print(f\"   üî¥ Low (<50):     {low_scores} ideas ({low_scores/len(all_scores)*100:.1f}%)\")\n",
    "    \n",
    "    # Show top ideas\n",
    "    display_count = min(top_n, len(scored_ideas))\n",
    "    print(f\"\\nüèÜ TOP {display_count} IDEAS\")\n",
    "    print(\"-\" * 100)\n",
    "    \n",
    "    for rank, (idea, total_score) in enumerate(scored_ideas[:top_n], 1):\n",
    "        # Handle both dict and object formats\n",
    "        if isinstance(idea, dict):\n",
    "            idea_id = idea.get('id')\n",
    "            title = idea.get('title', 'Untitled')\n",
    "            usefulness = idea.get('usefulness_potential', 0)\n",
    "            seo = idea.get('fitwith_seo_strategy', 0)\n",
    "            content = idea.get('fitwith_content_strategy', 0)\n",
    "            inspiration = idea.get('inspiration_potential', 0)\n",
    "            collaboration = idea.get('collaboration_potential', 0)\n",
    "            innovation = idea.get('innovation', 0)\n",
    "            difficulty = idea.get('difficulty', 0)\n",
    "            created_at = idea.get('created_at', 'Unknown')\n",
    "            conv_id = idea.get('conversation_id', 'N/A')\n",
    "            sent_to_prod = idea.get('sent_to_prod', False)\n",
    "        else:\n",
    "            idea_id = idea.id\n",
    "            title = idea.title\n",
    "            usefulness = idea.usefulness_potential\n",
    "            seo = idea.fitwith_seo_strategy\n",
    "            content = idea.fitwith_content_strategy\n",
    "            inspiration = idea.inspiration_potential\n",
    "            collaboration = idea.collaboration_potential\n",
    "            innovation = idea.innovation\n",
    "            difficulty = idea.difficulty\n",
    "            created_at = idea.created_at\n",
    "            conv_id = idea.conversation_id\n",
    "            sent_to_prod = idea.sent_to_prod\n",
    "        \n",
    "        # Create score bar\n",
    "        bar_length = 35\n",
    "        percentage = total_score / 70\n",
    "        filled = int(percentage * bar_length)\n",
    "        bar = \"‚ñà\" * filled + \"‚ñë\" * (bar_length - filled)\n",
    "        \n",
    "        # Medal emoji for top 3\n",
    "        medal = {1: \"ü•á\", 2: \"ü•à\", 3: \"ü•â\"}.get(rank, f\"{rank:2d}.\")\n",
    "        \n",
    "        # Color indicator based on score\n",
    "        if total_score >= 60:\n",
    "            indicator = \"üü¢\"  # High score\n",
    "        elif total_score >= 50:\n",
    "            indicator = \"üü°\"  # Medium score\n",
    "        else:\n",
    "            indicator = \"üî¥\"  # Low score\n",
    "        \n",
    "        print(f\"\\n{medal} {indicator} ID: {idea_id} | Score: {total_score}/70 ({percentage*100:.1f}%)\")\n",
    "        print(f\"   üìù {title}\")\n",
    "        print(f\"   üìä [{bar}] {total_score}/70\")\n",
    "        print(f\"   üí° Breakdown:\")\n",
    "        print(f\"      ‚Ä¢ Usefulness: {usefulness}/10 | SEO Fit: {seo}/10 | Content Fit: {content}/10\")\n",
    "        print(f\"      ‚Ä¢ Inspiration: {inspiration}/10 | Collaboration: {collaboration}/10\")\n",
    "        print(f\"      ‚Ä¢ Innovation: {innovation}/10 | Difficulty (ease): {difficulty}/10\")\n",
    "        print(f\"   üìÖ Created: {created_at}\")\n",
    "        print(f\"   üîó Conversation: {conv_id}\")\n",
    "        \n",
    "        if sent_to_prod:\n",
    "            print(f\"   ‚úÖ STATUS: SENT TO PRODUCTION\")\n",
    "        else:\n",
    "            print(f\"   üìù STATUS: Draft\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 100)\n",
    "    print(\"üí° USAGE TIPS:\")\n",
    "    print(\"   show_ideas_dashboard()              # Show all ideas\")\n",
    "    print(\"   show_ideas_dashboard(28)            # Show ideas from conversation 28\")\n",
    "    print(\"   show_ideas_dashboard(28, top_n=3)   # Show top 3 ideas only\")\n",
    "    print(\"=\" * 100 + \"\\n\")\n",
    "\n",
    "print(\"‚úÖ Terminal dashboard ready (using db.get_all_ideas and db.get_ideas_by_conversation)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e004553b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Quick view function ready\n"
     ]
    }
   ],
   "source": [
    "# Cell: Quick View - Compact Dashboard\n",
    "def quick_view(conversation_id=None):\n",
    "    \"\"\"Quick compact view of scored ideas\"\"\"\n",
    "    \n",
    "    ideas = db.get_ideas_by_conversation(conversation_id) if conversation_id else db.get_all_ideas()\n",
    "    \n",
    "    if not ideas:\n",
    "        print(\"‚ö†Ô∏è  No ideas found\")\n",
    "        return\n",
    "    \n",
    "    # Score and sort\n",
    "    scored = []\n",
    "    for idea in ideas:\n",
    "        if isinstance(idea, dict):\n",
    "            total = sum([idea.get('usefulness_potential', 0), idea.get('fitwith_seo_strategy', 0),\n",
    "                        idea.get('fitwith_content_strategy', 0), idea.get('inspiration_potential', 0),\n",
    "                        idea.get('collaboration_potential', 0), idea.get('innovation', 0), idea.get('difficulty', 0)])\n",
    "            scored.append((idea, total))\n",
    "        else:\n",
    "            total = sum([idea.usefulness_potential, idea.fitwith_seo_strategy, idea.fitwith_content_strategy,\n",
    "                        idea.inspiration_potential, idea.collaboration_potential, idea.innovation, idea.difficulty])\n",
    "            scored.append((idea, total))\n",
    "    \n",
    "    scored.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    print(f\"\\n{'='*100}\")\n",
    "    print(f\"üìä {'CONVERSATION ' + str(conversation_id) if conversation_id else 'ALL IDEAS'} | Total: {len(scored)} ideas | Avg: {sum(s[1] for s in scored)/len(scored):.1f}/70\")\n",
    "    print(f\"{'='*100}\\n\")\n",
    "    \n",
    "    for rank, (idea, score) in enumerate(scored, 1):\n",
    "        if isinstance(idea, dict):\n",
    "            idea_id, title = idea.get('id'), idea.get('title', 'Untitled')\n",
    "        else:\n",
    "            idea_id, title = idea.id, idea.title\n",
    "        \n",
    "        medal = {1: \"ü•á\", 2: \"ü•à\", 3: \"ü•â\"}.get(rank, f\"{rank:2d}.\")\n",
    "        indicator = \"üü¢\" if score >= 60 else \"üü°\" if score >= 50 else \"üî¥\"\n",
    "        \n",
    "        print(f\"{medal} {indicator} [{idea_id:3d}] {score:2d}/70 | {title[:75]}\")\n",
    "    \n",
    "    print(f\"\\n{'='*100}\\n\")\n",
    "\n",
    "print(\"‚úÖ Quick view function ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e508f9ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Test 1: Full dashboard for conversation 33\n",
      "\n",
      "====================================================================================================\n",
      "üìä BLOG IDEAS DASHBOARD\n",
      "====================================================================================================\n",
      "üìÅ Showing ideas from Conversation ID: 33\n",
      "\n",
      "üìà SUMMARY STATISTICS\n",
      "   Total Ideas: 5\n",
      "   Average Score: 44.2/70 (63.1%)\n",
      "   Highest Score: 51/70 (72.9%)\n",
      "   Lowest Score: 40/70 (57.1%)\n",
      "\n",
      "üìä SCORE DISTRIBUTION\n",
      "   üü¢ High (60-70):  0 ideas (0.0%)\n",
      "   üü° Medium (50-59): 1 ideas (20.0%)\n",
      "   üî¥ Low (<50):     4 ideas (80.0%)\n",
      "\n",
      "üèÜ TOP 5 IDEAS\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "ü•á üü° ID: 28 | Score: 51/70 (72.9%)\n",
      "   üìù Human-Centered AI: Why Your Team's Growth Matters More Than Your Technology Stack\n",
      "   üìä [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 51/70\n",
      "   üí° Breakdown:\n",
      "      ‚Ä¢ Usefulness: 7/10 | SEO Fit: 5/10 | Content Fit: 9/10\n",
      "      ‚Ä¢ Inspiration: 8/10 | Collaboration: 8/10\n",
      "      ‚Ä¢ Innovation: 8/10 | Difficulty (ease): 6/10\n",
      "   üìÖ Created: 2025-12-01 19:19:06\n",
      "   üîó Conversation: 33\n",
      "   üìù STATUS: Draft\n",
      "\n",
      "ü•à üî¥ ID: 29 | Score: 45/70 (64.3%)\n",
      "   üìù AI Implementation in 60 Days: How to Deliver Proof of Concept Without Sacrificing Quality\n",
      "   üìä [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 45/70\n",
      "   üí° Breakdown:\n",
      "      ‚Ä¢ Usefulness: 8/10 | SEO Fit: 8/10 | Content Fit: 5/10\n",
      "      ‚Ä¢ Inspiration: 6/10 | Collaboration: 8/10\n",
      "      ‚Ä¢ Innovation: 6/10 | Difficulty (ease): 4/10\n",
      "   üìÖ Created: 2025-12-01 19:19:06\n",
      "   üîó Conversation: 33\n",
      "   üìù STATUS: Draft\n",
      "\n",
      "ü•â üî¥ ID: 30 | Score: 43/70 (61.4%)\n",
      "   üìù From Local POC to Production: A Practical Guide to Scaling AI Document Retrieval Systems\n",
      "   üìä [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 43/70\n",
      "   üí° Breakdown:\n",
      "      ‚Ä¢ Usefulness: 8/10 | SEO Fit: 7/10 | Content Fit: 5/10\n",
      "      ‚Ä¢ Inspiration: 6/10 | Collaboration: 8/10\n",
      "      ‚Ä¢ Innovation: 6/10 | Difficulty (ease): 3/10\n",
      "   üìÖ Created: 2025-12-01 19:19:06\n",
      "   üîó Conversation: 33\n",
      "   üìù STATUS: Draft\n",
      "\n",
      " 4. üî¥ ID: 31 | Score: 42/70 (60.0%)\n",
      "   üìù Bridging the SharePoint API Gap: How to Build Technical Confidence When Implementing Enterprise AI\n",
      "   üìä [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 42/70\n",
      "   üí° Breakdown:\n",
      "      ‚Ä¢ Usefulness: 8/10 | SEO Fit: 6/10 | Content Fit: 7/10\n",
      "      ‚Ä¢ Inspiration: 5/10 | Collaboration: 8/10\n",
      "      ‚Ä¢ Innovation: 5/10 | Difficulty (ease): 3/10\n",
      "   üìÖ Created: 2025-12-01 19:19:06\n",
      "   üîó Conversation: 33\n",
      "   üìù STATUS: Draft\n",
      "\n",
      " 5. üî¥ ID: 32 | Score: 40/70 (57.1%)\n",
      "   üìù The Hidden Cost of Manual Document Search: Why Your Marketing Team Needs AI-Powered Knowledge Access\n",
      "   üìä [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 40/70\n",
      "   üí° Breakdown:\n",
      "      ‚Ä¢ Usefulness: 7/10 | SEO Fit: 8/10 | Content Fit: 5/10\n",
      "      ‚Ä¢ Inspiration: 6/10 | Collaboration: 7/10\n",
      "      ‚Ä¢ Innovation: 4/10 | Difficulty (ease): 3/10\n",
      "   üìÖ Created: 2025-12-01 19:19:06\n",
      "   üîó Conversation: 33\n",
      "   üìù STATUS: Draft\n",
      "\n",
      "====================================================================================================\n",
      "üí° USAGE TIPS:\n",
      "   show_ideas_dashboard()              # Show all ideas\n",
      "   show_ideas_dashboard(28)            # Show ideas from conversation 28\n",
      "   show_ideas_dashboard(28, top_n=3)   # Show top 3 ideas only\n",
      "====================================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test 1: Full dashboard for conversation 28\n",
    "print(\"üß™ Test 1: Full dashboard for conversation 33\")\n",
    "show_ideas_dashboard(33)\n",
    "\n",
    "# Test 2: Quick view for all ideas\n",
    "#print(\"\\nüß™ Test 2: Quick view for all ideas\")\n",
    "#quick_view()\n",
    "\n",
    "# Test 3: Quick view for conversation 33\n",
    "#print(\"\\nüß™ Test 3: Quick view for conversation 33\")\n",
    "#quick_view(33)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
