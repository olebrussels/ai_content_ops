{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb001904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AssemblyAI API Key loaded: ‚úÖ\n",
      "Key starts with: 972365f41d...\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Setup and Imports\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Add project root to Python path\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv(project_root / '.env')\n",
    "\n",
    "# Test API key\n",
    "assemblyai_key = os.getenv('ASSEMBLYAI_API_KEY')\n",
    "print(f\"AssemblyAI API Key loaded: {'‚úÖ' if assemblyai_key else '‚ùå'}\")\n",
    "print(f\"Key starts with: {assemblyai_key[:10] if assemblyai_key else 'None'}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30f9e880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All imports successful\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Import Dependencies\n",
    "import assemblyai as aai\n",
    "from langgraph.graph import StateGraph\n",
    "from typing import TypedDict, Optional, List  # ‚Üê Added List here\n",
    "import glob\n",
    "import time\n",
    "from pathlib import Path  # ‚Üê Also added Path here\n",
    "\n",
    "# Import our database\n",
    "from database.db_operations import db\n",
    "from database.models import ConversationCreate\n",
    "\n",
    "print(\"‚úÖ All imports successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e30147df",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. Pydantic Model for Structured Output\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Optional\n",
    "from enum import Enum\n",
    "\n",
    "class SpeakerRole(str, Enum):\n",
    "    \"\"\"Possible speaker roles in the conversation\"\"\"\n",
    "    CLIENT = \"client\"\n",
    "    INTERVIEWER = \"interviewer\"\n",
    "\n",
    "class Speaker(BaseModel):\n",
    "    \"\"\"Information about a person speaking in the conversation\"\"\"\n",
    "    name: Optional[str] = Field(default=None, description=\"Name of the speaker if mentioned\")\n",
    "    role: Optional[SpeakerRole] = Field(default=None, description=\"Role of the speaker in the conversation\")\n",
    "    company: Optional[str] = Field(default=None, description=\"Company they work for if mentioned\")\n",
    "\n",
    "class Challenge(BaseModel):\n",
    "    \"\"\"A challenge or problem mentioned in the conversation\"\"\"\n",
    "    description: Optional[str] = Field(default=None, description=\"Description of the challenge\")\n",
    "    impact: Optional[str] = Field(default=None, description=\"How this challenge affects them\")\n",
    "    urgency: Optional[str] = Field(default=None, description=\"Low, Medium, or High urgency\")\n",
    "\n",
    "class CurrentSolution(BaseModel):\n",
    "    \"\"\"How they currently solve their problems\"\"\"\n",
    "    solution: Optional[str] = Field(default=None, description=\"What they're currently doing\")\n",
    "    satisfaction_level: Optional[str] = Field(default=None, description=\"How satisfied they are: Very Satisfied, Satisfied, Neutral, Unsatisfied, Very Unsatisfied\")\n",
    "    limitations: Optional[List[str]] = Field(default=[], description=\"Limitations of current solution\")\n",
    "\n",
    "class Need(BaseModel):\n",
    "    \"\"\"A need identified using psychology frameworks like NVC\"\"\"\n",
    "    need_category: Optional[str] = Field(default=None, description=\"Category of need (e.g., autonomy, efficiency, security, connection)\")\n",
    "    description: Optional[str] = Field(default=None, description=\"Specific need description\")\n",
    "    intensity: Optional[str] = Field(default=None, description=\"Low, Medium, or High intensity\")\n",
    "\n",
    "class ExtractedInsights(BaseModel):\n",
    "    \"\"\"Complete structured output from conversation analysis\"\"\"\n",
    "    \n",
    "    # Speakers\n",
    "    speakers: Optional[List[Speaker]] = Field(default=[], description=\"People identified in the conversation\")\n",
    "    \n",
    "    # What they care about\n",
    "    core_values: Optional[List[str]] = Field(default=[], description=\"What this person/company cares about most\")\n",
    "    priorities: Optional[List[str]] = Field(default=[], description=\"Their current priorities and focus areas\")\n",
    "    \n",
    "    # Challenges\n",
    "    primary_challenges: Optional[List[Challenge]] = Field(default=[], description=\"Main problems they're facing\")\n",
    "    secondary_challenges: Optional[List[Challenge]] = Field(default=[], description=\"Secondary or related problems\")\n",
    "    \n",
    "    # Current solutions\n",
    "    current_solutions: Optional[List[CurrentSolution]] = Field(default=[], description=\"How they solve problems today\")\n",
    "    \n",
    "    # Needs analysis\n",
    "    psychological_needs: Optional[List[Need]] = Field(default=[], description=\"Underlying needs using NVC or similar frameworks\")\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19fad4ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ State defined\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Define LangGraph State\n",
    "class AudioPipelineState(TypedDict):\n",
    "    file_path: str\n",
    "    filename: str\n",
    "    transcript_text: Optional[str]\n",
    "    conversation_id: Optional[int]\n",
    "    extracted_insights: Optional[ExtractedInsights]  # ‚Üê NEW: Using our Pydantic model\n",
    "    error: Optional[str]\n",
    "    status: str\n",
    "\n",
    "print(\"‚úÖ State defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5cabeaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ AssemblyAI connection successful\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 4: Test AssemblyAI Connection\n",
    "# Configure AssemblyAI\n",
    "aai.settings.api_key = os.getenv('ASSEMBLYAI_API_KEY')\n",
    "\n",
    "# Test with a simple transcription (we'll use a file from temp folder)\n",
    "def test_assemblyai_connection():\n",
    "    \"\"\"Test if AssemblyAI is working\"\"\"\n",
    "    try:\n",
    "        # Just test the API key is valid\n",
    "        transcriber = aai.Transcriber()\n",
    "        print(\"‚úÖ AssemblyAI connection successful\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå AssemblyAI connection failed: {e}\")\n",
    "        return False\n",
    "\n",
    "test_assemblyai_connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01335e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå No audio files found in temp folder!\n",
      "\n",
      "üí° TIP: Add .wav files to data/temp/ folder for testing\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Batch File Discovery and Management\n",
    "def find_audio_files(temp_folder: Path) -> List[Path]:\n",
    "    \"\"\"Find all audio files in temp folder\"\"\"\n",
    "    audio_extensions = ['*.wav', '*.mp3', '*.m4a']\n",
    "    audio_files = []\n",
    "    \n",
    "    for ext in audio_extensions:\n",
    "        audio_files.extend(temp_folder.glob(ext))\n",
    "    \n",
    "    return sorted(audio_files)\n",
    "\n",
    "def display_batch_info(audio_files: List[Path]):\n",
    "    \"\"\"Display information about the batch of files\"\"\"\n",
    "    if not audio_files:\n",
    "        print(\"‚ùå No audio files found in temp folder!\")\n",
    "        return False\n",
    "    \n",
    "    total_size_mb = sum(f.stat().st_size for f in audio_files) / (1024 * 1024)\n",
    "    \n",
    "    print(f\"üìä BATCH PROCESSING INFO:\")\n",
    "    print(f\"   Files to process: {len(audio_files)}\")\n",
    "    print(f\"   Total size: {total_size_mb:.1f} MB\")\n",
    "    print(f\"\\nüìÅ Files found:\")\n",
    "    \n",
    "    for i, file_path in enumerate(audio_files, 1):\n",
    "        size_mb = file_path.stat().st_size / (1024 * 1024)\n",
    "        print(f\"   {i}. {file_path.name} ({size_mb:.1f} MB)\")\n",
    "    \n",
    "    return True\n",
    "\n",
    "def cleanup_processed_files(processed_files: List[Path]):\n",
    "    \"\"\"Delete all successfully processed files\"\"\"\n",
    "    print(f\"\\nüóëÔ∏è CLEANUP: Deleting {len(processed_files)} processed files...\")\n",
    "    deleted_count = 0\n",
    "    \n",
    "    for file_path in processed_files:\n",
    "        try:\n",
    "            file_path.unlink()  # Delete file\n",
    "            print(f\"   ‚úÖ Deleted: {file_path.name}\")\n",
    "            deleted_count += 1\n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå Failed to delete {file_path.name}: {e}\")\n",
    "    \n",
    "    print(f\"üóëÔ∏è Cleanup complete: {deleted_count}/{len(processed_files)} files deleted\")\n",
    "\n",
    "# Discover files in temp folder\n",
    "temp_folder = project_root / 'data' / 'temp'\n",
    "temp_folder.mkdir(parents=True, exist_ok=True)  # Ensure folder exists\n",
    "\n",
    "audio_files = find_audio_files(temp_folder)\n",
    "files_available = display_batch_info(audio_files)\n",
    "\n",
    "if files_available:\n",
    "    print(f\"\\nüöÄ Ready to process {len(audio_files)} files!\")\n",
    "else:\n",
    "    print(\"\\nüí° TIP: Add .wav files to data/temp/ folder for testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "419ae62d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ LangGraph nodes defined\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Define LangGraph Nodes\n",
    "def transcription_node(state: AudioPipelineState) -> AudioPipelineState:\n",
    "    \"\"\"Node 1: Transcribe audio file with AssemblyAI\"\"\"\n",
    "    try:\n",
    "        print(f\"üéôÔ∏è Transcribing: {state['filename']}\")\n",
    "        \n",
    "        # Configure transcriber\n",
    "        transcriber = aai.Transcriber()\n",
    "        \n",
    "        # Transcribe the file\n",
    "        transcript = transcriber.transcribe(state['file_path'])\n",
    "        \n",
    "        if transcript.status == aai.TranscriptStatus.error:\n",
    "            return {\n",
    "                **state,\n",
    "                \"error\": f\"AssemblyAI error: {transcript.error}\",\n",
    "                \"status\": \"transcription_failed\"\n",
    "            }\n",
    "        \n",
    "        return {\n",
    "            **state,\n",
    "            \"transcript_text\": transcript.text,\n",
    "            \"status\": \"transcribed\"\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            **state,\n",
    "            \"error\": f\"Transcription error: {str(e)}\",\n",
    "            \"status\": \"transcription_failed\"\n",
    "        }\n",
    "\n",
    "def database_saver_node(state: AudioPipelineState) -> AudioPipelineState:\n",
    "    \"\"\"Node 2: Save transcript to database\"\"\"\n",
    "    try:\n",
    "        print(f\"üíæ Saving to database: {state['filename']}\")\n",
    "        \n",
    "        # Create conversation object\n",
    "        conversation = ConversationCreate(\n",
    "            title=f\"Audio: {state['filename']}\",\n",
    "            raw_text=state['transcript_text'],\n",
    "            source=\"transcribed\"\n",
    "        )\n",
    "        \n",
    "        # Save to database\n",
    "        conversation_id = db.create_conversation(conversation)\n",
    "        \n",
    "        return {\n",
    "            **state,\n",
    "            \"conversation_id\": conversation_id,\n",
    "            \"status\": \"completed\"\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            **state,\n",
    "            \"error\": f\"Database error: {str(e)}\",\n",
    "            \"status\": \"database_failed\"\n",
    "        }\n",
    "\n",
    "print(\"‚úÖ LangGraph nodes defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0cd719a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Checking/creating database...\n",
      "Creating database at: data/app.db\n",
      "‚úÖ Database schema created successfully!\n",
      "‚úÖ Created tables: ['conversations', 'sqlite_sequence', 'blog_post_ideas', 'processing_status']\n",
      "‚úÖ Database ready!\n",
      "üìä Available tables: ['conversations', 'sqlite_sequence', 'blog_post_ideas', 'processing_status']\n"
     ]
    }
   ],
   "source": [
    "# Cell: Initialize Database\n",
    "from database.init_db import create_database\n",
    "\n",
    "print(\"üîß Checking/creating database...\")\n",
    "try:\n",
    "    create_database()\n",
    "    print(\"‚úÖ Database ready!\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Database error: {e}\")\n",
    "\n",
    "# Verify tables exist\n",
    "import sqlite3\n",
    "conn = sqlite3.connect('data/app.db')\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "tables = cursor.fetchall()\n",
    "print(f\"üìä Available tables: {[table[0] for table in tables]}\")\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c379c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ LangGraph pipeline compiled and ready\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Build LangGraph Workflow\n",
    "def build_pipeline():\n",
    "    \"\"\"Build the LangGraph workflow\"\"\"\n",
    "    workflow = StateGraph(AudioPipelineState)\n",
    "    \n",
    "    # Add nodes\n",
    "    workflow.add_node(\"transcribe\", transcription_node)\n",
    "    workflow.add_node(\"save_to_db\", database_saver_node)\n",
    "    \n",
    "    # Add edges\n",
    "    workflow.add_edge(\"transcribe\", \"save_to_db\")\n",
    "    workflow.set_entry_point(\"transcribe\")\n",
    "    workflow.set_finish_point(\"save_to_db\")\n",
    "    \n",
    "    return workflow.compile()\n",
    "\n",
    "# Build the pipeline\n",
    "pipeline = build_pipeline()\n",
    "print(\"‚úÖ LangGraph pipeline compiled and ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "078aae2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Batch processing function ready\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Batch Processing Function\n",
    "def process_audio_batch(audio_files: List[Path], pipeline) -> dict:\n",
    "    \"\"\"Process all audio files in batch\"\"\"\n",
    "    \n",
    "    if not audio_files:\n",
    "        print(\"‚ùå No files to process\")\n",
    "        return {\"processed\": [], \"failed\": [], \"total\": 0}\n",
    "    \n",
    "    print(f\"\\nüöÄ STARTING BATCH PROCESSING - {len(audio_files)} files\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    processed_files = []\n",
    "    failed_files = []\n",
    "    results = []\n",
    "    \n",
    "    for i, file_path in enumerate(audio_files, 1):\n",
    "        print(f\"\\nüìÇ Processing {i}/{len(audio_files)}: {file_path.name}\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        # Create initial state\n",
    "        initial_state = {\n",
    "            \"file_path\": str(file_path),\n",
    "            \"filename\": file_path.name,\n",
    "            \"transcript_text\": None,\n",
    "            \"conversation_id\": None,\n",
    "            \"error\": None,\n",
    "            \"status\": \"processing\"\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            # Run through pipeline\n",
    "            result = pipeline.invoke(initial_state)\n",
    "            \n",
    "            if result[\"status\"] == \"completed\":\n",
    "                print(f\"‚úÖ SUCCESS: {file_path.name}\")\n",
    "                print(f\"   Conversation ID: {result['conversation_id']}\")\n",
    "                print(f\"   Transcript preview: {result['transcript_text'][:100]}...\")\n",
    "                processed_files.append(file_path)\n",
    "            else:\n",
    "                print(f\"‚ùå FAILED: {file_path.name}\")\n",
    "                print(f\"   Error: {result.get('error', 'Unknown error')}\")\n",
    "                failed_files.append(file_path)\n",
    "            \n",
    "            results.append(result)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå PIPELINE ERROR: {file_path.name}\")\n",
    "            print(f\"   Exception: {str(e)}\")\n",
    "            failed_files.append(file_path)\n",
    "            \n",
    "            results.append({\n",
    "                **initial_state,\n",
    "                \"error\": str(e),\n",
    "                \"status\": \"pipeline_error\"\n",
    "            })\n",
    "    \n",
    "    return {\n",
    "        \"processed\": processed_files,\n",
    "        \"failed\": failed_files,\n",
    "        \"total\": len(audio_files),\n",
    "        \"results\": results\n",
    "    }\n",
    "\n",
    "print(\"‚úÖ Batch processing function ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4cb00a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üí° Add audio files to data/temp/ folder and rerun this cell\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: Execute Batch Processing with Cleanup\n",
    "if files_available:\n",
    "    print(\"üéØ Starting batch processing...\")\n",
    "    \n",
    "    # Process all files\n",
    "    batch_results = process_audio_batch(audio_files, pipeline)\n",
    "    \n",
    "    # Display summary\n",
    "    print(f\"\\nüìä BATCH PROCESSING COMPLETE!\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"‚úÖ Successfully processed: {len(batch_results['processed'])}\")\n",
    "    print(f\"‚ùå Failed: {len(batch_results['failed'])}\")\n",
    "    print(f\"üìÅ Total files: {batch_results['total']}\")\n",
    "    \n",
    "    # Show failed files\n",
    "    if batch_results['failed']:\n",
    "        print(f\"\\n‚ùå Failed files:\")\n",
    "        for file_path in batch_results['failed']:\n",
    "            print(f\"   - {file_path.name}\")\n",
    "    \n",
    "    # Cleanup successfully processed files\n",
    "    if batch_results['processed']:\n",
    "        confirm = input(f\"\\nüóëÔ∏è Delete {len(batch_results['processed'])} processed files? (y/N): \")\n",
    "        if confirm.lower() in ['y', 'yes']:\n",
    "            cleanup_processed_files(batch_results['processed'])\n",
    "        else:\n",
    "            print(\"üîß Files kept in temp folder for inspection\")\n",
    "    \n",
    "    print(\"\\nüéâ Batch processing complete!\")\n",
    "    \n",
    "else:\n",
    "    print(\"üí° Add audio files to data/temp/ folder and rerun this cell\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d95b79d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Recent Conversations (showing 4):\n",
      "------------------------------------------------------------\n",
      "ID: 4 | Title: Audio: blog_batxhtwo.wav\n",
      "Source: transcribed | Words: 4 | Status: pending\n",
      "Created: 2025-09-24 08:20:07\n",
      "Preview: Testing batch process into....\n",
      "------------------------------------------------------------\n",
      "ID: 3 | Title: Audio: blog_batchone.wav\n",
      "Source: transcribed | Words: 4 | Status: pending\n",
      "Created: 2025-09-24 08:20:02\n",
      "Preview: Testing batch processing one....\n",
      "------------------------------------------------------------\n",
      "ID: 2 | Title: Audio: blog_barchthreee.wav\n",
      "Source: transcribed | Words: 5 | Status: pending\n",
      "Created: 2025-09-24 08:19:57\n",
      "Preview: Testing batch processing number three....\n",
      "------------------------------------------------------------\n",
      "ID: 1 | Title: Audio: blog_recordcomtines.wav\n",
      "Source: transcribed | Words: 30 | Status: pending\n",
      "Created: 2025-09-24 07:48:54\n",
      "Preview: I'm uploading a file from my telephone, and the idea is that this file is going to be monitored and moved to the temporary file in the AI ContentOps f...\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Cell 10: View Results in Database\n",
    "def show_recent_conversations(limit=10):\n",
    "    \"\"\"Display recent conversations from database\"\"\"\n",
    "    conversations = db.get_all_conversations()\n",
    "    \n",
    "    if not conversations:\n",
    "        print(\"üìù No conversations found in database\")\n",
    "        return\n",
    "    \n",
    "    print(f\"üìù Recent Conversations (showing {min(limit, len(conversations))}):\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    for conv in conversations[:limit]:\n",
    "        print(f\"ID: {conv.id} | Title: {conv.title}\")\n",
    "        print(f\"Source: {conv.source} | Words: {conv.word_count} | Status: {conv.status}\")\n",
    "        print(f\"Created: {conv.created_at}\")\n",
    "        print(f\"Preview: {conv.raw_text[:150]}...\")\n",
    "        print(\"-\" * 60)\n",
    "\n",
    "# Show results\n",
    "show_recent_conversations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eeaef0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Anthropic LLM initialized\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Setup Anthropic LLM for Insights Extraction\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "import json\n",
    "\n",
    "# Initialize Anthropic (you'll need ANTHROPIC_API_KEY in your .env)\n",
    "anthropic_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "if not anthropic_key:\n",
    "    print(\"‚ö†Ô∏è  ANTHROPIC_API_KEY not found in .env file\")\n",
    "    print(\"Please add: ANTHROPIC_API_KEY=your_key_here\")\n",
    "else:\n",
    "    llm = ChatAnthropic(\n",
    "        model=\"claude-3-sonnet-20240229\",\n",
    "        api_key=anthropic_key,\n",
    "        temperature=0.1\n",
    "    )\n",
    "    print(\"‚úÖ Anthropic LLM initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b3cea20",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3. PainExtractor Node Implementation\n",
    "\n",
    "\n",
    "import openai\n",
    "import json\n",
    "from typing import Dict, Any\n",
    "\n",
    "# System prompt\n",
    "PAIN_EXTRACTOR_SYSTEM_PROMPT = \"\"\"\n",
    "You are a UX researcher and business analyst for BigKids Automation. Your job is listening to transcripts from interviews with users and potential clients. \n",
    "\n",
    "You pay special attention to problems that users have regarding how their company is automating, using web apps and AI to save time and move towards a more ethical and sovereign tech infrastructure.\n",
    "\n",
    "You will be given the transcript of an interview with a user or potential client.\n",
    "\n",
    "Your task is to extract structured information about:\n",
    "- Who is speaking and their role\n",
    "- What this person cares about (values, priorities)\n",
    "- Their main primary and secondary challenges\n",
    "- How they are solving problems today\n",
    "- Their underlying psychological needs (using frameworks like NVC - Non-Violent Communication)\n",
    "\n",
    "Focus on automation, web apps, AI, time-saving, ethical tech, and sovereign infrastructure themes.\n",
    "\n",
    "Be thorough but concise. \n",
    "\n",
    "IMPORTANT: Only extract information that is explicitly mentioned in the transcript. \n",
    "If information is not clearly stated, leave the field empty/null rather than guessing or inferring.\n",
    "Do not hallucinate or make assumptions about missing information.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "819a4829",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_insights_from_transcript(transcript_text: str, model=\"gpt-4o-2024-08-06\", temperature=0) -> ExtractedInsights:\n",
    "    \"\"\"\n",
    "    Extract structured insights from conversation transcript using OpenAI structured output\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = client.beta.chat.completions.parse(\n",
    "            model=model,\n",
    "            temperature=temperature,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": PAIN_EXTRACTOR_SYSTEM_PROMPT},\n",
    "                {\"role\": \"user\", \"content\": transcript_text},\n",
    "            ],\n",
    "            response_format=ExtractedInsights\n",
    "        )\n",
    "        \n",
    "        return response.choices[0].message.parsed\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error extracting insights: {e}\")\n",
    "        return None\n",
    "\n",
    "def pain_extractor_node(state: AudioPipelineState) -> AudioPipelineState:\n",
    "    \"\"\"\n",
    "    LangGraph node: Extract structured insights from conversation transcript\n",
    "    \"\"\"\n",
    "    print(\"üß† Starting pain extraction...\")\n",
    "    \n",
    "    try:\n",
    "        # Extract insights using OpenAI structured output\n",
    "        insights = extract_insights_from_transcript(state['transcript_text'])\n",
    "        \n",
    "        if insights:\n",
    "            print(f\"‚úÖ Extracted insights: {len(insights.primary_challenges)} primary challenges, {len(insights.speakers)} speakers\")\n",
    "            \n",
    "            return {\n",
    "                **state,\n",
    "                \"extracted_insights\": insights,\n",
    "                \"status\": \"insights_extracted\"\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                **state,\n",
    "                \"error\": \"Failed to extract insights from transcript\",\n",
    "                \"status\": \"error\"\n",
    "            }\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Pain extraction failed: {e}\")\n",
    "        return {\n",
    "            **state,\n",
    "            \"error\": f\"Pain extraction error: {str(e)}\",\n",
    "            \"status\": \"error\"\n",
    "        }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "205a8b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† Starting pain extraction...\n",
      "‚úÖ Extracted insights: 1 primary challenges, 1 speakers\n",
      "üéØ Extracted Insights:\n",
      "Speakers: ['John']\n",
      "Primary challenges: 1\n"
     ]
    }
   ],
   "source": [
    "## 4. Usage in Jupyter Notebook\n",
    "\n",
    "\n",
    "# Cell: Test Pain Extractor Node\n",
    "from openai import OpenAI\n",
    "\n",
    "# Initialize OpenAI client\n",
    "client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))\n",
    "\n",
    "# Test with sample transcript\n",
    "test_state = {\n",
    "    \"file_path\": \"data/temp/test.wav\",\n",
    "    \"filename\": \"test.wav\",\n",
    "    \"transcript_text\": \"Hi, I'm John from TechCorp. We're struggling with our manual processes. We spend hours every day on data entry and it's killing our productivity. We've tried some automation tools but they don't integrate well with our existing systems. What we really need is something that respects our data sovereignty and doesn't lock us into big tech platforms.\",\n",
    "    \"conversation_id\": 1,\n",
    "    \"extracted_insights\": None,\n",
    "    \"blog_ideas\": None,\n",
    "    \"error\": None,\n",
    "    \"status\": \"transcribed\"\n",
    "}\n",
    "\n",
    "# Run the pain extractor node\n",
    "result_state = pain_extractor_node(test_state)\n",
    "\n",
    "# Display results\n",
    "if result_state.get('extracted_insights'):\n",
    "    insights = result_state['extracted_insights']\n",
    "    print(\"üéØ Extracted Insights:\")\n",
    "    print(f\"Speakers: {[s.name for s in insights.speakers]}\")\n",
    "    print(f\"Primary challenges: {len(insights.primary_challenges)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "19d6e1ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Testing extract_insights_from_transcript...\n",
      "üìù Sample transcript: \n",
      "    Client: We're really struggling with our website performance. \n",
      "    It takes forever to load, es...\n",
      "‚úÖ Function executed successfully!\n",
      "\n",
      "üìä Extracted Insights:\n",
      "Speakers found: 2\n",
      "Primary challenges: 1\n",
      "Core values: None\n",
      "\n",
      "üî• First challenge:\n",
      "   Description: Website performance issues, especially on mobile devices.\n",
      "   Impact: Customers are complaining and the company is losing sales.\n",
      "   Urgency: High\n"
     ]
    }
   ],
   "source": [
    "# Cell 8A: Test extract_insights_from_transcript function\n",
    "def test_extract_insights_standalone():\n",
    "    \"\"\"Test the insight extraction function with sample transcript\"\"\"\n",
    "    \n",
    "    # Sample transcript for testing\n",
    "    sample_transcript = \"\"\"\n",
    "    Client: We're really struggling with our website performance. \n",
    "    It takes forever to load, especially on mobile devices. \n",
    "    Our customers are complaining and we're losing sales.\n",
    "    \n",
    "    Interviewer: What have you tried so far?\n",
    "    \n",
    "    Client: We hired a developer last year but they only made small improvements. \n",
    "    We're still not satisfied. The site crashes during peak hours and \n",
    "    our checkout process is confusing. We need something that actually works.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"üß™ Testing extract_insights_from_transcript...\")\n",
    "    print(f\"üìù Sample transcript: {sample_transcript[:100]}...\")\n",
    "    \n",
    "    try:\n",
    "        # Call your function\n",
    "        insights = extract_insights_from_transcript(sample_transcript)\n",
    "        \n",
    "        print(\"‚úÖ Function executed successfully!\")\n",
    "        print(\"\\nüìä Extracted Insights:\")\n",
    "        print(f\"Speakers found: {len(insights.speakers)}\")\n",
    "        print(f\"Primary challenges: {len(insights.primary_challenges)}\")\n",
    "        print(f\"Core values: {insights.core_values}\")\n",
    "        \n",
    "        # Print first challenge as example\n",
    "        if insights.primary_challenges:\n",
    "            challenge = insights.primary_challenges[0]\n",
    "            print(f\"\\nüî• First challenge:\")\n",
    "            print(f\"   Description: {challenge.description}\")\n",
    "            print(f\"   Impact: {challenge.impact}\")\n",
    "            print(f\"   Urgency: {challenge.urgency}\")\n",
    "            \n",
    "        return True, insights\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error in extract_insights_from_transcript: {e}\")\n",
    "        return False, None\n",
    "\n",
    "# Run the test\n",
    "success, test_insights = test_extract_insights_standalone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f2b8adac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Testing pain_extractor_node...\n",
      "üìù Mock state status: saved_to_db\n",
      "üß† Starting pain extraction...\n",
      "‚úÖ Extracted insights: 1 primary challenges, 1 speakers\n",
      "‚úÖ Node executed successfully!\n",
      "üìä Updated status: insights_extracted\n",
      "üîç Has insights: True\n",
      "\n",
      "üìã Insights Summary:\n",
      "   Speakers: 1\n",
      "   Primary challenges: 1\n",
      "   Current solutions: 0\n"
     ]
    }
   ],
   "source": [
    "# Cell 8B: Test pain_extractor_node with mock state\n",
    "def test_pain_extractor_node():\n",
    "    \"\"\"Test the LangGraph node with mock state\"\"\"\n",
    "    \n",
    "    # Create mock state (as if it came from previous nodes)\n",
    "    mock_state = {\n",
    "        \"file_path\": \"data/temp/test_file.wav\",\n",
    "        \"filename\": \"test_file.wav\", \n",
    "        \"transcript_text\": \"\"\"\n",
    "        Client: Our main problem is slow website loading times. \n",
    "        We're losing customers because of it. Also, our mobile app \n",
    "        keeps crashing and the user interface is confusing.\n",
    "        \"\"\",\n",
    "        \"conversation_id\": 99,  # Mock ID\n",
    "        \"extracted_insights\": None,\n",
    "        \"status\": \"saved_to_db\",\n",
    "        \"error\": None\n",
    "    }\n",
    "    \n",
    "    print(\"üß™ Testing pain_extractor_node...\")\n",
    "    print(f\"üìù Mock state status: {mock_state['status']}\")\n",
    "    \n",
    "    try:\n",
    "        # Call your node function\n",
    "        updated_state = pain_extractor_node(mock_state)\n",
    "        \n",
    "        print(\"‚úÖ Node executed successfully!\")\n",
    "        print(f\"üìä Updated status: {updated_state['status']}\")\n",
    "        print(f\"üîç Has insights: {'extracted_insights' in updated_state and updated_state['extracted_insights'] is not None}\")\n",
    "        \n",
    "        # Show extracted insights\n",
    "        if updated_state.get('extracted_insights'):\n",
    "            insights = updated_state['extracted_insights']\n",
    "            print(f\"\\nüìã Insights Summary:\")\n",
    "            print(f\"   Speakers: {len(insights.speakers) if insights.speakers else 0}\")\n",
    "            print(f\"   Primary challenges: {len(insights.primary_challenges) if insights.primary_challenges else 0}\")\n",
    "            print(f\"   Current solutions: {len(insights.current_solutions) if insights.current_solutions else 0}\")\n",
    "        \n",
    "        return True, updated_state\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error in pain_extractor_node: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return False, None\n",
    "\n",
    "# Run the test\n",
    "node_success, updated_state = test_pain_extractor_node()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cdfa5408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéâ Both functions work! Ready for integration.\n",
      "\n",
      "üîÑ Testing with real conversation: Audio: blog_batxhtwo.wav\n",
      "üß† Starting pain extraction...\n",
      "‚ùå Pain extraction failed: object of type 'NoneType' has no len()\n",
      "‚úÖ Real data test: error\n"
     ]
    }
   ],
   "source": [
    "# Cell 8C: Test integration (only run if previous tests pass)\n",
    "if success and node_success:\n",
    "    print(\"üéâ Both functions work! Ready for integration.\")\n",
    "    \n",
    "    # Test with real conversation from database\n",
    "    conversations = db.get_all_conversations()\n",
    "    if conversations:\n",
    "        real_conv = conversations[0]\n",
    "        print(f\"\\nüîÑ Testing with real conversation: {real_conv.title}\")\n",
    "        \n",
    "        real_state = {\n",
    "            \"conversation_id\": real_conv.id,\n",
    "            \"transcript_text\": real_conv.raw_text,\n",
    "            \"status\": \"saved_to_db\"\n",
    "        }\n",
    "        \n",
    "        final_result = pain_extractor_node(real_state)\n",
    "        print(f\"‚úÖ Real data test: {final_result['status']}\")\n",
    "    else:\n",
    "        print(\"‚ÑπÔ∏è No conversations in database for real data test\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Fix the failing tests before integration\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
